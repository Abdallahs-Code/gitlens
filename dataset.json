[
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jonas_kotlin_android\",\"seniority\":\"Mid\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\"],\"tech\":[\"Jetpack Compose\",\"Retrofit\"],\"databases\":[\"SQLite\"],\"testing\":[\"JUnit\"]}\n\nJob Summary:\nE-commerce app startup hiring a mid-level Android engineer. Kotlin is the language. Jetpack Compose is our UI framework. We use Retrofit for API calls. Firebase handles authentication and crash reporting. Fastlane manages release automation. JUnit and Mockito are the testing stack. Experience with the Play Store release process is preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin is the primary language — exact match\",\"Jetpack Compose aligns with the UI framework requirement\",\"Retrofit satisfies the API integration expectation\",\"JUnit covers part of the testing requirement\"],\"gaps\":[\"No Firebase experience for authentication and crash reporting\",\"No Fastlane experience for release automation\",\"No Mockito for mocking in unit tests\",\"No Play Store release experience signaled in profile\"],\"explanation\":\"The candidate has solid core Android development skills with Kotlin and Jetpack Compose but is missing several operational tools the company relies on, including Firebase, Fastlane, and Mockito. These are learnable but represent meaningful gaps in the current profile, particularly for a team that expects release process ownership.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"aisha_infra_eng\",\"seniority\":\"Mid\",\"roles\":[\"Infrastructure Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Terraform\",\"Ansible\",\"Docker\",\"Vault\"],\"architecture\":[\"Cloud-Native\"],\"ci_cd\":[\"GitLab CI\",\"GitHub Actions\"]}\n\nJob Summary:\nB2B software company looking for an infrastructure engineer to automate cloud provisioning on AWS. Terraform is the IaC tool. Ansible handles configuration management. HashiCorp Vault manages secrets. Docker for containerization. Kubernetes is on the roadmap and experience is preferred. Python and Bash scripting required. GitLab CI is the CI platform.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform covers the IaC requirement\",\"Ansible satisfies the configuration management expectation\",\"HashiCorp Vault for secrets management is an exact match\",\"Docker covers containerization\",\"Python and Bash scripting aligns with automation requirements\",\"GitLab CI matches the CI platform\"],\"gaps\":[\"No Kubernetes experience — on the roadmap and preferred by the company\",\"No AWS-specific tooling signaled in the profile\"],\"explanation\":\"The candidate covers the current infrastructure toolchain well, with particularly strong alignment on Terraform, Ansible, and Vault. However, the absence of Kubernetes experience is a relevant gap given the company's stated roadmap, and the lack of visible AWS-specific experience adds some uncertainty for an AWS-focused role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"grace_junior_ios\",\"seniority\":\"Junior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"UIKit\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nProptech startup building a home search iOS app. Swift is the primary language. We use both SwiftUI and UIKit across the codebase as we migrate to SwiftUI. GitHub Actions runs our CI. The role is collaborative with senior iOS engineers who will mentor junior developers. Experience with REST API integration via URLSession is expected. Testing with XCTest is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Swift is the primary language — exact match\",\"Both SwiftUI and UIKit are present, which is explicitly important during their migration\",\"GitHub Actions aligns with CI expectations\"],\"gaps\":[\"No XCTest experience listed for unit and UI testing\",\"No explicit REST API or URLSession integration experience signaled\"],\"explanation\":\"The candidate's Swift, SwiftUI, and UIKit experience aligns well with this role's core requirements, and the mixed UIKit and SwiftUI background is particularly relevant during the migration period. However, the absence of XCTest and REST API integration experience leaves two stated requirements uncovered, making this a moderate rather than strong match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ingrid_sveltekit\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"SvelteKit\",\"Svelte\",\"Tailwind CSS\",\"Vite\"],\"ci_cd\":[\"GitHub Actions\",\"Netlify\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nContent platform startup building editorial tools for journalists. We use SvelteKit for our frontend and Tailwind CSS for styling. Vite is our build tool. Vitest handles unit tests and Playwright handles end-to-end testing. The app is deployed via Netlify. TypeScript is required across the codebase. We move quickly and value engineers who can ship independently.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SvelteKit and Svelte match the primary frontend framework exactly\",\"Tailwind CSS and Vite align with the styling and build requirements\",\"Vitest and Playwright cover the full testing stack\",\"Netlify matches the deployment platform\",\"TypeScript is required and is the candidate's primary language\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a precise match for every technical requirement in the job description. SvelteKit, Tailwind, Vite, Vitest, Playwright, and Netlify are all present. Their mid-level seniority and TypeScript proficiency support independent shipping expectations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"omar_data_eng\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"Apache Airflow\",\"dbt\",\"Pandas\",\"Docker\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"Snowflake\",\"PostgreSQL\",\"BigQuery\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nData platform team at a retail analytics company. We are hiring a senior data engineer to own our Snowflake data warehouse, build dbt models, and manage Airflow DAGs for ingestion pipelines. Python is the primary scripting language. We are migrating some workloads to BigQuery so familiarity there is a plus. Engineers are expected to follow software engineering best practices including version control and CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Snowflake and dbt are the two primary data platform tools and both are present\",\"Airflow DAG authoring matches the ingestion pipeline requirement\",\"Python is the stated primary scripting language\",\"BigQuery familiarity is a stated plus and is listed in the profile\",\"GitHub Actions satisfies the CI and version control best practices expectation\"],\"gaps\":[],\"explanation\":\"The candidate's profile matches the job description at every key data engineering checkpoint — warehouse, transformation, orchestration, and language. Their BigQuery experience is an added bonus given the planned migration. There are no notable gaps for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"james_excel_analyst\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\"],\"tech\":[\"Tableau\",\"Power BI\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nAI research company hiring a mid-level ML engineer to build transformer-based models with PyTorch. The role involves fine-tuning LLMs using Hugging Face Transformers, running distributed training jobs with CUDA, and deploying models as Docker containers on Kubernetes. MLflow manages the experiment lifecycle. Python is essential. Experience with vector databases like Pinecone is preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"No Python \\u2014 the essential language for the role\",\"No PyTorch, Hugging Face, or any ML framework\",\"No Docker or Kubernetes for model deployment\",\"No MLflow, CUDA, or vector database experience\",\"BI analyst background does not transfer to ML engineering\"],\"explanation\":\"The candidate is a business intelligence analyst with SQL and visualization tooling expertise, which has no meaningful overlap with a machine learning engineering role requiring PyTorch, Hugging Face, CUDA, and Kubernetes. Every technical requirement for this position is absent from their profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"freddie_cicd\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"Jenkins\",\"Ansible\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"]}\n\nJob Summary:\nFinancial services firm seeking a DevOps engineer to maintain and modernize legacy CI/CD pipelines. Jenkins is the current CI server. GitHub Actions is being introduced as a replacement. Ansible handles server configuration. Docker for containerization. The team is not yet on Kubernetes. Python or Bash scripting is required for pipeline automation. No cloud experience required for this role.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Jenkins is the current CI server and is present\",\"GitHub Actions is the incoming CI platform and is listed\",\"Ansible aligns with the server configuration management requirement\",\"Docker covers containerization\",\"Python and Bash scripting satisfies the automation requirement\"],\"gaps\":[\"No observability or monitoring tooling visible in profile\",\"Profile is relatively sparse with limited depth beyond core CI tools\"],\"explanation\":\"The candidate is a functional match for the immediate scope of this role. They cover Jenkins, GitHub Actions, Ansible, and Docker, which are the stated tools. The profile is sparse however, and the absence of any observability, security, or infrastructure-as-code tooling may limit their growth potential in a financial services environment that often demands broader platform capabilities.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elena_data_analyst\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Tableau\",\"dbt\",\"Pandas\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nRetail analytics team at a large enterprise hiring a mid-level analytics engineer. We build and maintain dbt models on top of BigQuery. SQL is the core skill. Tableau is used for business intelligence reporting. Python and Pandas are used for ad hoc analysis. Engineers are expected to version-control their dbt models with Git and run CI checks via GitHub Actions.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt and BigQuery are the primary data platform tools — both present\",\"SQL is the core skill and the candidate's top language\",\"Tableau matches the BI reporting tool\",\"Python and Pandas cover the ad hoc analysis requirement\",\"GitHub Actions satisfies the CI check expectation for dbt\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a precise fit for an analytics engineering role. Every tool and language in the job description is represented in their profile. Their mid-level seniority aligns with the stated expectation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"victor_embedded\",\"seniority\":\"Senior\",\"roles\":[\"Embedded Engineer\"],\"languages\":[\"C\",\"C++\",\"Rust\"],\"tech\":[\"CUDA\",\"CMake\"],\"architecture\":[\"Distributed System\"]}\n\nJob Summary:\nAI hardware startup hiring a senior machine learning engineer focused on Python-based model training and Hugging Face integrations. The role involves building RAG pipelines with LangChain, managing MLflow experiments, and deploying models as Docker containers on Kubernetes. Strong Python skills are essential. Experience with vector databases such as Pinecone or ChromaDB is preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"CUDA experience is tangentially relevant to GPU-accelerated ML workloads\"],\"gaps\":[\"No Python in profile — the primary language for the role\",\"No Hugging Face, LangChain, or MLflow experience\",\"No Docker or Kubernetes experience for model deployment\",\"No vector database experience\",\"Embedded and systems engineering background does not transfer directly to ML engineering\"],\"explanation\":\"Despite working at an AI hardware company, this candidate's profile is focused on embedded systems and low-level programming, not Python-based ML engineering. The toolchain required — Hugging Face, LangChain, MLflow, and vector databases — is entirely absent. CUDA knowledge is a minor tangential signal but insufficient to bridge the gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"luca_frontend_it\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"Firebase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Cypress\"]}\n\nJob Summary:\nDigital agency hiring a mid-level React engineer to join a client delivery team. Strong TypeScript skills required. We use Next.js for most client projects, with Tailwind CSS for styling. Testing is handled with Jest and Playwright. Familiarity with CI via GitHub Actions is expected. The team moves fast across multiple client engagements so adaptability is important.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Strong TypeScript background matches the core language requirement\",\"Tailwind CSS experience directly applies\",\"GitHub Actions CI familiarity aligns\",\"Cypress testing experience is partially transferable to Playwright\"],\"gaps\":[\"Vue.js and Nuxt.js experience rather than React and Next.js, which are the agency's primary frameworks\",\"No Jest experience — uses Vitest instead\",\"Playwright not listed; only Cypress\"],\"explanation\":\"The candidate has solid frontend fundamentals and the right language skills but is primarily a Vue ecosystem developer in a React-first role. Tailwind and CI tooling align, but the framework mismatch is meaningful for a fast-moving client delivery team where ramp-up time on Next.js and the testing stack could slow early contributions.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tom_wordpress_dev\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"WordPress\",\"Bootstrap\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nFintech startup building a real-time trading platform. We use Go for backend services and React with TypeScript on the frontend. The data layer uses PostgreSQL and Redis. Kafka powers our event streaming. Kubernetes manages our infrastructure. Engineers are expected to have experience with high-throughput distributed systems and low-latency API design. Strong computer science fundamentals required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Full stack profile provides general web development context\"],\"gaps\":[\"No Go experience — primary backend language\",\"No React or TypeScript — primary frontend stack\",\"No PostgreSQL or Redis — only MySQL\",\"No Kafka or event streaming experience\",\"No Kubernetes or containerization experience\",\"PHP and WordPress background is oriented toward content management, not high-throughput systems\"],\"explanation\":\"The candidate's background in PHP and WordPress development does not translate to the fintech trading platform's technical requirements. Go, React, Kafka, and Kubernetes are all absent from their profile. The low-latency distributed systems context is a significant departure from content management tooling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sarah_fullstack_us\",\"seniority\":\"Junior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Express.js\",\"Docker\"],\"databases\":[\"MongoDB\",\"PostgreSQL\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nSeed-stage startup building a MERN stack application. React and Express.js are the primary technologies. MongoDB is the database. TypeScript is used on both frontend and backend. Jest for testing. The team is two engineers so everyone ships features end-to-end. Junior candidates are welcome if they show strong fundamentals and initiative.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Express.js match the MERN stack exactly\",\"MongoDB is the primary database and is listed\",\"TypeScript is required and present\",\"Jest satisfies the testing requirement\",\"Docker demonstrates infrastructure awareness\"],\"gaps\":[\"Junior seniority means the candidate may need guidance in a two-engineer team where senior oversight is limited\",\"No signal of full-stack TypeScript backend experience — primarily JavaScript-first\"],\"explanation\":\"The candidate's technical stack is a solid match for a MERN application, covering React, Express.js, MongoDB, and Jest. However, the two-engineer team dynamic means junior candidates need to be highly self-sufficient, which is a risk factor. The TypeScript backend experience is not well-signaled beyond its presence in the languages list.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"aarav_nestjs\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"Prisma\",\"Docker\",\"BullMQ\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nEdtech startup hiring a mid-level backend engineer for a Node.js platform. We use NestJS as our API framework and Prisma as our ORM over PostgreSQL. BullMQ handles async job queues with Redis. Jest and Supertest are our testing tools. GitHub Actions manages CI. Docker is used for containerization. TypeScript is required across the backend.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS is the API framework — exact match\",\"Prisma ORM over PostgreSQL aligns precisely\",\"BullMQ and Redis cover the async job queue requirement exactly\",\"Jest and Supertest match the testing tooling\",\"GitHub Actions satisfies CI requirements\",\"TypeScript is required and is the primary language\"],\"gaps\":[],\"explanation\":\"This candidate's profile aligns with every detail in the job description. NestJS, Prisma, BullMQ, and the full testing stack are all present. The TypeScript-first backend approach is consistent across both the candidate and the job.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priya_devops_99\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\",\"Go\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"Docker\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitLab CI\",\"Argo CD\"]}\n\nJob Summary:\nEnterprise SaaS company seeking a senior DevOps engineer to manage our multi-cluster Kubernetes environment on AWS. Experience with Helm, Terraform, and Argo CD for GitOps workflows is required. We use Prometheus and Grafana for observability. Engineers must be comfortable writing infrastructure-as-code and automating platform operations in Bash or Python. Cloud-native architecture experience is strongly preferred.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes and Helm directly match the multi-cluster management requirement\",\"Terraform covers infrastructure-as-code expectations\",\"Argo CD aligns with the GitOps workflow requirement\",\"Prometheus and Grafana match the observability stack\",\"Bash and Python satisfy the automation scripting requirement\",\"Cloud-native architecture experience is explicitly preferred and present\"],\"gaps\":[\"Profile shows GitLab CI rather than a specific AWS-native CI tool — minor consideration given Argo CD is already present\"],\"explanation\":\"The candidate's profile is a strong match for this role with direct experience across every major technical area. Their cloud-native and microservices background complements the Kubernetes-centric environment well. The only minor observation is GitLab CI versus AWS-native tooling, which is unlikely to be a barrier given their overall infrastructure expertise.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kwame_react_mid\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Redux\",\"Tailwind CSS\",\"Vite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"React Testing Library\"]}\n\nJob Summary:\nFinancial dashboard startup using React with Zustand for state management. TypeScript required. Tailwind CSS for styling. Vite as build tool. Playwright for end-to-end testing. React Testing Library for component tests. Vercel for deployment. GitHub Actions for CI. The team is small and values engineers who write thorough end-to-end tests.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and TypeScript match the primary stack\",\"Tailwind CSS and Vite align with styling and build tools\",\"React Testing Library covers component testing requirements\",\"GitHub Actions satisfies CI expectations\"],\"gaps\":[\"Uses Redux rather than Zustand \\u2014 different state management approach\",\"No Playwright experience \\u2014 end-to-end testing is highly valued by the team\",\"No Vercel deployment experience\"],\"explanation\":\"The candidate is a good day-to-day frontend match but has two meaningful gaps for this team: they use Redux rather than Zustand, and they lack Playwright experience despite end-to-end testing being a stated priority. React Testing Library is present but the missing Playwright coverage is a real gap for a team that values thorough e2e tests.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priya_mlops_jr\",\"seniority\":\"Junior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"Docker\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAI startup hiring a junior ML engineer to support the model training team. Python is required. scikit-learn and Pandas for classical ML and data manipulation. MLflow for experiment tracking. Docker for containerization. GitHub Actions for CI. PyTorch experience is a plus as the team is expanding into deep learning. Mentorship is provided for strong candidates.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python is required and present\",\"scikit-learn and Pandas match the classical ML and data tools\",\"Docker and GitHub Actions satisfy containerization and CI\",\"Junior seniority is appropriate with mentorship provided\"],\"gaps\":[\"No MLflow for experiment tracking \\u2014 a stated requirement\",\"No PyTorch experience \\u2014 listed as a plus for deep learning expansion\"],\"explanation\":\"The candidate covers the foundational requirements well and the junior level is explicitly accommodated with mentorship. However, the absence of MLflow is a gap in a stated requirement, and the lack of PyTorch may limit contribution as the team grows into deep learning. They are a viable hire with some ramp-up needed on MLflow.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"raj_platform\",\"seniority\":\"Lead\",\"roles\":[\"Platform Engineer\",\"DevOps Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Docker\",\"Prometheus\",\"Grafana\",\"Consul\"],\"architecture\":[\"Cloud-Native\",\"Microservices\",\"Service Mesh\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"Argo CD\",\"GitLab CI\",\"GitHub Actions\"]}\n\nJob Summary:\nScaleup hiring a lead platform engineer to own the internal developer platform across Kubernetes clusters. Candidates must have strong Terraform, Helm, and Kubernetes expertise. Go is used for internal tooling. Prometheus and Grafana are the observability stack. Consul is used for service discovery. Argo CD drives GitOps deployments. Cloud-native architecture experience at scale is essential.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Terraform, and Helm cover the three core platform requirements\",\"Prometheus and Grafana match the full observability stack\",\"Consul for service discovery is an exact match\",\"Argo CD satisfies the GitOps deployment requirement\",\"Go covers internal tooling development\",\"Cloud-native and service mesh architecture experience aligns with scale expectations\",\"Lead seniority is appropriate for the role scope\"],\"gaps\":[],\"explanation\":\"The candidate is an exceptional match. Their profile covers every stated technical requirement, including the less common Consul service discovery experience. Their lead seniority and cloud-native architecture background make them well-suited to own a developer platform at scale.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"henry_intern_py\",\"seniority\":\"Intern\",\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Pandas\",\"NumPy\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nData team at a startup looking for a data engineering intern. Python is required. Pandas and NumPy for data manipulation. SQLite or PostgreSQL for small-scale data work. The role is mentored and focused on building ETL pipelines and writing SQL queries for analysis. No prior professional experience required but solid Python fundamentals are expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python is required and present\",\"Pandas and NumPy match the data manipulation tools\",\"SQLite experience satisfies the small-scale database expectation\"],\"gaps\":[\"No PostgreSQL experience — mentioned as an alternative to SQLite\",\"No ETL pipeline experience signaled in profile\",\"No CI/CD or version control tooling visible\"],\"explanation\":\"The candidate meets the core baseline requirements for an intern data role. Python, Pandas, and NumPy are all present and the role explicitly does not require prior professional experience. However, the profile is quite sparse with no ETL pipeline work or version control tooling visible, which may be worth exploring in an interview context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nina_ruby_rails\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"Ruby\",\"JavaScript\"],\"tech\":[\"Ruby on Rails\",\"React\",\"Sidekiq\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MySQL\"],\"ci_cd\":[\"CircleCI\",\"GitHub Actions\"],\"testing\":[\"RSpec\",\"Cypress\"]}\n\nJob Summary:\nConsumer marketplace startup hiring a backend engineer. Node.js and TypeScript are the primary backend technologies. The team uses Express.js and Prisma with PostgreSQL. Redis is used for caching. Jest for testing. GitHub Actions for CI. React for the frontend. Engineers are expected to contribute to both backend and lightweight frontend features.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"PostgreSQL and Redis provide some data layer alignment\",\"React experience is relevant to the frontend contribution expectation\",\"GitHub Actions CI familiarity aligns\"],\"gaps\":[\"No Node.js or TypeScript — the primary backend language and runtime\",\"No Express.js or any Node.js framework\",\"No Prisma ORM experience\",\"No Jest — uses RSpec and Cypress instead\",\"Ruby on Rails background does not map to a TypeScript Node.js stack\"],\"explanation\":\"Despite some infrastructure overlap, the candidate's backend experience is entirely in Ruby on Rails, while the role requires Node.js and TypeScript expertise. The ORM, testing framework, and backend language are all mismatched. PostgreSQL and Redis overlap is insufficient to bridge the primary language and framework gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ryanmcallister_dev\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\"],\"tech\":[\"FastAPI\",\"Docker\",\"Kubernetes\",\"Redis\",\"Apache Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"pytest\",\"k6\"]}\n\nJob Summary:\nWe are a Series B fintech startup building a high-throughput payments platform. We need a senior backend engineer who can own microservices in Python or Go, work with Kafka-based event pipelines, and operate services on Kubernetes. Familiarity with PostgreSQL and Redis is expected. We run GitHub Actions for CI and deploy via Argo CD. Load testing experience is a plus as we scale to millions of transactions per day.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Python and Go match the two primary backend languages\",\"Kafka experience directly supports the event-driven payments pipeline\",\"Kubernetes and Argo CD match the deployment stack exactly\",\"PostgreSQL and Redis align with the stated data layer\",\"k6 load testing is relevant given the high-throughput scaling requirement\"],\"gaps\":[],\"explanation\":\"The candidate's profile aligns with every technical signal in the job description, from language to infrastructure to testing tooling. Their microservices and event-driven architecture experience is directly applicable to the payments domain. No meaningful gaps are present for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nikita_go_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Gin\",\"Docker\",\"Redis\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nSecurity tooling startup hiring a mid-level Go backend engineer. We use Echo as our HTTP framework. PostgreSQL is the primary database. gRPC is used for inter-service communication. Redis for caching. Kubernetes manages deployments. GitHub Actions for CI. Engineers are expected to write comprehensive unit tests using Go testing conventions.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go is the primary language \\u2014 exact match\",\"PostgreSQL and Redis align with the data and caching layer\",\"Microservices experience is applicable\",\"GitHub Actions satisfies the CI requirement\",\"Docker provides containerization foundation\"],\"gaps\":[\"Uses Gin framework rather than Echo \\u2014 different HTTP router and middleware model\",\"No gRPC experience for inter-service communication\",\"No Kubernetes experience for production deployments\"],\"explanation\":\"The candidate is a competent Go engineer but the framework mismatch from Gin to Echo, while bridgeable, means some ramp-up on Echo-specific middleware and routing patterns. More significantly, the absence of gRPC and Kubernetes limits their contribution to the service communication and deployment layers, which are core responsibilities.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"layla_python_dev\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Flask\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"SQLite\"]}\n\nJob Summary:\nConsulting firm hiring a mid-level backend engineer for enterprise Python projects. FastAPI is the preferred framework. SQLAlchemy is the ORM. Postgres is the database. Engineers are expected to write unit tests with pytest. Docker is required for local development. Some Kubernetes exposure is preferred for production deployments. Two or more years of professional Python experience expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python aligns with the primary language requirement\",\"PostgreSQL matches the database expectation\",\"Docker satisfies the local development containerization requirement\",\"Flask experience provides adjacent Python web framework knowledge\"],\"gaps\":[\"No FastAPI experience — the preferred framework\",\"No SQLAlchemy ORM experience\",\"No pytest in profile for unit testing\",\"No Kubernetes exposure\",\"Junior seniority versus mid-level requirement with 2+ years expected\"],\"explanation\":\"The candidate has foundational Python and database skills that partially align with the role, but they are missing the preferred framework, ORM, and testing tools. Their junior seniority and Flask-based experience suggest they are close to the right profile but would need time to ramp up on FastAPI, SQLAlchemy, and pytest in a professional setting.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leon_game_dev\",\"seniority\":\"Mid\",\"roles\":[\"Game Developer\"],\"languages\":[\"C++\",\"C#\"],\"tech\":[\"Unity\",\"Unreal Engine\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nIndependent game studio hiring a backend engineer to build matchmaking and leaderboard services for an online multiplayer game. Go is the primary backend language. gRPC is used for real-time service communication. Redis handles session and leaderboard data. PostgreSQL for persistent player data. Kubernetes manages deployments. The role is backend-only with no game engine involvement.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Game domain experience provides relevant product context\",\"C++ background suggests systems-level programming awareness\"],\"gaps\":[\"No Go experience — the primary backend language\",\"No gRPC or real-time service communication experience\",\"No Redis or Kubernetes experience\",\"No PostgreSQL beyond general game data handling\",\"Game engine background does not transfer to cloud backend service development\"],\"explanation\":\"The candidate is a game developer with engine-specific skills, but this role is a backend engineering position requiring Go, gRPC, Redis, and Kubernetes. None of these appear in their profile. Their game domain knowledge provides product context but is insufficient to offset the absence of backend infrastructure experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sara_wordpress_freelance\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"WordPress\",\"jQuery\",\"Bootstrap\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nCloud-native startup building a real-time IoT data platform. The backend is Go with gRPC for device communication. TimescaleDB stores time-series sensor data. Kafka handles device event streaming. Kubernetes on AWS EKS manages services. React and TypeScript on the dashboard frontend. Engineers must be comfortable with high-throughput distributed systems.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"No Go \\u2014 the primary backend language\",\"No gRPC or event streaming experience\",\"No TimescaleDB, Kafka, or any time-series/streaming tooling\",\"No Kubernetes or cloud-native infrastructure experience\",\"No React or TypeScript for the frontend\",\"WordPress and jQuery background is content-management focused, not systems engineering\"],\"explanation\":\"This candidate's entire background is in PHP-based content management and traditional web development. The role requires expertise in Go, gRPC, Kafka, TimescaleDB, and Kubernetes \\u2014 a distributed systems stack with no overlap with WordPress or jQuery development. The mismatch is fundamental across language, domain, and infrastructure.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elena_android_sr\",\"seniority\":\"Senior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Retrofit\",\"Dagger Hilt\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nIoT startup building a companion Android app for a hardware device. Kotlin is the language. The team uses XML-based layouts rather than Jetpack Compose for compatibility with older Android SDK versions. Retrofit handles REST API calls. Firebase is the backend. JUnit and Espresso are the testing tools. GitHub Actions for CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin is the primary language \\u2014 exact match\",\"Retrofit for REST API integration aligns directly\",\"Firebase covers the backend integration\",\"JUnit satisfies the unit testing baseline\",\"GitHub Actions matches CI requirements\"],\"gaps\":[\"Experience is Jetpack Compose-focused while the team uses XML-based layouts for legacy SDK compatibility\",\"No Espresso experience \\u2014 the UI testing tool used by the team instead of Mockito\"],\"explanation\":\"The candidate is a capable Android engineer but their expertise is oriented toward modern Jetpack Compose development, while this team intentionally uses XML layouts for older device compatibility. This is a skills mismatch around UI development approach. Espresso for UI testing is also absent from their profile, adding another gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sam_devops_intern\",\"seniority\":\"Intern\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"GitHub Actions\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nGrowth-stage startup seeking a mid-level DevOps engineer to own our Kubernetes platform on AWS EKS. Candidates must have hands-on Terraform and Helm experience. We use Prometheus and Grafana for observability. Argo CD manages deployments. Experience with service mesh technologies like Istio is a plus. Three or more years of professional DevOps experience expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker familiarity is a foundational overlap\",\"GitHub Actions provides basic CI exposure\"],\"gaps\":[\"Intern seniority versus mid-level requirement with 3+ years expected\",\"No Kubernetes or AWS EKS experience\",\"No Terraform or Helm for infrastructure and cluster management\",\"No Prometheus, Grafana, or observability tooling\",\"No Argo CD or GitOps deployment experience\",\"No Istio or service mesh exposure\"],\"explanation\":\"The candidate is early in their career and lacks virtually every platform technology the job requires. Docker and GitHub Actions are foundational but insufficient to offset the absence of Kubernetes, Terraform, observability tooling, and the expected professional experience level. This is not a match for the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex_webdev\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"React\",\"Bootstrap\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nFAANG-style company hiring a senior software architect to design and lead a multi-tenant SaaS platform migration. Candidates must have deep experience in distributed systems, cloud-native architecture on AWS, Kubernetes, and service mesh technologies. Twelve or more years of professional engineering experience expected. Go and Java expertise required. Strong track record of system design at scale is essential.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Junior seniority versus senior architect requirement is a fundamental mismatch\",\"No distributed systems, cloud-native, or Kubernetes experience\",\"No Go or Java — only JavaScript\",\"No AWS, service mesh, or multi-tenant architecture experience\",\"No CI/CD, testing, or infrastructure tooling present\"],\"explanation\":\"The candidate has no alignment with this role across any meaningful dimension. The seniority gap spans at least a decade of expected experience, and the technical stack required — Go, Java, Kubernetes, AWS, service mesh — is entirely absent from their profile. This is not a viable match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"chen_wei_backend\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Fiber\",\"Docker\",\"Redis\",\"gRPC\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nLogistics API company seeking a senior Go backend engineer. We use Echo as our HTTP framework. gRPC is used for internal service communication. PostgreSQL is the primary database. Redis handles caching. Docker and GitHub Actions support our development workflow. Microservices experience is required. We prefer engineers with strong API design skills in Go.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go is the primary language — matches the core requirement\",\"gRPC aligns with inter-service communication\",\"PostgreSQL and Redis match the data and caching layer\",\"Docker and GitHub Actions support development workflow\",\"Microservices experience meets the architecture requirement\"],\"gaps\":[\"Uses Fiber as HTTP framework rather than Echo, which is the company's chosen framework\",\"Testing listed as pytest which is Python-specific rather than Go testing tools\"],\"explanation\":\"The candidate has strong Go and infrastructure alignment but uses Fiber rather than Echo as their HTTP framework. While both are Go frameworks, the Echo-specific patterns may differ. The pytest listing suggests Python testing experience rather than Go test familiarity, which is a moderate concern for a Go-primary role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"emeka_react_dev\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Redux\",\"Webpack\",\"styled-components\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"Jest\",\"Enzyme\"]}\n\nJob Summary:\nProduct company modernizing their frontend stack. They currently use React with Redux but are migrating to Zustand and Vite. They use Tailwind CSS for new components and Playwright for end-to-end testing. TypeScript is required. The team wants engineers who can work in both the legacy Webpack and Redux codebase and contribute to the modernization effort.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Redux match the existing codebase\",\"Webpack experience is relevant for maintaining the legacy build system\",\"TypeScript is required and present\",\"Jest provides partial testing coverage\"],\"gaps\":[\"No Zustand experience — the target state management library\",\"No Vite experience — the target build tool\",\"No Tailwind CSS experience — used for new components\",\"No Playwright experience — the end-to-end testing tool\",\"Enzyme is deprecated in favor of React Testing Library\"],\"explanation\":\"The candidate is well-suited to maintaining the legacy stack but has gaps across every modernization target. They can contribute immediately to the existing Redux and Webpack codebase, but they will need to develop Zustand, Vite, Tailwind, and Playwright experience to fully participate in the migration effort, which is the team's primary focus.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tom_data_jr\",\"seniority\":\"Junior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Pandas\",\"dbt\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"]}\n\nJob Summary:\nData team at a mid-size SaaS company hiring a junior data engineer. dbt and BigQuery are the core stack. Python scripting for lightweight automation. Airflow manages ingestion DAGs. SQL is essential for model development. GitHub Actions for CI on dbt models. The team uses Great Expectations for data quality checks and expects all engineers to contribute quality rules.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt and BigQuery are the core stack and both are present\",\"SQL is essential and is a primary language\",\"Python scripting satisfies the automation requirement\",\"Junior level is appropriate for the role\"],\"gaps\":[\"No Airflow experience \\u2014 manages the ingestion DAG layer\",\"No Great Expectations experience \\u2014 data quality contributions are expected from all engineers\",\"No GitHub Actions in profile for dbt CI\"],\"explanation\":\"The candidate covers the core transformation layer well with dbt and BigQuery, and their junior level fits the role expectation. However, Airflow and Great Expectations represent meaningful operational gaps. Engineers are expected to contribute to both orchestration and data quality, making these gaps relevant beyond nice-to-haves.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"oliver_vue_mid\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Vuex\",\"Bootstrap\",\"Webpack\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"Jest\",\"Karma\"]}\n\nJob Summary:\nEnterprise SaaS company building an Angular-based ERP frontend. TypeScript is required. NgRx manages state. We use Angular Material for the component library. Jest and Jasmine for testing. Azure DevOps handles CI. Engineers should have deep Angular expertise including RxJS, dependency injection, and module architecture. Senior-level experience preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript is present\",\"Jest provides partial testing overlap\"],\"gaps\":[\"No Angular experience \\u2014 entire frontend stack is Vue.js\",\"No NgRx \\u2014 uses Vuex which is Vue-specific\",\"No Angular Material or RxJS experience\",\"No Azure DevOps \\u2014 uses GitLab CI\",\"No Jasmine for testing\",\"Vue ecosystem knowledge does not transfer to Angular's DI and module patterns\"],\"explanation\":\"The candidate is a Vue.js developer and this role requires deep Angular expertise. Beyond both using TypeScript, the frameworks have entirely different architectures, dependency injection models, and state management patterns. The absence of Angular, NgRx, RxJS, and Azure DevOps covers every major technical requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ines_php_cms\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"Symfony\",\"WordPress\",\"Bootstrap\",\"jQuery\"],\"databases\":[\"MySQL\"],\"ci_cd\":[\"GitLab CI\"]}\n\nJob Summary:\nSaaS company building a real-time collaboration tool. The backend is Elixir with Phoenix. The frontend uses React with TypeScript. PostgreSQL is the primary database. Ecto is the ORM. WebSocket is used for real-time updates. We use GitHub Actions for CI. Engineers should be comfortable with functional programming concepts.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Web development background provides general product context\"],\"gaps\":[\"No Elixir or Phoenix — the entire backend stack\",\"No React or TypeScript — the frontend stack\",\"No PostgreSQL or Ecto — only MySQL and no Elixir ORM\",\"No WebSocket or real-time systems experience signaled\",\"No GitHub Actions — uses GitLab CI\",\"PHP and Symfony background does not map to a functional Elixir/Phoenix stack\"],\"explanation\":\"The candidate's PHP and Symfony background has no meaningful overlap with the Elixir, Phoenix, React, and PostgreSQL stack this company uses. The language, framework, database, and paradigm differences are too significant. Real-time WebSocket experience is also absent, which is central to the product's value proposition.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"anna_backend_ru\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"Celery\",\"Docker\",\"Redis\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nLogistics platform hiring a backend engineer with Node.js and TypeScript experience. The team uses NestJS for API development and BullMQ for async job processing. PostgreSQL is the primary database. Prisma is the ORM. Docker is used for local development. Engineers write tests with Jest. Kubernetes is used for production deployments and familiarity is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"PostgreSQL and Docker show foundational alignment on data layer and containerization\",\"Async task processing experience with Celery is conceptually similar to BullMQ\",\"pytest testing discipline is transferable\"],\"gaps\":[\"No Node.js or TypeScript — the primary language and runtime\",\"No NestJS or Express.js experience\",\"No BullMQ or Node.js job queue experience\",\"No Prisma or any Node.js-native ORM\",\"No Jest for testing\",\"No Kubernetes experience\"],\"explanation\":\"While the candidate has solid backend fundamentals and some overlapping infrastructure experience, their entire application stack is Python-based and the role is firmly Node.js and TypeScript. The framework, ORM, job queue, and testing stack are all language-specific and do not transfer directly. This is a significant mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lucia_fullstack_es\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Next.js\",\"React\",\"FastAPI\",\"Docker\",\"Tailwind CSS\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\"]}\n\nJob Summary:\nB2C marketplace hiring a full stack engineer. Next.js and React on the frontend, Django on the backend. PostgreSQL for the database. Celery with Redis for background jobs. Tailwind CSS for styling. GitHub Actions for CI. pytest and Jest for testing. Engineers should be comfortable with Django ORM and Django REST Framework.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and React match the frontend requirements\",\"Tailwind CSS and GitHub Actions align with styling and CI\",\"PostgreSQL is the database and is present\",\"Jest and pytest cover the testing requirements\",\"TypeScript and Python are both relevant\"],\"gaps\":[\"Uses FastAPI rather than Django \\u2014 different backend framework with different ORM and REST tooling\",\"No Celery or Redis for background job processing\",\"No Django ORM or Django REST Framework experience\"],\"explanation\":\"The candidate is a capable full stack engineer with strong frontend alignment, but their Python backend experience is FastAPI-based rather than Django. The job specifically calls out Django ORM and Django REST Framework as expectations, and the absence of Celery and Redis for background jobs adds further gaps on the backend side.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ruth_nlp_researcher\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"Data Scientist\"],\"languages\":[\"Python\"],\"tech\":[\"Hugging Face Transformers\",\"PyTorch\",\"spaCy\",\"NLTK\",\"MLflow\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Elasticsearch\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nLegaltech company hiring a senior ML engineer specializing in NLP. Python is required. Hugging Face Transformers and PyTorch are the core model stack. spaCy is used for text preprocessing. MLflow manages model experiments. Elasticsearch enables document search. Docker for containerization. The role focuses on information extraction, entity recognition, and document classification for legal documents.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Hugging Face Transformers and PyTorch match the core model stack\",\"spaCy for text preprocessing is an exact match\",\"MLflow for experiment management aligns directly\",\"Elasticsearch for document search is an exact match\",\"Docker covers containerization\",\"NLTK adds additional NLP toolchain depth\"],\"gaps\":[],\"explanation\":\"This candidate is purpose-built for an NLP engineering role. Their profile covers every technical tool in the job description, with particularly strong alignment on the NLP-specific stack including Hugging Face, spaCy, and Elasticsearch. Their senior seniority supports independent ownership of the information extraction workstream.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mike_junior_py\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"Flask\",\"Docker\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nTelecommunications company hiring a principal engineer to lead architectural decisions for a carrier-grade messaging platform. Java or Go required. Candidates must have designed distributed systems handling millions of concurrent connections. Experience with Kafka, Cassandra, gRPC, and Kubernetes at scale is mandatory. Fifteen or more years of professional experience expected. Track record of leading large engineering teams required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Junior seniority versus principal engineer requirement with 15+ years expected\",\"No Java or Go \\u2014 only Python\",\"No Kafka, Cassandra, gRPC, or Kubernetes\",\"No distributed systems at scale experience\",\"Flask and SQLite background is oriented toward small-scale web services, not carrier-grade platforms\",\"No engineering leadership experience\"],\"explanation\":\"This is a complete mismatch across every dimension. A junior Flask developer with SQLite experience has no alignment with a principal engineering role requiring 15 years of experience, carrier-grade distributed systems expertise, and engineering team leadership. The seniority gap alone spans roughly four career levels.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"raj_java_intern\",\"seniority\":\"Intern\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Java\"],\"tech\":[\"Spring Boot\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nData engineering team at a streaming media company seeking a senior data engineer. Scala and Apache Spark are required for real-time pipeline development. Kafka handles event streaming. Flink for micro-batch processing. Databricks manages our Spark clusters. Snowflake is the warehouse. Airflow orchestrates jobs. Eight or more years of data engineering experience expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Intern seniority versus senior requirement with 8+ years expected\",\"No Scala \\u2014 the primary pipeline language\",\"No Spark, Kafka, or Flink for streaming data processing\",\"No Databricks, Snowflake, or Airflow\",\"Java and Spring Boot background is oriented toward web services, not distributed data engineering\"],\"explanation\":\"The candidate is a Java intern at the start of their career and this role requires senior-level expertise in a completely different technical domain. Scala, Spark, Kafka, Flink, Databricks, and Snowflake are all absent from their profile. There is no meaningful alignment across seniority, language, or tooling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tanvir_ml\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Hugging Face Transformers\",\"LangChain\",\"MLflow\",\"Docker\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"ChromaDB\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAI-native startup building retrieval-augmented generation products for enterprise clients. We need a senior ML engineer with hands-on LLM fine-tuning and RAG pipeline experience. PyTorch and Hugging Face Transformers are our primary ML stack. We use LangChain for orchestration and ChromaDB for vector storage. MLflow tracks experiments. Engineers own model deployment as Docker containers and are expected to design scalable inference pipelines.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PyTorch and Hugging Face Transformers match the core ML stack\",\"LangChain orchestration experience is directly applicable\",\"ChromaDB vector store experience aligns with the RAG pipeline\",\"MLflow for experiment tracking matches exactly\",\"Docker and microservices support the deployment and inference pipeline requirements\"],\"gaps\":[],\"explanation\":\"This candidate is purpose-built for the role. Their profile covers every key technical signal the job description calls out, from the LLM toolchain to vector databases to experiment tracking. Their senior seniority and microservices experience further support owning scalable inference pipelines independently.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amara_fullstack\",\"seniority\":\"Junior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"Flask\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"SQLite\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nLarge enterprise software company hiring a staff-level backend engineer to lead technical direction across distributed systems. The role requires designing fault-tolerant architectures with Kafka, owning Kubernetes cluster operations, and mentoring a team of six engineers. Candidates should have deep experience in Java or Go, with a track record of delivering systems at scale. Eight or more years of professional experience expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Junior seniority versus staff-level requirement is a fundamental mismatch\",\"No Java or Go experience — only JavaScript and Python\",\"No Kafka, Kubernetes, or distributed systems experience\",\"No mentorship or technical leadership signals\",\"No CI/CD tooling beyond Docker\"],\"explanation\":\"The candidate is at the very beginning of their career and the job requires staff-level seniority, distributed systems expertise, and people leadership. Every major technical and seniority dimension is misaligned. This is not a viable match for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex_ts_backend\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Express.js\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nProptech company hiring a mid-level backend engineer. We use NestJS with TypeScript as our API framework and Prisma as our ORM over PostgreSQL. BullMQ handles async queues with Redis. Jest and Supertest for testing. Docker for containerization. GitHub Actions for CI. Engineers should be comfortable with TypeScript decorators and dependency injection patterns.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript is the required language and is present\",\"PostgreSQL and Redis align with the data and queue layer\",\"Jest and Supertest match the testing stack\",\"Docker and GitHub Actions satisfy the dev and CI requirements\"],\"gaps\":[\"Uses Express.js rather than NestJS \\u2014 different framework with distinct patterns including decorators and DI\",\"No Prisma experience \\u2014 uses a different ORM approach\",\"No BullMQ experience \\u2014 uses Redis directly but not the queue abstraction\"],\"explanation\":\"The candidate has solid TypeScript backend fundamentals and covers the infrastructure tooling well, but their framework experience is Express.js rather than NestJS. NestJS has distinct architectural patterns around decorators and dependency injection that differ from Express, representing a meaningful ramp-up for someone coming from a plain Express background.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"felix_ios_dev\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"Xcode\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nConsumer fintech app with 2 million users seeking a mid-level iOS engineer. SwiftUI is our primary UI framework. We automate builds and deployments with Fastlane. Engineers write unit and UI tests using XCTest. The codebase is Swift-only. Some familiarity with REST API integration is expected as the app communicates with a Python backend. Our CI runs on GitHub Actions.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Swift and SwiftUI match the language and framework requirements exactly\",\"Fastlane and GitHub Actions align with the build automation and CI setup\",\"XCTest satisfies the unit and UI testing expectation\"],\"gaps\":[\"No explicit REST API integration experience signaled in profile\"],\"explanation\":\"The candidate matches all stated technical requirements for this iOS role. Their toolchain across SwiftUI, Fastlane, and XCTest is a precise fit. The only minor gap is the absence of REST API integration signals in their profile, though this is a supplementary expectation rather than a core requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"marcus_junior_js\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"React\",\"Bootstrap\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nGrowth agency hiring a mid-level React engineer. TypeScript is required. The stack includes Next.js, Tailwind CSS, and Zustand for state management. Engineers write Playwright end-to-end tests and maintain GitHub Actions pipelines. Strong component architecture skills expected. The candidate should be able to work independently across multiple client projects.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React experience provides foundational alignment\",\"Jest testing shows basic testing awareness\"],\"gaps\":[\"No TypeScript — a hard requirement\",\"No Next.js experience\",\"No Tailwind CSS — uses Bootstrap instead\",\"No Zustand for state management\",\"No Playwright for end-to-end testing\",\"No GitHub Actions CI experience\",\"Junior seniority versus mid-level expectation with independent multi-project ownership\"],\"explanation\":\"While the candidate has React and basic testing experience, they are missing TypeScript, Next.js, Tailwind CSS, Zustand, and Playwright — which collectively represent most of the required stack. Their junior seniority compounds the gap for a role requiring independent ownership across multiple client engagements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nadia_sre_cloud\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Bash\",\"Python\"],\"tech\":[\"Kubernetes\",\"Prometheus\",\"Grafana\",\"Terraform\",\"Docker\",\"Istio\"],\"architecture\":[\"Microservices\",\"Service Mesh\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nFAANG-adjacent adtech company hiring a senior SRE to own reliability across a high-traffic microservices platform. Strong Kubernetes and service mesh experience is required. We use Istio for traffic management and Prometheus with Grafana for observability. Terraform manages our infrastructure. Go is used for internal tooling. GitOps via Argo CD is our deployment standard.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes and Istio service mesh experience matches core platform requirements\",\"Prometheus and Grafana cover the full observability stack\",\"Terraform aligns with infrastructure management expectations\",\"Go satisfies the internal tooling language requirement\",\"Argo CD matches the GitOps deployment standard\",\"Service mesh architecture experience directly relevant\"],\"gaps\":[],\"explanation\":\"This is an exceptional fit. The candidate's profile covers every technical signal in the job description with no gaps. Their Istio and service mesh experience is particularly strong alignment given the high-traffic microservices context. They can contribute immediately without meaningful ramp-up on the tech stack.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mei_android\",\"seniority\":\"Mid\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Retrofit\"],\"databases\":[\"Firebase\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nStreaming media company building a next-generation Android TV app. Kotlin and Jetpack Compose are our primary development tools. We use JUnit and Mockito for unit testing. Firebase powers our analytics and remote configuration. Fastlane manages release automation. The ideal candidate has shipped Android apps to the Play Store and is comfortable with REST API consumption using Retrofit.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kotlin and Jetpack Compose match the core development stack exactly\",\"JUnit and Mockito align with the testing requirements\",\"Firebase covers analytics and remote configuration needs\",\"Fastlane satisfies release automation expectations\",\"Retrofit for REST API consumption is an exact match\"],\"gaps\":[],\"explanation\":\"Every technical signal in the job description is present in the candidate's profile. The alignment across language, UI framework, testing, analytics, and release tooling is comprehensive. This candidate can contribute immediately to the Android TV app with no meaningful ramp-up required on the tech stack.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sven_scala_dev\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Data Engineer\"],\"languages\":[\"Scala\",\"Java\",\"Python\"],\"tech\":[\"Apache Spark\",\"Apache Kafka\",\"Apache Flink\",\"Akka\",\"Docker\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"Cassandra\",\"PostgreSQL\",\"Elasticsearch\"],\"ci_cd\":[\"GitHub Actions\",\"Jenkins\"]}\n\nJob Summary:\nStreaming infrastructure company hiring a senior engineer for real-time data processing. Scala is the primary language. Kafka for event streaming. Flink for real-time stream processing. Cassandra for storage. Spark for batch workloads. The candidate should have deep distributed systems experience and be comfortable with JVM performance tuning.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Scala is the primary language — exact match\",\"Kafka for event streaming is directly required and present\",\"Flink for real-time stream processing is an exact match\",\"Cassandra for storage aligns precisely\",\"Spark covers the batch processing requirement\",\"Distributed systems and event-driven architecture experience is required and present\"],\"gaps\":[],\"explanation\":\"The candidate is an outstanding match for this streaming infrastructure role. Scala, Kafka, Flink, Cassandra, and Spark are all present. Their distributed systems background and depth across the JVM ecosystem support the performance tuning expectations of the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"k_osei_builds\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\",\"Python\"],\"tech\":[\"Next.js\",\"Express.js\",\"Docker\",\"Redis\"],\"architecture\":[\"Monolith\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Cypress\"]}\n\nJob Summary:\nGrowth-stage e-commerce company hiring a full stack engineer to extend our Next.js storefront and Node.js API layer. The ideal candidate writes TypeScript across the stack, is comfortable with PostgreSQL, and has shipped features end-to-end. Docker is used for local dev and CI. We value engineers who write Cypress end-to-end tests and maintain GitHub Actions pipelines. Microservices experience is preferred as we plan to decompose our monolith.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and TypeScript match the frontend stack\",\"Express.js covers the Node.js API layer requirement\",\"PostgreSQL and Docker align with data and local dev expectations\",\"Cypress and GitHub Actions match the testing and CI requirements\"],\"gaps\":[\"Only monolith architecture experience listed — microservices decomposition is a stated preference\",\"No explicit microservices or service decomposition patterns in profile\"],\"explanation\":\"The candidate covers the day-to-day technical requirements well, with strong alignment on the application and infrastructure stack. However, the company is planning a monolith-to-microservices migration and the candidate's architecture experience is limited to monolithic systems, which is a relevant gap for future growth in this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"diego_cloud_eng\",\"seniority\":\"Mid\",\"roles\":[\"Cloud Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Terraform\",\"Docker\",\"Ansible\"],\"architecture\":[\"Cloud-Native\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"]}\n\nJob Summary:\nHealthcare cloud team seeking a mid-level cloud engineer to manage infrastructure on AWS. Terraform is required for infrastructure-as-code. Ansible handles configuration management. Docker is used for containerization. Kubernetes experience is strongly preferred for future cluster management work. Python or Bash scripting for automation is required. The team operates in a HIPAA-compliant environment.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform covers the primary infrastructure-as-code requirement\",\"Ansible matches the configuration management tool\",\"Docker satisfies the containerization expectation\",\"Python and Bash scripting fulfills the automation requirement\",\"Cloud-native architecture experience is relevant\"],\"gaps\":[\"No Kubernetes experience — strongly preferred and roadmap-critical\",\"No explicit AWS service experience signaled in profile\"],\"explanation\":\"The candidate covers the immediate technical requirements well but is missing Kubernetes experience, which the job explicitly lists as strongly preferred for future work. Their AWS exposure is also unclear from the profile. They are a viable hire for current responsibilities but may need to develop Kubernetes skills to grow into the full scope of the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jess_nguyen42\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"Firebase\"],\"testing\":[\"Jest\",\"React Testing Library\"]}\n\nJob Summary:\nEarly-stage SaaS startup looking for a frontend engineer to build our customer-facing dashboard. We use React and TypeScript with Tailwind CSS for styling. Our build tool is Vite. We expect engineers to write unit and integration tests using Jest and React Testing Library. Firebase handles our auth and realtime data. This is a collaborative role with design and product — no backend ownership required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React and TypeScript are the core frontend stack\",\"Tailwind CSS and Vite match the tooling exactly\",\"Jest and React Testing Library align with the stated testing expectations\",\"Firebase experience covers the auth and realtime data layer\"],\"gaps\":[\"Junior seniority may slow ramp-up on complex dashboard state management\"],\"explanation\":\"The candidate's tech stack is a near-perfect match for this role despite their junior seniority. Every tool listed in the job description appears in their profile. The seniority level is a minor consideration but the role is collaborative and does not require backend ownership, which reduces risk.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ben_rustacean\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"C++\",\"Go\"],\"tech\":[\"Actix\",\"Tokio\",\"Docker\",\"gRPC\"],\"architecture\":[\"Microservices\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"ClickHouse\"]}\n\nJob Summary:\nInfrastructure startup building a high-performance data ingestion engine. We write everything in Rust and use Actix for our HTTP layer. gRPC is our primary inter-service protocol. ClickHouse is our analytical store. Performance-critical C++ experience is a strong differentiator. Candidates should be comfortable with systems-level programming, memory management, and distributed system design.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Rust is the primary language and the candidate's top language\",\"Actix matches the HTTP layer framework exactly\",\"gRPC aligns with inter-service communication requirements\",\"ClickHouse is the analytical store and is present in the profile\",\"C++ experience is explicitly a differentiator and is listed\",\"Distributed systems architecture experience directly applicable\"],\"gaps\":[],\"explanation\":\"This candidate is an ideal match for a systems-focused Rust role. Their profile covers Rust, Actix, gRPC, and ClickHouse without any gaps on the stated requirements. The C++ background adds meaningful differentiation that the job explicitly calls out as a strong signal.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"daniel_devops_aws\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Terraform\",\"Docker\",\"AWS EC2\",\"AWS S3\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nGrowth startup seeking a mid-level DevOps engineer for Kubernetes-first infrastructure. Helm manages application deployments. Argo CD drives GitOps. Prometheus and Grafana handle observability. Terraform for IaC. Bash and Python for automation. Engineers are expected to onboard teams to the developer platform and maintain cluster reliability.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform aligns with the IaC requirement\",\"Bash and Python satisfy the automation scripting need\",\"GitHub Actions provides CI familiarity\",\"Docker shows containerization awareness\"],\"gaps\":[\"No Kubernetes or Helm experience \\u2014 the core platform technology\",\"No Argo CD or GitOps deployment experience\",\"No Prometheus or Grafana \\u2014 observability stack is absent\"],\"explanation\":\"The candidate covers Terraform and scripting adequately but is missing Kubernetes, Helm, Argo CD, and the full observability stack, which together represent the core of this role. Their AWS and Docker background gives them adjacent cloud awareness, but they would need significant platform upskilling to be effective in a Kubernetes-first DevOps role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex_builds\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"Node.js\",\"FastAPI\",\"Docker\",\"AWS\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\",\"pytest\"]}\n\nJob Summary:\nWe are a Series B fintech startup looking for a Senior Full Stack Engineer to own our customer-facing web platform built on Next.js and FastAPI. You will design and ship product features end to end, improve system reliability, and collaborate closely with product and design. Our stack uses PostgreSQL, Redis, Docker, and deploys on AWS. We value engineers who write tests, think in systems, and can work across the entire product surface.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Exact stack match on Next.js, FastAPI, PostgreSQL, Redis, Docker, and AWS\",\"Testing discipline demonstrated across Jest, Playwright, and pytest covering unit and e2e layers\",\"Microservices and Event-Driven architecture experience aligns with scaling fintech platform needs\",\"Senior seniority matches the role level\"],\"gaps\":[],\"explanation\":\"This candidate mirrors the job's technical requirements almost exactly, from the core web stack to infrastructure and testing practices. Their architecture background in microservices and event-driven systems is directly relevant for a fintech platform that needs reliability and scalability. No meaningful gaps were identified given the role's stated priorities.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devops_dana\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"Docker\",\"Ansible\",\"AWS\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nEnterprise SaaS company seeks a Senior DevOps Engineer to manage our Kubernetes-based infrastructure on AWS. Responsibilities include maintaining Helm charts, writing Terraform for infrastructure as code, setting up monitoring with Prometheus and Grafana, and improving our CI/CD pipelines using GitHub Actions and Argo CD. Strong scripting ability in Python or Bash is required. Experience with service mesh technologies like Istio is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Helm, Terraform, AWS, Prometheus, Grafana, GitHub Actions, and Argo CD are all exact matches to the job requirements\",\"Python and Bash scripting proficiency satisfies the mandatory scripting requirement\",\"Cloud-native and microservices architecture experience is directly relevant\",\"k6 load testing signals infrastructure performance awareness\"],\"gaps\":[\"No Istio or service mesh experience visible, which is listed as a plus\"],\"explanation\":\"The candidate covers every core requirement listed in the job description with direct tool-level evidence. The only noted gap is the absence of Istio experience, which the employer listed as a bonus rather than a requirement. Overall fit is exceptionally strong.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_mira\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"NumPy\",\"MLflow\",\"Docker\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAI-first healthtech startup hiring a Machine Learning Engineer to train and deploy clinical NLP models. You will work with large language models, fine-tune transformers using Hugging Face, build RAG pipelines, and integrate models into production APIs. Experience with LangChain or LlamaIndex is a strong plus. Our stack is Python-based and we deploy on AWS with Docker and MLflow for experiment tracking.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch is the right deep learning framework for transformer fine-tuning work\",\"MLflow experience directly matches the stated experiment tracking toolchain\",\"Docker and GitHub Actions align with the deployment and CI pipeline expectations\",\"scikit-learn and Pandas demonstrate solid ML fundamentals\"],\"gaps\":[\"No Hugging Face Transformers experience visible, which is central to the role\",\"No RAG or LangChain experience despite these being core job requirements\",\"No AWS infrastructure experience listed\",\"NLP specialization is not evidenced in the profile\"],\"explanation\":\"The candidate has a reasonable ML engineering foundation with PyTorch and MLflow, but the role is specifically centered on LLM fine-tuning, Hugging Face, and RAG pipelines — none of which appear in their profile. They could ramp up, but there is a meaningful skills gap relative to what is immediately required.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jorge_rios_dev\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"Express.js\",\"Flask\",\"Docker\"],\"databases\":[\"MongoDB\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\"]}\n\nJob Summary:\nEarly-stage startup looking for a Mid-level Backend Engineer to build and maintain REST APIs using Node.js and Express. You will own several microservices, write database queries for both MongoDB and PostgreSQL, and contribute to system design decisions. We expect engineers at this level to work independently and mentor junior teammates. Prior experience with Docker and basic CI/CD is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Express.js and Node.js ecosystem experience directly matches the API stack\",\"MongoDB and PostgreSQL coverage aligns with the dual-database requirement\",\"Docker and GitHub Actions satisfy the stated CI/CD expectations\",\"Testing with Jest and pytest shows good engineering habits\"],\"gaps\":[\"Junior seniority is one level below the Mid-level requirement\",\"No microservices architecture experience visible\",\"Mentoring expectation may be premature given career stage\",\"No demonstrated system design contributions\"],\"explanation\":\"The candidate's technical stack is well-aligned with the job's tooling requirements, but their Junior seniority creates a real mismatch with a role that expects independent ownership and mentoring. The lack of microservices experience is also a gap. They could be a strong candidate in 12-18 months.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priya_cloudarch\",\"seniority\":\"Principal\",\"roles\":[\"Solutions Architect\",\"Software Architect\"],\"languages\":[\"Python\",\"Java\",\"Go\"],\"tech\":[\"AWS\",\"Kubernetes\",\"Terraform\",\"Kafka\",\"gRPC\",\"Docker\"],\"architecture\":[\"Distributed System\",\"Event-Driven\",\"CQRS\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\",\"Cassandra\"],\"ci_cd\":[\"GitLab CI\",\"Argo CD\"]}\n\nJob Summary:\nFAANG-scale company hiring a Principal Solutions Architect to design distributed systems handling billions of events daily. You will define cross-team technical standards, evaluate architectural trade-offs, and work directly with engineering leadership. Required expertise includes Kafka, gRPC, DynamoDB, and Kubernetes at scale. Experience with CQRS and event sourcing patterns is essential.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kafka, gRPC, DynamoDB, and Kubernetes are all exact matches to the stated required expertise\",\"CQRS and Event-Driven architecture experience directly satisfies the essential pattern requirements\",\"Distributed systems architecture at Principal level matches both the scope and seniority of the role\",\"Polyglot language background in Python, Java, and Go is appropriate for cross-team technical leadership\",\"Cassandra and PostgreSQL alongside DynamoDB demonstrate breadth in data storage trade-offs\"],\"gaps\":[],\"explanation\":\"This candidate's profile reads as purpose-built for this role, with exact matches across the required technologies, architecture patterns, and seniority level. Their distributed systems expertise and principal-level background make them well-equipped to drive cross-team standards at FAANG scale.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tomasz_wpdev\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"WordPress\",\"Laravel\",\"Vue.js\",\"Bootstrap\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nGrowth-stage SaaS company hiring a Mid-level Full Stack Engineer to build internal tooling and customer-facing dashboards using React, TypeScript, and Node.js on the frontend, with a FastAPI Python backend. We use PostgreSQL and deploy on AWS with Docker. Strong TypeScript skills are required. No WordPress or PHP experience is relevant to this role.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Vue.js experience provides some transferable frontend component knowledge toward React\"],\"gaps\":[\"No React or TypeScript experience despite these being required\",\"No Node.js or FastAPI skills; PHP and Laravel are explicitly irrelevant per the job description\",\"No PostgreSQL experience; only MySQL listed\",\"No Docker or AWS experience\",\"No Python in the profile\"],\"explanation\":\"The candidate's stack is centered on PHP, WordPress, and Laravel — a skillset the employer explicitly called out as irrelevant. Their Vue.js experience is the only transferable signal, but the role requires React, TypeScript, Python, and cloud infrastructure, none of which are evidenced. This is a poor fit for the current opening.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"data_devin\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Spark\",\"Apache Airflow\",\"dbt\",\"Kafka\",\"Pandas\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\",\"Redshift\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise analytics company seeking a Senior Data Engineer to build and maintain large-scale data pipelines. You will use Apache Spark and Airflow for orchestration, dbt for transformation, and work across Snowflake and BigQuery as primary warehouses. Experience with streaming data via Kafka is a strong plus. Python and SQL fluency are mandatory.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Apache Spark, Airflow, and dbt are exact matches to the core pipeline and transformation toolchain\",\"Snowflake and BigQuery are both listed as primary warehouses and both appear in the profile\",\"Kafka experience satisfies the streaming plus requirement\",\"Python and SQL fluency fulfill the mandatory language requirements\",\"Senior seniority matches the role level\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a near-perfect match for this role, covering every required technology and both core data warehouse platforms. Their streaming experience with Kafka adds additional value beyond the baseline requirements. No meaningful gaps were identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"li_wei_mobile\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Expo\"],\"testing\":[\"Detox\"]}\n\nJob Summary:\nConsumer startup hiring a Mid-level iOS Engineer to build and maintain a Swift-based iOS app using SwiftUI as the primary UI framework. You will work alongside the Android team and collaborate through shared REST APIs. UIKit knowledge is required for legacy screen maintenance. Experience with automated mobile testing frameworks is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Swift is the required language and is the candidate's primary language\",\"SwiftUI is the stated primary UI framework and is prominently listed\",\"UIKit experience satisfies the legacy screen maintenance requirement\",\"Detox experience directly addresses the testing framework plus\",\"Mid-level seniority matches the role\"],\"gaps\":[],\"explanation\":\"The candidate covers every stated requirement for this iOS role including the language, both UI frameworks, and mobile testing experience. Their background maps precisely to what the employer described, making them a strong match with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ruben_backendguru\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Python\"],\"tech\":[\"Spring Boot\",\"Docker\",\"AWS\",\"RabbitMQ\",\"Nginx\"],\"architecture\":[\"Microservices\",\"Layered Architecture\"],\"databases\":[\"PostgreSQL\",\"MySQL\",\"Redis\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nFinancial services firm hiring a Senior Backend Engineer to build high-throughput transaction processing services. The stack is Java with Spring Boot, PostgreSQL, Redis for caching, and RabbitMQ for async messaging. Services are deployed on AWS using Docker. You will own service design, write comprehensive unit and integration tests, and participate in on-call rotations.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Spring Boot, PostgreSQL, Redis, RabbitMQ, Docker, and AWS are all direct matches to the described stack\",\"JUnit and Mockito demonstrate the unit and integration testing rigor the role requires\",\"Microservices architecture experience aligns with transaction processing service ownership\",\"Senior seniority and backend specialization match the role expectations\"],\"gaps\":[\"No explicit on-call or SRE-adjacent experience visible in profile\"],\"explanation\":\"The candidate's Java and Spring Boot background maps exactly to the job's tech stack, and their testing toolkit with JUnit and Mockito satisfies the stated testing expectations. The only minor gap is that no on-call or reliability engineering experience is visible, though this is not a dealbreaker for a backend role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sparse_sam\",\"seniority\":\"Junior\",\"languages\":[\"JavaScript\"]}\n\nJob Summary:\nStartup hiring a Junior Frontend Engineer to build React components and work with a TypeScript codebase. You will implement designs from Figma, collaborate in a small agile team, and learn our existing Next.js architecture. Basic knowledge of HTML, CSS, and Git is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"JavaScript provides a baseline foundation for learning React and TypeScript\"],\"gaps\":[\"No React experience listed despite it being the core requirement\",\"No TypeScript experience, which the codebase relies on\",\"No Next.js familiarity\",\"No CSS, Git, or testing tools visible in the profile\",\"Very sparse profile makes it difficult to assess true capability\"],\"explanation\":\"The candidate's profile is extremely sparse, with only JavaScript listed, making it nearly impossible to assess fit with confidence. The role expects at minimum React and TypeScript knowledge, and neither is evidenced. Even at Junior level, this represents a significant gap against the stated requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"flutter_fiona\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"JavaScript\"],\"tech\":[\"Flutter\",\"Firebase\",\"React Native\",\"Expo\"],\"databases\":[\"Firestore\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Detox\"]}\n\nJob Summary:\nHealthtech company hiring a Mid-level Mobile Engineer to build a cross-platform patient-facing app using Flutter and Dart. The app persists data locally with SQLite and syncs with a Firebase backend using Firestore. You will write automated tests and own the mobile CI pipeline. Experience with React Native is not relevant but will not be penalized.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Flutter and Dart are the primary required technologies and are prominently listed\",\"Firestore and SQLite directly match the stated data persistence and sync requirements\",\"GitHub Actions ownership of the CI pipeline is evidenced\",\"Detox experience demonstrates automated mobile testing capability\",\"Mid-level seniority matches the role\"],\"gaps\":[],\"explanation\":\"The candidate's Flutter, Dart, Firestore, and SQLite experience aligns precisely with the role's technical requirements. Their CI and testing experience further reinforces fit. React Native, while present, was explicitly noted as neutral by the employer.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"samir_devops99\",\"seniority\":\"Junior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"GitHub Actions\",\"Nginx\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nScale-up company hiring a Senior DevOps Engineer to lead infrastructure modernization on AWS. You will design and maintain Kubernetes clusters, write Terraform modules, implement observability with Prometheus and Grafana, and establish GitOps workflows using Argo CD. Strong experience with service meshes and multi-tenant infrastructure is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker and basic CI experience with GitHub Actions provide foundational DevOps skills\"],\"gaps\":[\"Junior seniority is significantly below the Senior level required\",\"No Kubernetes or Helm experience\",\"No Terraform or infrastructure-as-code skills\",\"No Prometheus, Grafana, or observability tooling\",\"No Argo CD or GitOps experience\",\"No AWS experience\",\"No service mesh or multi-tenant infrastructure knowledge\"],\"explanation\":\"The candidate is at an early career stage with foundational DevOps exposure, but the role demands senior-level expertise across a wide range of advanced infrastructure technologies. The gap spans seniority, tooling, and architectural complexity. This candidate would need several years of growth before being competitive for this position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ananya_fullstack\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Node.js\",\"Django\",\"Docker\",\"Vercel\"],\"architecture\":[\"Monolith\",\"Modular Architecture\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\"]}\n\nJob Summary:\nB2B SaaS startup hiring a Mid-level Full Stack Engineer. The stack is React and TypeScript on the frontend and Django REST Framework on the backend with PostgreSQL. We use Docker for local dev and deploy via Vercel and AWS. We expect solid test coverage using pytest and Jest. Familiarity with modular architecture is a plus as we are preparing to split the monolith.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React, TypeScript, Django, PostgreSQL, Docker, and Vercel are all direct stack matches\",\"pytest and Jest satisfy the stated testing expectations\",\"Monolith and Modular Architecture experience is directly relevant to the stated monolith-splitting goal\",\"Mid-level seniority aligns with the role\"],\"gaps\":[\"No AWS experience listed despite it being part of the deployment stack\"],\"explanation\":\"This candidate covers nearly every technical requirement, including the stack, testing tools, and even the architectural context of migrating from a monolith to a modular system. The only minor gap is the absence of AWS experience, which appears secondary to Vercel in the job description.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kai_datascience\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"NumPy\",\"Weights & Biases\",\"Jupyter\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nRetail analytics company hiring a Senior Data Scientist to develop demand forecasting and recommendation models. Python and SQL fluency are required. Experience with scikit-learn and gradient boosting libraries like XGBoost or LightGBM is essential. Familiarity with Snowflake for data access is expected. MLflow or Weights and Biases for experiment tracking is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python and SQL fluency satisfy mandatory language requirements\",\"scikit-learn experience directly matches the essential modeling requirement\",\"Snowflake experience addresses the data access expectation\",\"Weights and Biases satisfies the experiment tracking plus requirement\",\"Senior seniority matches the role level\"],\"gaps\":[\"No XGBoost or LightGBM experience, which are listed as essential for forecasting models\",\"PyTorch is more aligned with deep learning than the gradient boosting focus of this role\"],\"explanation\":\"The candidate has strong general data science credentials and several direct matches, but the role is specifically oriented around gradient boosting models for forecasting, and neither XGBoost nor LightGBM appears in the profile. This is a meaningful gap given the employer described them as essential.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nico_sre\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Prometheus\",\"Grafana\",\"Datadog\",\"Terraform\",\"AWS\",\"Docker\"],\"architecture\":[\"Distributed System\",\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nStreaming platform hiring a Senior SRE to maintain five-nines reliability for a distributed video delivery system. You will manage Kubernetes clusters on AWS, build and own dashboards in Grafana and Datadog, write infrastructure as code with Terraform, and run chaos engineering and load tests. Go or Python scripting is required for automation tasks.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, AWS, Grafana, Datadog, and Terraform are exact matches to the core toolchain\",\"Go and Python scripting satisfies the mandatory automation requirement\",\"k6 load testing experience is directly relevant to the stated chaos and load testing expectations\",\"Distributed systems and cloud-native architecture background fits the scale of a streaming platform\",\"Senior SRE role and seniority are aligned\"],\"gaps\":[],\"explanation\":\"The candidate's profile covers every technical requirement listed in the job description, including monitoring, infrastructure as code, scripting, and load testing. Their distributed systems background at senior SRE level makes them highly qualified for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"backend_bart\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"Celery\",\"Docker\",\"Redis\",\"AWS\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nLogistics company hiring a Senior Backend Engineer to design and scale async job processing systems. The stack is Python with FastAPI, Celery for task queues, Redis as a broker, and PostgreSQL. We deploy on AWS and expect engineers at this level to lead technical discussions, review code, and define API contracts. GraphQL experience is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI, Celery, Redis, PostgreSQL, Docker, and AWS are all exact stack matches\",\"pytest demonstrates testing discipline\",\"Microservices architecture experience is relevant\"],\"gaps\":[\"Mid seniority is one level below the Senior requirement; leadership and code review expectations may not be met\",\"No GraphQL experience despite it being listed as a plus\"],\"explanation\":\"The candidate's technical stack is an excellent match — every core technology aligns with the role. However, the seniority gap is meaningful because the employer specifically expects senior-level behaviors like leading technical discussions and defining contracts, which may be premature for a Mid-level engineer.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"olga_frontend\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Framer Motion\",\"Storybook\",\"Vite\"],\"architecture\":[\"Modular Architecture\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\",\"Testing Library\"]}\n\nJob Summary:\nDesign-forward SaaS startup hiring a Senior Frontend Engineer to lead their component library and customer-facing UI. The stack is React with TypeScript and Next.js. You will own the Storybook design system, write animations with Framer Motion, and ensure cross-browser test coverage. Tailwind CSS is the styling system. Performance optimization experience is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React, TypeScript, Next.js, Tailwind CSS, Framer Motion, and Storybook are all exact matches to the described stack\",\"Playwright and Testing Library directly address the cross-browser test coverage requirement\",\"Senior seniority aligns with the lead component library expectation\",\"Vite and modular architecture signal performance and code organization awareness\"],\"gaps\":[],\"explanation\":\"The candidate matches every technology named in the job description, including the design system tooling and animation library, which are specific differentiators for this role. Their testing toolkit and senior seniority further reinforce their fit as someone ready to lead frontend at this company.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"carlos_java\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Hibernate\",\"Docker\",\"AWS\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nE-commerce company hiring a Senior Go engineer to rewrite their order processing backend. The new stack is Go with the Gin framework, PostgreSQL, and Kafka for event streaming. Services will run on AWS ECS. You will also write integration tests and contribute to infrastructure automation with Terraform.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Kafka and event-driven architecture experience transfers directly to the new system's messaging layer\",\"AWS and PostgreSQL experience provides some infrastructure familiarity\"],\"gaps\":[\"No Go or Gin experience; the entire role is centered on a Go rewrite\",\"No Terraform experience for the infrastructure automation requirement\",\"No AWS ECS-specific experience\",\"Java and Spring Boot are not relevant to this role\"],\"explanation\":\"Despite being a Senior engineer with solid backend credentials, the candidate lacks Go experience entirely, which is the foundational requirement for this role. The event streaming and database skills are transferable, but the absence of the primary language makes this a poor fit without a significant learning period.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"intern_izzy\",\"seniority\":\"Intern\",\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"React\",\"Flask\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nTech company offering a Software Engineering Internship for students or recent graduates. You will contribute to a React and Python Flask web application, fix bugs, add small features, and learn from senior engineers. PostgreSQL is the database. No prior professional experience is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React, Flask, Python, and PostgreSQL are exact matches to the internship's tech stack\",\"Intern seniority appropriately matches the role level\",\"Profile demonstrates enough breadth across frontend and backend for a learning-oriented position\"],\"gaps\":[],\"explanation\":\"For an internship with no professional experience required, this candidate's demonstrated knowledge of React, Flask, Python, and PostgreSQL aligns precisely with what the company is working with. They appear ready to contribute meaningfully from day one within the defined scope of an internship.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yuki_ml_ops\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"TensorFlow\",\"MLflow\",\"Docker\",\"Kubernetes\",\"Airflow\",\"FastAPI\"],\"architecture\":[\"Microservices\",\"Cloud-Native\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"]}\n\nJob Summary:\nAd tech company hiring a Senior MLOps Engineer to productionize machine learning models at scale. You will manage model serving infrastructure on Kubernetes, build ML pipelines with Airflow, track experiments with MLflow, and expose models via REST APIs. Python is the primary language. Experience with TensorFlow or PyTorch is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Airflow, MLflow, and FastAPI for REST APIs are direct matches to the role's core requirements\",\"TensorFlow satisfies the framework plus requirement\",\"Docker and cloud-native architecture experience supports the model serving infrastructure work\",\"Senior seniority matches the role level\"],\"gaps\":[],\"explanation\":\"The candidate's profile maps precisely to the MLOps engineering requirements, covering model serving, pipeline orchestration, experiment tracking, and API exposure. Their TensorFlow experience is an added bonus beyond the baseline expectations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rustacean_rob\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"C++\",\"Python\"],\"tech\":[\"Actix\",\"Docker\",\"Kafka\"],\"architecture\":[\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"]}\n\nJob Summary:\nLow-latency trading platform hiring a Senior Systems Engineer with strong Rust experience. You will build high-performance order routing services using Actix, work with low-level networking, and optimize for microsecond latency. Kafka is used for trade event streaming. C++ familiarity is a plus for legacy component integration.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Rust and Actix directly match the core technology requirements for the high-performance services\",\"Kafka experience aligns with the trade event streaming requirement\",\"C++ familiarity addresses the legacy integration plus\",\"Distributed systems experience is relevant to the trading platform context\"],\"gaps\":[\"Mid seniority is below the Senior level required for a latency-critical trading system\",\"No explicit low-level networking or performance optimization experience evidenced\"],\"explanation\":\"The candidate has the right core technical toolkit — Rust, Actix, and Kafka — but the seniority gap is a real concern for a latency-critical trading system where experience with microsecond optimization is expected at the senior level. They may be a strong candidate in one to two years.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"grace_frontend_mid\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Tailwind CSS\",\"Pinia\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\"]}\n\nJob Summary:\nDigital agency hiring a Mid-level Frontend Engineer proficient in Vue.js and Nuxt.js for building fast, SEO-optimized client websites. You will use Pinia for state management and Tailwind CSS for styling. Experience with automated testing in a Vue ecosystem is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Vue.js, Nuxt.js, Pinia, and Tailwind CSS are all exact matches to the described stack\",\"Vitest is the natural testing tool for the Vue ecosystem and satisfies the automated testing expectation\",\"Mid-level seniority aligns with the role\",\"TypeScript alongside JavaScript indicates modern development practices\"],\"gaps\":[],\"explanation\":\"Every technology listed in the job description appears in the candidate's profile. Their Vue ecosystem experience, including state management with Pinia and testing with Vitest, makes them a precise fit for this frontend role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devraj_backend\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"FastAPI\",\"Celery\",\"Redis\",\"Docker\",\"AWS\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nHealthcare startup seeking a Lead Backend Engineer to own architecture decisions for a multi-tenant patient data platform. The stack is Python with FastAPI, PostgreSQL, and Redis. You will mentor a team of three backend engineers, establish coding standards, and collaborate with product on API design. Multi-tenancy experience is essential.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI, PostgreSQL, Redis, Docker, and AWS are direct stack matches\",\"pytest demonstrates testing discipline relevant to a healthcare environment\",\"Senior experience positions them well to take on mentoring and standards setting\"],\"gaps\":[\"Lead seniority is one level above Senior and the role expects formal team leadership of three engineers\",\"No multi-tenancy experience evidenced despite it being listed as essential\"],\"explanation\":\"The candidate is technically well-aligned with the stack, but two gaps stand out: the role requires Lead-level ownership and formal mentoring responsibility, and multi-tenancy is listed as essential with no evidence in the profile. These are meaningful factors for a patient data platform where access isolation is critical.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"eleanor_ios\",\"seniority\":\"Junior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"UIKit\"],\"testing\":[\"Detox\"]}\n\nJob Summary:\nEnterprise software company hiring a Senior iOS Engineer to design and implement core features for a complex B2B mobile app with tens of thousands of daily users. You will mentor two junior engineers, define iOS architecture patterns, and collaborate with a backend team on API integration. Minimum five years of Swift experience is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Swift, SwiftUI, and UIKit provide the foundational technical skills for iOS development\"],\"gaps\":[\"Junior seniority is significantly below the Senior level required\",\"No demonstrated iOS architecture experience\",\"No mentoring or technical leadership experience at this career stage\",\"Minimum five years of Swift experience required; Junior seniority implies well under that threshold\"],\"explanation\":\"The candidate has the right technical foundation for iOS development but is at the very beginning of their career. The role demands senior-level ownership, architecture decision-making, and mentoring that are well beyond what a Junior engineer would be expected to provide. This is not a fit for this particular opening.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"maxime_cloud\",\"seniority\":\"Lead\",\"roles\":[\"Cloud Engineer\",\"Platform Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Terraform\",\"Kubernetes\",\"Helm\",\"AWS\",\"Google Cloud\",\"Pulumi\",\"Vault\"],\"architecture\":[\"Cloud-Native\",\"Multi-Tenant\",\"Service Mesh\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\",\"Tekton\"]}\n\nJob Summary:\nSeries D startup hiring a Lead Platform Engineer to design a multi-cloud platform strategy across AWS and GCP. You will own the Kubernetes infrastructure, implement Vault for secrets management, adopt GitOps practices using Argo CD, and build self-service developer tooling. Terraform and Pulumi experience are both desirable.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, AWS, Google Cloud, Vault, Argo CD, Terraform, and Pulumi are all direct matches to the job requirements\",\"Multi-tenant and service mesh architecture experience is relevant to a multi-cloud platform context\",\"Lead seniority aligns with the leadership expectations of the role\",\"Tekton alongside Argo CD demonstrates broad GitOps and CI/CD fluency\"],\"gaps\":[],\"explanation\":\"This candidate's profile reads as built for a multi-cloud platform engineering lead role. Every key technology, including Vault for secrets, Pulumi alongside Terraform, and Argo CD for GitOps, appears in their background. Their architecture breadth across multi-tenancy and service mesh reinforces readiness for the complexity of this position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tina_analytics\",\"seniority\":\"Mid\",\"roles\":[\"Analytics Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Airflow\",\"Looker\",\"Metabase\",\"Pandas\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"]}\n\nJob Summary:\nE-commerce company seeking a Mid-level Analytics Engineer to build and maintain dbt models on top of Snowflake, create Looker dashboards for business stakeholders, and orchestrate data jobs with Airflow. SQL fluency is required and Python scripting is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt, Snowflake, Looker, and Airflow are exact matches to the four core tools named in the job description\",\"SQL is listed as required and is the candidate's primary language\",\"Python satisfies the scripting plus requirement\",\"Mid-level seniority matches the role\"],\"gaps\":[],\"explanation\":\"The candidate's profile aligns precisely with every tool and requirement in the job description, including the primary analytical platform, visualization layer, and orchestration tooling. This is an excellent fit with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"oscar_mobile_game\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"C#\",\"Swift\"],\"tech\":[\"Unity\",\"SwiftUI\",\"Firebase\"],\"databases\":[\"Firestore\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nMobile-first fintech startup seeking a Mid-level React Native engineer to build a cross-platform iOS and Android app. The app uses REST APIs and stores user data via a Node.js backend. Familiarity with TypeScript is required. Experience with Expo is a strong plus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Firebase and mobile development experience show familiarity with the mobile app ecosystem\"],\"gaps\":[\"No React Native experience despite it being the core requirement\",\"No TypeScript, which is listed as required\",\"No Expo experience\",\"No Node.js or REST API integration experience visible\",\"Unity and game development experience does not transfer to this fintech mobile role\"],\"explanation\":\"The candidate's mobile background is primarily in Unity-based game development and native Swift, neither of which is relevant to this React Native fintech role. The absence of React Native, TypeScript, and Expo creates a fundamental skills mismatch across the role's core requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fatima_nlp_eng\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"AI Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"Hugging Face Transformers\",\"PyTorch\",\"LangChain\",\"FastAPI\",\"Docker\",\"AWS\"],\"architecture\":[\"Microservices\",\"RAG\"],\"databases\":[\"PostgreSQL\",\"Pinecone\",\"ChromaDB\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nLegal AI startup hiring a Senior AI Engineer to build document intelligence features. You will fine-tune transformer models using Hugging Face, design RAG pipelines with vector databases, and serve models via FastAPI. LangChain orchestration experience is expected. AWS and Docker for deployment are required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Hugging Face Transformers, RAG architecture, LangChain, FastAPI, Docker, and AWS are all exact matches to the stated requirements\",\"Pinecone and ChromaDB demonstrate direct vector database experience for RAG pipelines\",\"Senior AI Engineer seniority and role match the position\",\"PyTorch provides the underlying model training capability\"],\"gaps\":[],\"explanation\":\"The candidate's profile is precisely aligned with a legal AI document intelligence role, covering transformer fine-tuning, RAG pipeline design, vector databases, and production serving infrastructure. This is a highly specific technical match across every stated requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"liam_devops_fresh\",\"seniority\":\"Junior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"GitHub Actions\",\"AWS\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nStartup seeking a Junior DevOps Engineer to help maintain Docker-based development environments, write automation scripts, and support CI pipelines with GitHub Actions on AWS. You will work closely with a senior DevOps mentor. No Kubernetes experience required at this stage.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Docker, GitHub Actions, and AWS are exact matches to the stated toolchain\",\"Python and Bash scripting directly addresses the automation scripting requirement\",\"Junior seniority matches the role and mentoring structure\"],\"gaps\":[],\"explanation\":\"The candidate's profile covers every tool the employer listed for this junior role, and the role was scoped to exclude advanced requirements like Kubernetes. With a senior mentor in place, this is a strong match for an entry-level DevOps position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pascal_dba\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"PostgreSQL\",\"Redis\",\"Elasticsearch\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"MySQL\",\"Cassandra\",\"Elasticsearch\"]}\n\nJob Summary:\nMedia company seeking a Senior Backend Engineer with a Node.js and TypeScript focus to build high-traffic content APIs. The stack is NestJS, PostgreSQL, and Redis on AWS. Elasticsearch is used for full-text search. Experience with GraphQL is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PostgreSQL, Redis, and Elasticsearch experience are strong matches to the data layer requirements\",\"Senior seniority aligns with the role level\"],\"gaps\":[\"No Node.js, TypeScript, or NestJS experience despite these being the primary backend stack\",\"No AWS infrastructure experience\",\"No GraphQL experience despite it being a plus\"],\"explanation\":\"The candidate's database and search expertise is directly relevant to the data layer, but the entire application stack — NestJS, TypeScript, and Node.js — is absent from their profile. They bring valuable infrastructure knowledge but would need to ramp up significantly on the application layer.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sophie_react_senior\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Redux\",\"React Query\",\"Tailwind CSS\",\"Webpack\",\"Storybook\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"React Testing Library\",\"Cypress\"]}\n\nJob Summary:\nEnterprise HR software company seeking a Senior Frontend Engineer to maintain and expand a large React and TypeScript codebase. You will improve state management with Redux, optimize API data fetching, write unit and E2E tests, and contribute to the component library in Storybook. Performance and accessibility improvements are ongoing priorities.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React, TypeScript, Redux, React Query, Tailwind CSS, and Storybook are all exact stack matches\",\"Jest, React Testing Library, and Cypress cover unit, integration, and E2E testing as expected\",\"Senior seniority aligns with the role\",\"Webpack experience demonstrates build optimization awareness relevant to the performance priority\"],\"gaps\":[],\"explanation\":\"The candidate's profile mirrors the job description with direct matches across state management, data fetching, testing layers, and the component library toolchain. Their breadth in performance-relevant tooling reinforces their fit for a role that prioritizes optimization and accessibility.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jerome_sec_eng\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\",\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"AWS\",\"Docker\",\"Kubernetes\",\"Vault\",\"Terraform\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"]}\n\nJob Summary:\nCloud security company hiring a Senior Application Security Engineer. You will conduct security reviews of microservices, implement secrets management with HashiCorp Vault, work on cloud security posture in AWS, and build automated security scanning into CI/CD pipelines. Familiarity with Python or Go for tooling is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"HashiCorp Vault, AWS, Kubernetes, and Terraform directly match the core security toolchain\",\"Python and Go satisfy the mandatory scripting and tooling requirement\",\"Microservices and cloud-native architecture background is relevant to the security review scope\",\"Senior Security Engineer role aligns with seniority and role type\"],\"gaps\":[\"No explicit CI/CD security scanning tools mentioned, such as Snyk or Trivy\"],\"explanation\":\"The candidate covers the primary technical requirements including secrets management, cloud security posture in AWS, and relevant scripting languages. The only minor gap is the absence of specific CI/CD security scanning tools, but their broad security and infrastructure background makes them well-positioned to adopt these quickly.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mei_angular_dev\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Angular\",\"NgRx\",\"Tailwind CSS\",\"Karma\"],\"testing\":[\"Karma\",\"Jasmine\"]}\n\nJob Summary:\nLarge financial services firm hiring a Mid-level Frontend Engineer to maintain and extend a large-scale Angular enterprise application. The state management layer uses NgRx. You will write tests using Karma and Jasmine, follow strict TypeScript standards, and contribute to accessibility compliance efforts.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Angular, NgRx, TypeScript, Karma, and Jasmine are all exact matches to the described stack and testing requirements\",\"Mid-level seniority matches the role\",\"TypeScript-first profile aligns with the strict TypeScript standards expectation\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a precise match for this Angular enterprise role, including both the framework and the specific state management and testing tools. Their TypeScript-only language profile signals alignment with the firm's strict typing standards.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex_gamedev\",\"seniority\":\"Mid\",\"roles\":[\"Game Developer\"],\"languages\":[\"C++\",\"C#\"],\"tech\":[\"Unity\",\"Unreal Engine\",\"Docker\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nFAANG company hiring a Senior Backend Engineer to build distributed microservices in Go with gRPC, Kafka, and PostgreSQL on Kubernetes. Team uses GitHub Actions for CI. Strong distributed systems experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"No Go experience; Go is the primary language for this role\",\"No gRPC, Kafka, or distributed systems experience\",\"No Kubernetes or cloud infrastructure experience\",\"No PostgreSQL experience\",\"Mid seniority is below the Senior requirement\",\"Game development background does not transfer to distributed backend engineering\"],\"explanation\":\"The candidate's skill set is oriented entirely around game development, with no overlap with the distributed backend systems stack this role requires. There are no meaningful transferable technical signals for a Go-based microservices engineering position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nadia_nestjs_lead\",\"seniority\":\"Lead\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"Express.js\",\"GraphQL\",\"Apollo GraphQL\",\"Docker\",\"AWS\",\"BullMQ\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Modular Architecture\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nGrowth startup hiring a Lead Backend Engineer to architect and build a GraphQL API platform using NestJS and TypeScript. You will mentor engineers, own the module architecture, manage async job queues, and deploy on AWS. PostgreSQL and Redis are the primary databases.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS, GraphQL, Apollo GraphQL, PostgreSQL, Redis, Docker, and AWS are all direct stack matches\",\"BullMQ experience satisfies the async job queue requirement\",\"Lead seniority and mentoring expectations align with the role\",\"Modular and microservices architecture background directly supports the module architecture ownership expectation\",\"Jest and Supertest cover unit and integration testing\"],\"gaps\":[],\"explanation\":\"This candidate's profile is a highly specific match for the role — NestJS GraphQL with modular architecture, async job queues, and AWS deployment are all evidenced. Their Lead seniority and architecture background make them ready to take full ownership of the described platform.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ben_ml_data\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\",\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"scikit-learn\",\"XGBoost\",\"LightGBM\",\"Pandas\",\"NumPy\",\"Weights & Biases\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"]}\n\nJob Summary:\nInsurance company seeking a Senior Data Scientist to build actuarial and risk scoring models. You will primarily use gradient boosting methods like XGBoost and LightGBM, work with large structured datasets in BigQuery, and track experiments with Weights and Biases. Python and SQL fluency are required. Deep learning experience is not relevant to this role.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"XGBoost and LightGBM are exact matches and are listed as the primary modeling approaches\",\"BigQuery and SQL experience satisfies the data access requirement\",\"Weights and Biases directly matches the experiment tracking tool\",\"Python is the required language and is primary in the profile\",\"Senior seniority aligns with the role level\"],\"gaps\":[],\"explanation\":\"The candidate's profile is precisely scoped to what this role requires — gradient boosting, structured data, SQL, and experiment tracking — without the deep learning background that was explicitly called out as irrelevant. This is a high-confidence fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"erin_backend_go\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Gin\",\"Docker\",\"AWS\",\"gRPC\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nB2B API platform company hiring a Senior Backend Engineer in Go. You will build high-throughput gRPC services, design internal APIs with Gin, manage PostgreSQL and Redis, and deploy on AWS. The role requires senior-level ownership of architecture decisions and onboarding of new team members.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go, Gin, gRPC, PostgreSQL, Redis, Docker, and AWS are direct stack matches across the entire job description\",\"GitHub Actions experience aligns with CI expectations\"],\"gaps\":[\"Mid seniority is one level below Senior; architecture ownership and onboarding responsibilities are typically Senior-level expectations\",\"Testing only shows pytest (Python), not Go testing tooling\"],\"explanation\":\"The candidate's technical stack is an excellent match, covering every technology the role requires. However, the seniority gap is the key concern — the employer expects architecture decision ownership and team onboarding, which typically require senior-level experience that a Mid-level engineer is still developing.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"aws_aiko\",\"seniority\":\"Senior\",\"roles\":[\"Cloud Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"AWS\",\"Terraform\",\"Docker\",\"Kubernetes\",\"Ansible\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"]}\n\nJob Summary:\nMid-size company seeking a Senior Cloud Engineer to migrate on-premise infrastructure to Azure. You will design Azure-native services, write Bicep or ARM templates, and establish monitoring with Azure Monitor. Kubernetes experience on AKS is expected. Terraform and Ansible familiarity is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes experience is transferable to AKS with ramp-up\",\"Terraform and Ansible satisfy the listed plus requirements\",\"Prometheus and Grafana monitoring background provides observability fundamentals transferable to Azure Monitor\",\"Senior seniority matches the role level\"],\"gaps\":[\"No Azure experience; the role is specifically Azure-native\",\"No Bicep or ARM template experience\",\"AWS-centric background requires significant cloud platform transition\"],\"explanation\":\"The candidate is a strong cloud engineer, but their experience is deeply AWS-oriented while this role is explicitly Azure-native. Kubernetes and IaC skills transfer conceptually, but the absence of Azure-specific tooling is a meaningful practical gap for a migration-focused role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leon_php_dev\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"SQL\"],\"tech\":[\"Laravel\",\"Symfony\",\"Docker\",\"Nginx\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nAgency hiring a Mid-level PHP Backend Developer to build and maintain Laravel-based web applications. You will work with MySQL, write tests with PHPUnit, and use GitLab CI for deployments. Symfony familiarity is a plus. Nginx configuration experience is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Laravel and PHP are the primary stack requirements and are prominently listed\",\"MySQL, Redis, PHPUnit, GitLab CI, and Nginx are all exact matches\",\"Symfony satisfies the stated plus requirement\",\"Mid-level seniority matches the role\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a precise match for this PHP web development role, covering every tool and framework listed including the plus requirements. No gaps were identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ivan_node_junior\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Express.js\",\"Node.js\",\"Docker\"],\"databases\":[\"MongoDB\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nStartup seeking a Mid-level Node.js Backend Engineer to build REST APIs in Express, write integration and unit tests, manage MongoDB data models, and own small features end to end with minimal supervision. CI/CD experience with GitHub Actions is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Node.js, Express.js, MongoDB, and Jest are direct stack matches\",\"TypeScript alongside JavaScript signals modern JS development practices\",\"Docker experience is a positive signal for deployment awareness\"],\"gaps\":[\"Junior seniority is one level below Mid; autonomous ownership with minimal supervision is the expectation\",\"No GitHub Actions or CI/CD experience evidenced\"],\"explanation\":\"The candidate has solid technical alignment with the stack, but the seniority gap and missing CI/CD experience are meaningful for a role that expects autonomous feature ownership. With some mentoring and CI exposure, they could grow into this role within a reasonable timeframe.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amara_data_eng\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Airflow\",\"dbt\",\"Pandas\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nRetail analytics company seeking a Mid-level Data Engineer to build dbt transformation layers, orchestrate data pipelines with Airflow, and work with Snowflake as the primary warehouse. Python is the scripting language of choice. Experience with streaming data or Kafka is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt, Airflow, Snowflake, PostgreSQL, Python, and SQL are all direct matches to the stated requirements\",\"Mid-level seniority aligns with the role\",\"Docker signals solid engineering practices\"],\"gaps\":[\"No Kafka or streaming experience, which is listed as a plus\"],\"explanation\":\"The candidate covers every required technology for this data engineering role. The only gap is the Kafka streaming plus requirement, which is not a blocker. This is a strong match for the core responsibilities.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hiro_android_dev\",\"seniority\":\"Senior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Firebase\",\"Retrofit\"],\"databases\":[\"SQLite\",\"Firestore\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Espresso\",\"JUnit\"]}\n\nJob Summary:\nConsumer app company seeking a Senior Android Engineer to build and maintain an Android application using Jetpack Compose and Kotlin. You will integrate Firebase for analytics and push notifications, manage local data with SQLite, and write automated UI tests. GitHub Actions is the CI platform.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Jetpack Compose, Kotlin, Android SDK, Firebase, SQLite, and GitHub Actions are all exact stack matches\",\"JUnit and Espresso directly address the automated UI testing requirement\",\"Senior seniority matches the role level\"],\"gaps\":[],\"explanation\":\"Every technology listed in the job description is evidenced in the candidate's profile, including the specific testing tools and the CI platform. This is a highly precise match for a senior Android engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vera_fullstack_ts\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"FastAPI\",\"Tailwind CSS\",\"Docker\",\"AWS\",\"Redis\"],\"architecture\":[\"Microservices\",\"Modular Architecture\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\",\"pytest\"]}\n\nJob Summary:\nB2C product company hiring a Senior Full Stack Engineer to work on a consumer web app. Stack is Next.js, React, TypeScript, and FastAPI on the backend with PostgreSQL. Uses Tailwind CSS, deploys to AWS, and maintains pipelines via GitHub Actions. Looking for strong testing habits across frontend and backend.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js, React, TypeScript, FastAPI, PostgreSQL, Tailwind CSS, AWS, and GitHub Actions are all exact stack matches\",\"Jest, Playwright, and pytest cover frontend and backend testing as the employer emphasized\",\"Senior seniority aligns with the role\",\"Microservices and modular architecture experience signals systems thinking\"],\"gaps\":[],\"explanation\":\"This candidate is a comprehensive match across every dimension of the job description, from the full stack technologies to the testing toolchain. Their architecture background further reinforces readiness for the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"frank_data_warehousing\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\",\"Analytics Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Dagster\",\"Power BI\",\"Tableau\"],\"databases\":[\"Redshift\",\"Snowflake\",\"PostgreSQL\"]}\n\nJob Summary:\nHealthcare analytics firm seeking a Senior Analytics Engineer to own dbt models, build Power BI dashboards, and work with Redshift as the primary warehouse. Orchestration is handled with Prefect. SQL fluency is essential and Python scripting is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt and Redshift are exact matches to the core modeling and warehouse requirements\",\"Power BI directly satisfies the dashboard tooling requirement\",\"SQL and Python fulfill the mandatory language requirements\",\"Senior seniority aligns with the role level\"],\"gaps\":[\"No Prefect experience; Dagster is listed instead which is a different orchestration tool\",\"Snowflake familiarity may not directly transfer Redshift-specific optimization patterns\"],\"explanation\":\"The candidate covers the primary stack requirements well, but the orchestration gap is notable — Prefect is explicitly the tool in use and Dagster is a different system requiring ramp-up. This is a solid match on modeling and visualization but with a meaningful workflow tooling adjustment needed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dmitri_embedded\",\"seniority\":\"Senior\",\"roles\":[\"Embedded Engineer\",\"Firmware Engineer\"],\"languages\":[\"C\",\"C++\",\"Python\"],\"tech\":[\"Docker\",\"CMake\",\"Makefile\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nIoT startup hiring a Senior Embedded Software Engineer to write firmware for ARM Cortex-M microcontrollers in C and C++. You will use CMake for build configuration, work with RTOS environments, and integrate hardware drivers. Python is used for test automation and scripting. GitHub Actions is the CI system.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"C and C++ are the required languages and are primary in the candidate's profile\",\"CMake and Makefile directly match the build configuration requirement\",\"Python satisfies the test automation and scripting expectation\",\"GitHub Actions aligns with the CI system\",\"Senior Embedded and Firmware Engineer roles match the position\"],\"gaps\":[\"No explicit RTOS experience evidenced in the profile\"],\"explanation\":\"The candidate covers the core firmware engineering requirements with direct matches in language, build tooling, and CI. The absence of explicit RTOS experience is a gap worth exploring in an interview, but the overall technical depth suggests strong fit for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cleo_react_mid\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Zustand\",\"Vite\",\"Tailwind CSS\"],\"testing\":[\"Jest\",\"Testing Library\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nProduct startup hiring a Mid-level React Developer to build a customer-facing dashboard. Stack is React, TypeScript, and Zustand for state management, styled with Tailwind CSS and bundled with Vite. You will write unit tests using Jest and Testing Library. GitHub Actions is the CI platform.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React, TypeScript, Zustand, Tailwind CSS, Vite, Jest, Testing Library, and GitHub Actions are all exact matches\",\"Mid-level seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a precise, tool-for-tool match against every requirement in the job description. No gaps were identified, making this a straightforward strong fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex_python_int\",\"seniority\":\"Intern\",\"languages\":[\"Python\"],\"tech\":[\"Flask\",\"Pandas\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nData analytics startup offering a Data Science internship. You will clean datasets, run exploratory data analysis in Python, and help build basic reporting pipelines. No machine learning experience required. Familiarity with PostgreSQL is helpful.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Python and Pandas are the core tools for data cleaning and EDA as described\",\"PostgreSQL familiarity addresses the stated helpful skill\",\"Intern seniority matches the role\"],\"gaps\":[],\"explanation\":\"For a data science internship focused on EDA and reporting with no ML requirement, the candidate's Python, Pandas, and PostgreSQL background is a precise fit. The role is appropriately scoped to their current skill level.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"helena_platform\",\"seniority\":\"Staff\",\"roles\":[\"Platform Engineer\",\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Prometheus\",\"Grafana\",\"Istio\",\"AWS\",\"Vault\"],\"architecture\":[\"Service Mesh\",\"Multi-Tenant\",\"Cloud-Native\"],\"ci_cd\":[\"Argo CD\",\"GitHub Actions\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nLate-stage startup seeking a Staff Platform Engineer to define infrastructure standards across seven engineering teams. You will own the Kubernetes platform, implement service mesh policies with Istio, manage secrets with Vault, and drive observability with Prometheus and Grafana. GitOps via Argo CD is the deployment model. Go or Python scripting required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Istio, Vault, Prometheus, Grafana, Terraform, AWS, and Argo CD are all exact matches to stated requirements\",\"Staff seniority is appropriate for defining standards across multiple engineering teams\",\"Service mesh, multi-tenant, and cloud-native architecture background directly supports the platform ownership scope\",\"Go and Python scripting satisfies the mandatory automation requirement\",\"k6 experience signals load testing rigor for platform stability\"],\"gaps\":[],\"explanation\":\"The candidate's profile covers every requirement in the job description with direct tool-level and architecture-level evidence. Their Staff seniority and platform engineering background make them exceptionally well-positioned to lead infrastructure standards at this scale.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jan_infra_junior\",\"seniority\":\"Junior\",\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"Linux\",\"Git\"]}\n\nJob Summary:\nScale-up company hiring a Senior Infrastructure Engineer to design multi-region AWS infrastructure, write Terraform modules for a complex environment with over 100 services, integrate HashiCorp Vault, and lead incident response. Strong Kubernetes experience is required. This is a technical leadership role.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker and scripting with Bash and Python provide foundational infrastructure skills\"],\"gaps\":[\"Junior seniority is far below the Senior technical leadership requirement\",\"No AWS experience for a multi-region infrastructure role\",\"No Terraform or infrastructure-as-code experience\",\"No Kubernetes experience despite it being required\",\"No Vault or secrets management experience\",\"No incident response or on-call experience\"],\"explanation\":\"The candidate is at the very beginning of their infrastructure career. This role requires senior-level expertise across a wide range of advanced tooling and the ability to lead technical decisions at scale. The skills gap spans seniority, tooling, and scope.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mia_blockchain\",\"seniority\":\"Mid\",\"roles\":[\"Blockchain Engineer\",\"Smart Contract Developer\"],\"languages\":[\"Solidity\",\"TypeScript\",\"Python\"],\"tech\":[\"Ethereum\",\"Hardhat\",\"IPFS\",\"ethers.js\"],\"testing\":[\"Mocha\",\"Chai\"]}\n\nJob Summary:\nDeFi protocol startup seeking a Mid-level Smart Contract Developer to write and audit Solidity contracts, build deployment scripts, and maintain test suites. The team uses Hardhat for development and testing. Familiarity with ethers.js for frontend integration is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Solidity is the required smart contract language\",\"Hardhat directly matches the stated development and testing framework\",\"ethers.js satisfies the frontend integration plus requirement\",\"Mocha and Chai are standard test frameworks for Hardhat environments\",\"Mid-level seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a precise match for a Solidity and Hardhat smart contract development role, including the testing toolchain and the ethers.js integration plus. No meaningful gaps were identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"remy_python_only\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"Django\",\"Celery\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nSaaS company hiring a Senior Backend Engineer to build microservices in Go. You will design gRPC services, contribute to a Kubernetes-based deployment, and write comprehensive tests. The codebase is entirely in Go and the team has no Python services.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Senior backend engineering experience demonstrates software design maturity\",\"Docker, PostgreSQL, Redis, and AWS provide transferable infrastructure knowledge\"],\"gaps\":[\"No Go experience; the entire codebase is in Go\",\"No gRPC experience\",\"No Kubernetes experience\",\"Django and Celery experience is not relevant to this role\"],\"explanation\":\"The candidate is an experienced Python/Django backend engineer, but the role requires Go with gRPC and Kubernetes, and the employer explicitly stated there are no Python services. The infrastructure overlap is minor given the depth of the language and framework mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kenji_infra_mid\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"Kubernetes\",\"Helm\",\"Terraform\",\"AWS\",\"GitHub Actions\"],\"architecture\":[\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\",\"CircleCI\"]}\n\nJob Summary:\nStartup hiring a Mid-level DevOps Engineer to maintain AWS infrastructure, manage Kubernetes clusters with Helm, write Terraform modules, and support CI pipelines. Bash and Python scripting required. Experience with monitoring tools such as Prometheus or Datadog is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Docker, Kubernetes, Helm, Terraform, AWS, and GitHub Actions are all direct matches to the stated requirements\",\"Python and Bash scripting satisfies the mandatory scripting requirement\",\"Mid-level seniority matches the role\",\"CircleCI experience demonstrates CI breadth beyond the single tool listed\"],\"gaps\":[\"No Prometheus or Datadog experience for the monitoring plus requirement\"],\"explanation\":\"The candidate covers every core requirement for this DevOps role, including the infrastructure, container orchestration, and scripting expectations. The only gap is the monitoring tools plus, which is not a blocker. This is a strong match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tristan_nestjs\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"Express.js\",\"GraphQL\",\"Docker\",\"AWS\",\"BullMQ\",\"Socket.io\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nReal-time collaboration SaaS startup hiring a Senior Backend Engineer to build WebSocket-based features and background job processing pipelines. Stack is NestJS with TypeScript, PostgreSQL, Redis, and MongoDB. AWS deployment with Docker containers. GraphQL is used for internal service communication. We write tests with Jest and Supertest.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS, TypeScript, PostgreSQL, Redis, MongoDB, Docker, AWS, GraphQL, Jest, and Supertest are all exact stack matches\",\"Socket.io experience directly addresses the WebSocket real-time collaboration requirement\",\"BullMQ covers the background job processing pipeline expectation\",\"Event-driven and microservices architecture experience is relevant to the system design context\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a precise, tool-for-tool match against every technical requirement in the job description including the real-time and async processing elements that are central to this role. No meaningful gaps were identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"diana_quant\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\",\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"XGBoost\",\"Polars\",\"Pandas\",\"Weights & Biases\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nHedge fund hiring a Senior Quantitative Researcher to develop alpha-generating trading signals using statistical and machine learning methods. Python is the primary language with heavy use of scikit-learn and XGBoost for feature-based models. R is used for statistical analysis. Snowflake is the data warehouse. Experiment tracking with Weights and Biases is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Python, scikit-learn, and XGBoost directly match the primary modeling stack\",\"R experience satisfies the statistical analysis requirement\",\"Snowflake and SQL fluency address the data warehouse access expectation\",\"Weights and Biases matches the stated experiment tracking tool\",\"Senior seniority and dual Data Scientist and ML Engineer background is appropriate for quantitative research\"],\"gaps\":[],\"explanation\":\"The candidate covers every technical requirement including both primary languages, the modeling libraries, and the data infrastructure. Their combined data science and ML engineering background is well-suited for alpha signal development at a hedge fund.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"felix_rails_dev\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"Ruby\",\"JavaScript\"],\"tech\":[\"Ruby on Rails\",\"React\",\"Tailwind CSS\",\"Sidekiq\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"RSpec\",\"Cypress\"]}\n\nJob Summary:\nConsumer marketplace startup seeking a Mid-level Full Stack Engineer to work on a Ruby on Rails and React codebase. You will build API endpoints, background jobs with Sidekiq, and React components styled with Tailwind CSS. PostgreSQL and Redis are the databases. We use RSpec for backend testing and Cypress for end-to-end tests.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Ruby on Rails, React, Tailwind CSS, Sidekiq, PostgreSQL, Redis, and Docker are all exact stack matches\",\"RSpec and Cypress directly satisfy the stated backend and E2E testing requirements\",\"GitHub Actions aligns with the CI expectation\",\"Mid-level seniority matches the role\"],\"gaps\":[],\"explanation\":\"Every technology listed in the job description is evidenced in the candidate's profile, including the specific background job framework and both testing tools. This is a precise, high-confidence match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"asel_kotlin_android\",\"seniority\":\"Senior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Kotlin Multiplatform\",\"Retrofit\",\"Hilt\"],\"databases\":[\"Room\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"Espresso\",\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nFintech app company hiring a Senior Android Engineer to own native Android development in Kotlin using Jetpack Compose. You will integrate REST APIs via Retrofit, manage dependency injection with Hilt, and write automated UI tests with Espresso. Fastlane is used for release automation. Kotlin Multiplatform experience is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kotlin, Jetpack Compose, Android SDK, Retrofit, and Hilt are all direct stack matches to the core requirements\",\"Espresso and JUnit satisfy the automated UI and unit testing expectations\",\"Fastlane experience directly addresses the release automation requirement\",\"Kotlin Multiplatform satisfies the stated strong plus\",\"Senior seniority matches the role\"],\"gaps\":[],\"explanation\":\"The candidate covers every stated requirement and the strong plus with direct evidence. Their Android engineering background with the precise toolchain including Hilt, Fastlane, and KMP makes them an exceptionally strong match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"boaz_infra\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Terraform\",\"Docker\",\"AWS\",\"GitHub Actions\",\"Ansible\"],\"architecture\":[\"Cloud-Native\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nScale-up company seeking a Senior DevOps Engineer to lead Kubernetes migration for over 20 services, establish GitOps workflows with Argo CD, implement distributed tracing with Jaeger, and build a self-service developer platform on AWS. Terraform experience is expected. Strong Kubernetes expertise is mandatory.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Terraform and AWS experience are transferable to the infrastructure work\",\"Docker provides a foundation for the Kubernetes migration context\"],\"gaps\":[\"No Kubernetes experience despite it being the mandatory core skill\",\"No Argo CD or GitOps experience\",\"No distributed tracing or Jaeger experience\",\"Mid seniority is below Senior; leading a 20-service migration requires senior-level ownership\",\"No developer platform or self-service tooling background\"],\"explanation\":\"Despite solid foundational DevOps skills, the candidate lacks Kubernetes experience entirely, which the employer listed as mandatory for the entire focus of this role. The seniority gap compounds this, as leading a large-scale migration requires both technical depth and leadership capability that are not yet evidenced.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nurul_nextjs\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"Tailwind CSS\",\"shadcn/ui\"],\"testing\":[\"Jest\",\"Testing Library\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nEarly-stage startup hiring a Junior Frontend Engineer to build a Next.js and React SaaS dashboard. You will implement UI components using shadcn/ui and Tailwind CSS, write unit tests with Jest and Testing Library, and work in a small collaborative team. TypeScript is required throughout.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js, React, Tailwind CSS, shadcn/ui, TypeScript, Jest, and Testing Library are all exact stack matches\",\"GitHub Actions CI experience is a positive signal for a Junior candidate\",\"Junior seniority matches the role level\"],\"gaps\":[],\"explanation\":\"The candidate demonstrates proficiency in every technology the role requires, including the specific component library and testing tools. For a Junior position in a small startup, this profile shows sufficient technical breadth and alignment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"piotr_spring_boot\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Hibernate\",\"Docker\",\"AWS\",\"Kafka\",\"Nginx\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"CQRS\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"Cassandra\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\",\"Testcontainers\"]}\n\nJob Summary:\nStreaming media company hiring a Senior Java Backend Engineer to build high-throughput content delivery microservices. Stack is Spring Boot with Kafka for event streaming, PostgreSQL and Cassandra for storage, and Redis for caching. AWS and Docker for deployment. CQRS pattern is used across core services. We expect comprehensive test coverage including integration tests.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Spring Boot, Kafka, PostgreSQL, Cassandra, Redis, Docker, AWS, and CQRS architecture are all exact matches\",\"JUnit, Mockito, and Testcontainers directly address the comprehensive and integration testing expectation\",\"Event-driven and microservices architecture experience aligns with the content delivery system design\",\"Senior seniority and Java background match the role\"],\"gaps\":[],\"explanation\":\"The candidate's profile covers every layer of the job's technical requirements from the application stack to the data tier, architecture patterns, and testing toolchain. Testcontainers is a particularly strong signal for the integration testing expectation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leila_ml_junior\",\"seniority\":\"Junior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"Jupyter\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nFAANG-scale company hiring a Senior ML Engineer to design and deploy large-scale recommendation systems. You will train and serve PyTorch models, build feature pipelines on Apache Spark, manage experiments in MLflow, and deploy model endpoints on Kubernetes. Minimum five years of ML engineering experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"scikit-learn and Pandas provide basic ML fundamentals\"],\"gaps\":[\"Junior seniority is far below the Senior level with a five-year minimum requirement\",\"No PyTorch experience for deep learning model training\",\"No Apache Spark for large-scale feature pipelines\",\"No MLflow or experiment tracking tooling\",\"No Kubernetes or model serving infrastructure\",\"No recommendation systems experience evidenced\"],\"explanation\":\"The candidate is at the start of their ML career with foundational skills, while the role requires senior-level production ML engineering across a stack that none of the candidate's tools overlap with at the required depth. This is a significant seniority and skills mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"callum_sre\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Prometheus\",\"Grafana\",\"AWS\",\"Terraform\",\"Docker\",\"PagerDuty\"],\"architecture\":[\"Cloud-Native\",\"Distributed System\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nCloud infrastructure company hiring a Senior SRE to maintain multi-region Kubernetes clusters on AWS, own the Prometheus and Grafana observability stack, manage on-call response with PagerDuty, and write infrastructure automation in Go or Python. Terraform for infrastructure as code is required. Argo CD for GitOps deployments is used.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Prometheus, Grafana, AWS, Terraform, PagerDuty, Docker, Argo CD, Go, and Python are all exact matches to stated requirements\",\"k6 load testing demonstrates platform stability awareness appropriate for SRE work\",\"Distributed systems and cloud-native architecture experience is directly relevant\",\"Senior SRE seniority and role match precisely\"],\"gaps\":[],\"explanation\":\"Every technology, tool, and language listed in the job description is present in the candidate's profile. This is a comprehensive, high-confidence match for a senior SRE role with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mo_frontend_vue\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\"],\"testing\":[\"Vitest\",\"Cypress\"]}\n\nJob Summary:\nEnterprise SaaS company seeking a Senior Frontend Engineer to lead the React and Next.js component system. You will own the design system, mentor two junior engineers, establish testing standards with Playwright, and drive TypeScript adoption across the frontend team. GraphQL with Apollo Client is used for data fetching.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript experience aligns with the adoption initiative\",\"Vue.js and React share component-based mental models, making transition feasible\",\"Testing experience with Vitest and Cypress demonstrates testing discipline\"],\"gaps\":[\"No React or Next.js experience; the entire frontend stack is React-based\",\"No Playwright experience despite it being the stated testing standard\",\"No GraphQL or Apollo Client experience\",\"Mid seniority is below Senior; mentoring and leading a design system requires senior-level ownership\"],\"explanation\":\"The candidate is a strong Vue.js engineer but the role is entirely React and Next.js-based with senior leadership expectations. The framework mismatch and seniority gap are both meaningful, though their TypeScript and testing habits are transferable assets.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ingrid_data_platform\",\"seniority\":\"Staff\",\"roles\":[\"Data Engineer\",\"Platform Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"Apache Kafka\",\"dbt\",\"Airflow\",\"Docker\",\"Kubernetes\",\"Databricks\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"Cassandra\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"]}\n\nJob Summary:\nFAANG-scale company hiring a Staff Data Engineer to design the next-generation data platform supporting petabyte-scale analytics. You will architect Spark and Kafka-based streaming pipelines, manage Databricks workloads, define dbt modeling standards, and orchestrate with Airflow. Multi-cloud data warehouse strategy across Snowflake and BigQuery is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Spark, Kafka, Databricks, dbt, Airflow, Snowflake, and BigQuery are all exact matches to stated requirements\",\"Scala alongside Python demonstrates fluency in the Spark-native language stack\",\"Staff seniority is appropriate for platform design and standard-setting at this scale\",\"Event-driven and distributed systems architecture background aligns with petabyte-scale pipeline design\",\"Kubernetes and Docker signal production deployment maturity\"],\"gaps\":[],\"explanation\":\"The candidate's profile is purpose-built for a staff-level data platform engineering role. Every tool, warehouse platform, and architectural pattern named in the job description is directly evidenced with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"robin_django_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"Django\",\"Celery\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nHealthtech startup hiring a Mid-level Backend Engineer to build HIPAA-compliant REST APIs in Django REST Framework. PostgreSQL is the database, Redis for caching, and Celery for background tasks. Docker is used for local development and AWS for production. pytest for test coverage is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Django, Celery, Redis, PostgreSQL, Docker, pytest, and GitHub Actions are all direct stack matches\",\"Mid-level seniority aligns with the role\"],\"gaps\":[\"No AWS experience despite it being the production deployment target\",\"No explicit HIPAA compliance or security-conscious development experience visible in the profile\"],\"explanation\":\"The candidate's application stack aligns well with the role, but the absence of AWS experience is a gap for a production healthtech system. More importantly, there is no signal of HIPAA compliance awareness, which is a specific and non-negotiable requirement in healthcare software engineering.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"viktor_elixir\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Elixir\",\"JavaScript\"],\"tech\":[\"Phoenix\",\"Ecto\",\"Docker\",\"RabbitMQ\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nReal-time gaming backend startup hiring a Senior Elixir Engineer to build low-latency game state synchronization services using Phoenix and Ecto. PostgreSQL is the primary database with Redis for ephemeral state. RabbitMQ handles inter-service messaging. Docker for containers and GitHub Actions for CI. Comprehensive test coverage with ExUnit is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Elixir, Phoenix, Ecto, PostgreSQL, Redis, RabbitMQ, Docker, GitHub Actions, and ExUnit are all exact matches to the stated requirements\",\"Event-driven and distributed systems architecture experience is directly relevant to game state synchronization\",\"Senior seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a precise match for every technology in the job description. Elixir and Phoenix expertise is a rare and specific requirement that the candidate directly satisfies, making this a high-confidence strong match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jess_android_junior\",\"seniority\":\"Junior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Firebase\"],\"databases\":[\"Firestore\"],\"testing\":[\"JUnit\"]}\n\nJob Summary:\nStartup hiring a Senior Android Engineer with Kotlin Multiplatform experience to lead shared business logic development across iOS and Android. You will own the KMP architecture, mentor Android and iOS developers, define module boundaries, and integrate REST APIs. Minimum four years of Android engineering experience is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Kotlin and Jetpack Compose provide the foundational Android development skills\"],\"gaps\":[\"Junior seniority is far below the Senior requirement with a four-year minimum\",\"No Kotlin Multiplatform experience despite it being the central requirement\",\"No mentoring or technical leadership experience at this career stage\",\"No REST API integration or architectural design experience evidenced\",\"Firestore and Firebase focus does not align with a cross-platform shared logic architecture\"],\"explanation\":\"The candidate is at the beginning of their Android career with basic Jetpack Compose and Kotlin skills. The role demands senior-level KMP architecture ownership and team mentoring, neither of which is evidenced. This is a fundamental seniority and skills mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"camila_devrel\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Next.js\",\"React\",\"FastAPI\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"]}\n\nJob Summary:\nDeveloper tools startup hiring a Senior Full Stack Engineer to build internal dashboards and integrations. Stack is React with TypeScript on the frontend, FastAPI Python backend, PostgreSQL for primary data, and Docker for containers. No mobile experience required. AWS deployment knowledge is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React, TypeScript, FastAPI, PostgreSQL, Docker, and Python are all direct stack matches\",\"Next.js experience adds SSR capability beyond the listed requirements\",\"Senior seniority matches the role\"],\"gaps\":[\"No AWS experience for the listed deployment plus\",\"No CI/CD tooling visible in the profile\",\"No testing frameworks evidenced\"],\"explanation\":\"The candidate covers the core application stack well, but the absence of CI/CD tooling and testing frameworks in the profile raises questions about engineering process maturity. For a Senior engineer at a developer tools company, these would typically be expected baseline signals.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"adil_spark_eng\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"PySpark\",\"dbt\",\"Apache Airflow\",\"Docker\"],\"databases\":[\"BigQuery\",\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nMedia analytics company seeking a Senior Data Engineer to migrate batch ETL pipelines to Spark streaming on Databricks. You will write PySpark jobs, orchestrate with Airflow, transform data in dbt, and work with BigQuery as the target warehouse. Scala knowledge is a plus for Spark optimization tasks.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PySpark, Apache Spark, Airflow, dbt, and BigQuery are all direct matches to the core pipeline stack\",\"Scala satisfies the Spark optimization plus requirement\",\"Snowflake familiarity alongside BigQuery shows data warehouse breadth\",\"Senior seniority matches the role\"],\"gaps\":[\"No Databricks experience specifically, though general Spark expertise is directly transferable\"],\"explanation\":\"The candidate covers every stated requirement with direct evidence including the Scala plus. The only minor gap is Databricks-specific platform knowledge, but their deep Spark expertise makes this a trivial ramp-up rather than a real gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"helena_css_designer\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"CSS\"],\"tech\":[\"React\",\"Styled-components\",\"SCSS\",\"Bootstrap\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nProduct startup hiring a Mid-level Frontend Engineer to build performant dashboards in Next.js with TypeScript. State management uses Zustand and data fetching via React Query. Tailwind CSS is the styling system. Playwright is used for E2E testing. Strong TypeScript skills are required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React experience provides a foundation for working with Next.js components\",\"Jest familiarity shows some testing awareness\"],\"gaps\":[\"No TypeScript experience despite it being a strong requirement\",\"No Next.js experience for the SSR-based dashboard stack\",\"No Zustand or React Query experience\",\"No Tailwind CSS; Bootstrap and SCSS are different paradigms\",\"No Playwright; only Jest is listed and there is no E2E testing signal\"],\"explanation\":\"The candidate's React and basic testing background are transferable foundations, but they lack TypeScript, Next.js, and the specific state management and testing tools the role requires. For a role that lists TypeScript as a strong requirement, its complete absence is a dealbreaker without significant ramp-up time.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pierre_golang_svc\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Gin\",\"Docker\",\"Kubernetes\",\"gRPC\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Go testing\"]}\n\nJob Summary:\nLogistics tech company hiring a Mid-level Go Backend Engineer to build microservices with Gin and gRPC, work with Kafka for event streaming, PostgreSQL and Redis for storage, and Kubernetes for orchestration. GitHub Actions for CI. Strong testing practices required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go, Gin, gRPC, Kafka, PostgreSQL, Redis, Docker, Kubernetes, and GitHub Actions are all exact matches to the stated requirements\",\"Microservices and event-driven architecture experience aligns with the system design context\",\"Mid-level seniority matches the role\",\"Go testing experience satisfies the strong testing practices expectation\"],\"gaps\":[],\"explanation\":\"The candidate's profile matches every technology and architectural pattern listed in the job description. Their event-driven microservices background with the precise Go ecosystem toolchain makes this a high-confidence fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"selin_wordpress\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"WordPress\",\"WooCommerce\",\"jQuery\",\"Bootstrap\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nFinttech startup seeking a Senior Full Stack Engineer to build a React and TypeScript frontend with a Node.js NestJS backend. PostgreSQL is the primary database on AWS. The team uses Docker, GitHub Actions, and has high engineering standards including code reviews and comprehensive testing.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"No React or TypeScript experience\",\"No Node.js or NestJS experience\",\"No PostgreSQL experience; only MySQL listed\",\"No Docker or AWS experience\",\"No testing tools or CI/CD visible in the profile\",\"Mid seniority is below the Senior requirement\",\"WordPress and WooCommerce experience is not relevant to this stack\"],\"explanation\":\"The candidate's entire skill set is oriented around the WordPress and PHP ecosystem, which has no meaningful overlap with the React, TypeScript, NestJS, and AWS stack this role requires. The seniority gap compounds the technical mismatch. No transferable signals were identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mateo_llm_eng\",\"seniority\":\"Senior\",\"roles\":[\"AI Engineer\",\"LLM Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"LangChain\",\"LangGraph\",\"Hugging Face Transformers\",\"FastAPI\",\"Docker\",\"AWS\",\"ChromaDB\",\"Ollama\"],\"architecture\":[\"RAG\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Pinecone\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise AI company hiring a Senior LLM Engineer to build multi-agent orchestration systems using LangGraph, implement RAG pipelines with vector databases, fine-tune transformers via Hugging Face, and deploy model APIs on AWS with Docker. LangChain orchestration and Ollama for local model evaluation are used.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LangGraph, LangChain, Hugging Face Transformers, RAG architecture, FastAPI, Docker, AWS, ChromaDB, Pinecone, and Ollama are all exact matches to stated requirements\",\"Senior LLM Engineer role aligns precisely with the position\",\"Multi-agent and RAG architecture background directly addresses the core system design work\"],\"gaps\":[],\"explanation\":\"This candidate's profile is a comprehensive match for every technology, pattern, and tool named in the job description. Their combined LLM engineering and RAG architecture background positions them as an exceptionally strong fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nat_gcp_infra\",\"seniority\":\"Senior\",\"roles\":[\"Cloud Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"Google Cloud\",\"Terraform\",\"Kubernetes\",\"Docker\",\"Pub/Sub\",\"BigQuery\",\"Helm\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\",\"Cloud Build\"]}\n\nJob Summary:\nMedia tech company hiring a Senior Cloud Engineer to manage and scale GCP infrastructure. You will maintain Kubernetes clusters, write Terraform for infrastructure as code, integrate Pub/Sub messaging, and support BigQuery analytics pipelines. Python and Bash scripting are required. Cloud Build experience is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Google Cloud, Terraform, Kubernetes, Pub/Sub, BigQuery, Docker, Helm, Python, and Bash are all direct matches to stated requirements\",\"Cloud Build satisfies the stated plus requirement\",\"Go provides additional scripting capability beyond the baseline\",\"Senior seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate's GCP-native infrastructure background covers every requirement and even the plus item. Their toolchain across Kubernetes, Terraform, and GCP-native services is a precise match for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yasmin_qa_auto\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Playwright\",\"Cypress\",\"Selenium\",\"Appium\",\"Docker\"],\"testing\":[\"Playwright\",\"Cypress\",\"Selenium\",\"pytest\",\"Jest\"]}\n\nJob Summary:\nConsumer tech company hiring a Mid-level Backend Engineer to build REST APIs in Node.js and TypeScript using Express. You will design PostgreSQL schemas, write integration tests, and deploy services on AWS with Docker. API documentation with Swagger is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker experience is transferable to the deployment context\",\"Strong testing background is valuable in any engineering role\"],\"gaps\":[\"No Node.js or TypeScript experience; the entire backend stack is Node-based\",\"No Express experience\",\"No PostgreSQL or any database design experience visible\",\"No AWS experience\",\"No Swagger or API documentation tooling\",\"QA automation focus does not translate to backend API development\"],\"explanation\":\"The candidate's background is primarily in test automation tooling across multiple frameworks, which is a valuable specialty but does not align with building Node.js backend APIs. The absence of the core backend technologies and database skills makes this a poor fit for the described engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"levi_scala_de\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Scala\",\"Python\",\"SQL\"],\"tech\":[\"Apache Spark\",\"Apache Kafka\",\"Apache Flink\",\"Databricks\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"Cassandra\",\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nAdtech company seeking a Senior Data Engineer to build real-time bidding data pipelines using Kafka and Flink. You will process event streams into Cassandra, run batch transforms in Spark on Databricks, and write data contracts in SQL. Scala experience is essential for Flink job development.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kafka, Flink, Spark, Databricks, Cassandra, and Scala are all exact matches to the core requirements\",\"Scala as the primary language directly satisfies the essential Flink development requirement\",\"Event-driven and distributed systems architecture background is directly applicable to real-time bidding pipelines\",\"Senior seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"Every technical requirement in the job description is matched with direct evidence in the candidate's profile. Their Scala-first streaming background with Kafka and Flink expertise is precisely what this real-time adtech pipeline role demands.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tomas_backend_php\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"Python\"],\"tech\":[\"Symfony\",\"Laravel\",\"Docker\",\"Redis\",\"RabbitMQ\"],\"databases\":[\"MySQL\",\"PostgreSQL\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nE-commerce company hiring a Senior Backend Engineer to build high-traffic product catalog and inventory services in Go with the Echo framework. PostgreSQL is the primary database, Redis for caching, and Kafka for event streaming. AWS deployment. Strong concurrency and performance optimization experience in Go is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"PostgreSQL, Redis, and Docker experience is transferable to the infrastructure layer\",\"Senior backend engineering experience demonstrates software design maturity\"],\"gaps\":[\"No Go or Echo experience; the role is entirely Go-based\",\"No Kafka experience; RabbitMQ is a different messaging system\",\"No AWS experience\",\"PHP and Symfony experience is not relevant to this role\"],\"explanation\":\"Despite being a Senior backend engineer, the candidate has no experience in Go, which is the foundational and only accepted language for this role. The messaging system and cloud infrastructure gaps further reduce fit. This is primarily a language mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sara_ios_lead\",\"seniority\":\"Lead\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Combine\",\"XCTest\",\"Fastlane\",\"Firebase\"],\"architecture\":[\"Modular Architecture\",\"Clean Architecture\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"]}\n\nJob Summary:\nConsumer subscription app hiring a Lead iOS Engineer to own the iOS architecture, mentor a team of four iOS developers, drive SwiftUI adoption from legacy UIKit code, and establish testing standards with XCTest. Fastlane for release automation and GitHub Actions for CI. Clean architecture patterns required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SwiftUI, UIKit, XCTest, Fastlane, GitHub Actions, and Clean Architecture are all exact matches to stated requirements\",\"Lead seniority and iOS role align precisely with the team ownership and mentoring expectation\",\"Combine demonstrates reactive programming depth relevant to SwiftUI migration\",\"Modular architecture experience complements the clean architecture requirement\"],\"gaps\":[],\"explanation\":\"The candidate's Lead iOS engineering background with the exact toolchain \u2014 including SwiftUI migration experience from UIKit, testing standards via XCTest, and Fastlane automation \u2014 makes them a comprehensive match for every dimension of this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"arjun_fastapi_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"Celery\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nB2B platform company hiring a Senior Backend Engineer to lead API design and scalability improvements for a Python-based system serving enterprise clients. Stack is FastAPI, PostgreSQL, Redis, Celery, Docker on AWS. You will define API contracts, contribute to architecture decisions, and mentor two junior engineers.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI, Celery, Redis, PostgreSQL, Docker, GitHub Actions, and pytest are all direct stack matches\",\"Python fluency satisfies the primary language requirement\"],\"gaps\":[\"Mid seniority is one level below Senior; API contract definition and mentoring are Senior-level expectations\",\"No AWS experience for the production deployment environment\",\"No architecture decision-making experience evidenced at Mid level\"],\"explanation\":\"The candidate's stack alignment is excellent, covering every technology in the role. However, the seniority gap is meaningful because the employer expects senior-level API leadership and mentoring, and AWS production experience is absent despite being the deployment target.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"oluwaseun_infra\",\"seniority\":\"Senior\",\"roles\":[\"Platform Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"AWS\",\"Helm\",\"Prometheus\",\"Grafana\",\"Docker\",\"Consul\"],\"architecture\":[\"Cloud-Native\",\"Service Mesh\"],\"ci_cd\":[\"Argo CD\",\"GitHub Actions\"]}\n\nJob Summary:\nFinttech scale-up hiring a Senior Platform Engineer to build an internal developer platform on AWS Kubernetes. You will write Terraform modules, manage Helm releases, implement service discovery with Consul, and maintain observability using Prometheus and Grafana. GitOps deployments via Argo CD required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Terraform, AWS, Helm, Prometheus, Grafana, Consul, Argo CD, and Docker are all exact matches to stated requirements\",\"Service mesh architecture experience is relevant to service discovery and Consul usage\",\"Senior seniority aligns with the role\",\"Go and Python scripting provides strong automation capability\"],\"gaps\":[],\"explanation\":\"The candidate's profile covers every technology in the job description including Consul for service discovery, which is a specific and differentiating requirement. Their cloud-native and service mesh background makes them highly prepared for this internal developer platform role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cathy_ds_intern\",\"seniority\":\"Intern\",\"languages\":[\"Python\"],\"tech\":[\"Pandas\",\"NumPy\",\"Matplotlib\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nStartup offering a Data Science Internship for students. You will assist with data cleaning, exploratory analysis, and visualization using Python and Pandas. Basic SQL knowledge is required. No machine learning experience needed. This is a mentored, learning-focused role.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Python, Pandas, and NumPy are the core tools for data cleaning and EDA as described\",\"Matplotlib directly addresses the visualization requirement\",\"MySQL satisfies the basic SQL requirement\",\"Intern seniority matches the role and mentored context\"],\"gaps\":[],\"explanation\":\"For a mentored internship focused on data cleaning and visualization with no ML requirement, the candidate's Python data science toolkit is a direct and sufficient match. No gaps were identified for the defined scope of this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"zara_react_native\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React Native\",\"Expo\",\"Redux\",\"Firebase\"],\"databases\":[\"Firestore\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Detox\"]}\n\nJob Summary:\nConsumer fitness app hiring a Mid-level React Native Engineer to build cross-platform iOS and Android features. Expo is used for the build pipeline. Redux for state management, Firestore for real-time data, and SQLite for offline storage. Jest for unit testing and Detox for E2E. TypeScript throughout.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React Native, Expo, Redux, Firestore, SQLite, Jest, Detox, TypeScript, and GitHub Actions are all exact stack matches\",\"Mid-level seniority aligns with the role\",\"Mobile engineer role matches precisely\"],\"gaps\":[],\"explanation\":\"Every technology in the job description is present in the candidate's profile. The precision of the match across state management, storage, and testing tools makes this a high-confidence strong fit with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"chen_devops_senior\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Jenkins\",\"Ansible\",\"Docker\",\"AWS\",\"Terraform\",\"Nginx\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nSaaS company hiring a Senior DevOps Engineer to modernize their CI/CD platform from Jenkins to GitHub Actions, introduce Kubernetes on EKS, implement observability with Datadog, and adopt GitOps principles using Argo CD. Terraform for infrastructure as code is expected. This is a greenfield modernization effort.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform and AWS experience is directly relevant to the infrastructure modernization effort\",\"Docker provides the containerization foundation for the Kubernetes transition\",\"Senior seniority matches the role\",\"Jenkins-to-GitHub Actions migration is directly relevant given the candidate has Jenkins experience to migrate from\"],\"gaps\":[\"No Kubernetes or EKS experience\",\"No Datadog or modern observability tooling\",\"No Argo CD or GitOps experience\",\"No GitHub Actions experience despite it being the migration target\"],\"explanation\":\"The candidate brings AWS and infrastructure as code experience that is relevant, and their Jenkins background provides useful context for a migration project. However, the modernization targets \u2014 Kubernetes, Argo CD, Datadog, and GitHub Actions \u2014 are all gaps that represent the entire scope of the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"eva_haskell_dev\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Haskell\",\"Scala\",\"Python\"],\"tech\":[\"Apache Kafka\",\"Docker\",\"PostgreSQL\",\"Akka\"],\"architecture\":[\"Functional\",\"Distributed System\",\"Event-Driven\"]}\n\nJob Summary:\nFinttech infrastructure company hiring a Senior Backend Engineer to build payment processing services in Scala with Akka Streams. Kafka is used for event streaming and PostgreSQL for persistence. Docker for containers. The team values functional programming principles and deep type system knowledge.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Scala and Akka are exact matches to the core application stack\",\"Kafka and PostgreSQL directly satisfy the event streaming and persistence requirements\",\"Haskell background demonstrates deep functional programming and type system expertise, which is explicitly valued\",\"Distributed system and event-driven architecture experience aligns with payment processing design\",\"Senior seniority matches the role\"],\"gaps\":[],\"explanation\":\"The candidate's Scala, Akka, and Kafka stack is a precise technical match. Their Haskell background is a differentiating strength for a team that explicitly values functional programming principles, making them an exceptionally strong candidate.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priscilla_csharp\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C#\",\"SQL\"],\"tech\":[\"ASP.NET\",\"Entity Framework\",\"Docker\",\"Azure\"],\"architecture\":[\"Layered Architecture\"],\"databases\":[\"MS SQL Server\",\"PostgreSQL\"],\"ci_cd\":[\"Azure DevOps\",\"Azure Pipelines\"],\"testing\":[\"NUnit\",\"xUnit\"]}\n\nJob Summary:\nEnterprise software company hiring a Mid-level .NET Backend Developer to maintain and extend ASP.NET services connected to SQL Server. Entity Framework for ORM, Azure for cloud hosting, and Azure DevOps for CI/CD. Unit testing with NUnit or xUnit is expected. C# fluency is mandatory.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"C#, ASP.NET, Entity Framework, MS SQL Server, Azure, Azure DevOps, Azure Pipelines, NUnit, and xUnit are all exact matches to stated requirements\",\"Docker experience adds deployment flexibility\",\"Mid-level seniority matches the role\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a comprehensive match for every technology in the job description, including both testing frameworks. Their .NET and Azure ecosystem fluency makes them a precise and high-confidence fit for this enterprise backend role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kwame_fullstack_junior\",\"seniority\":\"Junior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Node.js\",\"Express.js\",\"Docker\"],\"databases\":[\"MongoDB\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nProduct startup seeking a Senior Full Stack Engineer to lead the architecture of a React and Node.js platform, establish engineering standards, conduct regular code reviews, and mentor a team of five engineers. Minimum five years of full stack experience required. Proven experience owning technical decisions end to end is essential.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React, Node.js, Express.js, PostgreSQL, MongoDB, Docker, and Jest are solid technical matches to the stack\"],\"gaps\":[\"Junior seniority is far below the Senior requirement with a five-year minimum\",\"No demonstrated leadership, mentoring, or code review experience\",\"No architectural decision-making experience evidenced at this career stage\",\"Minimum experience requirement of five years is not met\"],\"explanation\":\"The candidate's technical stack aligns well with the platform, but this is a Senior role centered on engineering leadership that requires team mentoring, architecture ownership, and establishing standards well beyond what a Junior engineer would provide. The technical signals are promising but the role is not appropriate for their current career stage.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"marina_rxswift\",\"seniority\":\"Senior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"RxSwift\",\"Alamofire\",\"XCTest\",\"Fastlane\"],\"architecture\":[\"Clean Architecture\",\"MVVM\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nStreaming app company seeking a Senior iOS Engineer to maintain a legacy RxSwift codebase while progressively migrating to Combine and SwiftUI. You will write unit and UI tests with XCTest, automate releases with Fastlane, and work in a clean architecture with MVVM patterns.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"RxSwift experience is directly relevant to maintaining and migrating the legacy codebase\",\"SwiftUI, UIKit, XCTest, Fastlane, Clean Architecture, and MVVM are all exact matches\",\"Alamofire demonstrates REST API integration experience relevant to a streaming app\",\"Senior seniority aligns with the role\"],\"gaps\":[\"No Combine experience, though SwiftUI familiarity makes the transition straightforward\"],\"explanation\":\"The candidate's RxSwift expertise is a rare and specific match for the legacy codebase maintenance requirement. Combined with SwiftUI and clean architecture experience, they are well-positioned for both the maintenance and migration dimensions of this role. The absence of Combine is a minor gap given their SwiftUI background.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tanaka_swe_principal\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\",\"Go\",\"Java\"],\"tech\":[\"React\",\"Next.js\",\"FastAPI\",\"Spring Boot\",\"Kafka\",\"Docker\",\"Kubernetes\",\"AWS\"],\"architecture\":[\"Domain-Driven Design\",\"Microservices\",\"Event-Driven\",\"Hexagonal Architecture\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"Redis\",\"DynamoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nGrowth-stage company hiring a Principal Software Architect to define system design standards, evaluate architectural trade-offs, and guide five engineering teams. Deep knowledge of microservices, DDD, and event-driven architecture is required. Experience across multiple language ecosystems and cloud-native deployment is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Domain-Driven Design, Microservices, Event-Driven, and Hexagonal Architecture are all direct matches to the stated requirements\",\"Polyglot background in TypeScript, Python, Go, and Java satisfies the multi-language ecosystem expectation\",\"Principal seniority aligns with cross-team architectural guidance and standard-setting\",\"Kubernetes, Argo CD, and AWS satisfy the cloud-native deployment requirement\",\"Full stack and architectural roles combined indicate breadth needed for principal-level system design\"],\"gaps\":[],\"explanation\":\"The candidate's profile is purpose-built for a principal architect role, with direct evidence across every stated architectural pattern, multiple language ecosystems, and cloud-native tooling. No meaningful gaps were identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"benedict_ml_platform\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"Platform Engineer\"],\"languages\":[\"Python\",\"Go\"],\"tech\":[\"MLflow\",\"Kubeflow\",\"Docker\",\"Kubernetes\",\"FastAPI\",\"TensorFlow\",\"AWS\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"]}\n\nJob Summary:\nData company seeking a Senior MLOps Engineer to build and maintain an ML platform. Responsibilities include managing model training pipelines with Kubeflow, experiment tracking with MLflow, containerized model serving via Kubernetes, and building internal APIs with FastAPI. AWS for cloud infrastructure. Python is required and Go is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubeflow, MLflow, Kubernetes, FastAPI, Docker, AWS, and Python are all exact matches to the stated requirements\",\"Go satisfies the strong plus requirement\",\"Combined ML Engineer and Platform Engineer background aligns with the MLOps domain\",\"Senior seniority matches the role\"],\"gaps\":[],\"explanation\":\"The candidate covers every required technology including the Go plus requirement. Their dual ML and platform engineering background is precisely the profile an MLOps role requires, bridging model development and production infrastructure.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elena_devops_intern\",\"seniority\":\"Intern\",\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"Linux\",\"GitHub Actions\"]}\n\nJob Summary:\nTech company offering a DevOps Internship for students. You will write automation scripts in Python or Bash, maintain Docker-based development environments, and contribute to GitHub Actions workflows under mentor supervision. No cloud or Kubernetes experience required at this stage.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Python and Bash scripting directly address the automation script requirement\",\"Docker satisfies the development environment maintenance expectation\",\"GitHub Actions experience is a direct match for the workflow contribution requirement\",\"Intern seniority matches the role and mentor structure\"],\"gaps\":[],\"explanation\":\"For a mentored DevOps internship scoped to scripting, Docker, and CI workflows with no cloud requirement, the candidate's toolkit is a precise and complete match. No gaps were identified within the defined scope of this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kwabena_svelte\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Svelte\",\"SvelteKit\",\"Tailwind CSS\",\"Vite\"],\"testing\":[\"Vitest\",\"Playwright\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nStartup hiring a Mid-level Frontend Engineer to build a content platform using SvelteKit and Tailwind CSS. TypeScript is required. Vitest for unit tests and Playwright for E2E tests. Vite is the build tool and GitHub Actions for CI. Performance and SEO optimization experience is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SvelteKit, Svelte, Tailwind CSS, TypeScript, Vitest, Playwright, Vite, and GitHub Actions are all exact matches to stated requirements\",\"Mid-level seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a tool-for-tool match against every requirement in the job description. SvelteKit expertise is a rare and specific skill that directly satisfies the primary framework requirement, making this a high-confidence strong fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"olena_ruby_backend\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Ruby\",\"SQL\"],\"tech\":[\"Ruby on Rails\",\"Sidekiq\",\"Docker\",\"Heroku\",\"Nginx\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"RSpec\"]}\n\nJob Summary:\nSaaS company seeking a Senior Backend Engineer to migrate a legacy Ruby on Rails monolith to a Go-based microservices architecture. You will design gRPC interfaces, build new services in Go with Gin, and maintain the Rails codebase during transition. AWS deployment on ECS. Minimum three years of Go experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Deep Ruby on Rails experience is valuable for the monolith maintenance dimension of the role\",\"RSpec and Sidekiq background demonstrate solid Rails engineering habits\"],\"gaps\":[\"No Go experience despite a minimum three-year requirement\",\"No gRPC or microservices design experience\",\"No AWS or ECS experience; only Heroku listed\",\"Migration architecture ownership requires Go proficiency the candidate does not have\"],\"explanation\":\"The candidate is a strong Rails engineer, which is useful for the maintenance portion of the transition, but the role's primary mandate is building Go microservices \u2014 a language entirely absent from their profile. The three-year Go minimum makes this a fundamental disqualifying gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"soren_dbt_analytics\",\"seniority\":\"Mid\",\"roles\":[\"Analytics Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Looker\",\"Airflow\",\"Metabase\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"]}\n\nJob Summary:\nRetail company seeking a Mid-level Analytics Engineer to build dbt models in Snowflake, create Tableau dashboards for the business team, and orchestrate jobs with Airflow. SQL is the primary language with Python for scripting.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt and Airflow are direct matches to the core pipeline and orchestration tools\",\"SQL and Python satisfy the mandatory language requirements\",\"Mid-level seniority aligns with the role\"],\"gaps\":[\"No Snowflake experience; the candidate has BigQuery which is a different warehouse with different SQL dialects and optimization patterns\",\"No Tableau experience; Looker and Metabase are different visualization tools\"],\"explanation\":\"The candidate has strong analytics engineering fundamentals with dbt and Airflow, but both the data warehouse and the visualization tool are mismatches. BigQuery and Snowflake are meaningfully different platforms, and Tableau is not interchangeable with Looker or Metabase for business stakeholder reporting.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nkechi_cyber\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\",\"AppSec Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"AWS\",\"Kubernetes\",\"Vault\",\"Terraform\",\"Docker\",\"Sentry\"],\"architecture\":[\"Cloud-Native\",\"Zero Trust\"]}\n\nJob Summary:\nFintech company hiring a Senior Application Security Engineer to integrate security scanning into CI/CD pipelines, conduct threat modeling for microservices, implement secrets management with HashiCorp Vault, and harden Kubernetes workloads on AWS. Python or Go scripting for tooling is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"HashiCorp Vault, Kubernetes, AWS, Terraform, and Docker directly match the core security infrastructure requirements\",\"Python and Go scripting satisfies the mandatory tooling requirement\",\"AppSec Engineer role and Senior seniority align with threat modeling and hardening responsibilities\",\"Zero Trust architecture background is directly relevant to a fintech security posture\"],\"gaps\":[\"No explicit SAST/DAST or CI pipeline security scanning tools mentioned such as Snyk or Semgrep\"],\"explanation\":\"The candidate brings strong cloud security and secrets management expertise with a directly relevant toolchain. The minor gap is the absence of specific security scanning tool experience, but their Go and Python background means they can integrate and operate these tools with minimal ramp-up.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lydia_ts_fullstack\",\"seniority\":\"Junior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Node.js\",\"Prisma\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nStartup hiring a Junior Full Stack Engineer to contribute to a TypeScript monorepo with React frontend and Node.js backend, using Prisma as the ORM and PostgreSQL for data. Docker for local development. GitHub Actions for CI. Small team with senior mentorship available.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"TypeScript, React, Node.js, Prisma, PostgreSQL, and Docker are all exact matches to the described stack\",\"Junior seniority matches the role and the available senior mentorship context\"],\"gaps\":[\"No GitHub Actions experience listed\"],\"explanation\":\"The candidate's profile covers every core technology in the job description precisely, including the ORM and database. The only gap is the absence of GitHub Actions experience, which is a minor gap for a junior role with senior mentorship available.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hugo_data_sci\",\"seniority\":\"Mid\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"Pandas\",\"NumPy\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nManufacturing company seeking a Mid-level Data Scientist to develop predictive maintenance models using sensor time-series data. Primary tools are Python, XGBoost, and scikit-learn. Models will be tracked with MLflow and served via REST APIs built with FastAPI. SQL knowledge required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python is the primary language and is the candidate's strongest language\",\"Pandas and NumPy are foundational tools directly useful for time-series feature engineering\",\"R provides additional statistical analysis capability\"],\"gaps\":[\"No XGBoost or scikit-learn experience, which are the primary stated modeling tools\",\"No MLflow for experiment tracking\",\"No FastAPI for model serving\",\"PyTorch and Hugging Face background is oriented toward deep learning and NLP, not the tabular gradient boosting focus of predictive maintenance\"],\"explanation\":\"The candidate's Python data science foundation is relevant, but their toolset is oriented toward deep learning and NLP while the role is focused on tabular gradient boosting models with specific tools they have not evidenced. MLflow and FastAPI are additional operational gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"paulo_staff_eng\",\"seniority\":\"Staff\",\"roles\":[\"Backend Engineer\",\"Software Architect\"],\"languages\":[\"Go\",\"Python\",\"Java\"],\"tech\":[\"Kubernetes\",\"Kafka\",\"gRPC\",\"Docker\",\"AWS\",\"Terraform\"],\"architecture\":[\"Microservices\",\"Domain-Driven Design\",\"Event-Driven\",\"CQRS\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\",\"Cassandra\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nScale-up company hiring a Staff Backend Engineer to set technical direction for three backend teams, design cross-service APIs using gRPC, evolve the Kafka event streaming architecture, and work with domain-driven design principles. Kubernetes on AWS for deployment. Minimum eight years of backend engineering experience.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"gRPC, Kafka, Kubernetes, AWS, DDD, CQRS, and Event-Driven architecture are all exact matches to stated requirements\",\"Staff seniority is appropriate for setting technical direction across three teams\",\"Polyglot background in Go, Python, and Java suits cross-team technical leadership\",\"DynamoDB and Cassandra alongside PostgreSQL demonstrate distributed data storage breadth\",\"Argo CD and GitHub Actions signal GitOps and modern CI/CD maturity\"],\"gaps\":[],\"explanation\":\"The candidate's Staff-level background spans every technical and architectural requirement in this role. Their domain-driven design and CQRS expertise alongside the Kafka and gRPC toolchain makes them a precisely qualified candidate for this technical leadership position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mina_vue_junior\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"Vue.js\",\"Bootstrap\",\"jQuery\"]}\n\nJob Summary:\nSaaS startup hiring a Junior Frontend Engineer to build dashboard components in React and TypeScript. You will use Tailwind CSS for styling and React Query for data fetching. Jest and Testing Library are used for unit tests. GitHub Actions for CI. No Vue.js experience relevant.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"No React experience; Vue.js and React are different frameworks with different paradigms\",\"No TypeScript experience despite it being required throughout\",\"No Tailwind CSS experience; Bootstrap is a different styling approach\",\"No React Query for data fetching\",\"No Jest or Testing Library experience\",\"No GitHub Actions CI experience\"],\"explanation\":\"The candidate's skill set is centered entirely on Vue.js, Bootstrap, and jQuery, with no overlap with the React and TypeScript ecosystem this role requires. The employer explicitly noted Vue.js experience is not relevant. No meaningful transferable technical signals were identified beyond basic JavaScript familiarity.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rashida_platform_lead\",\"seniority\":\"Lead\",\"roles\":[\"Platform Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"AWS\",\"Helm\",\"Argo CD\",\"Prometheus\",\"Grafana\",\"Vault\",\"Pulumi\"],\"architecture\":[\"Cloud-Native\",\"Multi-Tenant\",\"Service Mesh\"],\"ci_cd\":[\"Argo CD\",\"GitHub Actions\",\"Tekton\"]}\n\nJob Summary:\nLate-stage startup hiring a Lead Platform Engineer to own the Kubernetes platform across multiple engineering tenants on AWS, implement policy-as-code, manage secrets with Vault, maintain GitOps via Argo CD, and lead a team of three platform engineers. Terraform and Pulumi are both in use.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Terraform, Pulumi, AWS, Argo CD, Vault, Prometheus, Grafana, and Helm are all exact matches to the stated requirements\",\"Multi-tenant and cloud-native architecture experience directly addresses the multi-tenant platform ownership expectation\",\"Lead seniority is appropriate for team leadership of three platform engineers\",\"Tekton experience demonstrates CI pipeline depth beyond the listed tools\"],\"gaps\":[\"No explicit policy-as-code tooling mentioned, such as OPA or Kyverno\"],\"explanation\":\"The candidate's profile covers every technology in the job description with direct evidence. Their multi-tenant platform experience and Lead seniority make them well-suited for both the technical and team leadership dimensions. The policy-as-code gap is minor given their depth in adjacent security and governance tooling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tomoko_react_senior\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Redux\",\"Tailwind CSS\",\"Storybook\",\"Webpack\",\"Vite\"],\"testing\":[\"Jest\",\"Playwright\",\"React Testing Library\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nE-learning platform hiring a Senior Frontend Engineer to maintain a large React and TypeScript codebase, optimize Webpack build performance, build and document components in Storybook, and write comprehensive tests. Playwright for E2E and Jest with React Testing Library for unit tests. GitHub Actions for CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React, TypeScript, Webpack, Storybook, Playwright, Jest, React Testing Library, and GitHub Actions are all exact matches to stated requirements\",\"Vite experience alongside Webpack signals broad build tooling knowledge relevant to optimization work\",\"Senior seniority aligns with the role\",\"Redux and Next.js experience add architectural depth beyond the baseline\"],\"gaps\":[],\"explanation\":\"The candidate's profile matches every tool in the job description with direct evidence, including the specific testing combination and build optimization tooling. No meaningful gaps were identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"idris_cloud_junior\",\"seniority\":\"Junior\",\"roles\":[\"Cloud Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"AWS\",\"Docker\",\"Terraform\"]}\n\nJob Summary:\nMid-size company hiring a Senior Cloud Architect to design a hybrid cloud strategy, lead AWS and Azure multi-cloud architecture decisions, define FinOps practices, and mentor a cloud team of six engineers. Strong Kubernetes and Terraform expertise is required. Minimum seven years of cloud engineering experience.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"AWS and Terraform provide foundational cloud experience\",\"Docker shows container awareness\"],\"gaps\":[\"Junior seniority is far below the Senior Architect requirement with a seven-year minimum\",\"No Azure experience for a multi-cloud architecture role\",\"No Kubernetes experience despite it being required\",\"No FinOps or cloud cost optimization experience\",\"No team mentoring or leadership experience at this career stage\",\"Architecture and multi-cloud strategy design requires seniority well beyond Junior level\"],\"explanation\":\"The candidate is at the start of their cloud career and while they show relevant foundational tools, the role demands senior architect-level expertise including multi-cloud design, FinOps, Kubernetes, and team mentoring \u2014 none of which are evidenced. This is a severe seniority and scope mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"anders_backend_senior\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"FastAPI\",\"Docker\",\"AWS\",\"Celery\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"CircleCI\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nHR tech platform seeking a Senior Backend Engineer to build and scale REST APIs in Python using FastAPI, manage async job processing with Celery, and use PostgreSQL and Redis on AWS. Comprehensive pytest coverage is expected. Docker and CI with GitHub Actions are used.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"FastAPI, Celery, Redis, PostgreSQL, Docker, AWS, GitHub Actions, and pytest are all exact matches to stated requirements\",\"Senior seniority aligns with the role\",\"Django experience demonstrates deep Python web framework knowledge as additional context\",\"CircleCI alongside GitHub Actions shows CI breadth\"],\"gaps\":[],\"explanation\":\"The candidate's profile covers every technology in the job description with direct evidence. Their Python backend expertise with FastAPI, async job processing, and AWS deployment makes them a comprehensive and high-confidence fit for this HR tech role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dan_node_senior\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Express.js\",\"Node.js\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nScale-up company hiring a Senior Backend Engineer to build a high-throughput NestJS platform with TypeScript, PostgreSQL, Redis, and Kafka for async messaging. Docker and AWS for deployment. GitHub Actions for CI. The team uses GraphQL for internal APIs and expects comprehensive test coverage.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Node.js, TypeScript, PostgreSQL, Redis, Docker, AWS, GitHub Actions, Jest, and Supertest are strong foundational matches\",\"Senior seniority aligns with the role\"],\"gaps\":[\"No NestJS experience; Express.js is a different framework with a different architecture paradigm\",\"No Kafka experience for the async messaging requirement\",\"No GraphQL experience despite it being the internal API layer\"],\"explanation\":\"The candidate has a strong Node.js and TypeScript backend background with good infrastructure coverage, but NestJS is a meaningfully different framework from Express.js, and both Kafka and GraphQL are absent. These gaps span the async messaging and API layers that are core to the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sara_data_mid\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Airflow\",\"dbt\",\"Docker\",\"Pandas\"],\"databases\":[\"PostgreSQL\",\"Redshift\"]}\n\nJob Summary:\nStreaming company seeking a Senior Data Engineer to build real-time Kafka pipelines, orchestrate batch jobs with Airflow, transform data in dbt on Snowflake, and manage infrastructure on AWS with Terraform. PySpark experience is required for large-scale processing.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Airflow and dbt are direct matches to the orchestration and transformation requirements\",\"Python and SQL fluency are foundational to the role\"],\"gaps\":[\"Mid seniority is below the Senior requirement\",\"No Kafka or streaming experience despite it being a core requirement\",\"No Snowflake experience; Redshift is a different warehouse\",\"No PySpark or Spark experience, which is listed as required\",\"No Terraform or AWS infrastructure experience\"],\"explanation\":\"The candidate's Airflow and dbt experience aligns with part of the role, but multiple core requirements are missing including streaming with Kafka, PySpark processing, and Snowflake. The seniority gap adds further concern for a role that requires production ownership across a complex streaming stack.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"felix_nextjs_mid\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"Tailwind CSS\",\"Prisma\",\"Docker\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nHealthtech company hiring a Senior Full Stack Engineer to architect multi-tenant SaaS features in Next.js and Python FastAPI. The candidate will define database schemas, mentor two developers, lead code reviews, and drive technical roadmap decisions. Multi-tenancy and HIPAA-aware development experience is strongly preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js, React, Tailwind CSS, PostgreSQL, Docker, GitHub Actions, Jest, and Playwright are strong stack matches on the frontend side\",\"Mid-level full stack background provides relevant product engineering experience\"],\"gaps\":[\"Mid seniority is below Senior; mentoring and technical roadmap ownership are Senior-level expectations\",\"No FastAPI or Python backend experience\",\"No multi-tenancy or HIPAA-aware development experience despite these being strongly preferred\",\"Prisma ORM does not replace FastAPI backend expertise\"],\"explanation\":\"The candidate covers the Next.js and frontend portion of the stack well, but the role is equally focused on a Python FastAPI backend with multi-tenancy, where the candidate has no evidenced experience. The seniority gap further limits their readiness for the architectural leadership this role requires.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wei_spring_senior\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Spring\",\"Docker\",\"AWS\",\"RabbitMQ\",\"Nginx\"],\"architecture\":[\"Microservices\",\"Layered Architecture\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MySQL\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\",\"Testcontainers\"]}\n\nJob Summary:\nInsurance tech company hiring a Senior Java Backend Engineer to build policy management microservices using Spring Boot. PostgreSQL and Redis are the primary databases with RabbitMQ for messaging. Services deploy on AWS with Docker. We expect comprehensive test coverage using JUnit, Mockito, and Testcontainers for integration tests. Jenkins is the CI system.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Spring Boot, PostgreSQL, Redis, RabbitMQ, Docker, AWS, JUnit, Mockito, and Testcontainers are all exact matches to the stated requirements\",\"Jenkins CI aligns with the stated CI system\",\"Microservices architecture experience is directly relevant to the policy management service design\",\"Senior Java seniority matches the role\"],\"gaps\":[],\"explanation\":\"The candidate's profile covers every technology and testing tool listed in the job description with direct evidence. Their insurance-adjacent backend experience in a microservices context makes them a high-confidence fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amina_react_mid\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Zustand\",\"Tailwind CSS\",\"Radix UI\"],\"testing\":[\"Jest\",\"Testing Library\",\"Playwright\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nB2B SaaS startup seeking a Mid-level Frontend Engineer to build accessible dashboard components in React and TypeScript. Zustand is used for state management, Radix UI for accessible primitives, and Tailwind CSS for styling. Next.js for the application framework. Testing with Jest, Testing Library, and Playwright. GitHub Actions for CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React, Next.js, TypeScript, Zustand, Radix UI, Tailwind CSS, Jest, Testing Library, Playwright, and GitHub Actions are all exact matches\",\"Mid-level seniority aligns with the role\",\"Radix UI experience directly addresses the accessible components requirement\"],\"gaps\":[],\"explanation\":\"Every technology in the job description is evidenced in the candidate's profile, including the specific UI primitive library chosen for accessibility. This is a precise, high-confidence match with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"joel_flutter_senior\",\"seniority\":\"Senior\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"Kotlin\"],\"tech\":[\"Flutter\",\"Android SDK\",\"Jetpack Compose\",\"Firebase\",\"Riverpod\"],\"databases\":[\"Firestore\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"Flutter Test\",\"Mockito\"]}\n\nJob Summary:\nConsumer app startup hiring a Senior Flutter Engineer to build a cross-platform mobile app. Dart is the primary language, Riverpod for state management, Firestore for real-time sync, and SQLite for offline storage. Fastlane and GitHub Actions handle release and CI automation. Testing with Flutter Test framework is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Flutter, Dart, Riverpod, Firestore, SQLite, Fastlane, GitHub Actions, and Flutter Test are all direct matches to stated requirements\",\"Senior seniority aligns with the role\",\"Android SDK and Jetpack Compose experience signals native mobile depth as a complement to Flutter\"],\"gaps\":[],\"explanation\":\"The candidate's Flutter ecosystem expertise covers every requirement including the specific state management library and testing framework. Their native Android background further reinforces cross-platform mobile credibility.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lars_terraform_lead\",\"seniority\":\"Lead\",\"roles\":[\"Platform Engineer\",\"DevOps Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Terraform\",\"Kubernetes\",\"AWS\",\"Helm\",\"Vault\",\"Consul\",\"Docker\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Cloud-Native\",\"Multi-Tenant\",\"Service Mesh\"],\"ci_cd\":[\"Argo CD\",\"GitHub Actions\"]}\n\nJob Summary:\nGrowth-stage fintech hiring a Lead Platform Engineer to own infrastructure for a multi-tenant payments platform on AWS. You will manage Kubernetes with Helm, run GitOps deployments via Argo CD, handle secrets with Vault, and maintain service mesh reliability with Consul. Prometheus and Grafana for observability. Terraform for IaC.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Terraform, Kubernetes, Helm, Vault, Consul, Argo CD, Prometheus, Grafana, AWS, and Docker are all exact matches to stated requirements\",\"Multi-tenant and service mesh architecture experience directly addresses the payments platform context\",\"Lead seniority aligns with the ownership expectation\",\"Go and Python scripting provide strong automation capability\"],\"gaps\":[],\"explanation\":\"The candidate's profile covers every technology in the job description with precision, including the less common Consul service mesh requirement. Their multi-tenant infrastructure background makes them exceptionally well-suited for a payments platform with strict isolation needs.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kofi_django_senior\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"FastAPI\",\"Celery\",\"Docker\",\"AWS\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nEdtech platform hiring a Senior Backend Engineer to build REST APIs in FastAPI, manage background task queues with Celery, store content in PostgreSQL and MongoDB, and deploy on AWS with Docker. pytest for test coverage. GitHub Actions for CI pipelines.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"FastAPI, Celery, PostgreSQL, MongoDB, Redis, Docker, AWS, pytest, and GitHub Actions are all exact matches to stated requirements\",\"Senior seniority aligns with the role\",\"Django experience shows deep Python web framework breadth\"],\"gaps\":[],\"explanation\":\"The candidate's Python backend profile matches every technology in the job description directly. Their dual FastAPI and Django background demonstrates Python web API depth beyond the baseline requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tomislav_go_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Gin\",\"gRPC\",\"Docker\",\"Kubernetes\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Go testing\"]}\n\nJob Summary:\nLogistics startup hiring a Mid-level Go Backend Engineer to build microservices with Gin and gRPC, integrate Kafka for shipment event streaming, manage PostgreSQL and Redis, and deploy on Kubernetes. GitHub Actions for CI. Strong Go testing practices expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go, Gin, gRPC, Kafka, PostgreSQL, Redis, Docker, Kubernetes, GitHub Actions, and Go testing are all exact matches to stated requirements\",\"Event-driven and microservices architecture experience aligns with the shipment event streaming design\",\"Mid-level seniority matches the role\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a tool-for-tool match against every requirement in the job description. Their event-driven microservices background with the precise Go ecosystem toolchain makes this a high-confidence fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ozan_data_principal\",\"seniority\":\"Principal\",\"roles\":[\"Data Engineer\",\"Software Architect\"],\"languages\":[\"Python\",\"Scala\",\"SQL\",\"Java\"],\"tech\":[\"Apache Spark\",\"Apache Kafka\",\"Apache Flink\",\"dbt\",\"Airflow\",\"Databricks\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Event-Driven\",\"Distributed System\",\"Lambda Architecture\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"Cassandra\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"]}\n\nJob Summary:\nFAANG-scale company hiring a Principal Data Engineer to define the data platform architecture strategy, lead four data engineering teams, drive adoption of Spark and Flink streaming pipelines, standardize on dbt and Airflow for batch processing, and select the multi-cloud warehouse strategy across Snowflake and BigQuery. Databricks expertise required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Spark, Flink, dbt, Airflow, Databricks, Snowflake, and BigQuery are all direct matches to stated requirements\",\"Principal seniority is appropriate for multi-team leadership and platform strategy\",\"Lambda architecture background demonstrates the hybrid batch and streaming design thinking the role requires\",\"Polyglot in Python, Scala, SQL, and Java suits cross-team technical leadership at FAANG scale\",\"Cassandra experience adds distributed storage breadth\"],\"gaps\":[],\"explanation\":\"The candidate's Principal-level background spans every tool and architectural pattern named in the job description, including the multi-cloud warehouse strategy and both streaming frameworks. This is a comprehensive fit for the most senior data engineering scope described.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jada_embedded_mid\",\"seniority\":\"Mid\",\"roles\":[\"Embedded Engineer\"],\"languages\":[\"C\",\"C++\",\"Python\"],\"tech\":[\"FreeRTOS\",\"CMake\",\"Docker\",\"Makefile\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Unity Test\",\"pytest\"]}\n\nJob Summary:\nAutomotive startup hiring a Mid-level Embedded Software Engineer to write real-time firmware for ARM Cortex-M devices using FreeRTOS. C and C++ are required languages. CMake for build configuration and Unity Test for firmware unit tests. Python for test automation. GitHub Actions as CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"FreeRTOS, C, C++, CMake, Unity Test, Python, and GitHub Actions are all exact matches to stated requirements\",\"Makefile and Docker signal solid build and dev environment experience\",\"Mid-level seniority aligns with the role\",\"pytest alongside Unity Test shows testing breadth\"],\"gaps\":[],\"explanation\":\"The candidate's embedded firmware profile covers every technology and language in the job description, including the specific RTOS and testing framework. This is a precise match for a real-time automotive firmware engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"reza_mlops_senior\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"MLflow\",\"Kubeflow\",\"TensorFlow\",\"Docker\",\"Kubernetes\",\"FastAPI\",\"Airflow\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nAI platform company seeking a Senior MLOps Engineer to manage model training pipelines with Kubeflow, track experiments with MLflow, build model serving APIs with FastAPI, and orchestrate data prep jobs with Airflow. Kubernetes for container orchestration on AWS. GitOps with Argo CD.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubeflow, MLflow, FastAPI, Airflow, Kubernetes, Docker, and Argo CD are all exact matches to the stated requirements\",\"TensorFlow provides the model training framework depth relevant to the pipeline context\",\"Senior ML Engineer seniority and cloud-native architecture experience align with the role\",\"GitHub Actions alongside Argo CD shows CI/CD breadth\"],\"gaps\":[\"No explicit AWS experience listed despite it being the deployment cloud\"],\"explanation\":\"The candidate covers every primary tool in the MLOps stack with direct evidence. The only minor gap is the absence of explicit AWS experience, though their Kubernetes and cloud-native background makes this a low-friction ramp-up.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pedro_analytics_mid\",\"seniority\":\"Mid\",\"roles\":[\"Analytics Engineer\",\"Data Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Airflow\",\"Looker\",\"Great Expectations\",\"dask\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"]}\n\nJob Summary:\nE-commerce company seeking a Mid-level Analytics Engineer to build dbt models on Snowflake, create Looker dashboards for revenue reporting, orchestrate pipelines with Airflow, and enforce data quality with Great Expectations. Python and SQL fluency required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt, Airflow, Looker, Great Expectations, Snowflake, and BigQuery are all exact matches to stated requirements\",\"Python and SQL satisfy the mandatory language requirements\",\"Mid-level seniority aligns with the role\",\"Great Expectations is a specific and differentiating match for the data quality requirement\"],\"gaps\":[],\"explanation\":\"Every tool in the job description is directly evidenced in the candidate's profile, including the specific data quality framework. This is a precise and high-confidence match for the analytics engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"anya_rust_sys\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"C\",\"Python\"],\"tech\":[\"Axum\",\"Tokio\",\"Docker\",\"gRPC\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nInfrastructure software company hiring a Senior Rust Engineer to build a high-performance async API gateway using Axum and Tokio. Services communicate via gRPC. PostgreSQL and Redis for storage. Docker for containers and GitHub Actions for CI. C familiarity is a plus for FFI integration.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Rust, Axum, Tokio, gRPC, PostgreSQL, Redis, Docker, and GitHub Actions are all exact matches to stated requirements\",\"C experience satisfies the FFI integration plus\",\"Distributed systems and event-driven architecture background is relevant to the API gateway context\",\"Senior seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a precise match for every requirement including the Rust async runtime and RPC framework. Their C background adds the FFI plus that the employer noted. This is a high-confidence strong fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"chen_frontend_ts\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Framer Motion\",\"Storybook\",\"Vite\"],\"testing\":[\"Vitest\",\"Playwright\",\"Testing Library\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nCreative agency hiring a Senior Frontend Engineer to build animated, design-forward web experiences in React and Next.js with Framer Motion. TypeScript throughout, Tailwind CSS for styling, Storybook for component documentation. Playwright for E2E testing and Vitest for unit tests.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React, Next.js, TypeScript, Tailwind CSS, Framer Motion, Storybook, Playwright, Vitest, and GitHub Actions are all exact matches\",\"Senior seniority aligns with the role\",\"Vite signals modern build tooling awareness relevant to performance\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a tool-for-tool match against every requirement in the job description including the animation and documentation tooling that differentiates this creative agency role. No meaningful gaps were identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"femi_sre_lead\",\"seniority\":\"Lead\",\"roles\":[\"Site Reliability Engineer\",\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"AWS\",\"Prometheus\",\"Grafana\",\"Datadog\",\"PagerDuty\",\"Docker\",\"Helm\"],\"architecture\":[\"Distributed System\",\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nStreaming platform hiring a Lead SRE to own reliability for a high-traffic distributed system on AWS. You will lead a team of four SREs, manage Kubernetes clusters, maintain observability with Prometheus, Grafana, and Datadog, drive incident response with PagerDuty, and run load tests with k6. Terraform for IaC and Argo CD for GitOps.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Terraform, AWS, Prometheus, Grafana, Datadog, PagerDuty, k6, Helm, Argo CD, and Docker are all exact matches\",\"Lead SRE seniority aligns with team ownership of four engineers\",\"Distributed systems and cloud-native architecture background suits a high-traffic streaming platform\",\"Go and Python scripting provide automation capability for SRE tooling\"],\"gaps\":[],\"explanation\":\"The candidate's profile covers every tool and seniority requirement in the job description with direct evidence. Their Lead SRE background with the exact observability and incident response stack makes them an exceptionally strong fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lin_web_intern\",\"seniority\":\"Intern\",\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"Django\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nTech startup offering a Software Engineering Internship. Interns will contribute to a React and Django web application, fix bugs, write small features, and learn code review processes. PostgreSQL is the database. Senior mentorship provided throughout.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React, Django, JavaScript, Python, and PostgreSQL are exact matches to the internship stack\",\"Intern seniority matches the role and mentored context\"],\"gaps\":[],\"explanation\":\"For a mentored internship with no professional experience required, the candidate's demonstrated stack knowledge covers every technology in scope. They appear ready to contribute meaningfully from the first week within the defined internship boundaries.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"darius_android_senior\",\"seniority\":\"Senior\",\"roles\":[\"Android Engineer\",\"Mobile Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Hilt\",\"Retrofit\",\"Room\",\"WorkManager\"],\"databases\":[\"Room\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"Espresso\",\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nHealthcare app company hiring a Senior Android Engineer to build a patient-facing Kotlin app with Jetpack Compose. Hilt for dependency injection, Retrofit for REST API calls, Room for local persistence, and WorkManager for background sync. GitHub Actions and Fastlane for CI and release. Espresso and JUnit for testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kotlin, Jetpack Compose, Hilt, Retrofit, Room, WorkManager, GitHub Actions, Fastlane, Espresso, and JUnit are all exact matches to stated requirements\",\"Mockito adds testing depth beyond the listed requirements\",\"Senior seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate's Android engineering profile covers every library, framework, and tool listed in the job description. Their precise toolkit match, including WorkManager for background sync, makes this a high-confidence strong fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nora_azure_devops\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\",\"Cloud Engineer\"],\"languages\":[\"Python\",\"Bash\",\"PowerShell\"],\"tech\":[\"Azure\",\"Terraform\",\"Kubernetes\",\"Docker\",\"Helm\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Cloud-Native\"],\"ci_cd\":[\"Azure DevOps\",\"Azure Pipelines\",\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise SaaS company hiring a Senior DevOps Engineer to manage Azure-native infrastructure, write Terraform for IaC, maintain Kubernetes clusters on AKS, build CI/CD pipelines in Azure DevOps and Azure Pipelines, and operate monitoring with Prometheus and Grafana. PowerShell scripting required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Azure, Terraform, Kubernetes, Helm, Prometheus, Grafana, Azure DevOps, Azure Pipelines, GitHub Actions, PowerShell, Docker, and Python are all exact matches\",\"Senior seniority aligns with the role\",\"Cloud-native architecture background is directly relevant\"],\"gaps\":[],\"explanation\":\"The candidate's Azure-centric DevOps profile is a comprehensive match for every technology and requirement in the job description, including the PowerShell scripting requirement that is specific to Azure environments. No meaningful gaps were identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yosef_vue_lead\",\"seniority\":\"Lead\",\"roles\":[\"Frontend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\",\"GraphQL\",\"Apollo Client\",\"Vite\"],\"testing\":[\"Vitest\",\"Playwright\",\"Cypress\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nScale-up SaaS company seeking a Lead Frontend Engineer to own the Nuxt.js and Vue.js frontend architecture, manage two frontend engineers, define testing standards, and drive GraphQL adoption with Apollo Client. Tailwind CSS for styling. Vitest and Playwright for the testing suite.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Nuxt.js, Vue.js, Pinia, Tailwind CSS, GraphQL, Apollo Client, Vitest, Playwright, and GitHub Actions are all exact matches\",\"Lead seniority aligns with the team management and architecture ownership expectations\",\"Vite and Cypress add tooling depth beyond the listed requirements\"],\"gaps\":[],\"explanation\":\"Every technology in the job description is directly evidenced in the candidate's profile, including the specific state management library and the GraphQL client. Their Lead seniority makes them ready for both the architectural and people management dimensions of this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"isabel_react_native\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React Native\",\"Expo\",\"Redux\",\"React Query\",\"Firebase\"],\"databases\":[\"Firestore\",\"AsyncStorage\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Detox\"]}\n\nJob Summary:\nTravel app startup hiring a Mid-level React Native Engineer to build cross-platform iOS and Android features with Expo. TypeScript required. Redux for global state, React Query for API data fetching, Firestore for backend sync, and AsyncStorage for offline caching. Jest for unit tests and Detox for E2E.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React Native, Expo, TypeScript, Redux, React Query, Firestore, AsyncStorage, Jest, Detox, and GitHub Actions are all exact matches\",\"Mid-level seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a precise, tool-for-tool match against every requirement in the job description. No meaningful gaps were identified, making this a high-confidence strong fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"carla_backend_go\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Echo\",\"gRPC\",\"Docker\",\"AWS\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"CircleCI\"],\"testing\":[\"Go testing\",\"Testify\"]}\n\nJob Summary:\nFinttech company hiring a Senior Go Backend Engineer to build payment processing microservices using the Echo framework. gRPC for internal service communication, Kafka for transaction event streaming, PostgreSQL and DynamoDB for storage, Redis for caching. AWS deployment, GitHub Actions for CI, and Go testing with Testify.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go, Echo, gRPC, Kafka, PostgreSQL, DynamoDB, Redis, AWS, GitHub Actions, Go testing, and Testify are all exact matches\",\"Event-driven and microservices architecture experience aligns with payment processing design\",\"Senior seniority matches the role\"],\"gaps\":[],\"explanation\":\"The candidate's profile covers every technology in the job description with direct evidence, including the specific Go testing library and both storage technologies. Their event-driven payment processing context makes this a high-confidence fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mei_llm_research\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"AI Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"LangChain\",\"FAISS\",\"FastAPI\",\"Docker\"],\"architecture\":[\"RAG\"],\"databases\":[\"PostgreSQL\",\"Weaviate\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nLegal AI company hiring a Senior LLM Engineer to fine-tune transformer models using Hugging Face, design RAG pipelines with FAISS and Weaviate as vector stores, orchestrate workflows with LangChain, and serve inference via FastAPI. PyTorch is the training framework. Docker for containerization and GitHub Actions for CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PyTorch, Hugging Face Transformers, LangChain, FAISS, Weaviate, FastAPI, Docker, and GitHub Actions are all exact matches\",\"RAG architecture experience directly addresses the pipeline design requirement\",\"Senior LLM Engineer role and seniority match the position\"],\"gaps\":[],\"explanation\":\"Every technology in the job description is directly evidenced in the candidate's profile, including both vector store technologies. Their RAG architecture specialization makes them precisely suited for the core design work of this legal AI role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"grace_swiftui_mid\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Combine\",\"Core Data\",\"Alamofire\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nMobile-first startup seeking a Mid-level iOS Engineer to build SwiftUI-based features, manage local persistence with Core Data, handle reactive data flows with Combine, and integrate REST APIs via Alamofire. Fastlane for release automation and GitHub Actions for CI. XCTest for unit and UI tests.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SwiftUI, UIKit, Combine, Core Data, Alamofire, Fastlane, GitHub Actions, and XCTest are all exact matches\",\"Mid-level seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"Every technology in the job description is directly evidenced in the candidate's profile. Their iOS toolkit is a precise match including the reactive framework, persistence layer, and release automation tooling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nadia_bi_analyst\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Power BI\",\"Tableau\",\"Pandas\",\"Excel\"],\"databases\":[\"Snowflake\",\"PostgreSQL\"]}\n\nJob Summary:\nRetail company hiring a Mid-level Analytics Engineer to build dbt transformation models, create Looker dashboards, orchestrate jobs with Airflow, and work with BigQuery. SQL and Python are required. Experience with modern data stack tooling is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SQL and Python fluency satisfies the mandatory language requirements\",\"Snowflake and data warehousing experience provides relevant foundation\",\"Mid-level seniority aligns with the role\"],\"gaps\":[\"No dbt experience despite it being the core transformation tool\",\"No Looker experience; Power BI and Tableau are different BI tools\",\"No Airflow or orchestration experience\",\"No BigQuery experience; Snowflake SQL dialects and optimization differ\"],\"explanation\":\"The candidate has solid data analysis foundations but the role requires an analytics engineering toolkit \u2014 dbt, Looker, Airflow, and BigQuery \u2014 that is entirely absent from their profile. They would need significant ramp-up on every primary tool before contributing independently.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"megan_ios_mid\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Combine\",\"Alamofire\"],\"databases\":[\"CoreData\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"XCTest\",\"Quick\"]}\n\nJob Summary:\nFinttech app company seeking a Senior iOS Engineer to lead architecture decisions, define coding standards, mentor three iOS developers, and drive a SwiftUI migration from UIKit. Combine for reactive data flows and CoreData for local persistence. Minimum five years of Swift experience required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SwiftUI, UIKit, Combine, CoreData, and XCTest are strong technical matches to the stated stack\",\"Alamofire and SQLite add API integration and storage depth\"],\"gaps\":[\"Mid seniority is below Senior; architecture ownership and mentoring three developers are Senior-level expectations\",\"No demonstrated technical leadership or standard-setting experience\",\"Minimum five years of Swift experience is unlikely met at Mid level\"],\"explanation\":\"The candidate's technical toolkit is well-aligned with the SwiftUI migration and Combine-based architecture, but the role demands Senior-level mentoring and architectural leadership that a Mid-level engineer is still developing. The five-year minimum is a meaningful qualifier.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sam_devops_mid\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"Kubernetes\",\"Terraform\",\"AWS\",\"Helm\",\"GitHub Actions\"],\"architecture\":[\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\",\"CircleCI\"]}\n\nJob Summary:\nHealthtech startup hiring a Senior DevOps Engineer to design and lead the Kubernetes infrastructure strategy on AWS, define team-wide IaC standards with Terraform, mentor two junior DevOps engineers, implement distributed tracing with Jaeger, and establish SLO-based alerting. Strong Kubernetes expertise required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes, Terraform, AWS, Helm, Docker, and GitHub Actions are direct technical matches\",\"Cloud-native architecture experience is relevant\"],\"gaps\":[\"Mid seniority is one level below Senior; infrastructure strategy and mentoring are Senior-level expectations\",\"No Jaeger or distributed tracing experience\",\"No SLO-based alerting or observability standards work evidenced\"],\"explanation\":\"The candidate has solid Kubernetes and Terraform fundamentals that align with the technical stack, but the role demands Senior-level leadership including mentoring, strategy definition, and observability design. The absence of distributed tracing experience is also a notable gap for the stated requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nina_csharp_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C#\",\"SQL\"],\"tech\":[\"ASP.NET\",\"EF Core\",\"Docker\",\"Azure\"],\"databases\":[\"MS SQL Server\",\"PostgreSQL\"],\"ci_cd\":[\"Azure Pipelines\",\"GitHub Actions\"],\"testing\":[\"xUnit\",\"NUnit\"]}\n\nJob Summary:\nEnterprise logistics company hiring a Senior .NET Backend Engineer to design and lead development of Azure-hosted services using ASP.NET and EF Core. SQL Server is the primary database and Docker for containers. Azure Pipelines for CI/CD. Team expects comprehensive unit testing with xUnit.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"ASP.NET, EF Core, SQL Server, Docker, Azure, Azure Pipelines, xUnit, and NUnit are all direct matches to the stated stack\",\"C# fluency satisfies the primary language requirement\"],\"gaps\":[\"Mid seniority is one level below the Senior requirement; design leadership and team development are Senior-level expectations\",\"No explicit architectural design or technical leadership experience evidenced\"],\"explanation\":\"The candidate's .NET and Azure stack is a precise technical match for the role, but the seniority gap is meaningful because the employer expects a Senior engineer to lead design and guide the team. The technical foundation is strong, but leadership readiness is the open question.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fabio_spark_senior\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Spark\",\"PySpark\",\"Airflow\",\"Docker\",\"AWS\"],\"databases\":[\"Redshift\",\"PostgreSQL\"]}\n\nJob Summary:\nMedia company hiring a Senior Data Engineer to build real-time streaming pipelines using Kafka and Flink, orchestrate batch jobs with Airflow, store data in Snowflake, and run large-scale Spark jobs. Python and SQL are required. dbt for transformation and Databricks for managed Spark.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Apache Spark, PySpark, and Airflow directly match core batch processing and orchestration requirements\",\"Python and SQL satisfy mandatory language requirements\",\"Senior seniority aligns with the role\"],\"gaps\":[\"No Kafka or Flink experience for the real-time streaming pipeline requirement\",\"No Snowflake experience; Redshift is a different warehouse\",\"No dbt experience for the transformation layer\",\"No Databricks experience for managed Spark\"],\"explanation\":\"The candidate's Spark and Airflow expertise addresses the batch processing dimension well, but the role is equally focused on real-time streaming with Kafka and Flink, and the transformation and warehouse tools are also different from what the candidate has used. These are meaningful gaps across core responsibilities.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tobias_node_junior\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"NestJS\",\"Express.js\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nStartup hiring a Mid-level Node.js Backend Engineer to design and own REST APIs in NestJS and TypeScript, manage PostgreSQL schemas, write integration and unit tests, and work autonomously with minimal supervision. AWS deployment knowledge expected and GitHub Actions for CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"NestJS, TypeScript, PostgreSQL, MongoDB, Docker, and Jest are direct technical matches\",\"Junior-to-Mid transition profile shows relevant stack knowledge\"],\"gaps\":[\"Junior seniority is one level below Mid; autonomous ownership with minimal supervision is a Mid-level expectation\",\"No AWS experience despite it being expected\",\"No GitHub Actions CI experience\",\"No integration testing experience evidenced beyond Jest unit tests\"],\"explanation\":\"The candidate's NestJS and TypeScript stack aligns well with the job requirements, but the seniority gap is meaningful for a role that expects autonomous API ownership. The absence of AWS and CI experience adds to the gap for a Mid-level position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ali_platform_senior\",\"seniority\":\"Senior\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"AWS\",\"Prometheus\",\"Docker\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nFinttech scale-up hiring a Staff Platform Engineer to define platform standards across ten teams, own the Kubernetes multi-cluster strategy on AWS, lead the adoption of GitOps via Flux, implement distributed tracing with OpenTelemetry, and manage a team of three platform engineers. Terraform required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes, Helm, Terraform, AWS, Prometheus, Docker, and GitHub Actions are direct technical matches\",\"Go and Bash scripting provide automation capability\"],\"gaps\":[\"Senior seniority is one level below the Staff requirement; multi-team standard-setting and team management are Staff-level expectations\",\"No Flux or GitOps experience; only GitHub Actions CI listed\",\"No OpenTelemetry or distributed tracing experience\",\"No multi-cluster Kubernetes architecture experience evidenced\"],\"explanation\":\"The candidate has solid Kubernetes and Terraform foundations but the role demands Staff-level leadership and three specific technologies \u2014 Flux, OpenTelemetry, and multi-cluster strategy \u2014 that are not evidenced. Both the seniority and tooling gaps are meaningful for the defined scope.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ruth_typescript_mid\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Next.js\",\"React\",\"Django\",\"Docker\",\"Tailwind CSS\",\"Prisma\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\"]}\n\nJob Summary:\nE-commerce startup hiring a Senior Full Stack Engineer to own end-to-end feature delivery on a Next.js frontend and Django REST Framework backend, manage PostgreSQL and Redis, write comprehensive tests with Jest and pytest, and deploy on AWS with Docker. Mentor one junior engineer.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js, React, Django, TypeScript, Python, PostgreSQL, Redis, Docker, GitHub Actions, Jest, and pytest are all direct technical matches\",\"Prisma demonstrates ORM depth beyond Django's built-in ORM\"],\"gaps\":[\"Mid seniority is one level below Senior; feature ownership and mentoring expectations are Senior-level\",\"No AWS experience despite it being the deployment target\"],\"explanation\":\"The candidate's full stack toolkit is an excellent technical match for the role, covering both the frontend and backend precisely. However, the seniority gap is meaningful given the employer expects end-to-end feature ownership and mentoring, and the absence of AWS experience is an additional gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leon_android_mid\",\"seniority\":\"Mid\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Retrofit\",\"Room\",\"Hilt\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Espresso\"]}\n\nJob Summary:\nSenior Android Engineer needed at a fintech startup to design the app architecture, own release management, mentor two junior developers, and drive adoption of Kotlin Multiplatform for shared business logic with the iOS team. Minimum five years of Kotlin experience required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin, Jetpack Compose, Android SDK, Retrofit, Room, Hilt, JUnit, Espresso, and GitHub Actions are strong technical matches\",\"Mid-level Android experience provides solid foundational knowledge\"],\"gaps\":[\"Mid seniority is one level below Senior; architecture ownership and mentoring are Senior-level expectations\",\"No Kotlin Multiplatform experience despite it being a primary requirement\",\"Five-year minimum experience is unlikely met at Mid level\"],\"explanation\":\"The candidate's Android toolkit is well-aligned but the role's key differentiator \u2014 Kotlin Multiplatform \u2014 is entirely absent from the profile. Combined with the seniority gap and the five-year minimum, this is a meaningful mismatch despite strong technical fundamentals.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"paolo_rust_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"Go\"],\"tech\":[\"Axum\",\"Tokio\",\"Docker\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nFinttech company hiring a Senior Rust Systems Engineer to build ultra-low-latency order matching engines, optimize async runtime performance with Tokio, integrate PostgreSQL for trade persistence, and contribute to infrastructure automation with Terraform on AWS. Minimum four years of production Rust experience required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Rust, Axum, Tokio, PostgreSQL, Docker, and GitHub Actions are direct technical matches\",\"Go background demonstrates systems programming depth complementary to Rust\"],\"gaps\":[\"Mid seniority is one level below the Senior requirement with a four-year minimum in production Rust\",\"No Terraform or infrastructure automation experience\",\"No AWS experience\",\"No demonstrated low-latency optimization or financial systems experience\"],\"explanation\":\"The candidate has solid Rust fundamentals with the correct async runtime and is technically promising, but the seniority gap and absence of Terraform and AWS experience are meaningful for a production financial system. The low-latency optimization requirement also requires senior-level depth not yet evidenced.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ana_fullstack_senior\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"FastAPI\",\"Docker\",\"AWS\",\"Redis\",\"Tailwind CSS\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nHealthtech startup seeking a Senior Full Stack Engineer to build HIPAA-aware patient data features in Next.js and FastAPI. PostgreSQL for structured data, Redis for caching, Docker and AWS for deployment. GitHub Actions for CI. Comprehensive testing with Jest, pytest, and Playwright.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js, React, FastAPI, PostgreSQL, Redis, Docker, AWS, GitHub Actions, Jest, pytest, and Playwright are all direct matches to the stated tech stack\",\"Senior seniority aligns with the role\"],\"gaps\":[\"No HIPAA compliance or security-conscious healthcare development experience evidenced in the profile\"],\"explanation\":\"The candidate covers every technical tool in the job description precisely, but the HIPAA compliance requirement is a domain-specific expectation that is entirely absent from their visible profile. For a patient data platform in healthcare, this is a meaningful gap that should be explored carefully in the hiring process.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"val_swe_mid\",\"seniority\":\"Mid\",\"roles\":[\"Software Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"React\",\"Node.js\"],\"databases\":[\"MongoDB\"]}\n\nJob Summary:\nStartup hiring a Mid-level Full Stack Engineer to build TypeScript features in a Next.js and NestJS codebase. PostgreSQL is the database, Prisma for ORM, and Docker for containers. GitHub Actions for CI. Strong TypeScript skills and unit testing with Jest are required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Node.js provide transferable fundamentals for Next.js and NestJS work\",\"Mid-level seniority aligns with the role\"],\"gaps\":[\"No TypeScript experience despite it being a strong requirement throughout the codebase\",\"No Next.js or NestJS experience; both are different frameworks from vanilla React and Node.js\",\"No PostgreSQL or Prisma experience; only MongoDB listed\",\"No Docker or GitHub Actions experience\",\"No Jest or testing framework experience visible\"],\"explanation\":\"The candidate's JavaScript React and Node.js background provides a conceptual foundation, but the role requires TypeScript and framework-specific experience in Next.js and NestJS that are meaningfully different from what the candidate has used. The database, tooling, and testing gaps compound the mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lucas_backend_senior\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Node.js\",\"TypeScript\"],\"tech\":[\"Express.js\",\"Docker\",\"AWS\",\"Bull\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MongoDB\"]}\n\nJob Summary:\nAdtech company hiring a Senior Backend Engineer to build high-volume REST APIs in NestJS and TypeScript, manage async job queues with BullMQ, integrate PostgreSQL and Redis, and deploy on AWS with Docker. GitHub Actions for CI. GraphQL for internal API communication. Strong TypeScript skills required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript, PostgreSQL, Redis, Docker, and AWS are direct matches\",\"Bull experience is related to BullMQ and shows job queue familiarity\",\"Senior seniority aligns with the role\"],\"gaps\":[\"No NestJS experience; Express.js is a different framework requiring a paradigm shift\",\"No BullMQ experience specifically, though Bull is closely related\",\"No GraphQL experience for internal API communication\",\"No GitHub Actions CI experience listed\"],\"explanation\":\"The candidate has the right language, databases, and infrastructure background, but the shift from Express.js to NestJS is a meaningful framework transition and the absence of GraphQL is a notable gap given it is the internal API layer. These are ramp-up gaps rather than fundamental mismatches.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ben_ts_backend\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Express.js\",\"Node.js\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nSaaS company seeking a Senior Backend Engineer to own NestJS API development with TypeScript, integrate GraphQL using Apollo Server, manage PostgreSQL and Redis on AWS, and mentor two junior engineers. Strong architectural judgment required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript, Node.js, PostgreSQL, Redis, Docker, AWS, GitHub Actions, Jest, and Supertest are strong technical foundations\",\"Mid-level seniority and backend specialization are relevant\"],\"gaps\":[\"No NestJS experience; Express.js is a different architectural paradigm\",\"No GraphQL or Apollo Server experience\",\"Mid seniority is below Senior; mentoring and architectural judgment are Senior-level expectations\"],\"explanation\":\"The candidate has a solid Node.js TypeScript backend foundation, but the framework and API paradigm shift to NestJS and GraphQL are meaningful gaps. The seniority difference is also significant given the mentoring and architectural ownership expectations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yemi_aws_senior\",\"seniority\":\"Senior\",\"roles\":[\"Cloud Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"AWS\",\"Terraform\",\"Docker\",\"Ansible\",\"Jenkins\",\"Prometheus\"],\"architecture\":[\"Cloud-Native\"]}\n\nJob Summary:\nScale-up company hiring a Senior Platform Engineer to own a Kubernetes-based developer platform on GCP, implement GitOps with Flux, build observability with OpenTelemetry and Grafana, write Terraform for GCP-native services, and lead a team of two platform engineers.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform experience is transferable to GCP infrastructure management\",\"Docker and Ansible show solid infrastructure automation skills\",\"Senior seniority matches the role\",\"Prometheus experience is conceptually transferable to observability tooling\"],\"gaps\":[\"No GCP experience; the platform is GCP-native requiring ramp-up from AWS\",\"No Kubernetes experience despite it being the core platform technology\",\"No Flux or GitOps experience\",\"No OpenTelemetry or Grafana experience\"],\"explanation\":\"The candidate is an experienced AWS infrastructure engineer, but the role is centered on a GCP Kubernetes platform with GitOps and modern observability tooling. The cloud provider transition and Kubernetes absence are meaningful gaps for a platform ownership role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"irina_python_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"SQLAlchemy\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MySQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nFintech startup hiring a Senior Backend Engineer to design a high-throughput payments API in Go with the Fiber framework, manage PostgreSQL and Redis on AWS, build gRPC microservices, and lead API design reviews. Strong Go expertise required with minimum four years of experience.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PostgreSQL, Redis, Docker, and pytest show transferable infrastructure and testing discipline\",\"Mid-level backend engineering experience provides software design foundations\"],\"gaps\":[\"No Go experience; the entire role is Go-based with a four-year minimum\",\"No gRPC experience\",\"No AWS experience\",\"Mid seniority is below Senior; API design leadership requires Senior-level judgment\",\"FastAPI and Python experience does not transfer to a Go Fiber API\"],\"explanation\":\"The candidate's database and testing background provides some transferable value, but the primary language is entirely absent and the role requires minimum four years of Go production experience. The seniority gap further limits readiness for the API design leadership expectations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kofi_data_senior\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"NumPy\",\"Weights & Biases\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"]}\n\nJob Summary:\nManufacturing company seeking a Senior Data Scientist to build time-series anomaly detection models using XGBoost and isolation forests, track experiments with MLflow, serve predictions via FastAPI, and work with Snowflake for data access. Python and SQL are required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python and SQL fluency satisfy the mandatory language requirements\",\"scikit-learn background is relevant to anomaly detection methods\",\"Senior seniority aligns with the role\",\"Pandas and NumPy provide strong feature engineering foundations for time-series work\"],\"gaps\":[\"No XGBoost experience despite it being the primary modeling tool\",\"No MLflow; Weights and Biases is a different experiment tracking system\",\"No FastAPI for model serving\",\"No Snowflake experience; only BigQuery listed\"],\"explanation\":\"The candidate has strong Python data science fundamentals, but the specific tools \u2014 XGBoost, MLflow, FastAPI, and Snowflake \u2014 differ from what they have used. These are ramp-up gaps rather than domain mismatches, but they cover the full modeling, tracking, serving, and data access stack.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex_sre_mid\",\"seniority\":\"Mid\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Prometheus\",\"Grafana\",\"Docker\",\"AWS\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nStreaming company hiring a Senior SRE to lead reliability initiatives for a distributed video platform on AWS, define SLOs, manage incident response with PagerDuty, implement distributed tracing with Jaeger, write Terraform for infrastructure automation, and lead a team of three SREs.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes, Prometheus, Grafana, Docker, AWS, and GitHub Actions are strong technical matches\",\"Go scripting capability is relevant for SRE automation\"],\"gaps\":[\"Mid seniority is one level below Senior; team leadership and SLO definition are Senior-level expectations\",\"No PagerDuty or incident management experience\",\"No Jaeger or distributed tracing experience\",\"No Terraform for infrastructure automation\"],\"explanation\":\"The candidate has the right observability foundation but the role requires Senior-level team leadership and several additional tools \u2014 PagerDuty, Jaeger, and Terraform \u2014 that are absent from the profile. Both the seniority and tooling gaps are meaningful for a streaming platform reliability role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"diana_php_senior\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"SQL\"],\"tech\":[\"Symfony\",\"Docker\",\"Redis\",\"RabbitMQ\"],\"databases\":[\"MySQL\",\"PostgreSQL\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nE-commerce company hiring a Senior Backend Engineer to build high-traffic catalog and inventory services in Python using FastAPI and Celery. PostgreSQL and Redis on AWS with Docker. pytest for tests and GitHub Actions for CI.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Redis, PostgreSQL, and Docker experience is transferable to the infrastructure layer\",\"Senior backend seniority demonstrates software engineering maturity\"],\"gaps\":[\"No Python experience; the entire stack is Python-based\",\"No FastAPI or Celery experience\",\"No AWS experience\",\"No pytest or GitHub Actions; PHPUnit and GitLab CI are different systems\",\"PHP and Symfony experience is entirely irrelevant to a Python FastAPI role\"],\"explanation\":\"The candidate is a strong PHP engineer but the role requires Python, FastAPI, and Celery \u2014 a stack with no overlap with their background. The infrastructure overlap is minor given the depth of the language and framework mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nana_flutter_mid\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"Kotlin\"],\"tech\":[\"Flutter\",\"Riverpod\",\"Firebase\",\"Hive\"],\"databases\":[\"Firestore\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Flutter Test\"]}\n\nJob Summary:\nStartup seeking a Senior Flutter Engineer to lead architecture decisions for a cross-platform health app, mentor two junior mobile developers, define state management standards, and own the release pipeline with Fastlane. Minimum five years of Flutter experience required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Flutter, Dart, Riverpod, Firebase, Firestore, SQLite, GitHub Actions, and Flutter Test are strong technical matches\",\"Kotlin experience adds native mobile breadth\"],\"gaps\":[\"Mid seniority is below the Senior requirement with a five-year minimum\",\"No Fastlane experience for the release pipeline ownership\",\"No demonstrated architecture leadership or mentoring experience at this career stage\"],\"explanation\":\"The candidate's Flutter ecosystem expertise is technically well-aligned, but the role requires Senior-level architectural leadership and Fastlane release management that a Mid-level engineer is still developing. The five-year minimum and mentoring expectations are meaningful qualifiers.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"victor_cloud_senior\",\"seniority\":\"Senior\",\"roles\":[\"Cloud Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"AWS\",\"Terraform\",\"Kubernetes\",\"Docker\",\"Helm\",\"Prometheus\",\"Grafana\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nFintech company hiring a Staff Cloud Engineer to define cloud architecture standards across eight teams on Azure, lead adoption of Bicep for IaC, establish FinOps practices, implement Azure Monitor for observability, and mentor a team of four cloud engineers.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes, Terraform, Docker, Helm, Prometheus, Grafana, and Argo CD provide strong cloud infrastructure foundations\",\"Senior seniority is one step below Staff but demonstrates relevant depth\"],\"gaps\":[\"No Azure experience; the entire platform is Azure-native\",\"No Bicep or ARM template experience; Terraform on Azure is different from AWS\",\"No Azure Monitor experience; Prometheus and Grafana are different systems\",\"No FinOps experience\",\"Senior seniority is one level below the Staff requirement for multi-team standards ownership\"],\"explanation\":\"The candidate is a capable cloud engineer with strong Kubernetes fundamentals, but the role is entirely Azure-native and requires Bicep, Azure Monitor, and FinOps expertise that are all absent. Both the cloud provider mismatch and the seniority gap are meaningful barriers for a Staff-level Azure standards role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jun_backend_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"Docker\",\"AWS\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nB2B SaaS company hiring a Senior Backend Engineer to lead API design for a Python FastAPI platform, define data model standards across PostgreSQL and MongoDB, mentor three engineers, own the service architecture, and drive performance optimization.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI, PostgreSQL, MongoDB, Redis, Docker, AWS, GitHub Actions, and pytest are direct technical matches\",\"Python fluency is the required primary language\"],\"gaps\":[\"Mid seniority is one level below Senior; API design leadership and mentoring are Senior-level expectations\",\"No demonstrated architectural decision-making or team mentoring experience at Mid level\"],\"explanation\":\"The candidate's technical stack is a precise match for the role, but the employer requires Senior-level ownership including API design leadership, standard-setting, and mentoring three engineers. These responsibilities typically require senior-level experience and track record beyond what a Mid-level engineer is expected to have.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priya_junior_fe\",\"seniority\":\"Junior\",\"languages\":[\"JavaScript\"],\"tech\":[\"React\",\"CSS\"],\"databases\":[\"MongoDB\"]}\n\nJob Summary:\nEnterprise company hiring a Senior Frontend Engineer to architect a design system in React and TypeScript, lead a team of four engineers, define testing standards with Playwright and Jest, drive performance optimization, and establish frontend monitoring with Datadog. Minimum six years of React experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React experience provides a basic foundational overlap\"],\"gaps\":[\"Junior seniority is far below the Senior requirement with a six-year minimum\",\"No TypeScript experience despite it being central to the design system\",\"No team leadership or mentoring experience\",\"No Playwright, Jest, or any testing framework experience\",\"No Datadog or frontend monitoring experience\",\"No design system or architecture experience evidenced\"],\"explanation\":\"The candidate is at the very beginning of their frontend career with a minimal profile, while the role demands senior-level technical leadership, design system architecture, and extensive testing and monitoring expertise. The gap in seniority, tooling, and scope makes this a poor fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lina_fullstack_junior\",\"seniority\":\"Junior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Node.js\",\"Express.js\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nSaaS startup seeking a Senior Full Stack Engineer to own technical architecture, lead a six-person engineering team, define the data model strategy across PostgreSQL and MongoDB, establish CI/CD best practices, and conduct architectural reviews. Minimum eight years of software engineering experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React, Node.js, Express.js, PostgreSQL, MongoDB, and Jest provide solid technical stack alignment\"],\"gaps\":[\"Junior seniority is far below the Senior requirement with an eight-year minimum\",\"No architectural design or data model strategy experience at this career stage\",\"No technical team leadership experience\",\"No CI/CD ownership or best practice definition experience\",\"Architectural review responsibilities are entirely beyond a Junior engineer's current scope\"],\"explanation\":\"The candidate's technical stack aligns well with the platform, but this is a Senior architectural leadership role requiring eight years of experience and team ownership that a Junior engineer is years away from being ready for. The skills gap is primarily one of career stage rather than technology.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rashid_swe_intern\",\"seniority\":\"Intern\",\"languages\":[\"Python\",\"Java\"],\"tech\":[\"Spring Boot\",\"Flask\"]}\n\nJob Summary:\nEnterprise company seeking a Senior Software Engineer to design distributed microservices architectures, lead cross-team API standardization, mentor a team of eight engineers, contribute to quarterly roadmap planning, and manage vendor relationships for cloud infrastructure. Minimum ten years of software engineering experience.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Intern seniority is the maximum possible gap from the Senior requirement with a ten-year minimum\",\"No distributed systems or microservices architecture experience\",\"No technical leadership or mentoring experience\",\"No roadmap planning or vendor management experience\",\"The scope of this role is fundamentally incompatible with an internship-level candidate\"],\"explanation\":\"The candidate is at the very beginning of their software career and the role requires ten-plus years of experience with executive-adjacent responsibilities including team mentoring, roadmap ownership, and vendor management. There are no meaningful transferable signals for this particular opening.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amir_ds_junior\",\"seniority\":\"Junior\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"Matplotlib\"]}\n\nJob Summary:\nAI startup hiring a Senior Data Scientist to lead model development for a real-time fraud detection system. You will train and deploy deep learning models with PyTorch, build streaming feature pipelines on Kafka, manage experiments with MLflow, serve models via FastAPI, and mentor a team of three data scientists. Minimum six years of data science experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"scikit-learn and Pandas provide basic ML and data manipulation foundations\"],\"gaps\":[\"Junior seniority is far below the Senior requirement with a six-year minimum\",\"No PyTorch or deep learning experience\",\"No Kafka or streaming pipeline experience\",\"No MLflow for experiment tracking\",\"No FastAPI for model serving\",\"No mentoring or team leadership experience\"],\"explanation\":\"The candidate has foundational data science skills but the role requires senior-level production ML engineering across a stack \u2014 PyTorch, Kafka, MLflow, FastAPI \u2014 that none of the candidate's tools overlap with. The seniority and skills gap is severe.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wei_data_analyst\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Tableau\",\"Pandas\",\"Excel\"],\"databases\":[\"MySQL\",\"PostgreSQL\"]}\n\nJob Summary:\nE-commerce company seeking a Senior Data Engineer to build and own the real-time data ingestion pipeline using Kafka and Spark Streaming, design the dbt transformation layer on BigQuery, orchestrate jobs with Airflow, and mentor a team of two data engineers. Minimum seven years of data engineering experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"SQL and Python provide basic data manipulation foundations\"],\"gaps\":[\"Junior analyst seniority is far below the Senior Data Engineer requirement with a seven-year minimum\",\"Data Analyst and Data Engineer are different disciplines; this candidate has no pipeline engineering experience\",\"No Kafka, Spark, or streaming experience\",\"No dbt, BigQuery, or Airflow experience\",\"No team mentoring experience\"],\"explanation\":\"The candidate is a junior data analyst and the role requires a Senior Data Engineer with seven-plus years of pipeline engineering experience. These are different disciplines and the seniority gap compounds a fundamental skills domain mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sara_mobile_senior\",\"seniority\":\"Senior\",\"roles\":[\"Mobile Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React Native\",\"Expo\",\"NestJS\",\"GraphQL\",\"Apollo GraphQL\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Detox\"]}\n\nJob Summary:\nScale-up company hiring a Senior Mobile Engineer to focus exclusively on a native Swift iOS app. You will build features in SwiftUI, own the Core Data persistence layer, write UI tests with XCTest, manage releases with Fastlane, and collaborate with a Kotlin Android team.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript and mobile development experience show cross-platform mobile familiarity\"],\"gaps\":[\"No Swift or SwiftUI experience; the role is entirely Swift-based native iOS\",\"No Core Data or iOS-native persistence experience\",\"No XCTest experience for iOS UI testing\",\"No Fastlane for iOS release management\",\"React Native is cross-platform and does not substitute for native Swift development\",\"NestJS and GraphQL backend experience is not relevant to this native iOS role\"],\"explanation\":\"The candidate is a React Native and TypeScript mobile engineer, which does not translate to native Swift iOS development. The role requires native Swift, SwiftUI, and iOS-specific tooling that are entirely absent from the candidate's profile. This is a fundamental technology mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nina_backend_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Flask\",\"SQLAlchemy\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MySQL\"]}\n\nJob Summary:\nEnterprise data company hiring a Senior Backend Engineer to design a high-throughput GraphQL API using NestJS and TypeScript, build gRPC microservices, implement PostgreSQL with Prisma ORM, cache with Redis on AWS EKS. Comprehensive testing and CI with GitHub Actions required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"PostgreSQL and Redis experience provides some data layer familiarity\",\"Docker shows container awareness\"],\"gaps\":[\"No TypeScript or NestJS experience; the primary stack is TypeScript-based\",\"No GraphQL or gRPC experience\",\"No Prisma ORM experience\",\"No AWS or Kubernetes experience despite EKS being the deployment target\",\"No GitHub Actions CI experience\",\"Mid seniority is below the Senior requirement\",\"Flask and SQLAlchemy are not relevant to this role\"],\"explanation\":\"The candidate's Python Flask background has minimal overlap with a TypeScript NestJS GraphQL platform. The core language, framework, API paradigm, and infrastructure are all mismatched. The seniority gap adds to an already significant technical mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elena_ux_dev\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"HTML\",\"CSS\",\"jQuery\",\"Bootstrap\"]}\n\nJob Summary:\nFinttech company hiring a Senior Full Stack Engineer to build TypeScript microservices in NestJS with gRPC, design PostgreSQL schemas, manage Kubernetes deployments on AWS, implement observability with Datadog, and mentor a team of five engineers. Minimum seven years of experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"No TypeScript or NestJS experience\",\"No backend or API development experience\",\"No Kubernetes, Docker, or cloud infrastructure experience\",\"No PostgreSQL or database design experience\",\"No gRPC or microservices architecture\",\"No Datadog or observability tooling\",\"Mid seniority is far below Senior with a seven-year minimum\",\"jQuery and Bootstrap frontend skills are entirely irrelevant to this role\"],\"explanation\":\"The candidate is a junior frontend developer with HTML, CSS, and jQuery skills that have no meaningful overlap with a TypeScript NestJS backend platform role. The scope mismatch spans seniority, discipline, technology, and experience level.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"raj_java_senior\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Hibernate\",\"Jenkins\",\"Docker\"],\"databases\":[\"Oracle\",\"MySQL\"]}\n\nJob Summary:\nStartup hiring a Senior Go Backend Engineer to build a distributed caching and queuing service using Go with the Gin framework, Redis, Kafka, and Kubernetes on GCP. gRPC for inter-service communication. Terraform for infrastructure.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Senior backend engineering experience demonstrates software design maturity\",\"Docker familiarity provides container awareness\"],\"gaps\":[\"No Go or Gin experience; Go is the sole required language\",\"No Kubernetes or GCP experience\",\"No Kafka or gRPC experience\",\"No Redis experience despite it being the primary storage layer\",\"No Terraform or IaC experience\",\"Java and Spring Boot experience is not relevant to this Go service\"],\"explanation\":\"Despite being a Senior backend engineer, the candidate has no experience with Go, Kubernetes, Kafka, gRPC, or Terraform \u2014 the technologies that define the entire scope of this role. This is a comprehensive language and stack mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sana_nestjs_senior\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"GraphQL\",\"Apollo GraphQL\",\"Docker\",\"AWS\",\"BullMQ\",\"gRPC\"],\"architecture\":[\"Microservices\",\"Modular Architecture\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nB2B SaaS company hiring a Senior Backend Engineer to build a GraphQL API platform using NestJS and TypeScript. BullMQ handles background jobs, PostgreSQL and Redis are the data tier, and gRPC powers inter-service calls. AWS with Docker for deployment. GitHub Actions for CI. Jest and Supertest for testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS, GraphQL, Apollo GraphQL, BullMQ, gRPC, PostgreSQL, Redis, Docker, AWS, GitHub Actions, Jest, and Supertest are all exact matches\",\"Microservices and modular architecture experience aligns with the platform design context\",\"Senior seniority matches the role\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a comprehensive, tool-for-tool match against every requirement in the job description. No meaningful gaps were identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kweku_spark_mid\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"PySpark\",\"dbt\",\"Airflow\",\"Docker\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"]}\n\nJob Summary:\nE-commerce company hiring a Mid-level Data Engineer to build PySpark batch jobs on Databricks, transform data with dbt on Snowflake, orchestrate pipelines with Airflow, and write SQL and Python for feature engineering. Scala knowledge is a plus for Spark optimization.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PySpark, Apache Spark, dbt, Airflow, Snowflake, Python, and SQL are all direct matches\",\"Scala satisfies the optimization plus requirement\",\"Mid-level seniority aligns with the role\"],\"gaps\":[\"No Databricks-specific experience listed, though Spark expertise is directly transferable\"],\"explanation\":\"The candidate covers every primary tool in the job description including the Scala plus. The only minor gap is Databricks-specific platform experience, which represents minimal ramp-up given their deep Spark background.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ali_dotnet_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C#\",\"SQL\"],\"tech\":[\"ASP.NET\",\"Entity Framework\",\"Docker\",\"Azure\"],\"databases\":[\"MS SQL Server\",\"PostgreSQL\"],\"ci_cd\":[\"Azure Pipelines\"],\"testing\":[\"xUnit\"]}\n\nJob Summary:\nEnterprise logistics company hiring a Mid-level .NET Backend Engineer to maintain ASP.NET services with Entity Framework, SQL Server for storage, Azure for hosting, and Azure Pipelines for CI. xUnit for unit testing. C# fluency required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"ASP.NET, Entity Framework, SQL Server, Azure, Azure Pipelines, xUnit, and C# are all exact matches\",\"Docker and PostgreSQL add deployment and relational database breadth\",\"Mid-level seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate's .NET and Azure ecosystem maps precisely to every requirement in the job description. No gaps were identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mira_flutter_mid\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"JavaScript\"],\"tech\":[\"Flutter\",\"Firebase\",\"Riverpod\",\"Expo\"],\"databases\":[\"Firestore\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Flutter Test\"]}\n\nJob Summary:\nHealthtech startup hiring a Mid-level Flutter Engineer to build a cross-platform patient-facing app. Riverpod for state management, Firebase and Firestore for backend sync, SQLite for offline storage. GitHub Actions for CI and Flutter Test framework for automated tests.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Flutter, Dart, Riverpod, Firebase, Firestore, SQLite, GitHub Actions, and Flutter Test are all exact matches\",\"Mid-level seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"Every technology in the job description is directly evidenced in the candidate's profile. This is a precise, high-confidence match for the Flutter mobile engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jorge_rails_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"Ruby\",\"JavaScript\"],\"tech\":[\"Ruby on Rails\",\"Sidekiq\",\"React\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MySQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"RSpec\",\"Capybara\"]}\n\nJob Summary:\nMarketplace startup hiring a Mid-level Full Stack Engineer to build features on a Ruby on Rails and React codebase, process async jobs with Sidekiq, use PostgreSQL and Redis, and deploy with Docker. RSpec and Capybara for testing. GitHub Actions for CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Ruby on Rails, Sidekiq, React, Docker, PostgreSQL, Redis, GitHub Actions, RSpec, and Capybara are all exact matches\",\"Mid-level full stack seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate's profile maps precisely to every technology in the job description with no gaps. This is a high-confidence strong fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ingrid_k8s_lead\",\"seniority\":\"Lead\",\"roles\":[\"Platform Engineer\",\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"AWS\",\"Prometheus\",\"Grafana\",\"Vault\",\"Docker\",\"Argo CD\"],\"architecture\":[\"Cloud-Native\",\"Multi-Tenant\"],\"ci_cd\":[\"Argo CD\",\"GitHub Actions\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nFintech company hiring a Lead Platform Engineer to own a multi-tenant Kubernetes platform on AWS, manage Helm releases, implement GitOps via Argo CD, secure secrets with Vault, and maintain observability with Prometheus and Grafana. Terraform for IaC. Go or Python for automation.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Helm, Terraform, AWS, Argo CD, Vault, Prometheus, Grafana, Docker, Go, and Python are all exact matches\",\"Multi-tenant and cloud-native architecture background is directly relevant\",\"Lead seniority aligns with platform ownership and team leadership expectations\",\"k6 signals load testing maturity\"],\"gaps\":[],\"explanation\":\"Every tool, architecture pattern, and seniority expectation in the job description is matched with direct evidence. This is a comprehensive and high-confidence fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tamar_angular_senior\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Angular\",\"NgRx\",\"RxJS\",\"Tailwind CSS\",\"Karma\",\"Storybook\"],\"testing\":[\"Karma\",\"Jasmine\",\"Cypress\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise SaaS company hiring a Senior Angular Engineer to maintain and extend a large Angular codebase with NgRx and RxJS for state and reactive data. Storybook for component documentation. Karma and Jasmine for unit tests, Cypress for E2E. Tailwind CSS for styling.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Angular, NgRx, RxJS, Tailwind CSS, Storybook, Karma, Jasmine, Cypress, and GitHub Actions are all exact matches\",\"Senior seniority aligns with the role\",\"TypeScript-only language profile suits strict enterprise typing standards\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a tool-for-tool match for every requirement in this enterprise Angular role. Their RxJS depth is a specific and differentiating match for the reactive data management expectations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devraj_python_senior\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"Celery\",\"Docker\",\"AWS\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nLogistics startup hiring a Senior Backend Engineer to build REST APIs in FastAPI, process async tasks with Celery, manage PostgreSQL and MongoDB, cache with Redis on AWS. Docker for containers. pytest for tests. GitHub Actions for CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"FastAPI, Celery, PostgreSQL, MongoDB, Redis, Docker, AWS, pytest, and GitHub Actions are all exact matches\",\"Senior seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"Every technology in the job description is directly evidenced in the candidate's profile. No meaningful gaps were identified, making this a high-confidence match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nora_react_junior\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Vite\"],\"testing\":[\"Jest\",\"Testing Library\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nProduct startup hiring a Junior Frontend Engineer to contribute to a Next.js and React dashboard. TypeScript required. Tailwind CSS for styling, Vite for bundling, Jest and Testing Library for unit tests. GitHub Actions for CI. Senior mentorship available.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React, Next.js, TypeScript, Tailwind CSS, Vite, Jest, Testing Library, and GitHub Actions are all exact matches\",\"Junior seniority matches the role and mentored context\"],\"gaps\":[],\"explanation\":\"The candidate's profile covers every technology in the job description precisely. For a junior role with senior mentorship, this is a high-confidence fit with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"carlos_mlops_senior\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"MLflow\",\"Kubeflow\",\"PyTorch\",\"FastAPI\",\"Docker\",\"Kubernetes\",\"AWS\"],\"architecture\":[\"Cloud-Native\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"Argo CD\",\"GitHub Actions\"]}\n\nJob Summary:\nAI infrastructure company seeking a Senior MLOps Engineer to manage model training with Kubeflow, track experiments with MLflow, containerize models with Docker, serve via FastAPI, and deploy on Kubernetes with AWS. GitOps via Argo CD. Python required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubeflow, MLflow, FastAPI, Docker, Kubernetes, AWS, Argo CD, and Python are all exact matches\",\"PyTorch provides model training depth relevant to the pipeline context\",\"Senior seniority and cloud-native architecture background align with the role\"],\"gaps\":[],\"explanation\":\"The candidate's MLOps profile covers every requirement in the job description with direct evidence. No meaningful gaps were identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yuki_android_senior\",\"seniority\":\"Senior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Hilt\",\"Retrofit\",\"Room\",\"WorkManager\",\"Firebase\"],\"databases\":[\"Room\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"Espresso\",\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nConsumer fintech startup hiring a Senior Android Engineer to build a Kotlin and Jetpack Compose payment app. Hilt for DI, Retrofit for REST APIs, Room for local storage, Firebase for analytics. Fastlane and GitHub Actions for release and CI. Espresso and JUnit for testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kotlin, Jetpack Compose, Hilt, Retrofit, Room, Firebase, Fastlane, GitHub Actions, Espresso, and JUnit are all exact matches\",\"Mockito adds testing depth beyond listed requirements\",\"Senior seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"Every tool and framework in the job description is directly evidenced in the candidate's profile. This is a comprehensive, high-confidence match for the Android fintech engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tom_iac_senior\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\",\"Cloud Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Terraform\",\"Ansible\",\"Docker\",\"AWS\",\"Packer\",\"Vault\"],\"architecture\":[\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\",\"Jenkins\"]}\n\nJob Summary:\nEnterprise company hiring a Senior Infrastructure Engineer to write Terraform and Ansible automation for AWS environments, build immutable AMIs with Packer, manage secrets with HashiCorp Vault, and maintain Jenkins and GitHub Actions CI pipelines. Python and Bash scripting required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Terraform, Ansible, AWS, Packer, Vault, Jenkins, GitHub Actions, Python, and Bash are all exact matches\",\"Senior seniority aligns with the role\",\"Cloud-native architecture background supports the IaC-focused work\"],\"gaps\":[],\"explanation\":\"The candidate's profile covers every tool in the job description with direct evidence, including the less common Packer for immutable AMI builds. This is a high-confidence strong fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ross_data_junior\",\"seniority\":\"Junior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Airflow\",\"dbt\",\"Docker\",\"Pandas\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nData company offering a Junior Data Engineering role to build dbt models on Snowflake, write Airflow DAGs for pipeline orchestration, assist with data quality checks, and collaborate with senior engineers. Python and SQL are the primary languages. Docker for local development.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt, Airflow, Snowflake, PostgreSQL, Python, SQL, Docker, and Pandas are all direct matches\",\"Junior seniority matches the role and collaborative team context\"],\"gaps\":[],\"explanation\":\"The candidate's data engineering toolkit maps precisely to every requirement in the job description. For a junior role with senior collaboration, this profile represents a high-confidence fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ivan_ios_mid\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Combine\",\"Alamofire\",\"Core Data\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"XCTest\",\"Quick\"]}\n\nJob Summary:\nConsumer app company seeking a Mid-level iOS Engineer to build SwiftUI features, manage Core Data persistence, handle reactive flows with Combine, integrate REST APIs using Alamofire, automate releases with Fastlane, and test with XCTest.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SwiftUI, UIKit, Combine, Core Data, Alamofire, Fastlane, GitHub Actions, XCTest, and Quick are all direct matches\",\"Mid-level seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"Every tool in the job description is directly evidenced in the candidate's profile. This is a precise, high-confidence fit for the iOS engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fabian_aws_senior\",\"seniority\":\"Senior\",\"roles\":[\"Cloud Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"AWS\",\"Kubernetes\",\"Terraform\",\"Helm\",\"Docker\",\"Prometheus\",\"Grafana\",\"Argo CD\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nStartup hiring a Senior Cloud Engineer to manage AWS Kubernetes infrastructure, write Terraform for IaC, maintain Helm charts, operate observability with Prometheus and Grafana, and run GitOps deployments via Argo CD. Python and Go scripting expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"AWS, Kubernetes, Terraform, Helm, Prometheus, Grafana, Argo CD, Docker, Python, and Go are all exact matches\",\"Cloud-native and microservices architecture experience is directly relevant\",\"Senior seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate's cloud engineering profile covers every technology and scripting requirement in the job description. No meaningful gaps were identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"layla_mid_backend\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Gin\",\"Docker\",\"AWS\",\"Kafka\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Go testing\",\"Testify\"]}\n\nJob Summary:\nSaaS platform company hiring a Senior Go Backend Engineer to design and lead REST and gRPC microservices using Gin, integrate Kafka for event streaming, own PostgreSQL and Redis, deploy on AWS with Docker, and mentor two junior engineers.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go, Gin, Kafka, PostgreSQL, Redis, Docker, AWS, GitHub Actions, Go testing, and Testify are direct technical matches\",\"Mid-level experience provides solid Go foundations\"],\"gaps\":[\"Mid seniority is one level below Senior; mentoring and lead microservice design are Senior-level expectations\",\"No gRPC experience despite it being part of the service communication stack\"],\"explanation\":\"The candidate's Go stack aligns well technically, but the seniority gap is meaningful for a role that expects lead-level microservice design and mentoring. The absence of gRPC is an additional gap given it is listed alongside REST as a communication protocol.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sofia_mleng_mid\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"scikit-learn\",\"XGBoost\",\"Pandas\",\"NumPy\",\"MLflow\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nFinttech company hiring a Senior ML Engineer to build fraud detection models using deep learning in PyTorch, build real-time feature pipelines on Kafka, serve models via FastAPI on Kubernetes, and manage experiments in MLflow. AWS and Docker for infrastructure.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"MLflow and Docker are direct matches to the experiment tracking and containerization requirements\",\"Pandas, NumPy, and scikit-learn show solid ML fundamentals\"],\"gaps\":[\"No PyTorch or deep learning experience; role centers on neural network models\",\"No Kafka or streaming pipeline experience\",\"No FastAPI or model serving experience\",\"No Kubernetes or AWS experience\",\"Mid seniority is below the Senior requirement\"],\"explanation\":\"The candidate has machine learning fundamentals and experiment tracking experience, but the role requires deep learning with PyTorch and a production serving stack \u2014 Kafka, FastAPI, and Kubernetes \u2014 that are entirely absent. The seniority gap compounds this mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"marta_vue_senior\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\",\"Vite\",\"GraphQL\"],\"testing\":[\"Vitest\",\"Playwright\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nSaaS company seeking a Senior Frontend Engineer to own the Next.js and React frontend, establish TypeScript standards, lead GraphQL adoption with Apollo Client, define testing practices with Playwright and Jest, and mentor two junior engineers.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript and GraphQL experience are directly relevant to the adoption initiative\",\"Playwright aligns with the stated E2E testing expectation\",\"Senior seniority and frontend specialization match the leadership expectations\"],\"gaps\":[\"No React or Next.js experience; the frontend stack is entirely React-based\",\"No Apollo Client experience despite it being the specified GraphQL client\",\"No Jest experience; only Vitest listed\"],\"explanation\":\"The candidate is a strong Vue.js engineer with transferable TypeScript, GraphQL, and testing skills, but the role's React and Next.js stack is a meaningful framework mismatch. Apollo Client absence and the Jest gap add to the ramp-up required.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nadia_backend_junior\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"FastAPI\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nStartup hiring a Junior Backend Engineer to build REST API endpoints in FastAPI, write data models with SQLAlchemy for PostgreSQL, and work under senior guidance. Docker for local development. pytest for testing basics.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI, Python, Docker, and PostgreSQL are direct technical matches\",\"Junior seniority matches the role and senior guidance context\"],\"gaps\":[\"No SQLAlchemy experience for the ORM layer\",\"No pytest experience despite it being expected\"],\"explanation\":\"The candidate has the core stack in FastAPI and PostgreSQL but is missing SQLAlchemy and pytest, both of which are stated expectations for this role. These are learnable gaps but represent missing pieces for the defined starting requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex_spring_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Hibernate\",\"Docker\"],\"databases\":[\"MySQL\",\"Redis\"]}\n\nJob Summary:\nFinttech company hiring a Senior Java Backend Engineer to architect payment processing microservices in Spring Boot, lead technical design reviews, define Kafka messaging standards, manage PostgreSQL and Redis on AWS, mentor three engineers, and establish test coverage practices with Testcontainers.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Spring Boot, Hibernate, Docker, and Redis provide relevant technical foundations\",\"Java fluency is the required primary language\"],\"gaps\":[\"Mid seniority is one level below Senior; architectural design, technical reviews, and mentoring are Senior-level expectations\",\"No Kafka experience for the messaging standards requirement\",\"No PostgreSQL experience; only MySQL listed\",\"No AWS experience\",\"No Testcontainers or advanced testing experience\",\"No microservices or system design leadership experience evidenced\"],\"explanation\":\"The candidate has a solid Java Spring Boot foundation but multiple gaps across the technical stack and seniority expectations. Kafka, AWS, PostgreSQL, and Testcontainers are all absent, and the mentoring and design leadership expectations require Senior-level experience not yet demonstrated.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"joel_backend_ts\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Express.js\",\"Node.js\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nAdtech company hiring a Senior Backend Engineer to lead a NestJS and TypeScript platform with GraphQL APIs, PostgreSQL and Redis on AWS, async jobs with BullMQ, and mentor three engineers. Strong NestJS architecture experience required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript, Node.js, AWS, PostgreSQL, Docker, GitHub Actions, Jest, and Supertest are strong foundational matches\",\"Mid-level backend experience with the right language ecosystem\"],\"gaps\":[\"No NestJS experience; Express.js is a fundamentally different framework and paradigm\",\"No GraphQL or BullMQ experience\",\"No Redis experience\",\"Mid seniority is one level below Senior; mentoring and architectural leadership are Senior-level expectations\"],\"explanation\":\"The candidate has the right language and Node.js ecosystem foundation, but NestJS, GraphQL, and BullMQ are all absent \u2014 and these represent the primary technical differentiators of the role. The seniority gap further limits readiness for the mentoring and design ownership expectations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mia_ux_engineer\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"CSS\"],\"tech\":[\"React\",\"CSS Modules\",\"Styled-components\",\"Storybook\",\"Bootstrap\"]}\n\nJob Summary:\nEnterprise software company hiring a Senior Frontend Engineer to build performant TypeScript React dashboards with Zustand and React Query, Tailwind CSS for styling, Playwright and Jest for testing, and GitHub Actions for CI. Strong TypeScript required throughout.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React experience is a direct match to the core framework\",\"Storybook demonstrates component documentation awareness\"],\"gaps\":[\"No TypeScript experience despite being described as a strong requirement\",\"No Zustand or React Query experience\",\"No Tailwind CSS; Bootstrap and Styled-components are different styling approaches\",\"No Playwright or Jest testing experience visible\",\"No GitHub Actions CI experience\"],\"explanation\":\"The candidate's React background is a foundational match, but the absence of TypeScript is a critical gap for a codebase where it is described as a strong requirement throughout. The state management, styling, and testing tools also all differ from what the employer uses.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"peter_ruby_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Ruby\",\"SQL\"],\"tech\":[\"Ruby on Rails\",\"Sidekiq\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"RSpec\"]}\n\nJob Summary:\nB2C startup hiring a Senior Ruby on Rails Engineer to lead the backend architecture evolution, mentor a team of four, define Sidekiq queue strategies, migrate from a monolith to modular architecture, and own PostgreSQL performance tuning.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Ruby on Rails, Sidekiq, PostgreSQL, Redis, Docker, GitHub Actions, and RSpec are direct technical matches\",\"Mid-level Rails experience provides relevant foundations\"],\"gaps\":[\"Mid seniority is one level below Senior; architectural leadership and mentoring four engineers are Senior-level expectations\",\"No modular architecture or monolith decomposition experience evidenced\",\"No database performance tuning experience explicitly visible\"],\"explanation\":\"The candidate's Rails stack is a strong technical match, but the role demands Senior-level architectural judgment including monolith migration and team mentoring that require experience beyond what a Mid-level engineer typically demonstrates.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"bola_dataeng_mid\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"dbt\",\"Airflow\",\"Pandas\",\"Docker\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"]}\n\nJob Summary:\nMedia company seeking a Senior Data Engineer to design and own real-time Kafka streaming pipelines, build dbt transformations on Snowflake, orchestrate with Airflow, and run PySpark jobs on Databricks. Python and SQL required. Team lead responsibilities for two engineers.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt, Airflow, Python, SQL, and Docker are relevant partial stack matches\",\"BigQuery and PostgreSQL show data warehousing experience\"],\"gaps\":[\"Mid seniority is below Senior; team lead responsibilities are a Senior-level expectation\",\"No Kafka or streaming pipeline experience despite it being a core requirement\",\"No Snowflake experience; BigQuery is a different warehouse platform\",\"No PySpark or Databricks experience\",\"No Spark framework experience at all\"],\"explanation\":\"The candidate has dbt and Airflow foundations that overlap with the batch processing side, but the role is equally focused on real-time Kafka streaming and Spark on Databricks \u2014 both entirely absent. The seniority gap and team lead expectation add further concern.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mei_security_mid\",\"seniority\":\"Mid\",\"roles\":[\"Security Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"AWS\",\"Docker\",\"Vault\",\"Terraform\"],\"architecture\":[\"Cloud-Native\"]}\n\nJob Summary:\nCloud company hiring a Senior Application Security Engineer to conduct threat modeling, integrate SAST tools into CI pipelines, harden Kubernetes workloads, manage secrets with Vault, and build automated security tooling in Go or Python. AWS environment. Minimum five years of AppSec experience.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Vault, AWS, Terraform, Docker, and Python are relevant technical matches\",\"Cloud-native architecture background is relevant to the cloud security context\"],\"gaps\":[\"Mid seniority is below Senior with a five-year minimum AppSec experience requirement\",\"No Kubernetes experience for the workload hardening requirement\",\"No SAST or CI pipeline security integration experience\",\"No Go experience for tooling alongside Python\",\"No explicit threat modeling experience\"],\"explanation\":\"The candidate has relevant cloud security foundations with Vault and AWS, but lacks Kubernetes, SAST pipeline integration, and the five-year minimum experience the role requires for threat modeling and security engineering leadership.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ibrahim_swe_senior\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Spring Boot\",\"Docker\",\"AWS\",\"RabbitMQ\"],\"databases\":[\"PostgreSQL\",\"MySQL\",\"Redis\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nFinttech company hiring a Senior Kotlin Backend Engineer to build microservices in Spring Boot using Kotlin, stream financial events with Kafka, manage PostgreSQL and Redis on AWS EKS, and test with JUnit and Mockito. Docker for containers. GitHub Actions for CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin, Spring Boot, PostgreSQL, Redis, Docker, AWS, JUnit, and Mockito are direct matches to the stated tech stack\",\"Senior seniority aligns with the role\",\"RabbitMQ messaging experience provides adjacent async knowledge\"],\"gaps\":[\"No Kafka experience; RabbitMQ is a different messaging paradigm from Kafka streaming\",\"No Kubernetes or EKS experience despite EKS being the deployment target\",\"No GitHub Actions experience; Jenkins is a different CI system\"],\"explanation\":\"The candidate's Kotlin and Spring Boot background is a strong match for the application layer, but three meaningful gaps emerge: Kafka streaming vs RabbitMQ, EKS for Kubernetes orchestration, and the CI system difference. These represent the infrastructure and messaging layers of the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rin_backend_ts\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"GraphQL\",\"Docker\",\"AWS\",\"Prisma\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nSaaS startup hiring a Senior Backend Engineer to own NestJS GraphQL API architecture, mentor two engineers, define Prisma schema strategy for PostgreSQL, implement caching with Redis on AWS, and drive testing standards with Jest.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"NestJS, GraphQL, Prisma, PostgreSQL, Redis, Docker, AWS, GitHub Actions, Jest, and Supertest are all direct technical matches\",\"TypeScript fluency supports the codebase requirements\"],\"gaps\":[\"Mid seniority is one level below Senior; architecture ownership and mentoring two engineers are Senior-level expectations\"],\"explanation\":\"The candidate's technical stack is a precise match for every tool and technology in the role. The only gap is the seniority level \u2014 the employer expects Senior-level ownership and mentoring, which a Mid-level engineer is still developing. The technical alignment is otherwise excellent.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lars_vue_mid\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\"],\"testing\":[\"Vitest\",\"Cypress\"]}\n\nJob Summary:\nEnterprise SaaS company hiring a Senior Frontend Engineer to lead the React and TypeScript component system, own the Storybook design system, mentor three engineers, and establish Playwright testing standards. Apollo Client for GraphQL data fetching.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript experience is directly relevant to the codebase requirements\",\"Cypress testing background provides E2E test discipline\",\"Senior frontend expectations match the candidate's seniority experience level if promoted\"],\"gaps\":[\"No React experience; the entire stack is React-based\",\"No Storybook or design system tooling experience\",\"No Playwright experience despite it being the stated testing standard\",\"No GraphQL or Apollo Client experience\",\"Mid seniority is below Senior; mentoring and design system ownership are Senior-level expectations\"],\"explanation\":\"The candidate is a strong Vue.js engineer with transferable TypeScript and testing habits, but the framework mismatch and missing design system and GraphQL tooling are meaningful gaps. The seniority difference further limits readiness for the leadership expectations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"bea_data_mid\",\"seniority\":\"Mid\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"Weights & Biases\",\"PyTorch\"]}\n\nJob Summary:\nRetail company seeking a Senior Data Scientist to build demand forecasting models using XGBoost and LightGBM on tabular data, track experiments with MLflow, serve predictions via FastAPI, and query Snowflake for feature data. Python required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python fluency is the required language\",\"scikit-learn and Pandas provide relevant ML and feature engineering foundations\",\"Weights and Biases shows experiment tracking familiarity\"],\"gaps\":[\"No XGBoost or LightGBM experience; these are the primary forecasting tools\",\"No MLflow; Weights and Biases is a different system\",\"No FastAPI for model serving\",\"No Snowflake experience\",\"Mid seniority is below Senior\"],\"explanation\":\"The candidate has solid Python data science fundamentals but the role's specific gradient boosting tools, experiment tracking system, serving framework, and data warehouse are all different from what the candidate has used. The seniority gap is an additional qualifier.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vince_devops_senior\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"AWS\",\"Terraform\",\"Ansible\",\"Jenkins\",\"Docker\",\"Prometheus\"],\"architecture\":[\"Cloud-Native\"]}\n\nJob Summary:\nScale-up company hiring a Senior Platform Engineer to own a Kubernetes-first developer platform on GCP, implement service mesh with Istio, adopt GitOps via Flux, build observability with OpenTelemetry and Grafana, and lead three platform engineers.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform, Ansible, Docker, and Prometheus provide transferable infrastructure foundations\",\"Senior seniority matches the role level\",\"AWS experience is conceptually transferable to GCP\"],\"gaps\":[\"No Kubernetes experience despite it being the core platform technology\",\"No GCP experience; the platform is GCP-native\",\"No Istio or service mesh experience\",\"No Flux or GitOps tooling\",\"No OpenTelemetry or Grafana experience\"],\"explanation\":\"The candidate is an experienced traditional DevOps engineer, but the role requires modern cloud-native platform engineering with Kubernetes, Istio, and GitOps tooling that are entirely absent from the profile. Both the cloud provider and the platform stack represent meaningful ramp-up requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nia_react_mid\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Redux\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nFinttech startup seeking a Senior Frontend Engineer to architect the design system, own Storybook component library, lead four frontend engineers, define Playwright E2E standards, and drive TanStack Query adoption for server state management.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React, Next.js, TypeScript, Tailwind CSS, GitHub Actions, and Jest are relevant technical foundations\",\"Mid-level frontend experience with the right stack\"],\"gaps\":[\"Mid seniority is one level below Senior; design system leadership and mentoring four engineers are Senior-level expectations\",\"No Storybook experience for the component library requirement\",\"No Playwright experience despite it being the stated E2E standard\",\"No TanStack Query experience; Redux is a different state management approach\"],\"explanation\":\"The candidate's React and Next.js foundation is aligned with the tech stack, but the role requires Senior-level leadership and specific tooling \u2014 Storybook, Playwright, and TanStack Query \u2014 that are absent. The seniority gap is meaningful given the team leadership scope.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"obi_java_senior\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Docker\",\"AWS\",\"RabbitMQ\"],\"databases\":[\"PostgreSQL\",\"MySQL\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nStreaming company hiring a Senior Go Backend Engineer to build video delivery microservices using the Fiber framework, stream viewer events with Kafka, communicate via gRPC, manage PostgreSQL and Redis on AWS EKS, and write comprehensive Go tests.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"PostgreSQL, Docker, and AWS experience provides some infrastructure familiarity\",\"Senior backend experience demonstrates software engineering maturity\"],\"gaps\":[\"No Go experience; Go is the sole required language and concurrency model\",\"No Fiber framework experience\",\"No Kafka experience; RabbitMQ is a different messaging paradigm\",\"No gRPC experience\",\"No Redis or Kubernetes experience\",\"Java and Spring Boot are entirely irrelevant to a Go streaming platform\"],\"explanation\":\"Despite being a Senior backend engineer, the candidate has no Go experience which is the foundational and only language for this role. The messaging and service communication technologies also differ. This is a comprehensive language and stack mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dana_python_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"SQLAlchemy\",\"Docker\",\"Redis\",\"Celery\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nSaaS company hiring a Senior Backend Engineer to architect a Python FastAPI platform, define SQLAlchemy ORM patterns, lead API design across teams, manage PostgreSQL and Redis on AWS, mentor three engineers, and establish Celery queue strategies.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI, SQLAlchemy, Docker, Redis, Celery, PostgreSQL, GitHub Actions, and pytest are all direct technical matches\",\"Python fluency is the required primary language\"],\"gaps\":[\"Mid seniority is one level below Senior; API design leadership and mentoring three engineers are Senior-level expectations\",\"No AWS experience despite it being the production cloud platform\"],\"explanation\":\"The candidate's technical stack is a precise match for every tool in the role. The gaps are entirely around seniority and AWS experience \u2014 the employer expects Senior-level architectural guidance and production AWS ownership that a Mid-level engineer is still developing.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sam_android_mid\",\"seniority\":\"Mid\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Retrofit\",\"Room\",\"Hilt\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Espresso\"]}\n\nJob Summary:\nScale-up company hiring a Senior Android Engineer to own Android architecture using Kotlin Multiplatform for shared business logic with iOS, mentor two Android developers, define Clean Architecture standards, and manage releases with Fastlane.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin, Jetpack Compose, Hilt, Retrofit, Room, JUnit, Espresso, and GitHub Actions are strong technical matches\",\"Mid-level Android experience provides solid foundational skills\"],\"gaps\":[\"No Kotlin Multiplatform experience despite it being the central architectural requirement\",\"Mid seniority is below Senior; mentoring and Clean Architecture ownership are Senior-level expectations\",\"No Fastlane experience for release management\"],\"explanation\":\"The candidate's Android toolkit is technically well-aligned but KMP is entirely absent \u2014 and it is the defining technical requirement for shared iOS-Android logic. The seniority and Fastlane gaps further limit readiness for the architectural leadership this role requires.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"grace_ios_junior\",\"seniority\":\"Junior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"Firebase\"],\"databases\":[\"Firestore\"]}\n\nJob Summary:\nEnterprise company hiring a Lead iOS Engineer to design iOS architecture across three app teams, define Swift coding standards, lead a team of six iOS developers, own the CI/CD pipeline with Fastlane, and drive accessibility compliance. Minimum seven years of Swift experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Swift and SwiftUI provide the foundational iOS development language and framework\"],\"gaps\":[\"Junior seniority is the maximum possible gap from a Lead requirement with a seven-year minimum\",\"No team leadership or mentoring experience at this career stage\",\"No Fastlane or CI/CD pipeline experience\",\"No iOS architecture or coding standards leadership experience\",\"No accessibility compliance or audit experience\",\"Firestore and Firebase focus does not reflect enterprise iOS architecture patterns\"],\"explanation\":\"The candidate is at the very beginning of their iOS career, while the role requires a Lead engineer with seven-plus years of experience and team ownership responsibilities across three app teams. The gap in seniority, leadership, and tooling is fundamental.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leon_sre_mid\",\"seniority\":\"Mid\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Prometheus\",\"Grafana\",\"Docker\",\"AWS\",\"Terraform\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nStreaming company hiring a Lead SRE to own reliability for a distributed media delivery system, lead five SREs, define SLO frameworks, manage incident response with PagerDuty, implement distributed tracing with Jaeger, and run chaos engineering. Terraform for IaC.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes, Prometheus, Grafana, Terraform, Docker, AWS, and GitHub Actions are direct technical matches\",\"Python and Bash scripting provide SRE automation capability\"],\"gaps\":[\"Mid seniority is significantly below Lead; leading five engineers and defining SLO frameworks are Lead-level responsibilities\",\"No PagerDuty or incident management experience\",\"No Jaeger or distributed tracing tooling\",\"No chaos engineering experience\"],\"explanation\":\"The candidate has a strong observability and infrastructure foundation but the role demands Lead-level team management and advanced reliability engineering practices \u2014 PagerDuty, Jaeger, and chaos engineering \u2014 that are absent. The seniority gap is the most significant barrier given the team leadership scope.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ben_node_senior\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Express.js\",\"Node.js\",\"Docker\",\"AWS\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nFinttech company hiring a Senior Backend Engineer to lead a NestJS and TypeScript GraphQL API platform, integrate Kafka for payment event streaming, manage PostgreSQL and Redis on AWS, run comprehensive tests with Jest, and mentor two junior engineers.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript, Node.js, PostgreSQL, Redis, Docker, AWS, GitHub Actions, Jest, and Supertest are strong foundational matches\",\"Senior seniority and backend specialization align with the leadership expectations\"],\"gaps\":[\"No NestJS experience; Express.js is a different architectural framework\",\"No GraphQL experience despite it being the primary API paradigm\",\"No Kafka experience for the payment event streaming requirement\"],\"explanation\":\"The candidate has the right language, database tier, and infrastructure background, but the framework shift to NestJS and the absence of GraphQL and Kafka represent the primary technical differentiators of this role. These gaps span the API layer and event streaming core responsibilities.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fatou_fe_intern\",\"seniority\":\"Intern\",\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"HTML\",\"CSS\"]}\n\nJob Summary:\nProduct company hiring a Senior Full Stack Engineer to architect a TypeScript Next.js and FastAPI platform, define PostgreSQL and MongoDB schema strategy, own AWS infrastructure with Terraform, lead code reviews, and mentor a team of six engineers. Minimum eight years experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Intern seniority is the maximum possible gap from a Senior requirement with an eight-year minimum\",\"No TypeScript, Next.js, or FastAPI experience\",\"No PostgreSQL, MongoDB, AWS, or Terraform experience\",\"No team leadership or mentoring experience\",\"Intern-level React and HTML skills are entirely insufficient for a Senior architectural leadership role\"],\"explanation\":\"The candidate is at the very start of their career with fundamental web skills, while the role requires eight-plus years of full stack experience and senior leadership responsibilities. The gap in seniority, technology depth, and scope is fundamental and cannot be bridged for this particular opening.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yara_backend_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"Celery\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nHealthtech startup hiring a Senior Backend Engineer to architect multi-tenant patient data APIs in FastAPI, define PostgreSQL schema standards, mentor three engineers, own AWS deployment strategy, and establish Celery queue reliability patterns.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Celery, Redis, PostgreSQL, Docker, GitHub Actions, pytest, and Python are direct technical matches\",\"Django and FastAPI are both Python web frameworks with adjacent paradigms\"],\"gaps\":[\"Mid seniority is one level below Senior; multi-tenant architecture, mentoring, and deployment ownership are Senior-level expectations\",\"No FastAPI experience specifically; Django is a different framework with different design patterns\",\"No AWS experience despite it being the deployment target\",\"No multi-tenancy experience despite it being the architectural focus\"],\"explanation\":\"The candidate's Python backend toolkit overlaps well in the async and database layers, but the seniority gap and absence of FastAPI, AWS, and multi-tenancy experience are meaningful for a role centered on architectural ownership and team leadership.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cleo_embedded_mid\",\"seniority\":\"Mid\",\"roles\":[\"Embedded Engineer\"],\"languages\":[\"C\",\"Python\"],\"tech\":[\"FreeRTOS\",\"CMake\",\"Docker\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAutomotive company seeking a Senior Embedded Software Engineer to write firmware for ARM Cortex-M and Cortex-A devices in C, own real-time OS design with FreeRTOS, establish CMake build standards, write hardware-in-the-loop tests in Python, mentor two firmware engineers, and manage safety-critical code reviews for ISO 26262 compliance.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"C, FreeRTOS, CMake, Python, Docker, and GitHub Actions are direct technical matches\",\"Mid-level embedded experience provides relevant firmware foundations\"],\"gaps\":[\"Mid seniority is one level below Senior; mentoring two engineers and build standard ownership are Senior-level expectations\",\"No ISO 26262 or functional safety compliance experience despite it being a safety-critical system\",\"No hardware-in-the-loop testing experience specifically\",\"No Cortex-A experience; only Cortex-M is typical at mid-level\"],\"explanation\":\"The candidate's embedded toolkit aligns well with the core stack, but the role's safety-critical compliance requirements and Senior-level mentoring expectations introduce meaningful gaps. ISO 26262 experience in particular is a specialized domain requirement not evidenced in the profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kwesi_game_dev\",\"seniority\":\"Mid\",\"roles\":[\"Game Developer\"],\"languages\":[\"C#\",\"C++\"],\"tech\":[\"Unity\",\"Unreal Engine\",\"Docker\"]}\n\nJob Summary:\nFinttech company hiring a Senior Backend Engineer to design distributed payment processing microservices in Go, build Kafka event streaming pipelines, manage PostgreSQL on AWS EKS, define API contracts with Protobuf, and mentor four engineers.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker and C++ provide minor transferable systems programming context\"],\"gaps\":[\"No Go experience; Go is the sole required language\",\"No Kafka, gRPC, or Protobuf experience\",\"No PostgreSQL or AWS experience\",\"No microservices or distributed systems experience\",\"Mid seniority is below Senior; mentoring four engineers requires Senior-level experience\",\"Game development background has no meaningful overlap with distributed payment systems engineering\"],\"explanation\":\"The candidate's game development background has no meaningful technical overlap with a Go-based distributed fintech platform. The domain, language, architecture, and seniority are all mismatched for this senior leadership role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ines_backend_senior\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Flask\",\"SQLAlchemy\",\"Docker\",\"AWS\",\"Celery\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nMedia startup hiring a Senior Backend Engineer to build and scale REST APIs in Django REST Framework, process async jobs with Celery, manage PostgreSQL and Redis on AWS, containerize with Docker, and test with pytest. GitHub Actions for CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Celery, PostgreSQL, Redis, Docker, AWS, GitHub Actions, pytest, and Python are all direct matches\",\"Flask and Django are both Python web frameworks; the transition is meaningful but not a full stack change\",\"Senior seniority aligns with the role\",\"SQLAlchemy ORM experience is transferable to Django ORM patterns\"],\"gaps\":[\"No Django or Django REST Framework experience; Flask has a different architecture and no built-in ORM\",\"No Django-specific REST API patterns or serializer experience\"],\"explanation\":\"The candidate's Python backend infrastructure stack is a strong match, but the shift from Flask to Django REST Framework involves a meaningful framework transition with different conventions, ORM, and REST patterns. Their SQLAlchemy background is transferable but Django's integrated approach is distinct.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leo_dataeng_junior\",\"seniority\":\"Junior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"dbt\",\"Airflow\",\"Docker\",\"Pandas\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nFinttech company hiring a Senior Data Engineer to design and own real-time Kafka streaming pipelines, build Spark jobs on Databricks, define dbt modeling standards across three teams, orchestrate with Airflow on AWS, and mentor two data engineers.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"dbt and Airflow provide partial pipeline and orchestration familiarity\",\"Python and SQL are the required languages\"],\"gaps\":[\"Junior seniority is far below the Senior requirement; mentoring and multi-team standard-setting are Senior-level responsibilities\",\"No Kafka or real-time streaming experience\",\"No Spark or Databricks experience\",\"No AWS experience\",\"No team leadership or mentoring experience at Junior level\"],\"explanation\":\"The candidate has some foundational data engineering tools with dbt and Airflow, but the role requires Senior-level leadership and a production streaming and Spark stack that are entirely absent. The seniority gap and technical gaps are both substantial.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sara_infra_senior\",\"seniority\":\"Senior\",\"roles\":[\"Cloud Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"AWS\",\"Terraform\",\"Docker\",\"Kubernetes\",\"Helm\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nScale-up company hiring a Staff Cloud Engineer to define cloud architecture standards across ten teams on Azure, drive Bicep adoption for IaC, lead AKS Kubernetes strategy, implement Azure Monitor for observability, establish FinOps practices, and mentor four cloud engineers.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform, Kubernetes, Helm, Docker, and GitHub Actions provide strong infrastructure foundations\",\"AWS Kubernetes experience is conceptually transferable to AKS\"],\"gaps\":[\"Senior seniority is one level below Staff; multi-team standards ownership and mentoring four engineers are Staff-level expectations\",\"No Azure experience; the role is entirely Azure-native\",\"No Bicep experience; only Terraform listed\",\"No Azure Monitor or Azure-native observability tooling\",\"No FinOps experience\"],\"explanation\":\"The candidate is a strong AWS infrastructure engineer with Kubernetes depth, but the role demands Staff-level Azure-native expertise including Bicep, Azure Monitor, and FinOps that require significant cloud platform transition. Both the seniority and cloud provider gaps are meaningful.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jo_fullstack_ts\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"FastAPI\",\"Docker\",\"Tailwind CSS\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\"]}\n\nJob Summary:\nEdtech company seeking a Senior Full Stack Engineer to lead Next.js and FastAPI feature development, own PostgreSQL schema strategy, mentor two junior engineers, define testing standards with Jest, pytest, and Playwright, and manage AWS deployments.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React, FastAPI, TypeScript, Python, PostgreSQL, Docker, GitHub Actions, Jest, and pytest are direct technical matches\",\"Tailwind CSS and mid-level seniority provide relevant frontend and engineering depth\"],\"gaps\":[\"No Next.js experience specifically; React is foundational but Next.js SSR patterns are different\",\"Mid seniority is one level below Senior; mentoring and schema strategy ownership are Senior-level expectations\",\"No Playwright experience despite it being part of the stated testing standard\",\"No AWS experience for the deployment ownership requirement\"],\"explanation\":\"The candidate's stack alignment is strong across the core technologies, but the role expects Senior-level architectural ownership including Next.js SSR patterns, AWS deployment, and Playwright testing that introduce meaningful gaps beyond the current Mid-level baseline.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tom_ml_senior\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"XGBoost\",\"MLflow\",\"Pandas\",\"NumPy\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nHealthcare AI company hiring a Senior ML Engineer to train and deploy transformer-based clinical NLP models using Hugging Face, build RAG pipelines with vector databases, serve inference with FastAPI on Kubernetes, and track experiments with MLflow. Python required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch and MLflow are direct matches to the training framework and experiment tracking tools\",\"Strong ML engineering fundamentals with scikit-learn and XGBoost\",\"Senior seniority and Python fluency align with the role\"],\"gaps\":[\"No Hugging Face Transformers experience despite it being the primary fine-tuning framework\",\"No RAG pipeline or vector database experience\",\"No FastAPI for model serving\",\"No Kubernetes or production ML serving infrastructure experience\"],\"explanation\":\"The candidate's PyTorch and MLflow experience are strong starting points, but the role is centered on transformer fine-tuning and RAG engineering with Hugging Face and vector databases \u2014 specialized capabilities absent from the profile. The production serving stack with FastAPI and Kubernetes is also a gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yemi_fullstack_mid\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"Flask\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nStartup seeking a Senior Full Stack Engineer to architect a TypeScript Next.js frontend and NestJS backend, define PostgreSQL schema strategy, own AWS infrastructure with Terraform, lead code reviews, mentor a team of four engineers, and drive technical roadmap decisions.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and PostgreSQL experience provides partial stack familiarity\"],\"gaps\":[\"No TypeScript, Next.js, or NestJS experience; the entire stack is TypeScript-based\",\"No Terraform or AWS infrastructure experience\",\"Mid seniority is below Senior; roadmap ownership and mentoring four engineers require Senior-level leadership\",\"Flask Python experience is not relevant to a NestJS TypeScript platform\",\"No CI/CD tooling or testing experience visible\"],\"explanation\":\"The candidate's React and PostgreSQL background provides minimal overlap with a TypeScript NestJS platform that requires Senior-level ownership of architecture, infrastructure, and team leadership. The language and framework mismatch alone is disqualifying without a significant ramp-up period.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"gabriel_node_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"Express.js\",\"Node.js\",\"Docker\"],\"databases\":[\"MongoDB\"]}\n\nJob Summary:\nSaaS company seeking a Senior Backend Engineer to lead a TypeScript NestJS platform, design GraphQL APIs with Apollo Server, manage PostgreSQL and Redis on AWS EKS, define testing standards with Jest and Testcontainers, and mentor a five-person backend team.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Node.js and Express.js provide basic backend web framework familiarity\"],\"gaps\":[\"No TypeScript experience; the entire platform is TypeScript-based\",\"No NestJS experience despite it being the primary backend framework\",\"No GraphQL or Apollo Server experience\",\"No PostgreSQL or Redis experience\",\"No AWS or Kubernetes experience\",\"No Jest or Testcontainers experience\",\"Mid seniority is below Senior; mentoring five engineers and leading API design are Senior-level responsibilities\"],\"explanation\":\"The candidate's minimal Node.js profile lacks TypeScript, NestJS, GraphQL, and every database and cloud technology the role requires. The seniority gap compounds what is fundamentally a stack-wide mismatch for a Senior leadership role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nana_csharp_junior\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C#\",\"SQL\"],\"tech\":[\"ASP.NET\",\"Entity Framework\",\"Docker\"],\"databases\":[\"MS SQL Server\"]}\n\nJob Summary:\nEnterprise healthcare company hiring a Principal Software Architect to define .NET platform architecture across six teams, lead cloud migration to Azure, establish FinOps practices, design microservices boundaries using DDD, and mentor eight engineers. Minimum twelve years of experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"C#, ASP.NET, and Entity Framework show relevant .NET development fundamentals\"],\"gaps\":[\"Junior seniority is the maximum possible gap from a Principal requirement with a twelve-year minimum\",\"No Azure or cloud infrastructure experience\",\"No microservices or DDD architectural experience\",\"No FinOps or cloud cost management experience\",\"No team mentoring or technical leadership experience at this career stage\",\"Architecture and platform strategy across six teams requires Principal-level seniority well beyond Junior level\"],\"explanation\":\"The candidate has foundational .NET skills but the role requires a Principal Architect with twelve-plus years of experience and executive-adjacent responsibilities that are fundamentally incompatible with a junior engineer's current career stage.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"zola_backend_php\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"SQL\"],\"tech\":[\"Laravel\",\"Symfony\",\"Docker\",\"Redis\"],\"databases\":[\"MySQL\",\"PostgreSQL\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nStartup hiring a Senior Backend Engineer to build high-throughput event-driven microservices in Go with the Echo framework, Kafka for messaging, PostgreSQL on AWS EKS, and Redis for caching. gRPC for service communication. Strong Go concurrency experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"PostgreSQL, Redis, and Docker experience provides some infrastructure familiarity\",\"Senior backend experience demonstrates software engineering maturity\"],\"gaps\":[\"No Go experience; Go concurrency is listed as a strong requirement\",\"No Echo framework experience\",\"No Kafka or event-driven streaming experience\",\"No gRPC or microservices communication experience\",\"No AWS or Kubernetes experience\",\"PHP and Laravel experience is not relevant to a Go microservices platform\"],\"explanation\":\"The candidate is a strong PHP engineer but the role is entirely Go-based with a concurrency and distributed systems focus. The language and stack mismatch is fundamental with no meaningful overlap in the application layer.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ali_backend_python\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"Django\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nFinttech startup hiring a Senior Backend Engineer to architect a high-throughput payment processing system in Go, design distributed Kafka event pipelines, own PostgreSQL schema migration strategy, lead API design, manage AWS EKS deployments, and mentor four engineers.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"PostgreSQL and Docker provide minor infrastructure overlap\"],\"gaps\":[\"No Go experience; Go is the sole required language\",\"No Kafka or distributed systems experience\",\"No AWS or Kubernetes experience\",\"No API design leadership or mentoring experience\",\"Junior seniority is far below the Senior requirement\",\"Django Python experience is not relevant to a Go payments system\"],\"explanation\":\"The candidate is a junior Python Django developer with a profile that has no meaningful overlap with a Go-based distributed payments platform. Both the career stage and the technology stack are fundamentally mismatched for this senior leadership role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ravi-krishnamurthy\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\"],\"tech\":[\"FastAPI\",\"Docker\",\"Kubernetes\",\"Redis\",\"Nginx\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nWe are a Series B fintech startup building payment infrastructure at scale. We need a senior backend engineer with deep Python or Go experience to design and own microservices handling millions of transactions daily. You will work closely with platform and data teams, so familiarity with Kubernetes, Redis caching, and event-driven architecture is essential. Strong testing discipline and experience with CI/CD pipelines are required. PostgreSQL proficiency is a must.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Python and Go align directly with the role's core language requirements\",\"Kubernetes and Docker signal production-grade infrastructure experience\",\"Microservices and Event-Driven architecture match the system design expectations\",\"PostgreSQL proficiency meets the stated must-have\",\"pytest and GitHub Actions demonstrate testing and CI/CD discipline\"],\"gaps\":[\"No evidence of financial domain or compliance-related engineering\"],\"explanation\":\"Ravi's stack is a near-exact match for the technical requirements listed in the job summary. His combination of FastAPI, Kubernetes, Redis, and event-driven architecture experience directly maps to the payment infrastructure context. The only marginal gap is the absence of fintech-specific signals, which is a minor concern for a startup environment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jess-tanaka\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"Firebase\"],\"testing\":[\"Jest\",\"React Testing Library\"]}\n\nJob Summary:\nFast-growing e-commerce startup looking for a mid-level or senior frontend engineer to lead our design system migration to Next.js and TypeScript. You will own component architecture, mentor junior developers, and collaborate with product and design. Experience with server-side rendering, accessibility standards, and state management libraries such as Zustand or Redux is expected. Familiarity with Storybook and Playwright is a plus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript and React are foundational skills relevant to the role\",\"Jest and React Testing Library show testing awareness\"],\"gaps\":[\"Junior seniority does not meet the mid-level or senior expectation\",\"No evidence of Next.js or server-side rendering experience\",\"No state management library usage (Zustand, Redux) visible\",\"No Storybook or Playwright signals\",\"No mentorship or leadership indicators\"],\"explanation\":\"Jess has a relevant but thin frontend profile that does not meet the seniority or depth requirements of this role. The absence of Next.js, SSR, and state management experience are significant gaps for a position that expects ownership of a design system migration. This candidate would be better suited for a junior frontend role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tom-okonkwo\",\"seniority\":\"Intern\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"React\",\"Flask\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nMid-size logistics company looking for a mid-level backend engineer to maintain and extend a Java Spring Boot microservices platform. Experience with Kafka for event streaming, AWS ECS or EKS for deployments, and PostgreSQL is required. The role involves on-call responsibilities and ownership of production services. Strong understanding of distributed systems and reliability engineering is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Intern seniority is far below the mid-level requirement\",\"No Java or Spring Boot experience visible\",\"No Kafka or event streaming tooling\",\"No AWS or cloud infrastructure signals\",\"No PostgreSQL or production database experience\",\"No distributed systems or reliability engineering signals\"],\"explanation\":\"Tom's profile shows very early-stage skills in Python and JavaScript with lightweight tooling, none of which aligns with the Java-centric, cloud-native backend stack this role requires. The seniority gap alone would disqualify this candidate, and the absence of every required technical skill makes this a clear mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priya-subramaniam\",\"seniority\":\"Lead\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"Apache Airflow\",\"dbt\",\"Kafka\",\"Databricks\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nLarge financial services firm building a modern data platform. We need a lead data engineer with experience orchestrating complex pipelines using Airflow and dbt, streaming data with Kafka, and working across cloud data warehouses such as Snowflake or BigQuery. Scala and PySpark experience for large-scale batch processing is highly valued. Data quality tooling experience is a strong differentiator.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Airflow and dbt directly satisfy the orchestration requirements\",\"Kafka experience matches the streaming data requirement\",\"Snowflake and BigQuery cover both cloud warehouse platforms mentioned\",\"Scala and Apache Spark address the batch processing preference\",\"Great Expectations is a rare and directly relevant data quality signal\",\"Lead seniority aligns with the role level\"],\"gaps\":[\"No cloud platform (AWS, GCP, Azure) explicitly visible, though Databricks and BigQuery suggest GCP familiarity\"],\"explanation\":\"Priya's profile is an exceptionally strong match for this data engineering leadership role. Every major technical requirement is met directly, and her use of Great Expectations is a meaningful differentiator for a firm that emphasized data quality. The only ambiguity is cloud provider affiliation, which is unlikely to be a disqualifying gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lucas-ferreira\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"Kubernetes\",\"Terraform\",\"Helm\",\"Ansible\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nGrowth-stage startup seeking a mid-level DevOps or platform engineer to own our Kubernetes-based infrastructure. You will manage Helm chart releases, write Terraform for cloud resources, and maintain GitHub Actions CI/CD pipelines. Experience with GitOps workflows using Argo CD or Flux is a strong plus. We primarily use AWS, so familiarity with EKS, EC2, or S3 is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes and Helm experience directly match infrastructure ownership requirements\",\"Terraform satisfies the infrastructure-as-code requirement\",\"Argo CD is an exact match for the GitOps preference\",\"GitHub Actions covers the CI/CD pipeline requirement\",\"Mid seniority aligns with the stated level\"],\"gaps\":[\"No explicit AWS signals (EKS, EC2, S3) visible in the profile\",\"No cloud provider affiliation is confirmed\"],\"explanation\":\"Lucas has a strong DevOps tooling profile that matches most of the stated requirements. The meaningful gap is the absence of any visible AWS-specific experience, which the job explicitly expects. His Kubernetes and Terraform skills are transferable, but the lack of AWS signals introduces uncertainty for a team that is already cloud-committed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mei-linforth\",\"seniority\":\"Senior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Expo\"],\"architecture\":[\"Modular Architecture\",\"Client-Server\"],\"databases\":[\"Firebase\",\"SQLite\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"Detox\"]}\n\nJob Summary:\nConsumer app startup looking for a senior iOS engineer to lead the rebuild of our native Swift app. You will own the SwiftUI-first architecture, work with Firebase for real-time data, and ship releases via Fastlane. Experience with UIKit for legacy compatibility and strong testing practices using XCTest or similar are required. We value modular app architecture and clean code patterns.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SwiftUI and UIKit directly satisfy both the primary and legacy compatibility requirements\",\"Firebase experience matches the real-time data backend in use\",\"Fastlane demonstrates release engineering familiarity\",\"Modular Architecture signal aligns with the team's stated values\",\"Senior seniority meets the leadership expectation\"],\"gaps\":[\"Detox is primarily a React Native testing tool; no XCTest or native iOS testing framework signal is visible\"],\"explanation\":\"Mei's iOS profile closely matches the technical scope of this role, covering SwiftUI, UIKit, Firebase, and Fastlane with senior-level experience. The one notable gap is the testing tooling mismatch — Detox suggests some cross-platform exposure, and native XCTest experience cannot be confirmed. This is a minor concern and does not significantly undermine her overall fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"arjun-mehta\",\"seniority\":\"Junior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Express.js\",\"Node.js\",\"Docker\"],\"databases\":[\"MongoDB\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nRemote-first agency building client web applications. We need a mid-level full stack developer with React and Node.js experience. You will own feature delivery end-to-end, interface with clients directly, and are expected to make pragmatic architectural decisions independently. Familiarity with containerization and basic CI/CD is helpful. TypeScript proficiency is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Express.js cover the full stack requirements\",\"TypeScript proficiency meets the stated requirement\",\"Docker and GitHub Actions signal basic DevOps awareness\",\"MongoDB and PostgreSQL show database breadth\",\"Jest indicates testing habits\"],\"gaps\":[\"Junior seniority falls below the mid-level expectation\",\"No signals of independent architectural decision-making or client-facing communication\"],\"explanation\":\"Arjun's technical stack is well-aligned with the role's requirements, and he covers most of the listed technologies. The main concern is seniority — the role expects mid-level independent ownership and client interaction, which a junior profile does not strongly signal. With some upside potential, he may be worth a conversation but likely needs additional validation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ben-holloway\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"HTML\",\"CSS\"],\"tech\":[\"React\",\"Bootstrap\"]}\n\nJob Summary:\nB2B SaaS company seeking a senior frontend engineer to own the architecture of a complex React application. Requirements include TypeScript, advanced state management (Redux or Zustand), performance optimization experience, and a track record of leading frontend projects. Experience with design systems, Storybook, and accessibility compliance (WCAG) is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React is a foundational skill relevant to the role\"],\"gaps\":[\"Junior seniority does not meet the senior expectation\",\"No TypeScript experience visible\",\"No state management tooling (Redux, Zustand) present\",\"No Storybook or design system signals\",\"No accessibility or WCAG-related signals\",\"No evidence of architectural ownership or project leadership\"],\"explanation\":\"Ben's profile reflects an early-stage frontend developer with basic React skills and no TypeScript, which is a stated requirement. The role demands architectural ownership and senior-level leadership that a junior profile cannot credibly demonstrate. Nearly every technical differentiator listed in the job summary is absent from his profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yuki-tanaka\",\"seniority\":\"Mid\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Retrofit\",\"Firebase\"],\"architecture\":[\"Modular Architecture\",\"Client-Server\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Espresso\"]}\n\nJob Summary:\nConsumer fintech startup building a mobile banking app for Android-first markets. We need a mid-level Android engineer with strong Kotlin and Jetpack Compose experience. Familiarity with modular app architecture, CI/CD using Fastlane or GitHub Actions, and Firebase for analytics and crash reporting is preferred. Unit and UI testing discipline is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kotlin and Jetpack Compose directly match the core technical requirements\",\"Modular Architecture aligns with the stated architectural preference\",\"Fastlane and GitHub Actions satisfy the CI/CD requirement\",\"Firebase covers both analytics and crash reporting use cases mentioned\",\"JUnit and Espresso demonstrate both unit and UI testing discipline\",\"Mid seniority matches the stated level\"],\"gaps\":[\"No explicit fintech or financial data handling signals\"],\"explanation\":\"Yuki's Android profile is a comprehensive match for this role, covering every major technical requirement with precision. The combination of Jetpack Compose, modular architecture, and Fastlane alongside strong testing tooling is exactly what the job summary describes. The only gap is the absence of fintech-specific context, which is common and unlikely to be disqualifying.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"carlos-mendes\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"Laravel\",\"Vue.js\",\"Docker\",\"Redis\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nE-commerce company building on a React and Node.js stack. We need a senior backend engineer with Node.js and Express.js or NestJS experience to build scalable APIs. TypeScript is required across the codebase. Familiarity with PostgreSQL and AWS services including Lambda and SQS is expected. Experience with GraphQL is a plus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Senior seniority matches the stated level\",\"Docker and Redis indicate some infrastructure familiarity\"],\"gaps\":[\"No Node.js, Express.js, or NestJS experience visible\",\"No TypeScript signal, which is a stated requirement\",\"No PostgreSQL or AWS experience\",\"No GraphQL signals\",\"PHP and Laravel stack does not transfer directly to the Node.js ecosystem\"],\"explanation\":\"Carlos is a senior PHP engineer with a Laravel background, which does not align with the Node.js and TypeScript-centric stack this role requires. While his infrastructure and testing habits are positive signals, none of his primary technical skills match the stated requirements. A meaningful retraining investment would be needed, making this a weak fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ananya-iyer\",\"seniority\":\"Lead\",\"roles\":[\"Full Stack Engineer\",\"Software Architect\"],\"languages\":[\"TypeScript\",\"Python\",\"Go\"],\"tech\":[\"React\",\"Next.js\",\"FastAPI\",\"GraphQL\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Microservices\",\"Domain-Driven Design\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"Vitest\",\"Playwright\",\"pytest\"]}\n\nJob Summary:\nEnterprise SaaS company seeking a lead software engineer to own technical architecture across a multi-team product. You will define API contracts, lead domain modeling, guide junior engineers, and drive decisions on frontend and backend systems. Experience with DDD, GraphQL, and microservices is required. TypeScript on the frontend and Python or Go on the backend is the target stack.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Domain-Driven Design experience directly matches the architectural requirement\",\"GraphQL is an exact match for the API contract requirement\",\"TypeScript and React cover the frontend stack\",\"FastAPI with Python and Go address both backend language preferences\",\"Kubernetes and Argo CD signal production infrastructure maturity expected at lead level\",\"Lead and Software Architect roles signal the technical leadership and mentorship capacity required\"],\"gaps\":[\"No explicit signals of cross-team coordination or organizational influence at scale\"],\"explanation\":\"Ananya is a strong fit for this lead engineering role, with her DDD experience, GraphQL proficiency, and polyglot backend skills directly mapping to what the job requires. Her architect role signal suggests she has operated at the architectural decision-making level the position demands. The only uncertainty is whether her leadership experience extends to multi-team coordination at enterprise scale.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ethan-cross\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"Ansible\",\"Terraform\",\"Nginx\"],\"architecture\":[\"Cloud-Native\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"]}\n\nJob Summary:\nMedia streaming company looking for a senior DevOps or infrastructure engineer with deep AWS expertise. Must have hands-on experience with EKS, CloudWatch, and AWS networking. Kubernetes administration at scale is required. Experience with service mesh (Istio or Linkerd) and Helm is preferred. On-call rotation and incident management experience expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Terraform and Ansible show infrastructure-as-code discipline\",\"Docker and Cloud-Native architecture are foundational positives\"],\"gaps\":[\"Mid seniority does not meet the senior expectation\",\"No AWS-specific tooling (EKS, CloudWatch, EC2) visible\",\"No Kubernetes experience at any level\",\"No Helm or service mesh signals\",\"No incident management or on-call experience visible\"],\"explanation\":\"Ethan's DevOps profile covers foundational IaC and containerization skills but lacks the AWS depth and Kubernetes experience that are central to this role. The seniority gap compounds this, as the role expects senior-level infrastructure leadership. This candidate would need significant reskilling to meet the requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hana-johansson\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Framer Motion\",\"Storybook\",\"Radix UI\"],\"architecture\":[\"Monorepo\",\"Client-Server\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\",\"React Testing Library\"]}\n\nJob Summary:\nDesign-forward consumer startup building a creative tool. We need a senior frontend engineer who cares deeply about UI quality and interaction design. Next.js and TypeScript are the core stack. Experience with animation libraries like Framer Motion, accessible component systems, and end-to-end testing with Playwright is a strong differentiator. Storybook for component documentation is used by the team.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and TypeScript are the exact core stack\",\"Framer Motion is an explicit differentiator that Hana demonstrates\",\"Storybook is directly used by the team and present in her profile\",\"Playwright satisfies the end-to-end testing differentiator\",\"Radix UI signals an accessible component system background\",\"Tailwind CSS and React Testing Library indicate well-rounded frontend practices\"],\"gaps\":[\"No backend or API ownership signals for a potentially full-stack environment\"],\"explanation\":\"Hana's frontend profile is a near-perfect match for a design-forward consumer product role. She covers every differentiator the job summary highlights — Framer Motion, Storybook, and Playwright — which are specific enough signals to suggest genuine alignment. Her Radix UI usage further supports her accessibility and component system experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"isabella-romero\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Airflow\",\"dbt\",\"Pandas\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redshift\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nRetail analytics company hiring a senior data engineer to build and maintain ELT pipelines. Strong SQL and dbt experience is required. Airflow for orchestration and Redshift or BigQuery as the warehouse is the team's stack. PySpark or Kafka experience for real-time ingestion is a plus. Experience managing pipeline SLAs and data quality is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt is an exact match for the core transformation requirement\",\"Airflow satisfies the orchestration requirement\",\"Redshift experience covers the data warehouse expectation\",\"Strong SQL and Python form a solid foundation for the ELT work\"],\"gaps\":[\"No PySpark or Kafka experience, which are explicitly listed as a plus for real-time ingestion\",\"No BigQuery experience\",\"No data quality tooling signals beyond dbt\"],\"explanation\":\"Isabella covers the core ELT toolchain this team uses, which is a solid baseline. However, the role signals an interest in expanding toward real-time data ingestion and data quality automation, areas where her profile shows no activity. She is a competent match for the current state of the pipeline but may have limited growth into the evolving requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"felix-ngozi\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\",\"Backend Engineer\"],\"languages\":[\"Go\",\"Rust\",\"Python\"],\"tech\":[\"gRPC\",\"Kafka\",\"Kubernetes\",\"Docker\",\"Consul\",\"Vault\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"CQRS\",\"Event Sourcing\",\"Service Mesh\"],\"databases\":[\"PostgreSQL\",\"CockroachDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nDeep tech infrastructure company building high-throughput distributed systems in Go and Rust. We need a principal engineer to define the architecture of our core data plane. Expertise in event sourcing, CQRS, and gRPC-based service communication is essential. Experience with consensus algorithms, distributed databases like CockroachDB, and service mesh patterns is preferred. You will set standards across engineering.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go and Rust are the exact primary languages\",\"Event Sourcing and CQRS are both present and explicitly required\",\"gRPC satisfies the service communication requirement\",\"CockroachDB is a rare and directly relevant distributed database signal\",\"Service Mesh and Consul demonstrate deep infrastructure patterning\",\"Principal seniority aligns with the standard-setting expectation across engineering\"],\"gaps\":[\"No explicit signals of consensus algorithm implementation (Raft, Paxos)\"],\"explanation\":\"Felix's profile is an outstanding match for this principal engineering role in distributed systems infrastructure. His combination of event sourcing, CQRS, gRPC, and CockroachDB experience is specific and rare, and directly maps to the architectural requirements. The only gap is the absence of explicit consensus algorithm signals, which may be implicit in his CockroachDB and Consul usage.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lena-marek\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Next.js\",\"Express.js\",\"Tailwind CSS\",\"Docker\"],\"databases\":[\"MongoDB\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Cypress\"]}\n\nJob Summary:\nHealthtech startup building a patient portal on a React and Node.js stack. We need a mid-level full stack engineer with experience in Next.js, PostgreSQL, and RESTful API design. TypeScript throughout the stack is required. E2E testing with Cypress or Playwright is valued. Familiarity with healthcare data standards such as HL7 or FHIR is a differentiating plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and React satisfy the frontend requirement\",\"TypeScript is present and meets the stated requirement\",\"Express.js demonstrates Node.js API experience\",\"PostgreSQL covers the database requirement\",\"Cypress directly addresses the E2E testing preference\"],\"gaps\":[\"No HL7 or FHIR signals, which are listed as a differentiating plus in healthcare\",\"No indication of experience in regulated or healthcare-adjacent data environments\"],\"explanation\":\"Lena's technical stack aligns well with the core requirements of this healthtech role. The meaningful gap is the absence of any healthcare data standards experience, which the job highlights as a differentiator. In a patient data context, this could become a material gap depending on how deeply the role involves data modeling and interoperability.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tom-bauer\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"FastAPI\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nB2C marketplace startup hiring a junior to mid-level backend engineer. Go or Python preferred. You will build and maintain REST APIs, contribute to service improvements, and write tests. PostgreSQL is the primary database. Docker for local development. This is a collaborative team that values fast learners and clean code over deep experience.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go and Python match the stated language preferences\",\"FastAPI demonstrates practical REST API development experience\",\"PostgreSQL is the team's primary database and is present\",\"Docker and pytest signal appropriate foundational discipline\"],\"gaps\":[\"Junior seniority is at the lower bound of the junior-to-mid range\",\"No evidence of collaborative team contributions or code review participation\"],\"explanation\":\"Tom has a focused backend profile that covers the core technical expectations of this role. His Go and Python stack with FastAPI and PostgreSQL is directly applicable, and the team's stated preference for fast learners over deep experience benefits a junior candidate with this tooling alignment. The main uncertainty is whether his junior-level experience translates to enough practical API development ownership.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"diana-chen\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Ruby\",\"JavaScript\"],\"tech\":[\"Ruby on Rails\",\"Sidekiq\",\"Redis\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"CircleCI\"],\"testing\":[\"RSpec\"]}\n\nJob Summary:\nGrowth-stage SaaS company building on a Rails and React stack. We need a senior backend engineer with deep Ruby on Rails experience to own API development, background job processing, and database performance optimization. Sidekiq for async jobs and PostgreSQL for the database are central to the stack. CircleCI is the CI platform. Strong testing with RSpec expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Ruby on Rails is an exact match for the core backend requirement\",\"Sidekiq directly addresses the background job processing need\",\"PostgreSQL is the primary database and is present\",\"CircleCI matches the CI platform in use\",\"RSpec satisfies the testing expectation explicitly\",\"Redis covers caching and is relevant to Sidekiq queue management\"],\"gaps\":[\"No explicit signals of database query optimization or performance tuning experience\"],\"explanation\":\"Diana's Rails profile is a comprehensive match for this role, covering every named technology in the job summary. The combination of Sidekiq, PostgreSQL, CircleCI, and RSpec alongside Rails is a precise skill alignment. The one gap is the lack of visible database performance work, but this is a soft gap that may simply not appear in her public contribution signals.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex-petrova\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"Python\",\"SQL\",\"R\"],\"tech\":[\"Pandas\",\"Tableau\",\"dbt\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nE-commerce company seeking a mid-level analytics engineer to own our dbt models and Snowflake warehouse. Strong SQL and dbt skills required. Experience building dashboards in Looker or Tableau is a plus. Python for scripting and data validation expected. Familiarity with Airflow or similar orchestration is preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt and Snowflake are directly relevant to the core responsibilities\",\"Strong SQL and Python cover the baseline requirements\",\"Tableau satisfies the dashboard building preference\",\"PostgreSQL shows relational database depth\"],\"gaps\":[\"Junior seniority falls below the mid-level expectation\",\"No Airflow or orchestration tool signals\",\"No Looker experience, though Tableau is an accepted alternative\"],\"explanation\":\"Alex has the right technical tools for this analytics engineering role, particularly dbt and Snowflake, which are the core of the job. The seniority gap is the primary concern, as a mid-level role implies independent ownership of warehouse models and data pipelines that a junior profile may not fully demonstrate. She is a candidate worth evaluating for growth potential.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"derek-walsh\",\"seniority\":\"Mid\",\"roles\":[\"Security Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"Terraform\",\"Vault\"],\"architecture\":[\"Microservices\",\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nFinancial infrastructure company hiring a senior application security engineer. Requirements include hands-on penetration testing experience, SAST/DAST tooling knowledge, and familiarity with OWASP Top 10. Experience with secrets management (Vault or AWS Secrets Manager), cloud security on AWS, and security automation in CI/CD pipelines is essential. CISSP or equivalent certification preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"HashiCorp Vault signals secrets management awareness\",\"GitHub Actions with Terraform suggests some CI/CD security automation exposure\"],\"gaps\":[\"Mid seniority does not meet the senior requirement\",\"No penetration testing or offensive security signals\",\"No SAST/DAST tooling present\",\"No OWASP or application security framework signals\",\"No AWS security tooling visible\",\"No professional certification signals\"],\"explanation\":\"Derek's profile suggests a DevOps-oriented engineer with some security-adjacent tooling, but lacks the application security depth this role requires. The absence of penetration testing experience, security scanning tools, and cloud security signals are critical gaps. The seniority mismatch further compounds the misalignment with a senior appsec role in a financial environment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nina-osei\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Next.js\",\"React\",\"FastAPI\",\"Docker\",\"Redis\",\"Stripe\"],\"architecture\":[\"Serverless\",\"Monolith\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"Vercel\",\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nBootstrapped SaaS startup building a subscription billing product. We need a senior full stack engineer comfortable owning both the Next.js frontend and the Python API. Experience with Stripe integration is a significant differentiator. PostgreSQL and Supabase are the data layer. Vercel for frontend deployments. Strong TypeScript skills required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and React cover the frontend requirement\",\"FastAPI with Python satisfies the backend API requirement\",\"Stripe is a rare and significant differentiator that Nina demonstrates\",\"PostgreSQL and Supabase are an exact match for the data layer\",\"Vercel matches the deployment platform in use\",\"TypeScript proficiency is present and required\"],\"gaps\":[\"No billing domain or SaaS-specific business logic signals beyond Stripe tooling\"],\"explanation\":\"Nina's profile is an excellent match for this billing-focused SaaS role. Her Stripe integration experience is the most differentiating signal and directly addresses the job's top requirement. The full stack alignment across Next.js, FastAPI, Supabase, and Vercel covers the entire technology footprint described in the job summary.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"raj-pillai\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Node.js\",\"TypeScript\"],\"tech\":[\"NestJS\",\"GraphQL\",\"Apollo\",\"Docker\",\"BullMQ\"],\"architecture\":[\"Microservices\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nB2B platform company building a multi-tenant API product. We need a mid-level backend engineer with NestJS and TypeScript experience. GraphQL via Apollo is the API layer. Redis for caching and BullMQ for background jobs are in use. PostgreSQL is the primary database. Microservices and API gateway patterns expected. Strong unit and integration testing required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS and TypeScript are an exact match for the core stack\",\"GraphQL and Apollo directly satisfy the API layer requirement\",\"BullMQ is an exact match for the background job requirement\",\"Redis is present for the caching use case\",\"Microservices and API Gateway architecture are both present\",\"Jest and Supertest address the unit and integration testing requirement\"],\"gaps\":[\"No multi-tenancy or tenant isolation pattern signals visible\"],\"explanation\":\"Raj's backend profile is a precise fit for this B2B platform role, matching every named technology in the job summary. The combination of NestJS, Apollo GraphQL, BullMQ, and Redis is a specific and well-aligned stack. The only soft gap is the absence of explicit multi-tenancy signals, which may be implicit in his API gateway and microservices experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"chloe-martin\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nEuropean e-commerce company seeking a mid-level Vue.js frontend developer. Nuxt.js for SSR, Pinia for state management, and Tailwind CSS for styling are the current stack. GitLab CI for pipelines. Experience with Vitest and Playwright for testing is valued. TypeScript is required throughout the frontend codebase.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Vue.js and Nuxt.js are an exact match for the frontend framework requirements\",\"Pinia directly satisfies the state management requirement\",\"Tailwind CSS matches the styling stack\",\"GitLab CI aligns with the CI platform in use\",\"Vitest and Playwright address both testing requirements\",\"TypeScript meets the stated requirement\"],\"gaps\":[\"No backend or API integration signals for a potentially full-featured e-commerce context\"],\"explanation\":\"Chloe's frontend profile is an exact match for this Vue.js role, covering every technology named in the job summary. The specificity of her Nuxt.js, Pinia, Vitest, and Playwright stack is a strong alignment signal. The only soft gap is the lack of backend visibility, which is unlikely to matter for a frontend-scoped role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mike-benson\",\"seniority\":\"Junior\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Django\",\"React\",\"Docker\"]}\n\nJob Summary:\nEnterprise cloud company seeking a principal cloud architect with deep AWS and Azure multi-cloud expertise. Must have experience designing resilience patterns, disaster recovery architectures, and governance frameworks for enterprise customers. Terraform, Kubernetes, and service mesh experience required. Certifications in AWS and Azure architecture preferred. The role involves executive-level stakeholder management.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker is a minor foundational positive\"],\"gaps\":[\"Junior seniority is far below the principal-level requirement\",\"No AWS or Azure cloud experience\",\"No Terraform or Kubernetes experience\",\"No service mesh or enterprise resilience pattern signals\",\"No cloud architecture or certification signals\",\"No evidence of stakeholder management or executive communication\"],\"explanation\":\"Mike's early-stage profile has no meaningful overlap with the requirements of a principal cloud architecture role. Every core technical and leadership requirement — multi-cloud expertise, Terraform, Kubernetes, disaster recovery, and executive stakeholder management — is absent. This is a fundamental mismatch in both seniority and technical scope.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"paulo-carvalho\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"React\",\"Redux\",\"Webpack\",\"Bootstrap\"],\"databases\":[\"Firebase\"],\"ci_cd\":[\"CircleCI\"]}\n\nJob Summary:\nEnterprise software company modernizing their frontend to a Next.js and TypeScript stack. We need a senior frontend engineer with SSR experience, expertise in design systems, and a strong TypeScript background. Tailwind CSS, Radix UI, and Vitest are preferred. The role also involves migrating away from legacy Webpack setups to Vite or Turbopack.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and Redux form a relevant foundational baseline\",\"Senior seniority matches the stated level\"],\"gaps\":[\"No TypeScript experience, which is a core requirement\",\"No Next.js or SSR experience\",\"No Tailwind CSS, Radix UI, or design system signals\",\"No Vitest experience\",\"Webpack usage is the legacy system being migrated away from, which is a disadvantage\",\"No Vite or Turbopack experience\"],\"explanation\":\"Paulo's frontend profile is anchored in older tooling that the company is specifically moving away from. The absence of TypeScript, Next.js, and the preferred modern toolchain represents a fundamental misalignment with the modernization objectives of this role. His seniority is appropriate but his technical profile reads as a candidate from the previous era of this stack rather than its future direction.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fatima-al-rashid\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"XGBoost\",\"Pandas\",\"NumPy\",\"MLflow\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"]}\n\nJob Summary:\nInsurance company hiring a mid-level machine learning engineer to build risk scoring models. Python with scikit-learn and XGBoost required. SQL querying against BigQuery is expected. MLflow for experiment tracking is used by the team. Docker for model packaging. R for statistical validation is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"scikit-learn and XGBoost are an exact match for the modeling requirements\",\"BigQuery satisfies the SQL querying expectation\",\"MLflow directly meets the experiment tracking requirement\",\"Docker addresses the model packaging need\",\"R is present as an explicit plus\",\"Pandas and NumPy indicate strong data handling foundations\"],\"gaps\":[\"No insurance or actuarial domain signals\"],\"explanation\":\"Fatima's ML engineering profile is a comprehensive match for this insurance risk modeling role. Every named technical requirement is covered precisely, and her R proficiency as a bonus aligns with the statistical validation preference. The only gap is the absence of insurance or actuarial domain experience, which is a soft concern for a technically-focused mid-level role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sam-nakamura\",\"seniority\":\"Junior\",\"roles\":[\"Software Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"FastAPI\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nFull stack startup seeking a mid-level engineer comfortable shipping features across React and FastAPI. TypeScript required. Docker for containerization. PostgreSQL as the database. We are a small team that values ownership and initiative. Prior startup experience is a differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and FastAPI cover the full stack requirement\",\"TypeScript is present and required\",\"PostgreSQL and Docker match the stated stack\"],\"gaps\":[\"Junior seniority is below the mid-level expectation\",\"No signals of startup experience or end-to-end feature ownership\",\"Sparse profile limits confidence in independent delivery capacity\"],\"explanation\":\"Sam's technical stack aligns well with the tools this startup uses, covering all named technologies. The main concern is seniority — a junior engineer in a small startup environment without demonstrated ownership patterns may need more structure than a small team can provide. The sparse profile also limits confidence in assessing his practical delivery experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"max-lindgren\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Remix\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nE-commerce company rebuilding its storefront on Shopify and Hydrogen (React-based). We need a frontend engineer with strong React and TypeScript skills. Familiarity with Remix or similar file-based routing frameworks is preferred. Tailwind CSS for styling. Experience with Shopify APIs and GraphQL is a differentiator. SEO and performance optimization experience valued.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and TypeScript are the core frontend requirements\",\"Remix directly satisfies the file-based routing framework preference\",\"Tailwind CSS matches the styling approach\",\"Vitest and Playwright show testing maturity\"],\"gaps\":[\"No Shopify or Shopify Hydrogen-specific experience\",\"No GraphQL signals, which is a differentiator for this platform\",\"No explicit SEO or web performance optimization signals\"],\"explanation\":\"Max has a strong React and TypeScript foundation with the Remix experience that the team explicitly prefers. However, the role is rooted in the Shopify ecosystem, and the absence of Shopify API and GraphQL experience is a meaningful gap for a platform that depends heavily on both. He has the raw frontend skills but would need ramp-up time on the commerce platform itself.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tunde-adekunle\",\"seniority\":\"Principal\",\"roles\":[\"Machine Learning Engineer\",\"Software Architect\"],\"languages\":[\"Python\",\"Scala\",\"C++\"],\"tech\":[\"PyTorch\",\"TensorFlow\",\"ONNX\",\"CUDA\",\"Ray\",\"Triton\",\"MLflow\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Distributed System\",\"Microservices\"],\"databases\":[\"Snowflake\",\"PostgreSQL\",\"Pinecone\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nAI research company productionizing large-scale model training and inference infrastructure. We need a principal ML engineer with deep experience in distributed training, CUDA optimization, and model serving at scale. PyTorch and ONNX for model development and export. Triton Inference Server for serving. Ray for distributed compute. C++ for performance-critical paths. Kubernetes for orchestration.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PyTorch and ONNX directly satisfy the model development and export requirements\",\"CUDA signals deep hardware-level optimization experience\",\"Triton is a specific and exact match for the inference serving requirement\",\"Ray satisfies the distributed compute requirement\",\"C++ addresses the performance-critical path requirement\",\"Kubernetes covers the orchestration need\",\"Principal seniority aligns with the infrastructure ownership scope\"],\"gaps\":[\"No explicit large-scale distributed training framework signals (DeepSpeed, FSDP) beyond Ray\"],\"explanation\":\"Tunde's ML infrastructure profile is an exceptional match for this principal-level AI research role. His combination of CUDA, Triton, Ray, ONNX, and C++ is a rare and highly specific set of signals that map directly to every stated requirement. The only gap is the absence of explicit distributed training framework signals like DeepSpeed, which may be implicit in his CUDA and Ray experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"claire-fontaine\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"SQLAlchemy\",\"Alembic\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MySQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nHealthcare SaaS company building an EHR integration platform. We need a mid-level Python backend engineer familiar with RESTful APIs and database-heavy application development. SQLAlchemy and PostgreSQL are the core data layer. Redis for caching. Familiarity with HL7 FHIR standards or prior work in regulated healthcare environments is a strong differentiator. Docker and pytest required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI and SQLAlchemy are directly applicable to the API and data layer requirements\",\"PostgreSQL is the primary database and is present\",\"Redis covers the caching requirement\",\"Docker and pytest meet the stated deployment and testing requirements\",\"Alembic signals database migration discipline, relevant for schema-heavy EHR data\"],\"gaps\":[\"No HL7 FHIR or healthcare interoperability signals, listed as a strong differentiator\",\"No regulated environment or compliance engineering signals\"],\"explanation\":\"Claire's backend Python profile covers the core technical stack this role requires. The meaningful gap is healthcare domain experience — HL7 FHIR integration is a strong differentiator for an EHR platform, and the absence of any healthcare or compliance signals limits her fit relative to candidates with that background. She is technically capable but may face a domain knowledge ramp.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"will-foster\",\"seniority\":\"Junior\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"Flask\",\"Docker\"],\"databases\":[\"SQLite\",\"PostgreSQL\"]}\n\nJob Summary:\nClimate tech company seeking a senior full stack engineer with React and Node.js frontend and backend experience, TypeScript throughout, and experience managing cloud infrastructure on AWS. The role involves significant technical leadership including designing new systems, reviewing code across teams, and influencing engineering strategy. Kubernetes and Terraform required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker is a minor baseline positive\"],\"gaps\":[\"Junior seniority is far below the senior requirement\",\"No React, Node.js, or TypeScript experience\",\"No AWS, Kubernetes, or Terraform experience\",\"No technical leadership or code review signals\",\"No full stack background\"],\"explanation\":\"Will's profile is an early-stage Python engineer with minimal tooling and no overlap with the technical or leadership requirements of this senior full stack role. The gap in seniority, technology stack, and cloud infrastructure experience makes this a fundamental mismatch that no single strength compensates for.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nadia-berlova\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Java\"],\"tech\":[\"Apache Spark\",\"Apache Airflow\",\"Kafka\",\"Hadoop\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"Cassandra\",\"PostgreSQL\",\"Redshift\"],\"ci_cd\":[\"Jenkins\"]}\n\nJob Summary:\nRetail data platform team hiring a senior data engineer to migrate legacy Hadoop pipelines to a modern cloud-native stack. Spark on Databricks, Airflow or Prefect for orchestration, and Snowflake as the new warehouse are the targets. Experience with Kafka for streaming ingestion is valuable. Python and SQL are the primary languages. Familiarity with dbt is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Apache Spark experience is directly transferable to the Databricks migration target\",\"Airflow satisfies the orchestration requirement\",\"Kafka addresses the streaming ingestion value-add\",\"Python and SQL meet the primary language requirements\",\"Hadoop experience is directly relevant to the legacy system being migrated\"],\"gaps\":[\"No Databricks or cloud-native Spark experience specifically\",\"No Snowflake experience as the target warehouse\",\"No dbt experience, listed as a plus\",\"No cloud provider (AWS, GCP, Azure) signals for the cloud-native migration target\"],\"explanation\":\"Nadia has deep experience with the legacy stack being migrated, which is a useful asset for migration projects. However, her profile shows no exposure to the target modern stack — Databricks, Snowflake, and cloud-native tooling are absent. She has the right foundational skills but would require meaningful upskilling to lead delivery on the migration destination.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jakub-novak\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C#\",\"SQL\"],\"tech\":[\"ASP.NET\",\"Entity Framework\",\"Docker\",\"RabbitMQ\"],\"architecture\":[\"Microservices\",\"Layered Architecture\"],\"databases\":[\"MS SQL Server\",\"Redis\"],\"ci_cd\":[\"Azure DevOps\"],\"testing\":[\"xUnit\"]}\n\nJob Summary:\nEnterprise logistics company hiring a mid-level .NET backend engineer. ASP.NET Core and Entity Framework for API and ORM. MS SQL Server as the primary database. RabbitMQ for inter-service messaging. Azure DevOps for CI/CD pipelines. The team follows a microservices architecture. Unit testing with xUnit is standard.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"ASP.NET and Entity Framework are exact matches for the API and ORM requirements\",\"MS SQL Server is the named primary database and is present\",\"RabbitMQ directly satisfies the inter-service messaging requirement\",\"Azure DevOps matches the CI/CD platform\",\"Microservices architecture aligns with the team's approach\",\"xUnit satisfies the unit testing standard\"],\"gaps\":[\"No explicit .NET Core version signal, though ASP.NET implies modern .NET\"],\"explanation\":\"Jakub's .NET profile is a precise match for this enterprise logistics role, covering every named technology requirement without exception. His combination of ASP.NET, Entity Framework, RabbitMQ, Azure DevOps, and xUnit is a strong alignment signal with a mature enterprise engineering team. The only trivial gap is the lack of explicit .NET Core version signals.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ashley-woods\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Next.js\",\"Redux\",\"HTMX\",\"Webpack\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Cypress\"]}\n\nJob Summary:\nContent platform seeking a frontend engineer to work on a React and Next.js application with a strong emphasis on server components and streaming UI patterns. TypeScript required. Zustand or Jotai preferred for lightweight state management. Vitest and Playwright for testing. Tailwind CSS and shadcn/ui for the component layer. Webpack to Vite migration is in progress.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Next.js are the correct frontend framework\",\"TypeScript is present and required\",\"Cypress covers some E2E testing overlap with Playwright\",\"Senior seniority matches the expectation\"],\"gaps\":[\"Redux does not align with the preference for lightweight state management (Zustand, Jotai)\",\"No Tailwind CSS or shadcn/ui signals\",\"No Vitest experience; Jest is present but Vitest is preferred\",\"Webpack proficiency may not help in an active Vite migration and could represent legacy anchoring\",\"No Playwright signals\"],\"explanation\":\"Ashley has the right foundational React and Next.js experience but her tooling choices diverge from the team's current and future direction. Her Redux and Webpack background reflects an older frontend architecture pattern, while the team is actively moving toward lighter state management, Vite, and a Tailwind-based component system. She would need to adapt her toolset to fully fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"robin-hayes\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"C++\"],\"tech\":[\"Actix\",\"gRPC\",\"Docker\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Rust testing\"]}\n\nJob Summary:\nHigh-frequency trading infrastructure company building ultra-low latency services in C++ and Rust. We need a backend engineer with systems programming experience, gRPC for inter-service communication, and Kafka for market data streaming. PostgreSQL for trade record persistence. Experience with FPGA, memory management, or kernel-level optimization is a strong differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Rust and C++ are the exact primary language requirements for systems programming\",\"gRPC satisfies the inter-service communication requirement\",\"Kafka directly addresses the market data streaming requirement\",\"PostgreSQL covers the trade record persistence need\",\"Actix signals production-grade Rust web service experience\"],\"gaps\":[\"No FPGA, kernel-level, or memory management optimization signals, which are significant differentiators in HFT\",\"No financial domain or trading systems experience visible\"],\"explanation\":\"Robin has the systems programming language background this HFT role requires, with Rust and C++ both present alongside gRPC and Kafka. The notable gap is the absence of ultra-low latency specialization signals like FPGA or kernel-level work, which are strong differentiators in competitive HFT engineering roles. He is a moderate fit with good foundational alignment but lacking the HFT-specific depth that top candidates would demonstrate.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"anna-petrova\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"Python\",\"SQL\",\"R\"],\"tech\":[\"Pandas\",\"Matplotlib\",\"Tableau\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nGrowth-stage startup hiring a junior data analyst to support the business intelligence team. SQL and Python for data querying and transformation. Tableau for dashboarding. PostgreSQL is the warehouse. R is a plus for statistical reporting. No prior startup experience required. Collaborative environment with close mentorship from senior analysts.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SQL and Python directly match the querying and transformation requirements\",\"Tableau satisfies the dashboarding requirement\",\"PostgreSQL is the named warehouse and is present\",\"R is a plus that Anna provides\"],\"gaps\":[\"No experience in a structured BI or analytics team environment visible\",\"Pandas and Matplotlib suggest primarily exploratory work rather than production dashboarding\",\"Limited profile depth makes it difficult to assess output quality or stakeholder communication\"],\"explanation\":\"Anna's technical toolkit aligns with the stated requirements of this junior data analyst role. Her SQL, Python, Tableau, and PostgreSQL coverage is appropriate for the job level. The sparse profile limits confidence in her practical output quality and stakeholder communication ability, but the role's emphasis on mentorship reduces the risk of this gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tomasz-wierzbicki\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Prisma\",\"tRPC\",\"Tailwind CSS\",\"Docker\"],\"architecture\":[\"Serverless\",\"Monolith\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"Vercel\",\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nSolo-founder developer tools startup building a T3-stack application. Mid-level full stack engineer needed with Next.js, tRPC, and Prisma experience. TypeScript throughout. PostgreSQL via Supabase. Tailwind CSS for styling. Vercel for deployment. Docker for containerization. We move fast, prioritize clean code, and expect you to own features end to end.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js, tRPC, and Prisma are an exact match for the T3-stack requirement\",\"TypeScript is present throughout as required\",\"Supabase satisfies the PostgreSQL backend requirement\",\"Tailwind CSS meets the styling requirement\",\"Vercel and Docker cover the deployment and containerization requirements\",\"Vitest and Playwright indicate testing habits aligned with a clean code culture\"],\"gaps\":[\"No prior startup or founder environment signals\"],\"explanation\":\"Tomasz's profile is a precise match for this T3-stack developer tools role, covering every named technology with no technical gaps. His combination of tRPC, Prisma, and Supabase alongside Vercel and Tailwind is a specific and well-aligned signal. The only soft concern is the absence of startup environment signals, which the role's pace expectations make relevant but not disqualifying.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fatou-dieng\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Echo\",\"gRPC\",\"Kafka\",\"Docker\",\"Kubernetes\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"Go testing\",\"pytest\"]}\n\nJob Summary:\nB2B API platform company building developer-facing infrastructure services. Senior backend engineer required with Go as the primary language. Echo or Gin for HTTP services. gRPC for internal service communication. Kafka for event-driven workflows. Kubernetes and Argo CD for deployment. API gateway experience for external developer API design. PostgreSQL as the primary database.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go is the primary language and is strongly present\",\"Echo satisfies one of the two named HTTP framework options\",\"gRPC directly meets the internal service communication requirement\",\"Kafka covers the event-driven workflow requirement\",\"Kubernetes and Argo CD satisfy the deployment requirements\",\"API Gateway architecture aligns with the external developer API design expectation\",\"PostgreSQL is the named primary database and is present\"],\"gaps\":[\"No Gin experience as the alternative HTTP framework\"],\"explanation\":\"Fatou's Go backend profile is a precise and comprehensive match for this developer API platform role. Her combination of Echo, gRPC, Kafka, and API Gateway architecture covers every major requirement. The absence of Gin is negligible given Echo is listed as an accepted alternative and both are well-established Go HTTP frameworks.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nicolas-dubois\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\",\"Backend Engineer\"],\"languages\":[\"Go\",\"Rust\",\"Python\"],\"tech\":[\"gRPC\",\"Kafka\",\"Kubernetes\",\"Consul\",\"Vault\",\"Docker\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"CQRS\",\"Event Sourcing\",\"Service Mesh\"],\"databases\":[\"CockroachDB\",\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nDeep tech platform company building globally distributed infrastructure. Principal engineer needed to define architecture across distributed systems. Event sourcing and CQRS expertise required. gRPC for service communication. Kafka for event streaming. CockroachDB for globally distributed storage. Go or Rust as primary languages. Service mesh and secrets management experience valued.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Event Sourcing and CQRS are both present and explicitly required\",\"Go and Rust are both present as the named primary languages\",\"gRPC directly satisfies the service communication requirement\",\"Kafka covers the event streaming requirement\",\"CockroachDB is a rare and exact match for the distributed storage requirement\",\"Service Mesh and Vault address the service mesh and secrets management preferences\",\"Principal seniority aligns with the architectural leadership scope\"],\"gaps\":[\"No explicit signals of global-scale deployment or multi-region coordination experience\"],\"explanation\":\"Nicolas's profile is an exceptional match for this principal-level distributed infrastructure role. His Event Sourcing, CQRS, CockroachDB, and gRPC experience is a highly specific combination that maps directly to every stated requirement. The only uncertainty is whether his distributed systems experience extends to global multi-region deployments at the scale this role implies.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ibrahim-al-farsi\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"Laravel\",\"Vue.js\",\"Docker\",\"Redis\",\"Nginx\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"CircleCI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nE-commerce company migrating from PHP to a Python FastAPI and React stack. Senior backend engineer needed to lead the migration while maintaining existing systems. Python experience required. TypeScript and React for new frontend surfaces. PostgreSQL as the new database. Docker for containerization. The role requires someone comfortable working across legacy and modern systems simultaneously.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Senior seniority matches the requirement\",\"Docker demonstrates containerization familiarity\",\"Legacy system experience in Laravel is relevant for understanding the migration context\"],\"gaps\":[\"No Python or FastAPI experience for the migration target\",\"No React or TypeScript experience\",\"No PostgreSQL experience; MySQL is the current database\",\"No GitHub Actions or modern CI tooling\",\"PHP expertise, while useful for the legacy side, does not transfer to the migration destination\"],\"explanation\":\"Ibrahim brings senior-level PHP and Laravel experience that has some value for maintaining the existing system, but his profile shows no exposure to Python, FastAPI, React, or TypeScript \u2014 the target stack this role is explicitly hired to build toward. The breadth of the technical gap across both backend and frontend means he cannot credibly lead the migration even while maintaining legacy systems.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fabian-roth\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"Terraform\",\"Ansible\",\"Nginx\"],\"architecture\":[\"Cloud-Native\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"]}\n\nJob Summary:\nLogistics startup building cloud infrastructure on AWS. Mid-level DevOps engineer needed to manage ECS deployments, write Terraform for AWS resources, and maintain Jenkins and GitHub Actions pipelines. Familiarity with CloudWatch for monitoring and AWS networking basics required. Experience with containerized application deployments is essential.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform satisfies the IaC requirement for AWS resources\",\"Docker signals containerized deployment experience\",\"Jenkins and GitHub Actions both match the CI/CD platforms\",\"Ansible and Bash indicate infrastructure automation discipline\"],\"gaps\":[\"No AWS-specific tooling (ECS, CloudWatch, VPC) visible\",\"Cloud-Native architecture is generic and does not confirm AWS expertise\"],\"explanation\":\"Fabian has a solid DevOps foundation with the right IaC and CI/CD tooling, but the role requires AWS-specific experience that is absent from his profile. His Terraform skills are transferable but the lack of any ECS, CloudWatch, or AWS networking signals means a meaningful ramp-up period on cloud-specific services should be expected. He is a reasonable candidate if the team can accommodate that learning curve.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ingrid-lindqvist\",\"seniority\":\"Mid\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"NumPy\",\"Weights & Biases\",\"MLflow\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nBiotech company building predictive models for drug discovery. Mid-level data scientist required with Python and PyTorch or scikit-learn. SQL and Snowflake for data access. Experiment tracking with MLflow or Weights and Biases. R for statistical analysis is a plus. Domain experience in bioinformatics, genomics, or cheminformatics is a strong differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python, PyTorch, and scikit-learn cover the modeling requirements\",\"Snowflake and SQL satisfy the data access requirement\",\"Both MLflow and Weights and Biases are present for experiment tracking\",\"R is listed as a plus and Ingrid demonstrates it\"],\"gaps\":[\"No bioinformatics, genomics, or cheminformatics domain signals\",\"No biological data processing or domain-specific modeling signals\"],\"explanation\":\"Ingrid's data science toolkit is a strong technical match for the modeling and data access requirements. The limiting factor is domain \u2014 drug discovery modeling requires specialized knowledge of biological datasets and modeling approaches that her profile does not signal. She is technically capable but would be at a significant disadvantage compared to candidates with bioinformatics or cheminformatics backgrounds.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lars-bergmann\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Express.js\",\"Prisma\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nReal estate tech startup building property listing and search APIs. Mid-level backend engineer needed with Node.js and TypeScript. Prisma ORM and PostgreSQL for the database layer. Redis for search result caching. Docker for containerization. GitHub Actions for CI. Elasticsearch or Algolia for full-text property search is a valued differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript and Express.js cover the Node.js backend requirement\",\"Prisma is an exact match for the ORM requirement\",\"PostgreSQL satisfies the database layer requirement\",\"Redis meets the caching requirement\",\"Docker and GitHub Actions cover containerization and CI\",\"Jest and Supertest demonstrate appropriate testing habits\"],\"gaps\":[\"No Elasticsearch or Algolia signals for full-text property search, a valued differentiator\"],\"explanation\":\"Lars covers the core backend stack for this real estate API role with precision. The gap is Elasticsearch or Algolia search experience, which the job identifies as a valued differentiator. For a property listing platform where search quality is a core product feature, the absence of full-text search tooling experience is a meaningful gap that limits his competitiveness against candidates who bring it.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amina-traor\u00e9\",\"seniority\":\"Mid\",\"roles\":[\"AI Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"LangChain\",\"OpenAI API\",\"FastAPI\",\"Docker\",\"ChromaDB\"],\"architecture\":[\"RAG\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"ChromaDB\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nLegal tech startup building AI-powered contract review. Mid-level AI engineer required with LangChain and RAG pipeline experience. OpenAI API for LLM integration. ChromaDB or Weaviate as the vector store. FastAPI for serving inference endpoints. Docker for containerization. Prior experience with legal document processing or NLP on long documents is a differentiating signal.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"LangChain and RAG architecture are directly required and present\",\"OpenAI API satisfies the LLM integration requirement\",\"ChromaDB is one of the two named vector stores and is present\",\"FastAPI and Docker meet the serving and containerization requirements\"],\"gaps\":[\"No legal document processing or NLP on long document signals\",\"No chunking strategy, document parsing, or domain-specific RAG optimization signals\"],\"explanation\":\"Amina has the core AI engineering toolkit this role requires, with clean alignment on LangChain, RAG, and ChromaDB. The gap is domain specificity \u2014 legal contract review involves unique challenges around long document processing and domain-specific retrieval that her profile does not signal experience with. She is technically capable but would face a domain ramp-up compared to candidates with legal NLP backgrounds.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dmitri-volkov\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Docker\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"databases\":[\"PostgreSQL\",\"Redis\"]}\n\nJob Summary:\nGrowth-stage SaaS company hiring a mid-level DevOps or platform engineer. Kubernetes for container orchestration including Helm chart management. Terraform for provisioning cloud resources on GCP. Prometheus and Grafana for observability. GitHub Actions and Argo CD for CI and GitOps deployments. Python or Bash for internal tooling.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes and Helm directly satisfy the orchestration requirement\",\"Terraform meets the IaC requirement\",\"Prometheus and Grafana cover the observability stack\",\"GitHub Actions and Argo CD satisfy both CI and GitOps requirements\",\"Python and Bash meet the internal tooling language preferences\"],\"gaps\":[\"No GCP-specific tooling or experience visible\",\"Cloud-Native is a generic signal that does not confirm GCP alignment\"],\"explanation\":\"Dmitri's DevOps profile covers every tool named in the job summary with precision. The meaningful gap is the absence of GCP-specific experience \u2014 the role is committed to GCP but his profile shows no cloud provider affiliation. His Terraform and Kubernetes skills are transferable but a ramp-up on GCP-specific services should be expected.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"petra-novakova\",\"seniority\":\"Senior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Combine\",\"XCTest\"],\"architecture\":[\"Modular Architecture\",\"MVVM\"],\"databases\":[\"CoreData\",\"SQLite\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"]}\n\nJob Summary:\nHealthcare app company building a patient-facing iOS application. Senior iOS engineer required with SwiftUI and UIKit experience for a mixed legacy and modern codebase. Combine for reactive data flows. XCTest for unit and UI testing. Fastlane for automated releases. CoreData for offline-first data persistence. Modular architecture across feature frameworks.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SwiftUI and UIKit satisfy both the modern and legacy codebase requirements\",\"Combine directly addresses the reactive data flow requirement\",\"XCTest is the named testing framework and is present\",\"Fastlane satisfies the automated release requirement\",\"CoreData matches the offline-first persistence requirement\",\"Modular Architecture aligns with the feature framework structure\"],\"gaps\":[\"No healthcare or regulated data environment signals\"],\"explanation\":\"Petra's iOS profile is a precise technical match for this healthcare application role. Every named technology in the job summary is represented in her profile with no functional gaps. The only uncertainty is whether she has experience in regulated healthcare data environments, which is a soft contextual concern rather than a technical one.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"chiara-romano\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Redux\",\"Tailwind CSS\",\"Storybook\",\"Webpack\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Cypress\"]}\n\nJob Summary:\nEnterprise SaaS company seeking a senior frontend engineer to own their design system and component library. Next.js and TypeScript required. Tailwind CSS and Radix UI for accessible components. Storybook for component documentation. Zustand or Jotai for lightweight state management. Vitest and Playwright for testing. Accessibility standards compliance expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and TypeScript are the core requirements and both are present\",\"Tailwind CSS satisfies the styling requirement\",\"Storybook is explicitly required and present\",\"Senior seniority aligns with design system ownership\"],\"gaps\":[\"No Radix UI or accessible component library signals\",\"Redux does not align with the lightweight state management preference (Zustand, Jotai)\",\"No Vitest; Jest is present but Vitest is preferred\",\"No Playwright; Cypress is present as a partial alternative\",\"No explicit accessibility compliance signals\"],\"explanation\":\"Chiara has the right foundational skills and the Storybook experience this design system role requires. However, several tooling preferences diverge \u2014 her Redux usage conflicts with the lightweight state management direction, and her testing stack does not match the Vitest and Playwright preferences. For a role focused on a modern, accessible component system, these gaps in tooling alignment are meaningful but not disqualifying for a senior candidate willing to adapt.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kwabena-mensah\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Angular\",\"NgRx\",\"RxJS\",\"Tailwind CSS\"],\"ci_cd\":[\"Azure DevOps\"],\"testing\":[\"Karma\",\"Jasmine\"]}\n\nJob Summary:\nLarge insurance company maintaining an Angular enterprise portal. Mid-level Angular developer required with strong TypeScript, NgRx, and RxJS experience. Azure DevOps for CI/CD. Karma and Jasmine for unit testing. Accessibility standards compliance (WCAG 2.1) expected. The codebase follows a strict modular component architecture.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Angular and TypeScript are the core requirements and both are present\",\"NgRx satisfies the state management requirement\",\"RxJS meets the reactive programming requirement\",\"Azure DevOps matches the CI/CD platform\",\"Karma and Jasmine cover both testing requirements\"],\"gaps\":[\"No accessibility or WCAG compliance signals\",\"No modular architecture pattern signals beyond general frontend work\"],\"explanation\":\"Kwabena's Angular profile covers the core technical stack this enterprise insurance role requires. The gaps are in the compliance and architectural discipline dimensions \u2014 WCAG 2.1 accessibility is a stated expectation and is absent from his profile, and no explicit signals of strict modular component architecture are visible. These are meaningful gaps for an enterprise portal where accessibility and structure are organizational standards.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tobias-klein\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Express.js\",\"Socket.io\",\"Docker\",\"Redis\"],\"databases\":[\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nFAANG-style company building a distributed caching and session management layer at scale. Senior backend engineer required with deep systems programming experience in Go or Rust. Redis internals knowledge preferred. gRPC for inter-service communication. Experience with consistent hashing, replication, and distributed database theory. Strong performance benchmarking and profiling habits.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Redis usage is relevant to the subject matter of the role\",\"Docker and GitHub Actions show baseline DevOps awareness\"],\"gaps\":[\"Mid seniority does not meet the senior expectation\",\"No Go or Rust experience; JavaScript is the primary language\",\"No gRPC or distributed systems protocol experience\",\"No consistent hashing, replication, or distributed systems theory signals\",\"No performance benchmarking or profiling signals\",\"No systems programming background\"],\"explanation\":\"Tobias is a JavaScript backend engineer whose profile has no meaningful overlap with the systems programming and distributed infrastructure depth this role requires. While he uses Redis as a tool, there is no signal of the internals knowledge or distributed systems theory the job demands. The seniority gap and language ecosystem mismatch compound the misalignment significantly.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"maja-eriksson\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Go\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"Docker\",\"Argo CD\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nSaaS startup scaling its AWS-based platform. Mid-level DevOps engineer required to manage EKS clusters, write Terraform for AWS resources, and own Helm releases. Argo CD for GitOps deployments. GitHub Actions for CI. Familiarity with AWS networking, IAM, and CloudWatch monitoring required. Go or Bash for internal tooling automation.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes and Helm meet the EKS cluster management and Helm release requirements\",\"Terraform satisfies the IaC requirement\",\"Argo CD directly addresses the GitOps deployment requirement\",\"GitHub Actions covers the CI requirement\",\"Go and Bash meet both tooling language preferences\"],\"gaps\":[\"No AWS-specific signals (EKS, IAM, CloudWatch, VPC) despite explicit requirements\",\"EKS is inferred from Kubernetes but not confirmed as cloud-provider specific experience\"],\"explanation\":\"Maja's DevOps profile has strong tool alignment across Kubernetes, Helm, Terraform, and Argo CD but lacks AWS-specific signals that the role explicitly requires. EKS, IAM, and CloudWatch are named requirements, and the absence of any AWS tooling experience introduces meaningful uncertainty. Her skills are transferable but the AWS ramp-up is a real gap for a team that depends on AWS-specific services.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mia-lindstr\u00f6m\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Radix UI\",\"shadcn/ui\",\"Framer Motion\"],\"architecture\":[\"Monorepo\"],\"databases\":[\"Supabase\"],\"ci_cd\":[\"Vercel\",\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nConsumer app startup seeking a mid-level frontend engineer with a strong eye for UI quality. Next.js and TypeScript required. Tailwind CSS and shadcn/ui for the component system. Framer Motion for animations. Supabase as the backend. Vercel for hosting. Vitest and Playwright for testing. We care deeply about design precision and interaction quality.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and TypeScript are the stated core stack\",\"Tailwind CSS and shadcn/ui directly satisfy the component system requirement\",\"Framer Motion is an explicit requirement and is present\",\"Supabase matches the named backend\",\"Vercel satisfies the hosting requirement\",\"Vitest and Playwright cover both testing requirements\",\"Radix UI further signals accessible component system experience\"],\"gaps\":[],\"explanation\":\"Mia's frontend profile is a near-perfect match for this UI-quality-focused consumer app role. She covers every named technology in the job summary including Framer Motion and shadcn/ui, which are specific and differentiating signals. The absence of any meaningful gaps makes this an unusually strong fit for a mid-level frontend position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mike-ryan\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"jQuery\",\"Bootstrap\",\"Webpack\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nConsumer fintech startup building a React and TypeScript single-page application. Mid-level frontend engineer needed to build reusable components, own the design system, and implement accessibility standards. Tailwind CSS, Zustand for state management, and Vitest for testing are the target stack. Familiarity with modern bundlers like Vite is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Webpack experience is partially relevant for bundler migration context\"],\"gaps\":[\"No React or TypeScript experience, both central to the role\",\"No Tailwind CSS or Zustand signals\",\"No Vitest or modern testing tooling\",\"No Vite experience for the target bundler\",\"jQuery and Bootstrap represent an outdated technology stack\",\"No accessibility or design system signals\"],\"explanation\":\"Mike's frontend profile is anchored in legacy tooling that has no direct overlap with the modern React and TypeScript stack this role requires. The absence of React, TypeScript, Tailwind, Zustand, and Vitest represents a fundamental mismatch across every major requirement. Significant retraining would be needed to deliver value in this position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amara-diallo\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Pandas\",\"Tableau\",\"dbt\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nRetail company building out its analytics team. Junior data analyst needed with SQL and Python skills. Tableau for dashboarding. Snowflake as the warehouse. dbt knowledge is a strong plus for transformation work. Close collaboration with the data engineering team expected. Excellent communication skills valued as you will present insights to non-technical stakeholders.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SQL and Python meet the core analytical requirements\",\"Tableau satisfies the dashboarding requirement\",\"Snowflake is the named warehouse and is present\",\"dbt is listed as a strong plus and Amara demonstrates it\"],\"gaps\":[\"No stakeholder communication or presentation signals from a technical profile\",\"Sparse profile limits confidence in collaborative or cross-team work\"],\"explanation\":\"Amara's technical toolkit aligns well with the stated requirements, and her dbt knowledge is a meaningful differentiator for a junior analyst role. The gaps are soft \u2014 communication and stakeholder presentation ability cannot be assessed from a technical profile alone \u2014 but the role emphasizes them as key competencies, introducing some uncertainty. She is a reasonable fit for the technical component of the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"andres-morales\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Flask\",\"SQLAlchemy\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nData infrastructure startup hiring a mid-level backend engineer. FastAPI for high-performance async APIs. SQLAlchemy for ORM. PostgreSQL as the database. Redis for caching. Celery for background tasks. Docker for containerization. Strong pytest testing required. The team values engineers who understand async Python patterns.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SQLAlchemy is a direct match for the ORM requirement\",\"PostgreSQL satisfies the database requirement\",\"Docker meets the containerization requirement\",\"Python is the correct primary language\"],\"gaps\":[\"No FastAPI experience; Flask is used instead, which lacks async support\",\"No Redis or Celery signals for caching and background tasks\",\"No pytest signals despite it being a stated requirement\",\"No async Python pattern experience visible\"],\"explanation\":\"Andres has the right foundational Python and database skills but the specific tooling gaps are meaningful for this role. Flask's synchronous model contrasts with the async FastAPI focus the team emphasizes, and the absence of Redis and Celery are functional gaps in the backend stack. He is a reasonable candidate if the team can accommodate some technical ramp-up but is not an immediate fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"adaeze-nwosu\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"XGBoost\",\"LightGBM\",\"Pandas\",\"NumPy\",\"MLflow\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"]}\n\nJob Summary:\nInsurance company building a claims fraud detection platform. Senior ML engineer needed with Python, scikit-learn, and gradient boosting experience (XGBoost or LightGBM). BigQuery for data access. MLflow for experiment tracking. Docker for model packaging. Experience in fraud detection, anomaly detection, or risk scoring is a strong differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python, scikit-learn, XGBoost, and LightGBM are all present and directly required\",\"BigQuery satisfies the data access requirement\",\"MLflow meets the experiment tracking requirement\",\"Docker addresses the model packaging need\"],\"gaps\":[\"No fraud detection, anomaly detection, or risk scoring domain signals\",\"No imbalanced classification or threshold optimization signals relevant to fraud modeling\"],\"explanation\":\"Adaeze's ML engineering stack is a precise technical match for this fraud detection role. The gap is domain depth \u2014 fraud and anomaly detection are specialized problem domains that require specific modeling approaches, and her profile shows no signals of this background. She is technically capable of building the models but may need significant time to develop the domain intuition the role prioritizes.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pascal-nguyen\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"Go\"],\"tech\":[\"Axum\",\"gRPC\",\"Kafka\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"CockroachDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"Rust testing\",\"Go testing\"]}\n\nJob Summary:\nInfrastructure company building a high-performance distributed messaging platform in Rust and Go. Senior backend engineer required with Rust experience and Axum or similar framework. gRPC for inter-service communication. Kafka for event streaming. CockroachDB for distributed storage. Kubernetes for orchestration. Event-driven microservices architecture.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Rust and Go are both present as the named primary languages\",\"Axum directly satisfies the Rust framework requirement\",\"gRPC meets the inter-service communication requirement\",\"Kafka satisfies the event streaming requirement\",\"CockroachDB is a rare and exact match for the distributed storage requirement\",\"Kubernetes covers the orchestration requirement\",\"Event-Driven and Microservices architecture signals are both present\"],\"gaps\":[\"No explicit distributed systems theory or consensus algorithm signals\"],\"explanation\":\"Pascal's profile is a highly specific and precise match for this distributed messaging platform role. His Axum and CockroachDB experience are particularly rare and differentiating signals that map directly to the stated requirements. The combination of Rust, gRPC, Kafka, and CockroachDB across both Rust and Go is an exceptional alignment for this infrastructure role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kolade-aina\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Elixir\",\"Python\"],\"tech\":[\"Phoenix\",\"OTP\",\"RabbitMQ\",\"Docker\",\"Nginx\"],\"architecture\":[\"Event-Driven\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nReal-time communications company building a messaging infrastructure platform. Senior backend engineer required with Elixir and Phoenix. OTP for concurrency and fault tolerance. RabbitMQ for message queuing. PostgreSQL and Redis for data persistence and caching. ExUnit for testing. Experience with WebSocket or long-lived connection management is a differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Elixir and Phoenix are exact matches for the core requirements\",\"OTP directly satisfies the concurrency and fault tolerance requirement\",\"RabbitMQ meets the message queuing requirement\",\"PostgreSQL and Redis cover both data requirements\",\"ExUnit satisfies the testing requirement\"],\"gaps\":[\"No explicit WebSocket or long-lived connection management signals\",\"No Phoenix Channels or LiveView signals relevant to real-time communication\"],\"explanation\":\"Kolade's Elixir and OTP profile is technically well-aligned with this messaging infrastructure role. The gap is in real-time connection management \u2014 WebSocket or Phoenix Channels experience is listed as a differentiator and is absent from his profile. For a real-time communications platform, that specific capability is relevant enough to limit confidence in his immediate fit, even though the core stack is correct.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"chukwuemeka-obi\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\"],\"tech\":[\"FastAPI\",\"Docker\",\"Kubernetes\",\"Redis\",\"Celery\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nLegal technology company building a document processing platform. Senior backend Python engineer needed with FastAPI experience for REST APIs. Celery for async document processing workflows. PostgreSQL for metadata storage. Redis for caching. Docker and Kubernetes for containerized deployment. GitHub Actions and Argo CD for CI/CD and GitOps. Strong pytest testing culture.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"FastAPI directly satisfies the REST API requirement\",\"Celery meets the async document processing workflow requirement\",\"PostgreSQL covers the metadata storage requirement\",\"Redis satisfies the caching requirement\",\"Docker and Kubernetes meet the containerized deployment requirements\",\"GitHub Actions and Argo CD satisfy the CI/CD and GitOps requirements\",\"pytest addresses the testing culture requirement\"],\"gaps\":[\"No legal domain or document processing pipeline signals\"],\"explanation\":\"Chukwuemeka's backend profile is a precise match for every technical requirement in this legal technology role. His combination of FastAPI, Celery, PostgreSQL, Redis, and the GitOps stack covers the entire technical footprint described in the job summary. The only soft gap is the absence of legal domain signals, which is unlikely to be disqualifying for a technically-focused engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"soo-jin-park\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Zustand\",\"Storybook\"],\"architecture\":[\"Monorepo\"],\"databases\":[\"Supabase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nConsumer productivity startup seeking a mid-level frontend engineer. Next.js and TypeScript are the core stack. Tailwind CSS for styling and Zustand for lightweight state management. We use Storybook for component documentation and Playwright for end-to-end testing. Supabase as the backend. GitHub Actions for CI. Monorepo structure across packages.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and TypeScript are an exact match for the core stack\",\"Tailwind CSS satisfies the styling requirement\",\"Zustand directly meets the state management preference\",\"Storybook is explicitly required and present\",\"Playwright covers the end-to-end testing requirement\",\"Supabase matches the backend in use\",\"Monorepo architecture aligns with the project structure\"],\"gaps\":[],\"explanation\":\"Soo-Jin's frontend profile is a near-perfect match for this role, covering every named technology with no meaningful gaps. Her combination of Zustand, Storybook, and Playwright alongside the core Next.js stack is a specific and rare alignment. This is an unusually strong fit for a mid-level frontend position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nora-johansson\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Scala\",\"Python\"],\"tech\":[\"Apache Spark\",\"Kafka\",\"Akka\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"Cassandra\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nStreaming analytics company building a large-scale real-time event processing platform. Senior engineer required with Scala and Spark expertise. Kafka for event ingestion. Akka for actor-model concurrency. Cassandra for high-write event storage. Kubernetes for orchestration. Experience with exactly-once processing guarantees and distributed state management is a differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Scala is the primary language and is strongly present\",\"Spark directly satisfies the data processing requirement\",\"Kafka covers the event ingestion requirement\",\"Akka is a specific and exact match for the actor-model concurrency requirement\",\"Cassandra addresses the high-write event storage requirement\",\"Kubernetes satisfies the orchestration requirement\"],\"gaps\":[\"No exactly-once processing or distributed state management signals, listed as differentiators\",\"No stream processing framework specifics (Spark Streaming vs Flink) visible\"],\"explanation\":\"Nora's Scala and distributed systems profile is technically well-aligned with this real-time event processing role. The gap is depth in the advanced areas \u2014 exactly-once semantics and distributed state management are meaningful differentiators for a high-scale streaming platform and are not visible in her profile. She is a strong baseline candidate but may lack the specialized streaming expertise top candidates would demonstrate.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"grace-okafor\",\"seniority\":\"Senior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Retrofit\",\"Hilt\",\"Firebase\"],\"architecture\":[\"Modular Architecture\",\"MVVM\"],\"databases\":[\"Room\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Espresso\",\"Mockito\"]}\n\nJob Summary:\nFintechstartup building an Android-first mobile banking app. Senior Android engineer required with Kotlin and Jetpack Compose as the primary stack. Hilt for dependency injection. Retrofit for API communication. Room for local persistence. Modular architecture across feature modules. Fastlane for release automation. Strong testing culture with JUnit and Espresso.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kotlin and Jetpack Compose are an exact match for the primary stack\",\"Hilt directly satisfies the dependency injection requirement\",\"Retrofit meets the API communication requirement\",\"Room is the named local persistence library and is present\",\"Modular Architecture aligns with the feature module structure\",\"Fastlane satisfies the release automation requirement\",\"JUnit and Espresso address the testing culture requirements\"],\"gaps\":[\"No fintech or financial data handling domain signals\"],\"explanation\":\"Grace's Android profile maps precisely to every technical requirement in this role. Her combination of Jetpack Compose, Hilt, Room, and Fastlane alongside strong testing tooling is a comprehensive and specific alignment. The only gap is the absence of fintech domain signals, which is a soft concern that is unlikely to disqualify an otherwise exact technical match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex-petrov\",\"seniority\":\"Junior\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"React\",\"Flask\",\"Docker\"]}\n\nJob Summary:\nGlobal bank seeking a senior Java backend engineer with Spring Boot microservices experience. PostgreSQL and Oracle required. Kafka for event-driven architecture. Kubernetes for deployment. Jenkins for CI. Strong JUnit and Mockito testing culture. Experience with financial messaging protocols such as SWIFT or FIX is a differentiator. On-call responsibilities included.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker is a minor foundational positive\"],\"gaps\":[\"Junior seniority is far below the senior requirement\",\"No Java or Spring Boot experience\",\"No Kafka, Kubernetes, or Jenkins signals\",\"No PostgreSQL or Oracle experience\",\"No JUnit or Mockito testing signals\",\"No financial messaging protocol experience\"],\"explanation\":\"Alex's profile reflects an early-stage engineer with Python and JavaScript skills that have no meaningful overlap with the Java-centric, enterprise financial stack this role demands. The seniority gap alone would disqualify this candidate, and the absence of every required technical skill makes this a fundamental mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elena-marchetti\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\"],\"tech\":[\"Gin\",\"Docker\",\"Redis\",\"gRPC\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Go testing\"]}\n\nJob Summary:\nAdtech company building a real-time bidding platform in Go. Mid-level backend engineer required with Go and gRPC experience for high-throughput service communication. Redis for in-memory auction state. PostgreSQL for campaign data. Kafka for impression event streaming is preferred. Experience with low-latency API design and performance optimization is valued.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go is the primary language and is strongly present\",\"gRPC satisfies the high-throughput service communication requirement\",\"Redis directly addresses the in-memory auction state requirement\",\"PostgreSQL is the named campaign data store and is present\",\"Gin and Microservices architecture indicate production Go API experience\"],\"gaps\":[\"No Kafka signals for the impression event streaming preference\",\"No low-latency design or performance benchmarking signals\",\"No adtech or real-time bidding domain experience visible\"],\"explanation\":\"Elena's Go and gRPC profile is a solid technical foundation for this adtech role. The meaningful gaps are Kafka and performance optimization experience, both of which the job explicitly values. Her low-latency API design background cannot be confirmed from the profile, which is a meaningful uncertainty for a real-time bidding system where microsecond-level performance is a core concern.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wanjiru-kamau\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Kafka\",\"Docker\",\"Kubernetes\",\"gRPC\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"Cassandra\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nTelecommunications company modernizing its billing and provisioning platform in Java and Kotlin. Senior backend engineer required with Spring Boot microservices experience. Kafka for event-driven billing workflows. Cassandra for high-write billing records. PostgreSQL for relational data. gRPC for inter-service communication. Kubernetes for deployment. Strong JUnit testing culture.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Java and Kotlin match both language requirements\",\"Spring Boot is the named framework and is present\",\"Kafka satisfies the event-driven billing workflow requirement\",\"Cassandra directly addresses the high-write billing record requirement\",\"gRPC meets the inter-service communication requirement\",\"Kubernetes satisfies the deployment requirement\",\"JUnit and Mockito demonstrate the testing culture alignment\"],\"gaps\":[\"No telecommunications domain or billing system-specific signals\"],\"explanation\":\"Wanjiru's backend profile is a precise match for every technical requirement in this telecommunications modernization role. The specificity of her Cassandra and gRPC experience alongside Kafka and Spring Boot is a strong alignment signal for a billing platform that requires exactly that combination. Domain experience in telecom billing is the only soft gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"valentina-rossi\",\"seniority\":\"Junior\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Django\",\"React\"]}\n\nJob Summary:\nCloud infrastructure company hiring a principal cloud architect with deep multi-cloud expertise across AWS and Azure. Terraform and Pulumi for IaC. Kubernetes at scale across multiple clusters. Experience designing enterprise governance frameworks, disaster recovery, and compliance automation. The role requires executive stakeholder management and the ability to influence engineering strategy at the organizational level.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Junior seniority is far below the principal-level requirement\",\"No cloud platform experience (AWS, Azure, GCP)\",\"No Terraform, Pulumi, or Kubernetes signals\",\"No enterprise governance, DR, or compliance engineering signals\",\"No executive or organizational leadership indicators\",\"No architectural design or infrastructure experience\"],\"explanation\":\"Valentina's profile shows a beginner full stack developer with no overlap with the cloud architecture expertise, seniority, or leadership scope this principal-level role requires. Every technical, leadership, and domain requirement is absent. This is a complete mismatch across all dimensions.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ravi-sharma\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Hugging Face Transformers\",\"FastAPI\",\"Docker\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"ChromaDB\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nNLP startup building a document intelligence platform. Mid-level ML engineer required with Python and Hugging Face Transformers experience for named entity recognition and text classification. FastAPI for model serving endpoints. Docker for containerization. ChromaDB or Pinecone for vector retrieval. Experience with fine-tuning transformer models on custom datasets is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Hugging Face Transformers is an exact match for the NLP framework requirement\",\"FastAPI satisfies the model serving endpoint requirement\",\"ChromaDB covers the vector retrieval requirement\",\"Docker meets the containerization requirement\",\"PyTorch is a strong foundational signal for transformer model work\"],\"gaps\":[\"No explicit fine-tuning on custom dataset signals despite it being a stated requirement\",\"No NER or text classification task-specific signals\"],\"explanation\":\"Ravi's ML profile covers the foundational tooling this NLP role requires. The meaningful gap is the absence of evidence that he has specifically fine-tuned transformer models on custom datasets, which the job explicitly requires rather than lists as a preference. Tool presence alone does not confirm fine-tuning experience, and this distinction is important for a role where that capability is central to the work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ben-oduya\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Next.js\",\"React\",\"FastAPI\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\"]}\n\nJob Summary:\nB2B SaaS startup building a project management tool. Mid-level full stack engineer needed with Next.js and TypeScript on the frontend and Python FastAPI on the backend. PostgreSQL for the database. Redis for caching. Docker for containerization. GitHub Actions for CI. Vitest or Jest for frontend testing. We value clean code and ownership over deep experience.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and TypeScript match the frontend requirements\",\"FastAPI with Python satisfies the backend requirement\",\"PostgreSQL and Redis cover both data layer requirements\",\"Docker and GitHub Actions meet the containerization and CI needs\",\"Jest covers the frontend testing requirement\"],\"gaps\":[\"No explicit ownership or product intuition signals in the profile\",\"Sparse profile makes it difficult to assess independent delivery capacity\"],\"explanation\":\"Ben's technical stack aligns well with this role's requirements, covering all named technologies. The limitation is profile depth \u2014 the role emphasizes ownership and clean code culture, and a sparse mid-level profile provides limited evidence of those qualities. He is technically qualified but the fit confidence is moderate without more signal on working style.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mei-zhang\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Pandas\",\"Matplotlib\"]}\n\nJob Summary:\nConsulting firm seeking a senior analytics engineer to own dbt model architecture across three data warehouses. BigQuery, Snowflake, and Redshift experience required. Looker for BI and dashboard delivery. Airflow for pipeline orchestration. Experience leading data modeling initiatives and mentoring junior analysts expected. Strong SQL and dbt expertise required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"SQL and Python are foundational positives\"],\"gaps\":[\"Junior seniority is far below the senior expectation\",\"No dbt experience, which is a core requirement\",\"No BigQuery, Snowflake, or Redshift experience\",\"No Looker or Airflow signals\",\"No mentorship or team leadership indicators\",\"No data modeling or analytics engineering signals\"],\"explanation\":\"Mei's profile is that of an early-stage analyst with basic Python and SQL skills and no exposure to the analytics engineering toolchain this role requires. Every major technical and leadership requirement is absent. This is a complete mismatch in both seniority and technical depth.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leila-hosseini\",\"seniority\":\"Staff\",\"roles\":[\"Machine Learning Engineer\",\"AI Engineer\"],\"languages\":[\"Python\",\"Scala\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"LangChain\",\"LangGraph\",\"Ray\",\"MLflow\",\"Kubernetes\",\"Docker\"],\"architecture\":[\"RAG\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Weaviate\",\"Pinecone\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nAI product company building a staff-level LLM platform for enterprise customers. Deep experience with LLM fine-tuning, RAG pipeline architecture, and multi-agent orchestration using LangGraph required. Hugging Face Transformers for model work. Ray for distributed training and serving. MLflow for experiment lifecycle. Weaviate or Pinecone as vector stores. Kubernetes for production deployment.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LangGraph satisfies the multi-agent orchestration requirement directly\",\"Hugging Face Transformers meets the model development requirement\",\"RAG architecture is explicitly present and required\",\"Ray covers distributed training and serving\",\"MLflow addresses the experiment lifecycle requirement\",\"Both Weaviate and Pinecone are present as named vector stores\",\"Staff seniority aligns with the platform leadership scope\"],\"gaps\":[\"No explicit LLM fine-tuning methodology signals beyond tool presence\"],\"explanation\":\"Leila's AI engineering profile is an outstanding match for this staff-level LLM platform role. Her combination of LangGraph, Hugging Face, Ray, and dual vector store experience is rare and precisely aligned with every stated requirement. The only soft gap is that fine-tuning depth cannot be fully confirmed from tool signals alone, though her stack strongly implies it.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"funmi-adegoke\",\"seniority\":\"Lead\",\"roles\":[\"Full Stack Engineer\",\"Software Architect\"],\"languages\":[\"TypeScript\",\"Python\",\"Go\"],\"tech\":[\"Next.js\",\"React\",\"FastAPI\",\"GraphQL\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Domain-Driven Design\",\"Microservices\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"Vitest\",\"Playwright\",\"pytest\"]}\n\nJob Summary:\nEnterprise SaaS company hiring a lead engineer to own technical architecture across multiple product teams. Domain-driven design and GraphQL API contracts are required. TypeScript on the frontend with Next.js and Python or Go on the backend. Kubernetes for orchestration. Microservices and API gateway patterns. The role involves technical mentorship, cross-team coordination, and architectural decision-making.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Domain-Driven Design is explicitly required and present\",\"GraphQL satisfies the API contract requirement\",\"Next.js and TypeScript cover the frontend stack\",\"FastAPI and Go address both backend language preferences\",\"Kubernetes meets the orchestration requirement\",\"Microservices and API Gateway architecture are both present\",\"Software Architect and Lead roles signal the technical leadership and cross-team coordination capacity\"],\"gaps\":[\"No explicit multi-team coordination or organizational influence signals from public profile\"],\"explanation\":\"Funmi's profile is an outstanding match for this lead engineering role, with every named technical requirement covered directly. Her Software Architect role signal reinforces that she has operated at the architectural decision-making level this position demands. The only uncertainty is whether her leadership experience explicitly spans multiple product teams at the organizational scale this enterprise role requires.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"patrick-osei\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Airflow\",\"dbt\",\"Docker\",\"Pandas\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nE-commerce analytics company seeking a mid-level data engineer. Airflow and dbt for orchestration and transformation. Snowflake as the warehouse. Python for scripting. Data quality tooling such as Great Expectations is preferred. Spark or dask for large dataset processing is a plus. Experience managing pipeline SLAs and documentation practices valued.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Airflow and dbt directly satisfy the orchestration and transformation requirements\",\"Snowflake is the named warehouse and is present\",\"Python and SQL form a strong pipeline scripting foundation\",\"Docker and GitHub Actions indicate deployment and CI discipline\"],\"gaps\":[\"No Great Expectations or data quality tooling signals\",\"No Spark or Dask experience for large dataset processing\",\"No pipeline SLA or documentation practice signals\"],\"explanation\":\"Patrick covers the core orchestration and transformation stack this role requires. The gaps are in the more advanced expectations \u2014 data quality tooling, large dataset processing, and pipeline operations maturity \u2014 which the job highlights as preferences and valued practices. He is a functional fit for baseline pipeline development but may struggle with the operational reliability and quality engineering dimensions of the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"olga-petrenko\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Redux\",\"Webpack\",\"Bootstrap\",\"jQuery\"],\"databases\":[\"MySQL\"],\"ci_cd\":[\"Jenkins\"]}\n\nJob Summary:\nSaaS company seeking a senior frontend engineer to lead a migration from a legacy React and Webpack codebase to a modern Next.js and Vite stack. TypeScript throughout. Tailwind CSS and shadcn/ui for the component system. Zustand for state management. Vitest and Playwright for testing. You will own the migration roadmap and mentor junior engineers.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and TypeScript provide the correct foundational framework\",\"Senior seniority aligns with the mentorship and leadership expectation\",\"Webpack experience is directly relevant for understanding the legacy codebase being migrated\"],\"gaps\":[\"No Next.js or SSR experience for the migration target\",\"No Vite, Tailwind CSS, or shadcn/ui signals in the modern stack direction\",\"No Zustand or lightweight state management experience (Redux is present but being replaced)\",\"No Vitest or Playwright signals for the target testing stack\"],\"explanation\":\"Olga has the right seniority and the legacy React experience needed to understand what is being migrated away from, which is genuinely useful. However, her profile shows no alignment with the target modern stack \u2014 Next.js, Vite, Tailwind, and Zustand are all absent. She may be able to drive the migration strategically but would need significant upskilling on the destination technology.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"daniel-kovacs\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"Celery\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MySQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nMarketplace startup hiring a mid-level backend Python engineer. FastAPI or Django for REST API development. Celery with Redis for async task processing. PostgreSQL as the database. Docker for containerization. Strong pytest testing habits required. Experience with payment gateway integrations (Stripe or similar) is a valued differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Django meets the REST API framework preference\",\"Celery and Redis directly satisfy the async task processing requirement\",\"PostgreSQL matches the primary database\",\"Docker and pytest cover the containerization and testing requirements\"],\"gaps\":[\"No FastAPI experience as the preferred alternative framework\",\"No payment gateway integration signals (Stripe or similar)\"],\"explanation\":\"Daniel covers the core Django and Celery stack this role requires, and his testing and containerization habits are appropriate. The meaningful gap is the absence of payment integration experience, which the job identifies as a valued differentiator for a marketplace product. He is a solid baseline fit but would be at a disadvantage compared to candidates who bring Stripe or similar integration experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"emre-yilmaz\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nIoT platform company building device management and telemetry processing services. Mid-level backend engineer needed with Go or Rust for high-performance services. TimescaleDB for time-series telemetry data. Kafka for device event streaming. MQTT protocol familiarity is a differentiator. Kubernetes for deployment. Strong testing habits required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python, Docker, and pytest show foundational engineering discipline\",\"PostgreSQL is adjacent to TimescaleDB but not a match\"],\"gaps\":[\"No Go or Rust experience in the required performance languages\",\"No TimescaleDB or time-series database experience\",\"No Kafka or event streaming signals\",\"No Kubernetes signals\",\"No MQTT or IoT protocol experience\",\"Django is not applicable to the performance-critical service design required\"],\"explanation\":\"Emre's Python and Django backend profile has no meaningful overlap with the Go/Rust, Kafka, and IoT-focused requirements of this device management role. The combination of wrong language ecosystem, missing streaming and time-series tooling, and no IoT protocol experience represents a fundamental mismatch across every stated requirement. A significant reskilling investment would be needed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ava-chen\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\"],\"tech\":[\"Spring Boot\",\"Docker\",\"Jenkins\"],\"databases\":[\"MySQL\"],\"testing\":[\"JUnit\"]}\n\nJob Summary:\nFAANG-adjacent company building a real-time recommendation engine. Senior backend engineer required with Go or Python, Kafka for streaming, Kubernetes for orchestration, and Redis for feature serving. Experience with ML model serving infrastructure and low-latency API design. Distributed systems background expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Spring Boot and JUnit indicate structured Java backend experience\",\"Docker shows containerization awareness\"],\"gaps\":[\"Mid seniority does not meet the senior requirement\",\"No Go or Python experience in the target languages\",\"No Kafka or streaming experience\",\"No Kubernetes or Redis signals\",\"No ML serving or model infrastructure experience\",\"No distributed systems or low-latency design signals\"],\"explanation\":\"Ava's Java Spring Boot profile has no meaningful overlap with the Go/Python, Kafka, and Kubernetes-centric stack this recommendation engine role requires. The seniority gap compounds the technical mismatch, and the absence of any ML serving or streaming experience makes this a fundamental misalignment across all stated requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sean-mcallister\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Node.js\",\"TypeScript\"],\"tech\":[\"NestJS\",\"GraphQL\",\"Apollo\",\"BullMQ\",\"Docker\",\"Redis\"],\"architecture\":[\"Microservices\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nHR tech company building an API-first talent platform. Mid-level backend engineer needed with NestJS and TypeScript. GraphQL via Apollo as the API layer. BullMQ for background job processing. Redis for caching. PostgreSQL as the primary database. Microservices with an API gateway pattern. Jest and Supertest for unit and integration testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS and TypeScript are an exact match for the core stack\",\"GraphQL and Apollo directly satisfy the API layer requirement\",\"BullMQ is the named job processing library and is present\",\"Redis meets the caching requirement\",\"PostgreSQL is the primary database and is present\",\"Microservices and API Gateway architecture align with the system design\",\"Jest and Supertest cover both testing requirements\"],\"gaps\":[],\"explanation\":\"Sean's backend profile is a comprehensive and precise match for this HR tech API role. Every named technology in the job summary is covered without exception. His combination of NestJS, Apollo GraphQL, BullMQ, and the correct testing stack makes this an unusually tight alignment for a mid-level position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nkechi-eze\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Prometheus\",\"Grafana\",\"Datadog\",\"Terraform\",\"Docker\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nGrowth-stage startup scaling its production platform on AWS. Senior SRE needed to own observability, on-call response, and infrastructure reliability. Prometheus and Grafana for monitoring. Datadog for alerting and APM. Terraform for IaC. Kubernetes for container orchestration. Argo CD for GitOps. Go or Python for tooling. AWS experience including CloudWatch and EKS expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Prometheus, Grafana, and Datadog cover the observability and alerting requirements\",\"Terraform satisfies the IaC requirement\",\"Kubernetes meets the container orchestration requirement\",\"Argo CD satisfies the GitOps requirement\",\"Go and Python meet both tooling language preferences\"],\"gaps\":[\"No AWS-specific signals (EKS, CloudWatch, VPC) despite AWS being explicitly required\",\"Cloud-Native is a generic architecture signal that does not confirm AWS alignment\"],\"explanation\":\"Nkechi's SRE profile covers the observability and GitOps tooling requirements comprehensively. The meaningful gap is the absence of AWS-specific experience \u2014 the role explicitly requires CloudWatch and EKS familiarity, and those signals are not present. Her Terraform and Kubernetes skills are transferable but the cloud platform gap introduces meaningful uncertainty for a team fully committed to AWS infrastructure.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hiroshi-tanaka\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"SQLAlchemy\",\"Docker\",\"Celery\",\"Redis\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nEdtech startup building an adaptive learning platform. Mid-level Python backend engineer needed with FastAPI and SQLAlchemy experience. PostgreSQL as the primary database. Celery and Redis for async processing of learning events. Docker for containerization. GitHub Actions for CI. Strong pytest habits required. Prior experience with educational platforms or LMS integrations is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI and SQLAlchemy are exact matches for the API and ORM requirements\",\"PostgreSQL is the named database and is present\",\"Celery and Redis satisfy the async processing requirement\",\"Docker and GitHub Actions meet the deployment and CI needs\",\"pytest demonstrates the required testing discipline\"],\"gaps\":[\"No edtech, LMS, or educational platform domain signals\",\"Profile is technically sound but sparse, limiting depth assessment\"],\"explanation\":\"Hiroshi's Python backend profile maps precisely to the technical stack this role requires. The gap is domain experience \u2014 prior exposure to educational platforms or LMS integrations is listed as a differentiator and is absent from his profile. He is a clean technical fit but would be at a disadvantage compared to candidates who bring edtech context to the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rafael-moura\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"gRPC\",\"Kafka\",\"Docker\",\"Kubernetes\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Cassandra\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"pytest\",\"Go testing\"]}\n\nJob Summary:\nFinancial data company building high-throughput transaction processing services. We need a senior backend engineer with Go or Python and strong Kafka and gRPC experience. PostgreSQL and Cassandra for data persistence. Kubernetes for orchestration. Event-driven microservices architecture. Argo CD for GitOps-based deployments. Strong testing habits required across services.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go and Python match both stated language preferences\",\"Kafka and gRPC are both explicitly required and present\",\"Cassandra and PostgreSQL cover both persistence requirements\",\"Kubernetes satisfies the orchestration requirement\",\"Argo CD is a direct match for the GitOps deployment requirement\",\"Event-Driven and Microservices architecture signals align with the system design context\"],\"gaps\":[\"No financial domain or transaction processing-specific signals\"],\"explanation\":\"Rafael's backend profile is a precise technical match for this high-throughput financial data role. His combination of Kafka, gRPC, Cassandra, and Kubernetes with senior-level Go and Python experience covers every stated requirement. The only soft gap is the absence of financial domain signals, which is unlikely to be disqualifying for a technically-scoped engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"marcus-steinberg\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Ruby\",\"Python\"],\"tech\":[\"Ruby on Rails\",\"Sidekiq\",\"Redis\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"CircleCI\"],\"testing\":[\"RSpec\",\"Minitest\"]}\n\nJob Summary:\nE-commerce platform hiring a senior backend engineer to extend a high-traffic Rails API. Deep Ruby on Rails experience required. Sidekiq for background job processing. PostgreSQL for the database. Redis for caching. CircleCI for CI pipelines. Strong RSpec testing culture. Experience with API versioning and performance optimization at scale preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Ruby on Rails is an exact match for the core requirement\",\"Sidekiq directly satisfies the background job processing requirement\",\"PostgreSQL and Redis meet both data layer requirements\",\"CircleCI matches the CI platform\",\"RSpec satisfies the testing culture requirement\"],\"gaps\":[\"No API versioning or API design pattern signals\",\"No explicit performance optimization or high-traffic scaling signals\"],\"explanation\":\"Marcus covers the core Rails stack this role requires, and his Sidekiq and RSpec experience is a solid baseline. The gaps are in the more advanced expectations \u2014 performance optimization at scale and API versioning \u2014 which the role lists as preferences but which are meaningful differentiators for a high-traffic e-commerce platform. He is a competent fit for baseline responsibilities but may lack depth in the scaling dimension.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yuna-cho\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Vite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nCreative agency hiring a mid-level frontend engineer to lead client-facing web builds in Next.js and TypeScript. You will own frontend architecture, drive component library decisions, and communicate directly with clients. Experience with animation libraries, performance optimization, and accessibility compliance is expected. Storybook and Playwright required for component testing and QA.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and TypeScript are the correct core stack\",\"React and Tailwind CSS are relevant foundational skills\",\"GitHub Actions and Jest show CI and testing awareness\"],\"gaps\":[\"Junior seniority does not meet the mid-level expectation\",\"No Storybook or Playwright signals, both explicitly required\",\"No animation library experience visible\",\"No accessibility or WCAG signals\",\"No client communication or project ownership indicators\"],\"explanation\":\"Yuna has the correct foundational frontend stack but falls short on seniority and the specific tooling this agency requires. The absence of Storybook, Playwright, and accessibility experience are material gaps for a role that depends on these skills daily. She may be a strong candidate for a junior position but is not ready for the ownership level this role demands.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ada-nwosu\",\"seniority\":\"Junior\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Flask\",\"React\",\"Docker\"]}\n\nJob Summary:\nClimate tech company seeking a principal engineer to define and execute a multi-year backend architecture roadmap. Deep distributed systems expertise required. Go or Rust as primary languages. Kafka, Kubernetes, and Terraform at enterprise scale. Experience leading engineering teams of 20 or more and influencing C-level stakeholders on technical strategy.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Junior seniority is far below the principal-level requirement\",\"No Go or Rust experience\",\"No Kafka, Kubernetes, or Terraform signals\",\"No distributed systems experience\",\"No engineering leadership or stakeholder management indicators\",\"No architectural roadmap or long-term planning signals\"],\"explanation\":\"Ada's profile reflects an early-stage developer with beginner-level tooling and no overlap with the technical, leadership, or organizational requirements of this principal engineering role. Every dimension of the job summary \u2014 language, infrastructure, leadership scale, and organizational influence \u2014 is absent from her profile. This is a fundamental mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"xiulan-chen\",\"seniority\":\"Senior\",\"roles\":[\"Mobile Engineer\",\"Flutter Engineer\"],\"languages\":[\"Dart\",\"Swift\"],\"tech\":[\"Flutter\",\"Firebase\",\"Riverpod\",\"Dio\"],\"architecture\":[\"Modular Architecture\",\"Clean Architecture\"],\"databases\":[\"Firebase\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"Flutter Test\",\"Integration Test\"]}\n\nJob Summary:\nHealthcare startup hiring a senior Flutter mobile engineer. Flutter and Dart required. Riverpod for state management. Firebase for backend and authentication. Fastlane for automated release pipelines. Clean architecture across feature modules. Experience with HIPAA-compliant data handling or medical device regulations is a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Flutter and Dart are the primary requirements and both are present\",\"Riverpod directly satisfies the state management requirement\",\"Firebase covers both backend and authentication needs\",\"Fastlane satisfies the release pipeline requirement\",\"Clean Architecture aligns with the feature module structure\"],\"gaps\":[\"No HIPAA compliance or healthcare data regulation signals\",\"No medical device regulatory experience\"],\"explanation\":\"Xiulan's Flutter profile is a technically precise match, covering every tool named in the job summary. The meaningful gap is healthcare domain compliance \u2014 HIPAA and medical device regulations are significant differentiators for a healthcare startup, and the absence of these signals limits her fit relative to candidates with regulated mobile app experience. She is a strong technical candidate with a domain knowledge gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tomas-guerrero\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"C++\"],\"tech\":[\"PyTorch\",\"ONNX\",\"CUDA\",\"Triton\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Pinecone\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAI inference company optimizing model serving at scale. Senior ML engineer needed with deep PyTorch and CUDA experience for GPU kernel optimization. ONNX for model export and portability. Triton Inference Server for production serving. C++ for performance-critical inference paths. Kubernetes for orchestration of serving infrastructure.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PyTorch and CUDA are the core technical requirements and both are present\",\"ONNX satisfies the model export and portability requirement\",\"Triton is an exact match for the production serving requirement\",\"C++ directly addresses the performance-critical inference path requirement\",\"Kubernetes covers the serving infrastructure orchestration need\"],\"gaps\":[\"No explicit kernel optimization or CUDA programming pattern signals beyond tool presence\"],\"explanation\":\"Tomas's ML infrastructure profile is a highly specific match for this inference optimization role. The combination of CUDA, Triton, ONNX, and C++ alongside PyTorch is rare and directly maps to every requirement in the job summary. The gap around explicit kernel optimization depth is a soft concern that may simply not appear as a distinct GitHub signal.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"paulo-santos\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Gin\",\"FastAPI\",\"Docker\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Go testing\"]}\n\nJob Summary:\nCloud infrastructure startup hiring junior to mid-level backend engineers. Go or Python preferred. Gin or FastAPI for REST services. PostgreSQL as the primary database. Docker for local development. GitHub Actions for CI. We are a collaborative team that values strong testing habits. Good opportunity for engineers who want to grow quickly in a technical environment.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go and Python match both stated language preferences\",\"Gin and FastAPI cover both named framework preferences\",\"PostgreSQL satisfies the primary database requirement\",\"Docker and GitHub Actions meet the local dev and CI requirements\",\"pytest and Go testing demonstrate the strong testing habits the team values\"],\"gaps\":[\"Junior seniority is at the lower bound of the junior-to-mid range\",\"Sparse profile provides limited evidence of collaborative work or independent delivery\"],\"explanation\":\"Paulo's technical stack is a precise match for every tool named in this role, which is a strong positive signal for a junior candidate. The team's emphasis on growth and collaboration is favorable for a junior profile with this level of technical alignment. The main uncertainty is whether his experience translates to the practical delivery independence a startup environment requires, which cannot be fully assessed from tools alone.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"carlos-ben\u00edtez\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C#\",\"SQL\"],\"tech\":[\"ASP.NET\",\"Entity Framework\",\"Docker\",\"Redis\",\"SignalR\"],\"architecture\":[\"Microservices\",\"Layered Architecture\"],\"databases\":[\"MS SQL Server\",\"PostgreSQL\"],\"ci_cd\":[\"Azure DevOps\"],\"testing\":[\"xUnit\",\"Moq\"]}\n\nJob Summary:\nEnterprise software company building a real-time collaboration platform in .NET. Mid-level C# engineer required with ASP.NET Core and SignalR for WebSocket-based real-time features. Entity Framework for ORM. MS SQL Server as the primary database. Azure DevOps for CI/CD. xUnit and Moq for unit testing. Docker for containerization.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"C# and ASP.NET are the core language and framework requirements\",\"SignalR is explicitly required for real-time features and is present\",\"Entity Framework satisfies the ORM requirement\",\"MS SQL Server is the named primary database and is present\",\"Azure DevOps matches the CI/CD platform\",\"xUnit and Moq cover both testing requirements\",\"Docker meets the containerization requirement\"],\"gaps\":[\"No explicit experience with high-concurrency WebSocket connection management\"],\"explanation\":\"Carlos's .NET profile is a precise and comprehensive match for this real-time collaboration platform role. SignalR is the most differentiating signal and is directly present. His coverage of xUnit, Moq, Azure DevOps, and Entity Framework alongside ASP.NET and MS SQL Server leaves no meaningful technical gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dmitry-kuznetsov\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"Django\",\"Celery\",\"Docker\",\"Redis\",\"Nginx\"],\"architecture\":[\"Monolith\",\"Modular Architecture\"],\"databases\":[\"PostgreSQL\",\"MySQL\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nB2B logistics platform hiring a senior backend engineer. Go as the primary language for high-performance microservices. Gin or Echo for REST APIs. gRPC for inter-service communication. Kafka for order event streaming. PostgreSQL for persistence. Kubernetes for deployment. GitHub Actions for CI. Strong testing habits required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"PostgreSQL experience is directly relevant to the persistence requirement\",\"Docker shows basic containerization familiarity\"],\"gaps\":[\"No Go experience; Python is the primary language and does not transfer to the Go microservices stack\",\"No Gin, Echo, or Go HTTP framework experience\",\"No gRPC or inter-service communication protocol experience\",\"No Kafka or event streaming signals\",\"No Kubernetes signals for deployment\",\"No GitHub Actions; GitLab CI is present but not the team's platform\",\"Monolith architecture background contrasts with the microservices requirement\"],\"explanation\":\"Dmitry is a senior Python and Django engineer whose entire stack diverges from the Go-centric microservices architecture this logistics role requires. The language ecosystem mismatch alone is a disqualifying gap, and the absence of gRPC, Kafka, and Kubernetes compounds it across every technical dimension. A fundamental reskilling investment would be needed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"claire-devereaux\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\",\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Prometheus\",\"Grafana\",\"Datadog\",\"Istio\",\"Vault\"],\"architecture\":[\"Service Mesh\",\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\",\"Tekton\"]}\n\nJob Summary:\nFAANG-adjacent company scaling its internal platform across hundreds of Kubernetes clusters. Senior SRE required with deep Kubernetes and service mesh expertise. Istio for traffic management. HashiCorp Vault for secrets. Terraform for IaC. Prometheus and Grafana for observability. Datadog for APM. GitOps with Argo CD. Go or Python for internal tooling.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes expertise with Helm and Istio covers the core platform and service mesh requirements\",\"Vault directly satisfies the secrets management requirement\",\"Terraform meets the IaC requirement\",\"Prometheus and Grafana form the complete observability stack\",\"Datadog addresses the APM requirement\",\"Argo CD satisfies the GitOps requirement\",\"Go and Python meet both internal tooling language preferences\"],\"gaps\":[\"No explicit multi-cluster or large-scale Kubernetes fleet management signals\"],\"explanation\":\"Claire's SRE and platform profile covers every named technology in the job summary with precision. The combination of Istio, Vault, Datadog, and Argo CD is comprehensive for an enterprise-scale platform team. The only soft gap is the absence of explicit signals around managing Kubernetes at hundreds-of-clusters scale, which is implied by the FAANG-adjacent context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ruth-nkemdirim\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Next.js\",\"React\",\"FastAPI\",\"GraphQL\",\"Docker\",\"Redis\"],\"architecture\":[\"Microservices\",\"Domain-Driven Design\"],\"databases\":[\"PostgreSQL\",\"Supabase\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Vercel\"],\"testing\":[\"Vitest\",\"Playwright\",\"pytest\"]}\n\nJob Summary:\nB2B SaaS startup building a team productivity platform. Senior full stack engineer needed. Next.js and TypeScript on the frontend. FastAPI with Python on the backend. GraphQL for the API layer. PostgreSQL via Supabase. Redis for caching. Docker for containerization. Vercel for frontend deployment. Domain-driven design for service modeling. Strong testing required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and TypeScript satisfy the frontend requirements\",\"FastAPI with Python covers the backend requirement\",\"GraphQL meets the API layer requirement\",\"Supabase addresses PostgreSQL hosting\",\"Redis satisfies the caching requirement\",\"Domain-Driven Design is explicitly required and present\",\"Vercel and Docker meet the deployment requirements\",\"Vitest, Playwright, and pytest demonstrate comprehensive testing across the stack\"],\"gaps\":[\"No explicit B2B SaaS or enterprise product domain signals\"],\"explanation\":\"Ruth's full stack profile is a comprehensive and precise match for this productivity platform role. Every named technology and architectural pattern is covered, including the less common Domain-Driven Design requirement. Her testing coverage across Vitest, Playwright, and pytest is particularly strong for a team that emphasizes testing discipline.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nadia-fernandez\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"LangChain\",\"LangGraph\",\"FastAPI\",\"Docker\",\"Weaviate\"],\"architecture\":[\"RAG\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Weaviate\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise AI company building agentic document processing pipelines. Senior AI or ML engineer required with LangChain and LangGraph experience for multi-step agent orchestration. Hugging Face Transformers for LLM integration. Weaviate as the vector store. FastAPI for serving AI endpoints. RAG pipeline architecture required. Docker for containerization.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LangChain and LangGraph are an exact match for the multi-step agent orchestration requirement\",\"Hugging Face Transformers satisfies the LLM integration requirement\",\"Weaviate is the named vector store and is present\",\"RAG architecture is explicitly required and present\",\"FastAPI meets the AI endpoint serving requirement\",\"Docker covers the containerization requirement\"],\"gaps\":[\"No document parsing or long-context chunking strategy signals for document processing\"],\"explanation\":\"Nadia's AI engineering profile is a precise and comprehensive match for this agentic document processing role. Her LangGraph experience is the most critical differentiating signal for multi-step agent orchestration. The only soft gap is the absence of document-specific processing signals, which is a domain concern rather than a technical one.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kwame-owusu\",\"seniority\":\"Junior\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"React\",\"Django\",\"Docker\"]}\n\nJob Summary:\nFinancial services company seeking a principal engineer to define a five-year distributed systems architecture roadmap. Deep expertise in event sourcing, CQRS, and global data replication required. Go or Rust as primary languages. Experience managing and growing engineering organizations of 50 or more. Board-level and C-suite technical advisory experience expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Junior seniority is far below the principal-level requirement\",\"No Go or Rust experience\",\"No distributed systems, event sourcing, or CQRS signals\",\"No global data replication or large-scale infrastructure signals\",\"No engineering organization management experience\",\"No C-suite or board advisory signals\"],\"explanation\":\"Kwame's junior Python and React profile has no meaningful overlap with any dimension of this principal engineering role. The seniority gap spans the full range from junior to principal, and every technical, leadership, and organizational requirement is absent from his background. This is a complete mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mark-oduya\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Express.js\",\"Docker\",\"Redis\"],\"databases\":[\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise software company hiring a senior iOS engineer with Swift and UIKit expertise to own a complex financial app. SwiftUI required for new features. Combine for reactive data flows. XCTest for testing. Fastlane for release pipelines. CoreData for offline persistence. Accessibility compliance (WCAG) expected. Experience with financial app architecture or App Store compliance is valued.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker and GitHub Actions show basic DevOps awareness\"],\"gaps\":[\"No Swift or iOS development experience of any kind\",\"No SwiftUI, UIKit, or Combine signals\",\"No XCTest or iOS testing framework experience\",\"No CoreData or iOS persistence experience\",\"No Fastlane signals\",\"Mid seniority does not meet the senior expectation\",\"JavaScript Node.js backend background does not overlap with iOS engineering\"],\"explanation\":\"Mark is a JavaScript backend engineer with no iOS development experience. There is a complete technical domain mismatch \u2014 not a single iOS-related tool or skill appears in his profile despite iOS engineering being the entirety of what this role requires. The seniority gap and domain gap together make this a fundamental mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"liam-o-sullivan\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Spring Boot\",\"Ktor\",\"Docker\",\"Kubernetes\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"JUnit\",\"Kotest\"]}\n\nJob Summary:\nScandinavian fintech building real-time payment APIs in Kotlin. Senior backend engineer required with Kotlin as primary language. Ktor or Spring Boot for service development. Kafka for payment event streaming. PostgreSQL for persistence. Redis for caching. Kubernetes and Argo CD for deployment. Kotest for testing. PCI DSS compliance experience is a strong differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin is the primary language and is strongly present\",\"Both Ktor and Spring Boot are named and Liam has both\",\"Kafka satisfies the payment event streaming requirement\",\"PostgreSQL and Redis meet the persistence and caching requirements\",\"Kubernetes and Argo CD satisfy the deployment requirements\",\"Kotest meets the testing requirement\"],\"gaps\":[\"No PCI DSS or payment compliance domain signals, listed as a strong differentiator\"],\"explanation\":\"Liam's Kotlin backend profile is technically precise, with the rare combination of both Ktor and Spring Boot alongside the complete deployment and testing stack. The gap is the absence of PCI DSS compliance experience, which the job identifies as a strong differentiator. For a fintech handling live payment APIs, compliance engineering background is a meaningful competitive advantage that Liam does not demonstrate.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tobias-lundqvist\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"NestJS\",\"GraphQL\",\"Apollo\",\"Docker\",\"BullMQ\",\"Redis\"],\"architecture\":[\"Microservices\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nE-learning platform building an API-first course delivery system. Mid-level backend engineer needed with NestJS and TypeScript. GraphQL via Apollo as the primary API layer. PostgreSQL for relational data. BullMQ for async video processing jobs. Redis for caching. GitHub Actions for CI. Jest and Supertest for unit and integration tests.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"NestJS and TypeScript are an exact match for the core backend stack\",\"GraphQL and Apollo directly satisfy the API layer requirement\",\"BullMQ is the named job queue library and is present\",\"PostgreSQL meets the relational data requirement\",\"Redis covers caching\",\"Jest and Supertest satisfy the testing requirements\"],\"gaps\":[\"No video processing or media pipeline domain signals\",\"No CDN or media delivery infrastructure signals\"],\"explanation\":\"Tobias's backend profile covers every named tool in the job summary precisely. The gap is domain context \u2014 video processing and async media delivery involve specialized infrastructure patterns (transcoding, CDN, adaptive streaming) that his profile does not signal. He is a strong technical fit for the API and queue infrastructure but may face a domain ramp-up for the video processing dimension of the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sade-akinwale\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"Ansible\",\"Jenkins\"],\"architecture\":[\"Cloud-Native\"]}\n\nJob Summary:\nFAANG-style company scaling platform infrastructure. Senior DevOps or SRE required with deep Kubernetes and Terraform experience across multi-region AWS deployments. Prometheus and Grafana for observability. Argo CD for GitOps. Istio service mesh. Vault for secrets. Go for internal tooling. On-call responsibilities and incident command experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker shows containerization familiarity\",\"Ansible and Jenkins indicate basic CI and configuration management experience\"],\"gaps\":[\"Mid seniority does not meet the senior SRE expectation\",\"No Kubernetes experience at any level\",\"No Terraform or IaC signals\",\"No AWS experience (multi-region or otherwise)\",\"No Prometheus, Grafana, or observability tooling\",\"No Argo CD or GitOps signals\",\"No Istio or service mesh signals\",\"No Vault or secrets management signals\",\"No Go or tooling language experience\"],\"explanation\":\"Sade's DevOps profile covers only foundational containerization and basic CI tooling, with no overlap with the advanced Kubernetes, AWS, observability, and GitOps stack this FAANG-scale SRE role requires. The seniority gap and the absence of every named technology make this a comprehensive mismatch. Significant upskilling would be required across every technical dimension.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"carlos-oviedo\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Docker\",\"Kafka\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MySQL\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nTelecommunications company hiring a mid-level Java backend engineer for its billing platform. Spring Boot microservices required. Kafka for billing event streaming. PostgreSQL for relational billing data. Redis for caching. Jenkins and GitHub Actions for CI. JUnit and Mockito for testing. Experience with Kubernetes deployment and OpenAPI documentation is preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Java and Spring Boot are the core requirements and both are present\",\"Kafka satisfies the billing event streaming requirement\",\"PostgreSQL meets the relational billing data requirement\",\"Redis covers the caching requirement\",\"Jenkins and GitHub Actions match both CI platforms\",\"JUnit and Mockito satisfy the testing requirements\"],\"gaps\":[\"No Kubernetes signals despite it being a preference\",\"No OpenAPI or Swagger documentation signals\"],\"explanation\":\"Carlos covers the core Java microservices stack for this billing platform role precisely. The gaps are in the preferred skills \u2014 Kubernetes and OpenAPI documentation \u2014 rather than requirements, which limits their impact. He is a strong fit for the baseline responsibilities with some upside potential if he can develop Kubernetes deployment experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hawa-diallo\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"XGBoost\",\"LightGBM\",\"Pandas\",\"NumPy\",\"MLflow\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"]}\n\nJob Summary:\nRetail company hiring a senior ML engineer to build personalization and recommendation models. Python and XGBoost or LightGBM required. BigQuery for data access. MLflow for experiment tracking. Docker for model packaging. Experience with collaborative filtering, matrix factorization, or embedding-based recommendation systems is a strong differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python, XGBoost, and LightGBM directly satisfy the modeling requirements\",\"BigQuery meets the data access requirement\",\"MLflow covers the experiment tracking requirement\",\"Docker addresses the model packaging need\"],\"gaps\":[\"No collaborative filtering, matrix factorization, or embedding-based recommendation signals\",\"No recommendation system or personalization domain signals\"],\"explanation\":\"Hawa's ML engineering toolkit matches the stated tool requirements precisely. The meaningful gap is recommendation system depth \u2014 collaborative filtering and embedding-based models are specialized techniques that her gradient boosting-focused profile does not signal. For a personalization role where those approaches are core to the product's differentiation, candidates who have built recommendation systems would have a significant advantage.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kweku-amponsah\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Docker\",\"Kafka\",\"Nginx\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nLogistics platform hiring a mid-level Java engineer. Spring Boot for microservices. Kafka for order routing event streams. MySQL for transactional data. Redis for caching. Jenkins for CI. JUnit and Mockito for unit testing. Experience with AWS deployment including ECS or EKS is required. Familiarity with OpenAPI and Swagger for contract documentation is preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Java and Spring Boot are an exact match for the core requirement\",\"Kafka satisfies the order routing event stream requirement\",\"MySQL meets the transactional data requirement\",\"Redis covers the caching requirement\",\"Jenkins matches the CI platform\",\"JUnit and Mockito satisfy the testing requirements\"],\"gaps\":[\"No AWS experience (ECS, EKS), which is a stated requirement\",\"No OpenAPI or Swagger signals for contract documentation\"],\"explanation\":\"Kweku covers the core Java microservices stack precisely but is missing AWS deployment experience, which the job lists as a requirement rather than a preference. The absence of ECS or EKS signals is a meaningful gap for a logistics platform that depends on AWS infrastructure. His OpenAPI gap is a softer concern but reinforces the pattern of missing cloud and API documentation tooling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"grace-adebayo\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"HTML\",\"CSS\"],\"tech\":[\"React\",\"Bootstrap\"]}\n\nJob Summary:\nEnterprise SaaS company seeking a senior frontend engineer to lead the migration of a complex React application to Next.js with TypeScript. The role requires architectural ownership, design system leadership, mentoring junior engineers, and experience with Storybook, Playwright, and accessibility standards. Strong TypeScript and state management expertise required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React is a foundational skill relevant to the role\"],\"gaps\":[\"Junior seniority is far below the senior expectation\",\"No TypeScript experience, a core stated requirement\",\"No Next.js or SSR experience for the migration target\",\"No Storybook or Playwright signals\",\"No accessibility or WCAG standards signals\",\"No state management tooling visible\",\"No mentorship or architectural ownership indicators\"],\"explanation\":\"Grace's profile reflects an early-stage frontend developer with basic React skills and no TypeScript, which is a stated requirement for this migration-focused role. The seniority gap is fundamental, and the absence of every named technical differentiator \u2014 Next.js, Storybook, Playwright, and TypeScript \u2014 makes this a clear mismatch. She would be better suited to a junior React position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vasile-popescu\",\"seniority\":\"Lead\",\"roles\":[\"Data Engineer\",\"Analytics Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"Apache Airflow\",\"dbt\",\"Kafka\",\"Databricks\",\"Great Expectations\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nMedia company building a real-time content analytics platform. Lead data engineer required to own pipeline architecture across streaming and batch workloads. Kafka for event ingestion, Spark on Databricks for processing, Snowflake as the cloud warehouse, and dbt for transformations. Python and Scala for pipeline code. Data quality tooling required. Team mentorship expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kafka satisfies the streaming ingestion requirement\",\"Spark on Databricks directly covers the processing requirement\",\"Snowflake is the named warehouse and is present\",\"dbt meets the transformation requirement\",\"Python and Scala address both pipeline language requirements\",\"Great Expectations is a specific and exact data quality tooling match\",\"Lead seniority aligns with the mentorship and architecture ownership expectations\"],\"gaps\":[\"No explicit cross-team mentorship or people management signals\"],\"explanation\":\"Vasile's data engineering profile comprehensively covers every technical requirement of this real-time analytics platform role. His Great Expectations usage is a meaningful differentiator given the explicit data quality tooling requirement. The only soft gap is whether his lead experience extends to formal team mentorship, which is unlikely to surface in a technical profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lin-chen\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Next.js\",\"React\",\"NestJS\",\"GraphQL\",\"Apollo\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Microservices\",\"Domain-Driven Design\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"Vitest\",\"Playwright\",\"Jest\"]}\n\nJob Summary:\nEnterprise HR platform hiring a senior full stack engineer. Next.js and TypeScript on the frontend. NestJS with GraphQL and Apollo on the backend. PostgreSQL for core data. Redis for session management. Domain-driven design for service boundaries. Kubernetes with Argo CD for deployment. GitHub Actions for CI. Vitest and Playwright for frontend testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and TypeScript are the exact frontend requirements\",\"NestJS with GraphQL and Apollo satisfies the backend stack precisely\",\"PostgreSQL meets the core data requirement\",\"Redis covers the session management requirement\",\"Domain-Driven Design is explicitly required and present\",\"Kubernetes and Argo CD satisfy the deployment requirement\",\"Vitest and Playwright address the frontend testing requirements\"],\"gaps\":[\"No HR domain or workforce management signals\"],\"explanation\":\"Lin's full stack profile is a comprehensive and precise match for this enterprise HR platform role. Every named technology and architectural pattern is covered, including Domain-Driven Design which is a less common but explicitly required signal. His Vitest and Playwright testing coverage alongside the full stack alignment makes this an unusually strong fit for a senior position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pedro-alves\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Echo\",\"gRPC\",\"Docker\",\"Redis\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Go testing\",\"pytest\"]}\n\nJob Summary:\nAdtech company building a supply-side platform for programmatic advertising. Mid-level backend engineer needed with Go for high-throughput auction services. Echo or Gin for HTTP APIs. Redis for bid caching. Kafka for impression event streaming. PostgreSQL for campaign metadata. Experience with real-time bidding, OpenRTB protocol, or sub-100ms API design is valued.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go is the primary language and is strongly present\",\"Echo satisfies one of the two named HTTP framework preferences\",\"Redis directly addresses the bid caching requirement\",\"Kafka covers the impression event streaming requirement\",\"PostgreSQL meets the campaign metadata requirement\"],\"gaps\":[\"No OpenRTB or real-time bidding protocol signals\",\"No sub-100ms API design or latency optimization signals\",\"No adtech domain experience visible\"],\"explanation\":\"Pedro has the right Go and infrastructure stack for this adtech role, covering the core tool requirements. The meaningful gap is domain expertise \u2014 real-time bidding and OpenRTB are specialized protocol domains that require specific design patterns, and the absence of any such signals limits his competitiveness for a supply-side platform role where microsecond-level latency is a core constraint.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leo-vandenberg\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Flask\",\"Express.js\",\"Docker\"]}\n\nJob Summary:\nAerospace company hiring a staff software engineer with deep distributed systems experience. Rust or C++ required for safety-critical embedded systems components. Experience with real-time operating systems, formal verification, or DO-178C certification is required. Architecture leadership across multiple engineering teams and executive stakeholder management expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Junior seniority is far below the staff-level expectation\",\"No Rust or C++ experience for safety-critical systems\",\"No embedded systems, RTOS, or real-time computing signals\",\"No formal verification or certification (DO-178C) signals\",\"No distributed systems or architectural leadership indicators\",\"No executive stakeholder management experience\"],\"explanation\":\"Leo's junior Python and JavaScript profile has no overlap with any dimension of this aerospace staff engineering role. The seniority gap spans multiple levels, and the technical requirements for safety-critical embedded systems in Rust or C++ are entirely absent from his background. This is a fundamental mismatch across every criterion.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tae-yang-oh\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"Apache Airflow\",\"dbt\",\"Kafka\",\"Databricks\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nCloud data platform company building batch and streaming pipelines for enterprise clients. Senior data engineer needed with Spark on Databricks, Airflow for orchestration, and dbt for transformations. Kafka for streaming ingestion. Snowflake and BigQuery experience valued. Python and Scala for pipeline code. Data quality with Great Expectations required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Spark on Databricks satisfies the core processing requirement\",\"Airflow meets the orchestration requirement\",\"dbt covers the transformation requirement\",\"Kafka addresses the streaming ingestion requirement\",\"Both Snowflake and BigQuery are present as valued platforms\",\"Python and Scala meet both pipeline code requirements\",\"Great Expectations is an explicit requirement and is present\"],\"gaps\":[\"No explicit enterprise client delivery or multi-tenant pipeline signals\"],\"explanation\":\"Tae-Yang's data engineering profile is a comprehensive and precise match for this cloud data platform role. Every named technology including the specific Great Expectations data quality requirement is covered. His breadth across both Snowflake and BigQuery alongside Kafka and Databricks is a strong signal of platform-level data engineering experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amelia-wright\",\"seniority\":\"Junior\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"Matplotlib\",\"Jupyter\"]}\n\nJob Summary:\nAI company building a production MLOps platform for enterprise clients. Senior ML engineer required with deep experience deploying models at scale using Kubernetes and KFServing or Triton. Ray for distributed training. MLflow and Weights and Biases for experiment lifecycle. Docker for model packaging. CI/CD for ML pipelines using GitHub Actions or Kubeflow Pipelines. Strong Python and Go or Rust for platform tooling.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and scikit-learn show entry-level ML modeling knowledge\"],\"gaps\":[\"Junior seniority is far below the senior ML engineer requirement\",\"No Kubernetes, KFServing, or Triton signals for production model serving\",\"No Ray or distributed training experience\",\"No MLflow or Weights and Biases for experiment tracking\",\"No Docker or containerization signals\",\"No CI/CD for ML pipelines experience\",\"No Go or Rust for platform tooling\",\"Jupyter-based workflow is research-oriented and contrasts with production MLOps requirements\"],\"explanation\":\"Amelia's profile is that of a junior data scientist or researcher with a Jupyter-based ML workflow that has no overlap with the production MLOps infrastructure this role requires. The seniority gap spans from junior to senior, and every platform engineering requirement \u2014 Kubernetes, Ray, Triton, and MLflow \u2014 is absent. This is an academic ML profile applying for a production engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amira-fall\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"Terraform\",\"Ansible\",\"Kubernetes\",\"Helm\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nFintech startup scaling on Google Cloud. Mid-level DevOps or platform engineer required to manage GKE clusters, write Terraform for GCP resources, and maintain Helm releases. Argo CD for GitOps. GitHub Actions for CI. Python or Bash for automation scripts. Familiarity with GCP networking, Cloud IAM, and Cloud Monitoring required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes and Helm meet the GKE cluster management and Helm release requirements\",\"Terraform satisfies the IaC requirement\",\"Argo CD directly addresses the GitOps requirement\",\"GitHub Actions covers the CI requirement\",\"Python and Bash meet both automation scripting preferences\"],\"gaps\":[\"No GCP-specific tooling (GKE, Cloud IAM, Cloud Monitoring) visible despite explicit requirements\",\"Ansible is present but not relevant to the GCP-native tooling expectation\"],\"explanation\":\"Amira's DevOps profile has strong alignment on the tool layer but lacks GCP-specific signals that are explicitly required. Her Kubernetes and Terraform skills are transferable but the absence of GCP IAM, Cloud Monitoring, and GKE-specific experience introduces a meaningful ramp-up concern for a team fully committed to Google Cloud.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mateus-silva\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"Celery\",\"Redis\",\"Docker\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nSaaS startup building workflow automation for operations teams. Mid-level backend Python engineer needed with FastAPI and Celery experience. PostgreSQL as the database. Redis for caching and queue management. Docker for containerization. GitHub Actions for CI. Strong pytest testing habits required. Experience with Stripe or payment integrations is a valued differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI and Celery are exact matches for the API and async task requirements\",\"PostgreSQL is the named database and is present\",\"Redis covers the caching and queue management requirement\",\"Docker and GitHub Actions meet the containerization and CI needs\",\"pytest satisfies the testing requirement\"],\"gaps\":[\"No Stripe or payment integration signals, listed as a valued differentiator\"],\"explanation\":\"Mateus covers the core backend stack for this workflow automation role precisely. The limiting factor is the absence of payment integration experience, which the job identifies as a valued differentiator for an operations-focused SaaS product. He is a strong technical fit for the baseline requirements but would be at a competitive disadvantage against candidates who bring Stripe experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tobias-weber\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Pandas\",\"Tableau\"]}\n\nJob Summary:\nBiotech company hiring a senior ML engineer to build and productionize genomic prediction models. PyTorch or JAX required for deep learning. Experience with bioinformatics toolkits (BioPython, GATK, or similar) is essential. CUDA for GPU acceleration. MLflow for experiment tracking. Kubernetes for model serving at scale. Experience with genomic variant calling or sequence alignment is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and SQL are foundational positives\"],\"gaps\":[\"Junior seniority is far below the senior ML engineer requirement\",\"No PyTorch or JAX experience\",\"No bioinformatics toolkit signals (BioPython, GATK)\",\"No CUDA or GPU computing experience\",\"No MLflow or experiment tracking signals\",\"No Kubernetes signals\",\"No genomics or computational biology domain signals\"],\"explanation\":\"Tobias's profile is that of a junior data analyst with no ML engineering, bioinformatics, or GPU computing background. Every technical requirement for this senior genomics ML role is absent from his profile. The seniority gap alone spans three levels, and the domain and technical depth mismatches compound across every stated requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ana-lucia-rojas\",\"seniority\":\"Mid\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"scikit-learn\",\"XGBoost\",\"Pandas\",\"NumPy\",\"MLflow\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nRetail company building a customer churn prediction model. Mid-level data scientist needed with Python and scikit-learn or XGBoost. SQL and Snowflake for data access. MLflow for experiment tracking. Experience with time series analysis or survival analysis for churn modeling is a differentiator. Tableau or Power BI for model output dashboarding is preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python, scikit-learn, and XGBoost directly satisfy the modeling requirements\",\"Snowflake and SQL cover the data access requirement\",\"MLflow meets the experiment tracking requirement\"],\"gaps\":[\"No time series or survival analysis signals for churn modeling depth\",\"No Tableau or Power BI signals for output dashboarding\"],\"explanation\":\"Ana-Lucia covers the core ML and data access tooling this churn modeling role requires. The meaningful gaps are the absence of churn-specific modeling techniques (time series, survival analysis) and dashboarding tooling, both of which the job highlights as differentiators. She can deliver baseline classification models but may lack the specialized statistical depth that separates strong candidates for this specific problem domain.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amara-kouyate\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Zustand\",\"Framer Motion\",\"Radix UI\"],\"architecture\":[\"Monorepo\"],\"databases\":[\"Supabase\"],\"ci_cd\":[\"Vercel\",\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nConsumer design tool startup hiring a mid-level frontend engineer who cares about UI craft. Next.js and TypeScript are the core stack. Tailwind CSS and Radix UI for the accessible component system. Zustand for lightweight state management. Framer Motion for animations. Vitest and Playwright for testing. Vercel for deployment. Supabase as the backend.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and TypeScript are the exact core stack\",\"Tailwind CSS and Radix UI directly satisfy the accessible component system requirement\",\"Zustand meets the lightweight state management preference\",\"Framer Motion is explicitly required and present\",\"Vitest and Playwright cover both testing requirements\",\"Vercel and Supabase match both infrastructure requirements\"],\"gaps\":[],\"explanation\":\"Amara's frontend profile is a near-perfect match for this design-tool startup role, covering every named technology without exception. The specificity of her Framer Motion, Radix UI, and Zustand experience alongside the full deployment and testing stack is an unusually tight alignment. There are no meaningful technical gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"olga-kovalenko\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Scala\",\"Python\"],\"tech\":[\"Akka\",\"Kafka\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"Cassandra\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nFinancial exchange platform building a real-time order matching engine. Senior backend engineer required with Scala and Akka for actor-model concurrency. Kafka for order event streaming. Cassandra for order book persistence. Kubernetes for deployment. Experience with FIX protocol, low-latency design, or co-location infrastructure is a strong differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Scala and Akka are the core language and concurrency requirements\",\"Kafka satisfies the order event streaming requirement\",\"Cassandra is the named persistence layer and is present\",\"Kubernetes meets the deployment requirement\"],\"gaps\":[\"No FIX protocol, low-latency design, or co-location infrastructure signals\",\"No financial exchange or order matching domain experience visible\"],\"explanation\":\"Olga's Scala and Akka profile is technically well-aligned with this order matching engine role. The meaningful gap is financial exchange specialization \u2014 FIX protocol and low-latency co-location engineering are strong differentiators in this highly specialized domain, and their absence limits her fit relative to candidates who have built exchange or HFT infrastructure. She is a technically capable but domain-generalist candidate for a domain-specialist role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alice-morgan\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Redux\"],\"databases\":[\"Firebase\"],\"ci_cd\":[\"Netlify\",\"GitHub Actions\"]}\n\nJob Summary:\nIoT device management startup requiring a senior backend Go engineer. gRPC and Protobuf for device communication protocols. Kafka for telemetry event streaming. TimescaleDB for time-series device metrics. MQTT protocol experience is required. Kubernetes for orchestration. Strong Go testing with testify required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript and React show front-end engineering maturity\"],\"gaps\":[\"No Go experience; the role requires Go as the primary language\",\"No gRPC, Protobuf, or MQTT signals for device communication\",\"No Kafka or event streaming experience\",\"No TimescaleDB or time-series database experience\",\"No Kubernetes signals\",\"No backend engineering signals of any kind\",\"Mid seniority does not meet the senior expectation\"],\"explanation\":\"Alice is a frontend React engineer whose entire professional focus is on the wrong side of the stack for this IoT backend role. There is no overlap between her skills and any stated requirement \u2014 not the language, the protocols, the data infrastructure, or the seniority level. This is a fundamental domain and stack mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nicolas-petrov\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Next.js\",\"Express.js\",\"Prisma\",\"Tailwind CSS\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nEdtech company building an LMS platform in React and Node.js. Mid-level full stack engineer needed with Next.js and TypeScript. Express.js or NestJS for the backend. Prisma and PostgreSQL for the data layer. Tailwind CSS for styling. Docker for containerization. Jest and Playwright for testing. Experience with LTI standards or LMS integrations is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and TypeScript are the correct core frontend stack\",\"Express.js satisfies the backend requirement\",\"Prisma and PostgreSQL are an exact match for the data layer\",\"Tailwind CSS meets the styling requirement\",\"Docker, Jest, and Playwright satisfy the containerization and testing requirements\"],\"gaps\":[\"No NestJS experience as the alternative backend preference\",\"No LTI or LMS integration domain signals, listed as a plus\"],\"explanation\":\"Nicolas covers the core full stack requirements for this LMS platform role with precision. The modest gaps are the absence of NestJS and any LMS integration domain signals. The NestJS gap is minor given Express.js is an accepted alternative, but the lack of edtech or LTI standards experience limits his fit relative to candidates who have built in this specific domain.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"adwoa-mensah\",\"seniority\":\"Staff\",\"roles\":[\"Platform Engineer\",\"DevOps Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Prometheus\",\"Grafana\",\"Vault\",\"Consul\",\"Pulumi\"],\"architecture\":[\"Cloud-Native\",\"Microservices\",\"Service Mesh\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\",\"Tekton\"]}\n\nJob Summary:\nHigh-growth fintech hiring a staff platform engineer to own infrastructure reliability and developer experience across a multi-cloud environment. Kubernetes at scale, Terraform and Pulumi for IaC, Prometheus and Grafana for observability, Vault for secrets, Consul for service discovery, and GitOps with Argo CD. Go or Python for internal tooling. Staff-level technical leadership required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes at staff level addresses the scaled infrastructure ownership requirement\",\"Both Terraform and Pulumi are present and explicitly required for multi-cloud IaC\",\"Prometheus and Grafana satisfy the observability requirement\",\"Vault and Consul are both named and present for secrets and service discovery\",\"Argo CD meets the GitOps requirement\",\"Go and Python cover both tooling language preferences\",\"Staff seniority aligns with the technical leadership expectation\"],\"gaps\":[\"No explicit multi-cloud provider signals (AWS, GCP, Azure) beyond tool presence\"],\"explanation\":\"Adwoa's platform engineering profile is an exceptional match for this staff-level fintech role, covering every named technology including the rare combination of both Terraform and Pulumi. Her Consul and Vault experience alongside Prometheus and Grafana is a comprehensive and specific alignment. The only uncertainty is which cloud providers her experience spans, which matters in a multi-cloud context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"maya-steinberg\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"FastAPI\",\"Docker\",\"Redis\",\"Stripe\"],\"architecture\":[\"Serverless\",\"Monolith\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"Vercel\",\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\",\"pytest\"]}\n\nJob Summary:\nBootstrapped fintech startup building a B2B invoicing and payment platform. Senior full stack engineer required. Next.js and TypeScript on the frontend. FastAPI with Python on the backend. PostgreSQL via Supabase. Stripe for invoice payments and subscription billing. Vercel for deployment. Redis for caching. Strong TypeScript and testing discipline required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and TypeScript are the exact frontend requirements\",\"FastAPI with Python satisfies the backend requirement\",\"Supabase addresses the PostgreSQL hosting requirement\",\"Stripe is an explicit requirement and is present as the core payment signal\",\"Vercel meets the deployment requirement\",\"Redis covers the caching requirement\",\"Vitest, Playwright, and pytest demonstrate strong testing discipline across the stack\"],\"gaps\":[\"No B2B invoicing or subscription billing domain signals beyond Stripe tool presence\"],\"explanation\":\"Maya's full stack profile is a precise match for this B2B invoicing platform role. Her Stripe experience is the most differentiating signal and maps directly to the invoice payments and subscription billing core requirement. The complete coverage of Next.js, FastAPI, Supabase, and Vercel leaves no meaningful technical gaps in the stated stack.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mihail-ionescu\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\",\"Backend Engineer\"],\"languages\":[\"Go\",\"Rust\",\"Python\"],\"tech\":[\"gRPC\",\"Kafka\",\"Kubernetes\",\"Consul\",\"Vault\",\"Istio\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"CQRS\",\"Event Sourcing\",\"Service Mesh\"],\"databases\":[\"CockroachDB\",\"PostgreSQL\",\"Cassandra\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nDeep tech company building globally distributed infrastructure for autonomous systems. Principal engineer needed to define distributed architecture strategy. CQRS and event sourcing required for audit-grade event history. gRPC and Kafka for service communication and streaming. CockroachDB and Cassandra for distributed storage. Go and Rust for performance-critical services. Service mesh required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"CQRS and Event Sourcing are both present and explicitly required for audit-grade history\",\"Go and Rust are both present as the named performance-critical languages\",\"gRPC and Kafka satisfy the service communication and streaming requirements\",\"CockroachDB and Cassandra are both named and present for distributed storage\",\"Service Mesh and Istio cover the service mesh requirement\",\"Principal seniority aligns with the architectural strategy-setting scope\"],\"gaps\":[\"No autonomous systems, embedded, or safety-critical engineering signals\"],\"explanation\":\"Mihail's distributed systems profile is an exceptional match for this principal-level infrastructure role. His combination of Event Sourcing, CQRS, CockroachDB, Cassandra, and dual language fluency in Go and Rust is both rare and precisely aligned with every stated requirement. The only gap is domain specificity around autonomous systems engineering.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nneka-obi\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"Apache Airflow\",\"dbt\",\"Kafka\",\"Databricks\",\"Great Expectations\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nCloud analytics startup building batch and streaming data infrastructure for enterprise retail clients. Senior data engineer needed with Spark on Databricks, Airflow for orchestration, and Kafka for streaming. Snowflake as the warehouse and dbt for transformations. Python and Scala for pipelines. Data quality tooling required. BigQuery experience is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Spark on Databricks satisfies the core processing requirement\",\"Airflow meets the orchestration requirement\",\"Kafka covers the streaming requirement\",\"Snowflake is the named warehouse and is present\",\"dbt satisfies the transformation requirement\",\"Python and Scala meet both pipeline language requirements\",\"Great Expectations is the explicit data quality requirement and is present\",\"BigQuery is a listed plus and is present\"],\"gaps\":[\"No explicit retail domain or enterprise client delivery signals\"],\"explanation\":\"Nneka's data engineering profile is a comprehensive match for every technical requirement in this analytics startup role, including the uncommon Great Expectations data quality signal. Her BigQuery experience as an additional plus further strengthens her fit. The only soft gap is the absence of retail domain context, which is unlikely to be disqualifying for a technically-scoped senior engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"adeola-balogun\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"FastAPI\",\"Docker\",\"Tailwind CSS\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\"]}\n\nJob Summary:\nSmart home IoT startup building a device management dashboard and API platform. Mid-level full stack engineer needed with Next.js and TypeScript on the frontend and FastAPI with Python on the backend. PostgreSQL for device metadata. Redis for real-time device state. Docker for containerization. Tailwind CSS for styling. Experience with MQTT, WebSocket, or IoT device protocols is a strong differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and TypeScript satisfy the frontend requirements\",\"FastAPI with Python covers the backend requirement\",\"PostgreSQL and Redis meet both data layer requirements\",\"Docker and Tailwind CSS match the containerization and styling requirements\",\"GitHub Actions, Jest, and pytest demonstrate CI and testing discipline\"],\"gaps\":[\"No MQTT, WebSocket, or IoT device protocol signals, listed as a strong differentiator\",\"No IoT or device management domain experience visible\"],\"explanation\":\"Adeola's full stack profile covers the core web application requirements for this IoT platform role. The meaningful gap is IoT protocol experience \u2014 MQTT and WebSocket are listed as strong differentiators and are absent from her profile. For a smart home device management product, candidates who understand real-time device communication protocols would have a significant advantage over a generalist full stack engineer.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"olumide-adeyemi\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"SQLAlchemy\",\"Celery\",\"Docker\",\"Redis\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nLegaltech company building a contract management API platform. Senior Python backend engineer needed with FastAPI and SQLAlchemy. PostgreSQL for relational contract data. Celery for async document processing. Redis for caching. Kafka for event-driven workflow triggers. Docker for containerization. Argo CD for GitOps deployment. Strong pytest culture.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"FastAPI and SQLAlchemy are exact matches for the API and ORM requirements\",\"PostgreSQL is the named relational database and is present\",\"Celery satisfies the async document processing requirement\",\"Redis covers the caching requirement\",\"Kafka meets the event-driven workflow trigger requirement\",\"Docker and Argo CD satisfy the containerization and GitOps deployment requirements\",\"pytest addresses the testing culture requirement\"],\"gaps\":[\"No legal domain or contract lifecycle management signals\"],\"explanation\":\"Olumide's Python backend profile is a comprehensive and precise match for this legaltech contract management role. Every named technology in the job summary is covered without exception. The only soft gap is the absence of legal domain signals, which is a contextual concern rather than a technical one for a technically-scoped senior engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kwasi-boateng\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"Celery\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nDronetech startup building a fleet management and telemetry platform. Mid-level backend engineer needed with Go or Rust for high-throughput telemetry APIs. gRPC for drone communication. TimescaleDB for time-series flight data. Kafka for real-time telemetry streaming. Kubernetes for deployment. Experience with MQTT or MAVLink drone protocols is a differentiator.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and Docker show foundational software engineering discipline\"],\"gaps\":[\"No Go or Rust experience; the role requires one of these as primary languages\",\"No gRPC or protocol buffer signals\",\"No TimescaleDB or time-series database experience\",\"No Kafka or streaming signals\",\"No Kubernetes signals\",\"No MQTT or MAVLink drone protocol signals\",\"FastAPI and Celery are not applicable to the high-throughput telemetry API requirements\"],\"explanation\":\"Kwasi's Python web backend profile has no meaningful overlap with the systems-oriented, Go or Rust telemetry engineering this drone platform role requires. The language ecosystem mismatch combined with the absence of gRPC, TimescaleDB, and Kafka means every major technical requirement is unmet. This is a fundamental stack mismatch rather than a skills gap that can be bridged incrementally.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fatimah-bello\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Airflow\",\"dbt\",\"Pandas\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nHealthcare analytics company hiring a mid-level data engineer. Airflow and dbt for pipeline orchestration and transformation. Snowflake as the primary warehouse. Python for scripting. Experience with HIPAA-compliant data handling and PHI anonymization is required. Familiarity with HL7 FHIR for healthcare data standards is a strong differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Airflow and dbt satisfy the orchestration and transformation requirements\",\"Snowflake is the named warehouse and is present\",\"Python covers the scripting requirement\",\"Docker and GitHub Actions indicate deployment and CI discipline\"],\"gaps\":[\"No HIPAA compliance or PHI data handling signals, listed as a requirement\",\"No HL7 FHIR signals, listed as a strong differentiator\",\"Healthcare compliance is a requirement rather than a preference, making this gap material\"],\"explanation\":\"Fatimah has the right data engineering toolchain for this role but is missing the healthcare compliance experience the job lists as a requirement. HIPAA-compliant data handling and PHI anonymization are not optional for a healthcare analytics platform handling patient data, making this gap more significant than a typical domain mismatch. She would need demonstrable compliance engineering experience to be a viable hire.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rafael-delgado\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nMobile gaming studio hiring a senior backend engineer to build game server infrastructure. Go or C++ for low-latency game server logic. WebSocket or TCP socket handling for real-time player communication. Redis for session state. Kubernetes for deployment. Experience with game server frameworks (Agones, Nakama, or similar) is required. Unity or Unreal Engine backend integration experience is a differentiator.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Redis is relevant to the session state requirement\",\"Docker and GitHub Actions show basic deployment awareness\"],\"gaps\":[\"No Go or C++ experience for game server logic\",\"No WebSocket or TCP socket programming signals\",\"No game server framework experience (Agones, Nakama)\",\"No Kubernetes signals\",\"Mid seniority does not meet the senior requirement\",\"Python and Django are not applicable to low-latency game server requirements\",\"No Unity or Unreal Engine integration signals\"],\"explanation\":\"Rafael's Python and Django backend profile has no overlap with the low-latency game server engineering this role requires. The language ecosystem mismatch \u2014 Go or C++ versus Python \u2014 combined with the absence of socket programming, game server frameworks, and Kubernetes makes this a fundamental technical mismatch. Game server backend engineering is a specialized domain far removed from his Django API development background.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mei-xiao\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Combine\",\"Core Data\"],\"architecture\":[\"Modular Architecture\",\"MVVM\"],\"databases\":[\"Core Data\",\"SQLite\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nFinancial services firm building an iOS trading app. Mid-level iOS engineer required with SwiftUI and UIKit for mixed codebase. Core Data for offline-first persistence. Combine for reactive programming. Fastlane for CI release automation. XCTest for testing. Modular architecture across feature frameworks. Experience with Touch ID, Face ID, or secure storage on iOS is valued.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SwiftUI and UIKit satisfy both the modern and legacy codebase requirements\",\"Core Data is the named offline-first persistence library and is present\",\"Combine meets the reactive programming requirement\",\"Fastlane and XCTest satisfy the release and testing requirements\",\"Modular Architecture aligns with the feature framework structure\"],\"gaps\":[\"No biometric authentication (Touch ID, Face ID) or secure iOS storage signals\",\"No fintech or financial data compliance signals\"],\"explanation\":\"Mei's iOS profile covers every core technical requirement for this trading app role precisely. The gap is in security-specific iOS engineering \u2014 biometric authentication and secure storage are valued differentiators for a financial application, and their absence limits her competitiveness against candidates who bring that experience. She is a strong technical baseline fit with a meaningful security specialization gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yasmin-al-rashid\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Airflow\",\"dbt\",\"Docker\",\"Pandas\"],\"databases\":[\"Redshift\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nCommerce analytics company hiring a senior data engineer. Airflow for orchestration and dbt for transformations are core. Snowflake as the primary warehouse with Redshift as a secondary. PySpark for large-scale data processing is a strong preference. Kafka for streaming ingestion is valued. Data quality tooling experience is a differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Airflow and dbt directly satisfy the core orchestration and transformation requirements\",\"Redshift is one of the two named warehouses and is present\",\"Python and SQL form a solid pipeline scripting foundation\"],\"gaps\":[\"No Snowflake experience for the primary warehouse\",\"No PySpark or large-scale batch processing signals, listed as a strong preference\",\"No Kafka or streaming ingestion signals\",\"No data quality tooling (Great Expectations or similar)\"],\"explanation\":\"Yasmin covers the dbt and Airflow core requirements well, but her profile shows significant gaps in the directional priorities of this role. The absence of Snowflake as the primary warehouse, PySpark for large-scale processing, and any streaming or data quality tooling limits her fit in the areas the team considers most important for growth. She is a functional baseline fit for transformation and orchestration only.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"brendan-otoole\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Elixir\",\"Python\"],\"tech\":[\"Phoenix\",\"Phoenix LiveView\",\"OTP\",\"RabbitMQ\",\"Docker\"],\"architecture\":[\"Event-Driven\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nReal-time collaboration platform hiring a senior Elixir engineer. Phoenix and Phoenix LiveView required for server-rendered real-time UI. OTP for concurrency and fault tolerance. PostgreSQL and Redis for data. RabbitMQ for async messaging. ExUnit for testing. Docker for containerization. Experience with WebSocket or long-lived connection handling is a strong differentiator.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Elixir and Phoenix are the primary stack requirements and both are present\",\"Phoenix LiveView is explicitly required and present as a key differentiator\",\"OTP directly satisfies the concurrency and fault tolerance requirement\",\"RabbitMQ meets the async messaging requirement\",\"PostgreSQL and Redis cover both data requirements\",\"ExUnit satisfies the testing requirement\"],\"gaps\":[\"No explicit WebSocket or long-lived connection management signals beyond Phoenix LiveView\"],\"explanation\":\"Brendan's Elixir profile is a precise and comprehensive match for this real-time collaboration role. His Phoenix LiveView experience is the most differentiating signal and maps directly to the server-rendered real-time UI requirement. OTP alongside ExUnit and RabbitMQ covers every remaining technical requirement with precision.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"anna-kalinina\",\"seniority\":\"Senior\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"Swift\"],\"tech\":[\"Flutter\",\"Firebase\",\"Riverpod\",\"Dio\",\"GetX\"],\"architecture\":[\"Clean Architecture\",\"Modular Architecture\"],\"databases\":[\"Firebase\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"Flutter Test\"]}\n\nJob Summary:\nFintech startup building a cross-platform mobile wallet in Flutter. Senior Flutter engineer needed with Dart and Riverpod or GetX for state management. Firebase for auth and Firestore for data. Fastlane for release automation. Clean architecture across feature modules. SQLite for local storage. Experience with biometric authentication or secure enclave mobile patterns is a differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Flutter and Dart are the primary stack requirements and both are present\",\"Both Riverpod and GetX are listed as options and Anna demonstrates both\",\"Firebase covers auth and data requirements\",\"Fastlane satisfies the release automation requirement\",\"Clean Architecture and SQLite meet the architecture and local storage requirements\"],\"gaps\":[\"No biometric authentication or secure enclave mobile pattern signals\",\"No fintech or financial compliance mobile engineering signals\"],\"explanation\":\"Anna's Flutter profile is a strong technical match for the core stack requirements. The gap is in the security-specific mobile engineering that a fintech wallet application demands \u2014 biometric authentication and secure enclave patterns are differentiators that her profile does not signal. For a financial product handling sensitive user funds, these security patterns are meaningful rather than marginal gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yemi-ogundimu\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Node.js\",\"TypeScript\"],\"tech\":[\"NestJS\",\"GraphQL\",\"Apollo\",\"Docker\",\"Redis\",\"BullMQ\"],\"architecture\":[\"Microservices\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nMedia streaming startup building a subscription and content delivery API. Mid-level backend engineer needed with NestJS and TypeScript. GraphQL via Apollo for the content API. PostgreSQL for subscription data. BullMQ for async content processing jobs. Redis for caching and session management. Microservices with an API gateway pattern. Jest and Supertest for testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS and TypeScript are an exact match for the core backend stack\",\"GraphQL and Apollo satisfy the content API requirement\",\"PostgreSQL is the named database and is present\",\"BullMQ is explicitly required for async jobs and is present\",\"Redis covers both caching and session management\",\"Microservices and API Gateway architecture align with the system design\",\"Jest and Supertest satisfy both testing requirements\"],\"gaps\":[\"No media streaming or content delivery domain signals\"],\"explanation\":\"Yemi's backend profile is a precise match for every technical requirement in this media streaming role. His combination of NestJS, Apollo GraphQL, BullMQ, and Redis alongside the correct testing and architecture patterns covers the entire technology footprint described in the job summary. The only soft gap is the absence of streaming or content delivery domain experience, which is unlikely to be disqualifying for a technically-scoped role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"aleksei-volkov\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"Go\"],\"tech\":[\"Axum\",\"Actix\",\"gRPC\",\"Docker\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Rust testing\",\"Go testing\"]}\n\nJob Summary:\nCybersecurity startup building a real-time network traffic analysis platform. Mid-level backend engineer needed with Rust for performance-critical packet parsing. Actix or Axum for service APIs. Kafka for streaming network events. PostgreSQL for alert storage. Redis for in-memory state. Docker for containerization. Experience with network protocols (TCP/IP, DNS, TLS) is a strong differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Rust is the primary language and is strongly present\",\"Both Actix and Axum are named options and Aleksei demonstrates both\",\"Kafka satisfies the streaming network event requirement\",\"PostgreSQL and Redis meet the storage and in-memory state requirements\",\"Docker covers containerization\"],\"gaps\":[\"No network protocol signals (TCP/IP, DNS, TLS), listed as a strong differentiator\",\"No cybersecurity or network analysis domain signals\"],\"explanation\":\"Aleksei has the right Rust ecosystem experience for this network analysis platform role, and his dual Actix and Axum coverage is a rare bonus. The meaningful gap is network protocol depth \u2014 TCP/IP, DNS, and TLS knowledge is a strong differentiator for a packet-level analysis platform, and its absence from his profile limits his fit against candidates who bring that network engineering background.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"inger-solberg\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Redux\",\"Tailwind CSS\",\"Storybook\",\"Webpack\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Cypress\"]}\n\nJob Summary:\nEnterprise software company modernizing frontend to a Next.js and Vite stack. Senior frontend engineer needed with TypeScript and Next.js. Zustand or Jotai for state management. Tailwind CSS with shadcn/ui for the component system. Vitest and Playwright for testing. Storybook for documentation. Accessibility compliance expected. Webpack to Vite migration experience is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and TypeScript are the correct core stack\",\"Tailwind CSS satisfies part of the component system requirement\",\"Storybook is explicitly required and present\",\"Senior seniority aligns with the role expectation\"],\"gaps\":[\"No shadcn/ui experience for the component system\",\"Redux is present but Zustand or Jotai are preferred for lighter state management\",\"No Vitest or Playwright signals; Jest and Cypress are partial alternatives\",\"No accessibility compliance signals\",\"Webpack experience in a Vite migration context reflects legacy anchoring rather than target alignment\"],\"explanation\":\"Inger has the right foundational Next.js and TypeScript skills and the Storybook experience this role requires. However, her tooling choices diverge from the team's modernization direction across state management, testing, and the component system. She is a viable candidate with a willingness to adapt but would need to transition away from multiple tools she currently relies on.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yaw-asante\",\"seniority\":\"Senior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Hilt\",\"Retrofit\",\"Room\",\"Firebase\"],\"architecture\":[\"Modular Architecture\",\"Clean Architecture\"],\"databases\":[\"Room\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Espresso\",\"Mockito\"]}\n\nJob Summary:\nHealthcare startup building a patient monitoring Android app. Senior Android engineer required with Kotlin and Jetpack Compose. Hilt for dependency injection. Retrofit for API communication. Room for local offline-first data storage. Clean and modular architecture across feature modules. Firebase for analytics. Fastlane for release automation. JUnit and Espresso for testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kotlin and Jetpack Compose are an exact match for the primary stack\",\"Hilt satisfies the dependency injection requirement\",\"Retrofit meets the API communication requirement\",\"Room is the named local storage library and is present\",\"Clean Architecture and Modular Architecture are both present as required\",\"Firebase covers the analytics requirement\",\"Fastlane and JUnit with Espresso satisfy the release and testing requirements\"],\"gaps\":[\"No healthcare compliance or patient data handling signals\"],\"explanation\":\"Yaw's Android profile covers every named technology in this healthcare patient monitoring role with precision. His combination of Jetpack Compose, Hilt, Room, and the full testing stack is a comprehensive technical alignment. The only soft gap is the absence of healthcare-specific compliance signals, which is contextual rather than technical.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"chisom-okeke\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"FastAPI\",\"Docker\",\"ChromaDB\"],\"architecture\":[\"RAG\"],\"databases\":[\"PostgreSQL\",\"ChromaDB\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nNLP company building a multilingual document classification service. Mid-level ML engineer required with Hugging Face Transformers for cross-lingual model fine-tuning. FastAPI for model endpoints. Docker for containerization. ChromaDB or Pinecone for embedding storage. Experience with multilingual NLP, tokenizer customization, or low-resource language modeling is a strong differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Hugging Face Transformers is an exact match for the cross-lingual model requirement\",\"FastAPI satisfies the model endpoint requirement\",\"ChromaDB is one of the two named embedding stores and is present\",\"PyTorch and Docker cover foundational modeling and deployment needs\"],\"gaps\":[\"No multilingual NLP, tokenizer customization, or low-resource language signals\",\"No evidence of fine-tuning on custom classification datasets\"],\"explanation\":\"Chisom has the correct tooling for this NLP role but lacks the domain depth the job prioritizes most. Multilingual model fine-tuning and tokenizer customization are specialized skills that her profile does not signal, which limits her competitive fit for a role where those capabilities are the core differentiation. She can serve models and build RAG pipelines but the specialized NLP depth is unclear.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"bogdan-popa\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\"],\"tech\":[\"FastAPI\",\"Gin\",\"Docker\",\"Redis\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Go testing\"]}\n\nJob Summary:\nClimate tech company building a carbon accounting platform. Senior backend engineer needed with Python or Go. FastAPI or Gin for REST services. PostgreSQL for data. Kafka for event-driven data ingestion. Redis for caching. Docker for containerization. GitHub Actions for CI. Strong testing habits required. Prior experience with energy sector data or emissions standards is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python and Go match both stated language preferences\",\"FastAPI and Gin cover both named framework preferences\",\"PostgreSQL satisfies the primary database requirement\",\"Kafka meets the event-driven data ingestion requirement\",\"Redis and Docker cover caching and containerization\",\"GitHub Actions and pytest and Go testing satisfy CI and testing requirements\"],\"gaps\":[\"No energy sector, emissions standards, or sustainability domain signals\"],\"explanation\":\"Bogdan's backend profile is a strong technical match covering every tool named in the job summary. The only gap is domain \u2014 climate tech and carbon accounting involve specialized data standards and regulatory context that his profile does not signal. For a senior role at a domain-focused company, this is a soft but real limitation compared to candidates who bring energy sector experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priyanka-rao\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Scala\",\"Python\"],\"tech\":[\"Akka\",\"Apache Spark\",\"Kafka\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"Cassandra\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ScalaTest\"]}\n\nJob Summary:\nFintechfirm building a high-throughput trade execution platform. Senior backend engineer required with Scala and Akka for actor-based concurrency. Kafka for trade event streaming. Cassandra for order history storage. Kubernetes for deployment. ScalaTest for testing. Experience with financial message formats (FIX, SWIFT) or trade lifecycle modeling is a strong differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Scala is the primary language and is strongly present\",\"Akka directly satisfies the actor-based concurrency requirement\",\"Kafka meets the trade event streaming requirement\",\"Cassandra is the named order history store and is present\",\"Kubernetes satisfies the deployment requirement\",\"ScalaTest meets the testing requirement\"],\"gaps\":[\"No FIX or SWIFT financial message format signals\",\"No trade lifecycle modeling or financial trading domain signals\"],\"explanation\":\"Priyanka's Scala and Akka profile is a technically precise match for this trade execution platform role. The meaningful gap is domain depth \u2014 financial message formats like FIX and SWIFT and trade lifecycle knowledge are strong differentiators that her profile does not signal. In a high-throughput trading system, that domain context is meaningful for a senior engineer expected to model complex trade workflows.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"soren-nielsen\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Ruby\",\"Python\"],\"tech\":[\"Ruby on Rails\",\"Sidekiq\",\"Redis\",\"Docker\",\"GraphQL\"],\"architecture\":[\"Monolith\",\"Modular Architecture\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"CircleCI\",\"GitHub Actions\"],\"testing\":[\"RSpec\",\"FactoryBot\"]}\n\nJob Summary:\nGrowth-stage e-commerce SaaS building on a Rails stack. Senior backend engineer required with deep Ruby on Rails experience to own core API development and modular decomposition. Sidekiq for background processing. PostgreSQL. Redis for caching. GraphQL API layer. CircleCI for CI. Strong RSpec testing culture. FactoryBot for test fixtures.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Ruby on Rails is the core requirement and is strongly present\",\"Sidekiq directly satisfies the background processing requirement\",\"PostgreSQL and Redis meet both data layer requirements\",\"GraphQL is an exact match for the named API layer\",\"CircleCI matches the CI platform\",\"RSpec and FactoryBot satisfy both testing requirements explicitly\"],\"gaps\":[\"No microservices or service extraction experience for the modular decomposition goal\"],\"explanation\":\"Soren's Rails profile is a comprehensive match for this e-commerce SaaS role, covering every named technology including the less common FactoryBot signal. His combination of Sidekiq, GraphQL, and RSpec alongside Rails maps precisely to the stack described. The only soft gap is the absence of explicit service extraction or modular decomposition project signals, which may be implicit in his Modular Architecture experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ingrid-magnusson\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\"],\"tech\":[\"Laravel\",\"Docker\",\"Redis\"],\"databases\":[\"MySQL\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nCloud-native startup building real-time analytics APIs in Go and Rust. Senior backend engineer required. Axum or Actix for Rust services. gRPC for communication. Kafka for streaming. CockroachDB for distributed storage. Kubernetes for deployment. GitHub Actions for CI. Strong Rust testing habits required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker and Redis show basic infrastructure familiarity\"],\"gaps\":[\"No Go or Rust experience; PHP is the primary language\",\"No Axum or Actix framework experience\",\"No gRPC or protocol buffer signals\",\"No Kafka or streaming signals\",\"No CockroachDB or distributed database experience\",\"No Kubernetes signals\",\"Mid seniority does not meet the senior requirement\",\"PHP ecosystem does not transfer to the Go and Rust cloud-native stack\"],\"explanation\":\"Ingrid is a PHP and Laravel engineer whose language ecosystem has no overlap with the Go and Rust cloud-native stack this role requires. The technical gap spans every stated requirement \u2014 framework, communication protocol, data infrastructure, and deployment \u2014 and the seniority gap adds further distance. This is a fundamental mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"james-okafor\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\",\"SRE\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Prometheus\",\"Grafana\",\"Datadog\",\"Argo CD\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nE-commerce company scaling its AWS platform. Senior SRE needed to manage EKS clusters, write Terraform for AWS resources, maintain Helm releases, and own observability with Prometheus, Grafana, and Datadog. Argo CD for GitOps. GitHub Actions for CI. Go or Python for tooling. CloudWatch for AWS-native monitoring is also in use.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes and Helm meet the EKS cluster management requirement\",\"Terraform satisfies the IaC requirement for AWS resources\",\"Prometheus, Grafana, and Datadog cover the observability requirements\",\"Argo CD and GitHub Actions satisfy the GitOps and CI requirements\",\"Go and Python meet both tooling language preferences\"],\"gaps\":[\"No explicit AWS-specific signals (EKS, CloudWatch, IAM) despite requirements\",\"No CloudWatch experience for the AWS-native monitoring requirement\"],\"explanation\":\"James has a strong SRE toolchain covering observability, GitOps, and IaC with precision. The meaningful gap is cloud provider specificity \u2014 AWS services like EKS, CloudWatch, and IAM are explicitly required but absent from his profile. His Kubernetes and Terraform experience is transferable but the absence of AWS signals introduces real uncertainty for a team that depends on AWS-specific tooling daily.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alexmoreno_dev\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\",\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"Python\",\"SQL\"],\"tech\":[\"Next.js\",\"React\",\"FastAPI\",\"Docker\",\"AWS\",\"Redis\",\"Nginx\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nWe are a Series B fintech startup seeking a Senior Full Stack Engineer to own our core payments platform. You will work across a TypeScript and Python codebase, build microservices on AWS, and ensure high reliability with strong test coverage. Experience with PostgreSQL, Redis caching, and containerized deployments is required. Our stack includes Next.js on the frontend, FastAPI on the backend, and GitHub Actions for CI. We value engineers who can move fast and own features end to end.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"TypeScript and Python align directly with the stated codebase\",\"FastAPI, Next.js, and React match the exact frontend and backend stack\",\"AWS and Docker experience satisfies the containerized deployment requirement\",\"PostgreSQL and Redis are both present and match the database requirements\",\"GitHub Actions CI/CD matches the stated pipeline\",\"Playwright and pytest demonstrate strong test culture\",\"Microservices and event-driven architecture fit the payments platform context\"],\"gaps\":[\"No explicit evidence of payments domain or PCI compliance experience\"],\"explanation\":\"This candidate matches the job stack almost point for point across language, framework, infrastructure, and testing layers. The only meaningful gap is the absence of explicit payments or fintech domain experience, which may matter for compliance-sensitive work but is not a technical blocker.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"riya_ml_builds\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\",\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"NumPy\",\"MLflow\",\"Apache Airflow\",\"Docker\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nWe are building the ML infrastructure team at a mid-size e-commerce company and need a Machine Learning Engineer with solid Python skills and experience shipping models to production. Candidates should have hands-on experience with PyTorch or TensorFlow, experiment tracking tools such as MLflow or Weights and Biases, and data pipeline orchestration. Familiarity with BigQuery and SQL for feature engineering is a plus. The role involves close collaboration with data engineers and does not require frontend or mobile experience.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch matches the stated model training requirement directly\",\"MLflow covers the experiment tracking requirement\",\"Apache Airflow demonstrates data pipeline orchestration experience\",\"BigQuery and SQL align with the feature engineering stack\",\"scikit-learn and Pandas indicate broad ML and data manipulation competency\",\"Docker and GitHub Actions show production-readiness mindset\"],\"gaps\":[\"No evidence of TensorFlow experience, though PyTorch is sufficient\",\"Mid-level seniority may be a consideration for infrastructure ownership tasks\"],\"explanation\":\"The candidate's core ML stack aligns well with the role, but mid-level seniority introduces some uncertainty around infrastructure ownership and independent research engineering expectations. PyTorch and MLflow match directly, though deeper distributed training experience is not evidenced in the profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"frontend_felix\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"Firebase\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nWe are a growth-stage SaaS company hiring a Senior Frontend Engineer to lead our design system migration from Bootstrap to a custom component library using React and TypeScript. The ideal candidate has deep experience with accessibility standards, performance optimization, and mentoring junior engineers. Familiarity with Storybook, Chromatic, or similar visual testing tools is strongly preferred. You will work closely with product and design and will be expected to drive technical decisions independently.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and TypeScript are present and match the core stack\"],\"gaps\":[\"Junior seniority does not meet the Senior-level requirement including mentoring and independent technical decision-making\",\"No evidence of Storybook or visual testing tools\",\"No design system or component library experience visible\",\"No accessibility or performance optimization signals\",\"Tailwind CSS is not the same as building a custom component library\"],\"explanation\":\"While the candidate uses React and TypeScript, the seniority gap is significant given the role demands leadership, mentoring, and autonomous architectural decisions. Critical tooling like Storybook and experience with component library design are also absent from the profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devops_dmitri\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\",\"Site Reliability Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"Kubernetes\",\"Docker\",\"Terraform\",\"Helm\",\"AWS\",\"Prometheus\",\"Grafana\",\"Ansible\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nA FAANG-adjacent company is looking for a Senior SRE to manage Kubernetes clusters at scale, drive infrastructure-as-code adoption with Terraform, and improve observability across a large microservices platform on AWS. The role requires experience with Helm, GitOps workflows, and performance testing. Candidates should be comfortable writing automation in Python or Go and have deep knowledge of Prometheus and Grafana for monitoring.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes and Helm directly match the cluster management requirement\",\"Terraform covers the infrastructure-as-code mandate\",\"Argo CD demonstrates GitOps workflow experience\",\"Prometheus and Grafana match the observability stack exactly\",\"AWS aligns with the cloud platform\",\"Python and Go satisfy the automation scripting requirement\",\"k6 addresses the performance testing signal\",\"Cloud-native and microservices architecture experience is directly relevant\"],\"gaps\":[],\"explanation\":\"This candidate is an exceptional match across every stated technical requirement including Kubernetes management, GitOps with Argo CD, Terraform IaC, observability tooling, and automation languages. No meaningful gaps are evident from the profile relative to this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priya_data_wrangler\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\",\"Analytics Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"dbt\",\"Tableau\",\"Pandas\",\"Apache Airflow\"],\"databases\":[\"Snowflake\",\"PostgreSQL\",\"BigQuery\"]}\n\nJob Summary:\nA retail analytics company needs a Mid-level Analytics Engineer comfortable with dbt, Snowflake, and SQL to build and maintain data models powering executive dashboards. The role involves working with Tableau for visualization and coordinating data quality checks. Python scripting for lightweight ETL is a plus. No backend or mobile engineering experience required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt matches the core data modeling requirement directly\",\"Snowflake is the stated primary database\",\"SQL and Python are both present and relevant\",\"Tableau covers the dashboard visualization requirement\",\"BigQuery and PostgreSQL show broad data platform exposure\",\"Apache Airflow demonstrates ETL orchestration experience\",\"Mid-level seniority aligns with the stated role level\"],\"gaps\":[\"No explicit mention of data quality tooling such as Great Expectations\"],\"explanation\":\"The candidate's stack aligns precisely with the job's technical requirements including dbt, Snowflake, Tableau, and SQL. The only minor gap is the absence of explicit data quality framework experience, which is a secondary requirement in this posting.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mobilemike99\",\"seniority\":\"Junior\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"JavaScript\"],\"tech\":[\"Flutter\",\"Firebase\",\"Expo\"],\"databases\":[\"Firebase\",\"Firestore\"]}\n\nJob Summary:\nAn early-stage healthtech startup needs a Mid-level iOS Engineer experienced with SwiftUI and UIKit to build patient-facing features. Experience with HealthKit, push notifications, and HIPAA-aware data practices is strongly preferred. The team ships weekly to the App Store and values engineers with native iOS experience. React Native or Flutter experience is not relevant to this role.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Some mobile development experience is present via Flutter and Expo\"],\"gaps\":[\"No SwiftUI or UIKit experience, which are the core requirements\",\"Junior seniority does not meet the Mid-level requirement\",\"No native iOS tooling or Swift language visible in profile\",\"No HealthKit or health data experience\",\"Flutter and Expo are explicitly stated as not relevant by the employer\",\"No App Store shipping experience in native iOS context\"],\"explanation\":\"The candidate is a mobile developer but operates in a cross-platform paradigm that the employer has explicitly deprioritized. The absence of Swift, SwiftUI, UIKit, and any native iOS signals means there is no meaningful technical overlap with this role's requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"backendbruno_go\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\",\"SQL\"],\"tech\":[\"Gin\",\"Docker\",\"Kubernetes\",\"AWS\",\"Redis\",\"Apache Kafka\",\"gRPC\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"CQRS\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"k6\",\"pytest\"]}\n\nJob Summary:\nA fintech infrastructure company is hiring a Senior Backend Engineer to work on high-throughput payment processing services written in Go. The role requires deep experience with Kafka for event streaming, gRPC for inter-service communication, and Kubernetes for deployment. PostgreSQL and Cassandra experience is a plus given our mixed relational and wide-column storage needs. The team practices event-driven architecture and CQRS patterns.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go is the primary language and matches the codebase directly\",\"Kafka covers the event streaming requirement exactly\",\"gRPC aligns with the inter-service communication requirement\",\"Kubernetes satisfies the deployment requirement\",\"PostgreSQL and Cassandra are both present and match the database stack\",\"Event-driven architecture and CQRS are explicitly listed in the profile\",\"Gin framework demonstrates Go web service experience\",\"Argo CD and GitHub Actions show mature deployment practices\"],\"gaps\":[\"No explicit evidence of payment processing domain experience\"],\"explanation\":\"The candidate demonstrates near-complete technical alignment with the role across language, messaging, RPC, orchestration, and architectural patterns. The only gap is domain-specific payments experience, which is not listed as a hard requirement in the posting.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cloudnative_carla\",\"seniority\":\"Lead\",\"roles\":[\"Platform Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\",\"TypeScript\"],\"tech\":[\"Terraform\",\"Kubernetes\",\"Helm\",\"AWS\",\"Pulumi\",\"Cloudflare\",\"Docker\"],\"architecture\":[\"Cloud-Native\",\"Serverless\",\"Multi-Tenant\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"]}\n\nJob Summary:\nAn enterprise SaaS company is seeking a Lead Platform Engineer to design and operate their multi-tenant AWS infrastructure. The role requires expertise in Terraform or Pulumi, Kubernetes, and Helm-based deployments. The candidate should understand multi-tenancy patterns and have experience with serverless architectures such as AWS Lambda. GitLab CI or GitHub Actions experience is expected. The team is scaling from 50 to 500 enterprise customers and needs strong infrastructure leadership.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Lead seniority matches the leadership requirement\",\"Terraform and Pulumi both present, satisfying the IaC requirement\",\"Kubernetes and Helm match the deployment stack\",\"Multi-Tenant and Serverless architecture experience directly addresses core design requirements\",\"AWS is the stated cloud provider and is present\",\"GitHub Actions and GitLab CI match the CI/CD requirement\",\"Multi-tenancy architecture experience is rare and explicitly required\"],\"gaps\":[\"No explicit AWS Lambda or serverless compute tooling visible beyond architecture tag\"],\"explanation\":\"The candidate covers IaC, Kubernetes, and multi-tenancy requirements well, but the absence of explicit AWS Lambda or serverless compute tooling beyond architectural tags is a moderate gap for a serverless-heavy platform role. Lead-level infrastructure experience is present but the serverless execution layer knowledge is unverified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"spark_sanjay\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"Scala\",\"SQL\"],\"tech\":[\"Apache Spark\",\"PySpark\",\"Apache Kafka\",\"Apache Airflow\",\"dbt\",\"Databricks\"],\"databases\":[\"Snowflake\",\"PostgreSQL\",\"Redshift\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nA logistics company is hiring a Senior Data Engineer to own their real-time and batch data pipelines. The candidate must have deep Spark and Kafka experience, be comfortable writing production Python and Scala, and have worked with Databricks or a similar managed Spark environment. Airflow for orchestration is required. Snowflake and Redshift familiarity is a plus. The team processes billions of events daily and reliability is critical.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Apache Spark and PySpark match the core batch processing requirement\",\"Kafka covers the real-time streaming requirement\",\"Databricks satisfies the managed Spark environment requirement\",\"Apache Airflow matches the stated orchestration tool\",\"Python and Scala are both present and align with the language requirements\",\"Snowflake and Redshift both present as bonus qualifications\",\"Senior seniority fits the level of ownership described\"],\"gaps\":[\"No evidence of streaming reliability or monitoring tooling beyond Kafka\"],\"explanation\":\"The candidate has strong batch and streaming tooling alignment including Spark, Kafka, and Databricks, but lacks streaming reliability and monitoring tooling signals beyond Kafka itself. For a role processing billions of events daily, observability gaps at this scale present moderate risk.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vue_vivienne\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"Firebase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nA European e-commerce company is hiring a Mid-level Frontend Engineer to build new storefront features using React and Next.js. The team uses TypeScript, Tailwind CSS, and React Query for data fetching. Experience with Vitest or Jest for unit testing and Playwright for end-to-end testing is expected. The candidate should be comfortable working in a monorepo managed with Turborepo.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript and Tailwind CSS match the stated stack\",\"Vitest and Playwright match the testing requirements exactly\",\"Mid-level seniority aligns with the role level\",\"Nuxt.js experience suggests familiarity with SSR patterns transferable to Next.js\",\"Pinia and Vite show modern frontend toolchain experience\"],\"gaps\":[\"Vue.js and Nuxt.js are the primary frameworks but the role requires React and Next.js\",\"No React experience visible in the profile\",\"No React Query or TanStack Query experience\",\"No Turborepo or monorepo tooling experience\"],\"explanation\":\"The candidate is a competent mid-level frontend engineer but is Vue-native, while the role is React and Next.js focused. The testing and styling alignment is good, but the core framework gap is significant and would require a meaningful ramp-up period.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"liam_backend_basics\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Flask\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"SQLite\"]}\n\nJob Summary:\nA Series A startup is hiring a Junior Backend Engineer to help build internal tooling and REST APIs in Python. The team uses Flask or FastAPI, PostgreSQL, and Docker for local development. Candidates should be comfortable writing SQL and have some exposure to REST API design. This is a mentorship-heavy role with room to grow. No advanced cloud or Kubernetes experience required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python matches the core language requirement\",\"Flask aligns with the stated framework options\",\"PostgreSQL and SQL are both present and match the data layer\",\"Docker experience satisfies local development tooling requirement\",\"Junior seniority matches the role level\"],\"gaps\":[\"No FastAPI experience, though Flask is acceptable\",\"No explicit REST API design patterns or OpenAPI documentation visible\",\"Profile is sparse and lacks testing or CI/CD signals\"],\"explanation\":\"The candidate covers the essential technical bases for this junior role including Python, Flask, PostgreSQL, and Docker. The profile is thin on testing and API design signals which introduces some uncertainty, but the core overlap is sufficient for a mentorship-oriented position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"solidity_sam\",\"seniority\":\"Mid\",\"roles\":[\"Blockchain Engineer\",\"Smart Contract Developer\"],\"languages\":[\"Solidity\",\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Hardhat\",\"ethers.js\",\"IPFS\",\"Docker\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Mocha\",\"Chai\"]}\n\nJob Summary:\nA DeFi protocol is hiring a Mid-level Smart Contract Developer with deep Solidity experience to build and audit on-chain financial primitives. Candidates should be comfortable with Hardhat or Foundry for testing and deployment, understand EVM internals, and have contributed to production contracts. TypeScript is used for scripting and frontend integration. Security awareness and familiarity with common DeFi attack vectors is strongly preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Solidity is the primary language and is present\",\"Hardhat matches one of the two stated testing and deployment tools\",\"TypeScript covers the scripting and integration requirement\",\"Mocha and Chai demonstrate a testing mindset in the smart contract context\",\"Mid-level seniority aligns with the role\"],\"gaps\":[\"No Foundry experience, which is increasingly the preferred tool in production DeFi\",\"No explicit mention of EVM internals, gas optimization, or security audit experience\",\"No evidence of DeFi protocol or financial primitive development\",\"Lack of formal security tooling such as Slither or Echidna\"],\"explanation\":\"The candidate has a relevant foundation in Solidity and Hardhat, but the profile lacks signals around DeFi-specific depth including security awareness, EVM optimization, and production contract experience that this role demands. A moderate fit with upside if DeFi experience exists but is not captured in the profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ios_isabelle\",\"seniority\":\"Senior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Expo\",\"Firebase\",\"Xcode\"],\"databases\":[\"Firebase\",\"SQLite\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nA consumer fintech app with 5 million users is looking for a Senior iOS Engineer to own their Swift codebase. The role requires deep SwiftUI and UIKit experience, strong App Store release management skills, and the ability to work with a design system. Fastlane for CI automation is used. The team values engineers who write well-tested Swift and can mentor junior iOS developers.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Swift and SwiftUI are present and match the core language and framework requirement\",\"UIKit experience covers the legacy and hybrid UI requirement\",\"Fastlane matches the CI automation tooling exactly\",\"XCTest demonstrates native iOS testing practice\",\"Senior seniority fits the mentoring and ownership expectations\",\"Objective-C experience is a bonus for dealing with legacy code\"],\"gaps\":[\"No explicit design system contribution or component library experience visible\"],\"explanation\":\"This candidate is a strong match for the Senior iOS role, covering Swift, SwiftUI, UIKit, Fastlane, and test experience in the native iOS ecosystem. The only minor gap is the absence of an explicit design system background, which is a secondary signal in the posting.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"generalist_gus\",\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"Flask\",\"Docker\"],\"databases\":[\"MongoDB\"]}\n\nJob Summary:\nAn enterprise software company is hiring a Staff Engineer to lead a platform modernization initiative. The role requires 10 or more years of experience, deep distributed systems expertise, experience with Kubernetes at scale, and the ability to drive technical roadmaps across multiple teams. The candidate should have Staff or Principal-level experience and a track record of large-scale architectural decisions.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React, Flask, and Python show general full-stack capability\"],\"gaps\":[\"No seniority information provided and no Staff or Principal-level signals\",\"No distributed systems experience visible\",\"No Kubernetes or container orchestration beyond Docker\",\"No architectural decision-making or technical leadership signals\",\"Profile is sparse and lacks the breadth expected at Staff level\",\"No CI/CD, testing, or infrastructure tooling visible\"],\"explanation\":\"The candidate's sparse profile does not surface any of the technical leadership, distributed systems, or infrastructure depth this Staff Engineer role demands. There is no evidence of the seniority, scale, or architectural experience required to drive a platform modernization at enterprise scope.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nestjs_nina\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"Express.js\",\"Docker\",\"AWS\",\"Redis\",\"BullMQ\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nA B2B SaaS startup is hiring a Mid-level Backend Engineer to build scalable APIs and background job processing systems using NestJS and TypeScript. The team uses BullMQ for job queues, Redis for caching, and PostgreSQL as the primary database. AWS for deployment and GitHub Actions for CI are standard. The role involves writing integration and unit tests with Jest.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS is the primary framework and matches exactly\",\"TypeScript is the stated language\",\"BullMQ covers the job queue requirement directly\",\"Redis satisfies the caching requirement\",\"PostgreSQL is the stated primary database\",\"AWS and GitHub Actions match the deployment and CI stack\",\"Jest and Supertest satisfy the testing requirements\",\"Mid-level seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"This is a near-perfect stack match across framework, language, job queue system, caching, database, cloud, and testing layers. The candidate appears purpose-built for this role with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"embedded_ethan\",\"seniority\":\"Senior\",\"roles\":[\"Embedded Engineer\",\"Firmware Engineer\"],\"languages\":[\"C\",\"C++\",\"Python\"],\"tech\":[\"CMake\",\"Docker\"],\"ci_cd\":[\"GitLab CI\"]}\n\nJob Summary:\nA cloud infrastructure company is hiring a Senior Backend Engineer to build distributed storage services in Go. The team uses gRPC for inter-service communication, Kubernetes for orchestration, and Prometheus for observability. Strong systems programming background preferred but Go experience is required. The role involves designing APIs and mentoring junior engineers.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"C and C++ demonstrate strong systems programming fundamentals\",\"Senior seniority matches the level requirement\"],\"gaps\":[\"No Go experience visible in the profile\",\"No gRPC or inter-service communication tooling\",\"No Kubernetes experience\",\"No Prometheus or observability tooling\",\"No API design or REST/gRPC service development signals\",\"Embedded and firmware domain is largely orthogonal to distributed cloud storage services\"],\"explanation\":\"While this candidate has senior-level systems programming experience, the domain gap between embedded firmware and distributed cloud services is wide. The absence of Go, gRPC, Kubernetes, and observability tooling means they would need significant ramp-up time before contributing effectively to this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"django_dara\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"Python\",\"JavaScript\",\"SQL\"],\"tech\":[\"Django\",\"React\",\"Celery\",\"Docker\",\"AWS\",\"Nginx\",\"Redis\"],\"architecture\":[\"Monolith\",\"Layered Architecture\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Selenium\"]}\n\nJob Summary:\nA healthcare SaaS company is seeking a Senior Backend Engineer to maintain and extend a large Django monolith. The role involves writing reliable Python code, managing Celery background tasks, optimizing PostgreSQL queries, and integrating with third-party health data APIs. Candidates should be comfortable with AWS deployment and Docker. A testing-first mindset with pytest is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Django is the core framework and matches exactly\",\"Celery covers the background task requirement directly\",\"PostgreSQL and query optimization experience is implied by senior-level PostgreSQL use\",\"pytest satisfies the testing requirement\",\"AWS and Docker align with the deployment environment\",\"Monolith and Layered Architecture experience is directly relevant to maintaining a large Django codebase\",\"Senior seniority fits the level of ownership\"],\"gaps\":[\"No explicit third-party API integration signals in profile\",\"No HIPAA or health data compliance experience visible\"],\"explanation\":\"The candidate is a strong fit for this Django monolith role, matching on framework, background task tooling, database, deployment, and testing. Minor gaps exist around healthcare compliance and API integration experience, but neither is a hard technical blocker for a senior-level hire.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_intern_mia\",\"seniority\":\"Intern\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nA deep learning research lab is hiring a Mid-level Machine Learning Engineer to build and deploy large language model fine-tuning pipelines. The role requires experience with PyTorch, Hugging Face Transformers, and distributed GPU training using CUDA or similar frameworks. Familiarity with MLflow or Weights and Biases for experiment tracking is expected. Candidates should be able to operate independently on complex research engineering tasks.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is the correct language and scikit-learn shows foundational ML knowledge\"],\"gaps\":[\"Intern seniority does not meet the Mid-level requirement\",\"No PyTorch or deep learning framework experience\",\"No Hugging Face Transformers or LLM fine-tuning experience\",\"No CUDA or distributed GPU training experience\",\"No experiment tracking tooling such as MLflow or Weights and Biases\",\"Profile suggests classical ML exposure only, not deep learning or LLM engineering\"],\"explanation\":\"The candidate is at the very beginning of their ML journey with classical tooling and intern-level experience. This role demands mid-level independence in deep learning, distributed training, and LLM fine-tuning, which are entirely absent from the profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rubyonrails_rosa\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\",\"Backend Engineer\"],\"languages\":[\"Ruby\",\"JavaScript\",\"SQL\"],\"tech\":[\"Ruby on Rails\",\"React\",\"Sidekiq\",\"Docker\",\"Heroku\"],\"architecture\":[\"Monolith\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"CircleCI\"],\"testing\":[\"RSpec\",\"Cypress\"]}\n\nJob Summary:\nA marketplace startup is looking for a Mid-level Full Stack Engineer to work on their Ruby on Rails backend and React frontend. The team uses Sidekiq for background jobs, PostgreSQL as the primary database, and Redis for caching. Heroku or AWS deployment experience is preferred. CircleCI is used for CI. The candidate should be comfortable writing RSpec tests and contributing to both frontend and backend features.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Ruby on Rails matches the backend framework exactly\",\"React covers the frontend requirement\",\"Sidekiq matches the background job system\",\"PostgreSQL and Redis are both present and match the database stack\",\"Heroku satisfies the deployment preference\",\"CircleCI matches the CI pipeline\",\"RSpec and Cypress cover the testing requirements\",\"Mid-level seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate's stack matches well across framework, database, and CI, but the profile lacks signals around large-scale codebase experience or complex multi-service integration, which are typical demands in marketplace engineering at scale. The overall fit is solid but not complete.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"k8s_kyle\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Kubernetes\",\"Docker\",\"Helm\",\"Terraform\",\"AWS\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Cloud-Native\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"]}\n\nJob Summary:\nA media streaming company is seeking a Senior DevOps Engineer to lead their cloud migration to GCP and design CI/CD pipelines at scale. The candidate should have deep GCP experience including GKE, Cloud Build, and BigQuery. Terraform and Kubernetes expertise is required. The role involves mentoring junior engineers and setting platform standards.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes and Helm match the orchestration requirement\",\"Terraform satisfies the IaC requirement\",\"Prometheus and Grafana show observability awareness\",\"GitHub Actions demonstrates CI/CD pipeline experience\",\"Cloud-native architecture experience is relevant\"],\"gaps\":[\"No GCP experience visible, only AWS, which is a significant gap for a GCP migration leadership role\",\"No GKE, Cloud Build, or BigQuery experience\",\"Mid-level seniority does not meet the Senior requirement including mentoring expectations\",\"Jenkins is dated and Cloud Build familiarity is absent\"],\"explanation\":\"The candidate has a solid Kubernetes and Terraform foundation, but the role centers on leading a GCP migration with GCP-specific tooling and the candidate's experience appears to be AWS-only. The seniority gap and missing GCP expertise are significant blockers for this leadership-oriented position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"llm_builder_leo\",\"seniority\":\"Senior\",\"roles\":[\"AI Engineer\",\"LLM Engineer\"],\"languages\":[\"Python\",\"TypeScript\"],\"tech\":[\"LangChain\",\"LangGraph\",\"OpenAI API\",\"Ollama\",\"FastAPI\",\"Docker\",\"AWS\"],\"architecture\":[\"Microservices\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"ChromaDB\",\"Pinecone\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nA legal tech company is hiring a Senior AI Engineer to build LLM-powered document analysis pipelines. The role requires experience with LangChain or similar orchestration frameworks, RAG architectures using vector databases, and API development in Python. OpenAI API or similar LLM provider experience is required. Familiarity with AWS and Docker for deployment is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LangChain and LangGraph directly match the orchestration framework requirement\",\"ChromaDB and Pinecone satisfy the vector database and RAG requirement\",\"OpenAI API covers the LLM provider requirement\",\"FastAPI covers the Python API development requirement\",\"AWS and Docker match the deployment expectations\",\"Ollama suggests experience with local and open-source LLM deployment\",\"LangGraph indicates advanced agent workflow experience relevant to document pipelines\",\"Senior seniority fits the role level\"],\"gaps\":[\"No explicit legal domain experience or document parsing tooling visible\"],\"explanation\":\"The candidate's profile is purpose-aligned for an LLM engineering role, with direct coverage of orchestration, RAG, vector databases, LLM provider APIs, and Python API development. The only gap is domain-specific legal tech experience, which is secondary to the technical requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"php_philomena\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"JavaScript\",\"SQL\"],\"tech\":[\"Laravel\",\"Vue.js\",\"Docker\",\"Nginx\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nAn agency is hiring a Mid-level Backend Engineer to maintain and extend a large Laravel-based CMS for enterprise clients. The candidate should have strong PHP and Laravel experience, be comfortable with MySQL, and have some Vue.js skills for admin panel work. Docker and GitLab CI are used for development and deployment. PHPUnit testing knowledge is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Laravel is the primary framework and matches exactly\",\"PHP is the core language and is present\",\"Vue.js covers the admin panel frontend requirement\",\"MySQL matches the primary database\",\"Redis satisfies additional caching needs\",\"Docker and GitLab CI match the development and CI/CD stack\",\"PHPUnit covers the testing requirement\",\"Mid-level seniority aligns with the role\"],\"gaps\":[\"No explicit CMS customization or multi-client enterprise project signals\"],\"explanation\":\"The candidate aligns with the Laravel and PHP requirements but the profile lacks evidence of enterprise-scale CMS customization or multi-client project management, which are important for an agency serving large enterprise accounts. The technical foundation is right but the domain depth is uncertain.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"android_aisha\",\"seniority\":\"Mid\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Retrofit\",\"Firebase\"],\"databases\":[\"Firestore\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Espresso\"]}\n\nJob Summary:\nA ride-sharing company is hiring a Mid-level Android Engineer to build passenger-facing features in their Kotlin codebase. The team uses Jetpack Compose for UI, Retrofit for API calls, and Firestore for real-time data. CI is managed with GitHub Actions and Fastlane handles release automation. JUnit and Espresso are used for testing. Strong Kotlin skills are required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin is the primary language and is the top language in the profile\",\"Jetpack Compose matches the UI framework\",\"Android SDK confirms native Android experience\",\"Retrofit covers the API client requirement\",\"Firestore matches the real-time data requirement\",\"GitHub Actions and Fastlane match the CI and release automation stack\",\"JUnit and Espresso satisfy the testing requirements\",\"Mid-level seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate's Android stack is a strong technical match, but the absence of any caching strategy signals or performance optimization tooling may be a concern for a ride-sharing app with high-concurrency real-time data requirements. The core fit is good but production scale experience is unverified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ops_oliver\",\"seniority\":\"Junior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"Ansible\",\"AWS\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nA financial services firm is hiring a Senior SRE to design incident response playbooks, own SLO and SLI frameworks, and drive observability initiatives using OpenTelemetry and Datadog. The role requires deep experience with Kubernetes, Terraform, and large-scale distributed systems. The candidate must have demonstrated experience leading post-mortems and influencing engineering culture around reliability.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Some DevOps tooling in Docker and AWS shows foundational infrastructure exposure\"],\"gaps\":[\"Junior seniority is significantly below the Senior SRE requirement\",\"No Kubernetes experience\",\"No Terraform or IaC experience beyond Ansible\",\"No OpenTelemetry or Datadog experience\",\"No SLO, SLI, or reliability engineering practice visible\",\"No distributed systems or incident management experience at scale\"],\"explanation\":\"The candidate is at the beginning of their DevOps journey with basic tooling and junior-level experience. This Senior SRE role demands deep reliability engineering, observability platform ownership, and Kubernetes expertise, none of which are present in the profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"react_native_raj\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React Native\",\"Expo\",\"Redux\",\"React Query\",\"Firebase\"],\"databases\":[\"Firestore\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Detox\"]}\n\nJob Summary:\nA fitness app startup is hiring a Mid-level Mobile Engineer to build features in their React Native and TypeScript codebase. The team uses Expo for managed builds, Redux for state management, and React Query for API data fetching. Firebase and Firestore are used for backend services. Detox for end-to-end testing and Jest for unit testing are standard. Both iOS and Android delivery experience is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React Native matches the core mobile framework\",\"TypeScript is the stated language\",\"Expo matches the build system\",\"Redux covers the state management requirement\",\"React Query satisfies the data fetching requirement\",\"Firebase and Firestore match the backend services\",\"Jest and Detox cover both unit and end-to-end testing requirements\",\"Mid-level seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate matches the React Native stack well, but fitness app context often requires device sensor integrations, HealthKit or similar, or complex real-time features that are not evidenced in the profile. State management and testing coverage are solid, but domain-specific mobile health feature experience is absent.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"scala_simon\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Data Engineer\"],\"languages\":[\"Scala\",\"Python\",\"SQL\"],\"tech\":[\"Apache Spark\",\"Apache Kafka\",\"Akka\",\"Docker\"],\"architecture\":[\"Event-Driven\",\"Microservices\"],\"databases\":[\"Cassandra\",\"PostgreSQL\"],\"ci_cd\":[\"Jenkins\"]}\n\nJob Summary:\nA streaming media company is hiring a Senior Backend Engineer for their recommendation engine team. The role is in Java and Spring Boot, using Kafka for event ingestion, Cassandra for high-throughput reads, and AWS for deployment. Experience with machine learning model serving is a plus. The team prefers Java engineers and familiarity with the JVM ecosystem is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kafka covers the event ingestion requirement directly\",\"Cassandra is present and matches the high-throughput database requirement\",\"Scala runs on the JVM, giving some transferable ecosystem knowledge\",\"Event-driven architecture experience is relevant\",\"Senior seniority matches the role level\"],\"gaps\":[\"No Java experience visible, which is the preferred primary language\",\"No Spring Boot experience, which is the stated backend framework\",\"No AWS experience visible\",\"Jenkins is present but no modern AWS-compatible CI/CD tooling\",\"No ML model serving or recommendation system experience\"],\"explanation\":\"The candidate has valuable Kafka and Cassandra experience that directly overlaps with the role, but the core language and framework mismatch between Scala and Java/Spring Boot introduces meaningful friction. AWS and ML serving gaps add additional risk for a team with a stated preference for Java engineers.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"principal_petra\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\",\"Backend Engineer\"],\"languages\":[\"Java\",\"Go\",\"Python\",\"TypeScript\"],\"tech\":[\"Spring Boot\",\"Kubernetes\",\"Terraform\",\"AWS\",\"Kafka\",\"gRPC\",\"Istio\",\"Helm\"],\"architecture\":[\"Microservices\",\"Domain-Driven Design\",\"Event-Driven\",\"CQRS\",\"Service Mesh\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"DynamoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"JUnit\",\"k6\"]}\n\nJob Summary:\nA global enterprise software company is seeking a Principal Engineer to define the architecture of their next-generation platform. The role requires deep Java and Spring Boot experience, microservices design at scale, Kafka for event streaming, Kubernetes and Istio for service mesh operations, and Terraform for infrastructure. The candidate must have a track record of cross-team technical leadership and architectural decision-making at scale.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Principal seniority matches the level of architectural leadership expected\",\"Java and Spring Boot are the primary language and framework\",\"Kafka satisfies the event streaming requirement\",\"Kubernetes and Istio match the service mesh and orchestration requirements\",\"Terraform satisfies the IaC requirement\",\"Domain-Driven Design, CQRS, and Event-Driven patterns show architectural depth\",\"Argo CD and GitHub Actions reflect modern GitOps CI/CD practices\",\"Polyglot language profile indicates broad systems thinking\"],\"gaps\":[],\"explanation\":\"This candidate has a comprehensive and directly aligned profile for a Principal Engineer role at enterprise scale, covering every stated technical and architectural requirement. The depth of architectural pattern knowledge and operational tooling make this an exceptional match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"gatsby_grace\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Gatsby\",\"React\",\"GraphQL\",\"Tailwind CSS\",\"Netlify\"],\"databases\":[\"Contentful\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nA digital agency is hiring a Junior Frontend Engineer to build Jamstack marketing sites using Gatsby, React, and GraphQL. The team uses Contentful as a headless CMS, Netlify for deployment, and Tailwind CSS for styling. Jest for unit testing is standard. Candidates should be comfortable with TypeScript and working in a fast-paced client delivery environment.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Gatsby is the primary framework and matches exactly\",\"React and GraphQL are both present and required\",\"Contentful covers the headless CMS requirement\",\"Netlify matches the deployment platform\",\"Tailwind CSS satisfies the styling requirement\",\"TypeScript is present\",\"Jest covers the unit testing requirement\",\"Junior seniority aligns with the role level\"],\"gaps\":[\"No explicit agency or client delivery environment experience visible\"],\"explanation\":\"The candidate's Gatsby and Jamstack tooling are a good match, but the junior profile and absence of agency or client delivery environment experience introduces uncertainty about delivery pace and stakeholder management in a fast-moving agency context. The technical tools are right but professional context is unverified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kotlin_backend_kai\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Kotlin\",\"Java\",\"SQL\"],\"tech\":[\"Ktor\",\"Spring Boot\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nA startup building developer tooling is hiring a Mid-level Backend Engineer to work on their Node.js and TypeScript API platform. The team uses NestJS, PostgreSQL, and Redis, deployed on AWS. Jest is used for testing. The candidate should be comfortable with TypeScript and the JavaScript ecosystem. Kotlin or Java experience is not relevant to this role.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"PostgreSQL and Redis are both present and match the database stack\",\"AWS experience aligns with the deployment environment\",\"Mid-level seniority fits the role level\"],\"gaps\":[\"No TypeScript or JavaScript experience visible\",\"No Node.js or NestJS experience\",\"No Jest experience, only JUnit and Mockito which are Java/JVM ecosystem tools\",\"Kotlin and Java are explicitly stated as not relevant by the employer\",\"The entire backend language and framework stack is mismatched\"],\"explanation\":\"Despite matching on database and cloud infrastructure, the candidate's language and framework experience is entirely in the JVM ecosystem while the role requires TypeScript and Node.js. The employer has also explicitly noted that JVM languages are not relevant, making this a poor fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"svelte_sofia\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"SvelteKit\",\"Svelte\",\"Tailwind CSS\",\"Vite\",\"Vercel\"],\"databases\":[\"Supabase\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nA productivity SaaS company is hiring a Mid-level Frontend Engineer to build features in their SvelteKit application. The team uses TypeScript, Tailwind CSS, Supabase for the backend, and deploys to Vercel. Vitest and Playwright are standard for testing. The candidate should be comfortable with Svelte reactivity patterns and SSR concepts in SvelteKit.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SvelteKit and Svelte are the primary framework and exactly match\",\"TypeScript is the stated language\",\"Tailwind CSS satisfies the styling requirement\",\"Supabase matches the backend-as-a-service stack\",\"Vercel is the deployment platform and matches\",\"Vitest and Playwright satisfy the testing requirements\",\"Mid-level seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate's stack aligns with every stated requirement, but the profile is sparse in CI, backend integration, and collaborative tooling signals beyond the frontend layer. For a SaaS product role where frontend engineers often interact with APIs and product feedback loops, the broader engineering context is thin.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"terraform_tomas\",\"seniority\":\"Senior\",\"roles\":[\"Cloud Engineer\",\"Infrastructure Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Terraform\",\"AWS\",\"Docker\",\"Ansible\",\"Vault\"],\"architecture\":[\"Cloud-Native\",\"Multi-Tenant\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Jenkins\"]}\n\nJob Summary:\nA cybersecurity company is hiring a Senior Cloud Engineer focused on AWS infrastructure automation, secrets management, and compliance automation. Terraform is the IaC tool of choice, HashiCorp Vault is used for secrets management, and the team enforces multi-tenant isolation. Python scripting for automation is expected. Security-first infrastructure mindset is essential.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Terraform is the IaC tool and is present\",\"AWS matches the cloud provider\",\"HashiCorp Vault directly satisfies the secrets management requirement\",\"Multi-Tenant architecture experience addresses the isolation requirement\",\"Python covers the automation scripting requirement\",\"Ansible shows additional infrastructure automation depth\",\"Cloud-native architecture experience is relevant\",\"Senior seniority fits the role level\"],\"gaps\":[\"No explicit compliance automation or policy-as-code tooling such as OPA or Sentinel visible\"],\"explanation\":\"The candidate aligns strongly on Terraform, AWS, Vault, multi-tenancy, and Python automation, which are the core pillars of this role. The only notable gap is the absence of explicit compliance automation tooling, which is a secondary concern given the otherwise excellent technical fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wordpress_wren\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"PHP\",\"JavaScript\",\"SQL\"],\"tech\":[\"WordPress\",\"Vue.js\",\"Docker\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nA climate tech startup is hiring a Mid-level Full Stack Engineer to build a real-time carbon tracking dashboard using React, TypeScript, and D3.js for data visualization. The backend is a FastAPI Python service using PostgreSQL and Redis. The team uses Docker and GitHub Actions for deployment. Strong data visualization and API development skills are required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Some JavaScript experience is transferable\",\"Docker is present\"],\"gaps\":[\"No React or TypeScript experience, Vue.js is not equivalent here\",\"No D3.js or data visualization experience\",\"No Python or FastAPI experience\",\"No PostgreSQL experience, only MySQL\",\"No Redis experience\",\"No GitHub Actions CI/CD\",\"WordPress background is not relevant to a data-intensive React and Python stack\",\"No testing signals visible\"],\"explanation\":\"The candidate's background in PHP, WordPress, and Vue.js does not map to the React, TypeScript, D3.js, and FastAPI stack this role requires. The overlap is limited to basic JavaScript and Docker, which is insufficient for a mid-level position demanding specialized data visualization and Python API skills.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rust_engineer_remi\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Embedded Engineer\"],\"languages\":[\"Rust\",\"C\",\"Python\"],\"tech\":[\"Axum\",\"Docker\",\"gRPC\",\"ONNX\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Cargo\"]}\n\nJob Summary:\nA robotics infrastructure company is hiring a Senior Backend Engineer to build low-latency service APIs in Rust. The team uses Axum as the web framework, gRPC for inter-service communication, and runs inference pipelines with ONNX. PostgreSQL and Redis are the primary datastores. Docker is used for containerized deployments. Strong Rust experience and comfort with systems-level programming is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Rust is the primary language and the top language in the profile\",\"Axum matches the stated web framework exactly\",\"gRPC satisfies the inter-service communication requirement\",\"ONNX matches the inference pipeline tooling\",\"PostgreSQL and Redis are both present and match the datastores\",\"Docker covers the containerization requirement\",\"C experience demonstrates systems-level programming depth\",\"Senior seniority fits the role level\"],\"gaps\":[\"No robotics domain experience is visible, though not a hard technical requirement\"],\"explanation\":\"The candidate is an exceptional technical match for this Rust-focused backend role, covering the language, framework, RPC, inference tooling, and data layer with precision. The robotics domain gap is minor given the role's focus on infrastructure services rather than robotics application logic.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"spring_stephan\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Spring\",\"Docker\",\"AWS\"],\"architecture\":[\"Layered Architecture\",\"Microservices\"],\"databases\":[\"MySQL\",\"PostgreSQL\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nA logistics enterprise is hiring a Mid-level Backend Engineer to maintain and extend Java Spring Boot services. The team uses MySQL, Docker, and Jenkins for CI. Mockito and JUnit are used for unit and integration testing. Familiarity with layered architecture and basic AWS deployment is a plus. The role does not require frontend experience.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Spring Boot and Spring match the core framework\",\"Java is the primary language\",\"MySQL is the stated database\",\"Docker is present\",\"Jenkins satisfies the CI requirement\",\"JUnit and Mockito match the testing stack\",\"Layered architecture experience is explicitly mentioned as relevant\",\"Mid-level seniority aligns with the role\",\"AWS is present as a bonus qualification\"],\"gaps\":[],\"explanation\":\"The candidate covers the Java Spring Boot stack well for a maintenance-focused role, but the profile lacks signals around performance tuning, legacy code refactoring, or working within large enterprise codebases, which are common demands in logistics platform engineering. The technical basics are present but depth is unverified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"data_intern_dani\",\"seniority\":\"Intern\",\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"Pandas\",\"NumPy\",\"Tableau\"],\"databases\":[\"SQLite\",\"PostgreSQL\"]}\n\nJob Summary:\nA market research firm is hiring a Junior Data Analyst to build dashboards in Tableau, write SQL queries against PostgreSQL, and support data cleaning workflows in Python. No engineering background required. The role is ideal for candidates with some Python and SQL exposure and a willingness to learn. Tableau experience is strongly preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Tableau is present and matches the dashboard requirement\",\"SQL and PostgreSQL align with the query writing requirement\",\"Python and Pandas cover the data cleaning workflow requirement\",\"R shows quantitative analysis background\"],\"gaps\":[\"Intern seniority is below the Junior level listed, though the gap is narrow\",\"No evidence of dashboard design or stakeholder reporting experience\",\"Profile is sparse with no CI, testing, or collaborative workflow signals\"],\"explanation\":\"The candidate has the essential tools for this analyst role including Tableau, SQL, and Python for data cleaning. The intern-to-junior seniority gap is minor given the role's explicitly low engineering bar, but the profile's sparseness introduces some uncertainty around practical output quality.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"three_js_theo\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Three.js\",\"React\",\"WebGL\",\"Next.js\",\"Tailwind CSS\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nAn interactive media studio is hiring a Mid-level Frontend Engineer to build immersive 3D web experiences. The team uses Three.js and WebGL for rendering, React and Next.js for application structure, and TypeScript throughout. Experience with shader programming or WebGPU is a bonus. The candidate should be comfortable with performance optimization for 3D scenes.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Three.js is the primary 3D library and matches exactly\",\"WebGL directly satisfies the low-level rendering requirement\",\"React and Next.js match the application structure stack\",\"TypeScript is present\",\"Tailwind CSS shows frontend versatility\",\"Mid-level seniority aligns with the role\",\"Jest and Playwright show testing discipline\"],\"gaps\":[\"No shader programming or WebGPU experience visible\"],\"explanation\":\"The candidate's Three.js and WebGL foundation is relevant, but the absence of shader programming and WebGPU experience is a real gap for an immersive media studio where visual performance optimization is central to the product. The candidate can likely contribute but may be limited in the most performance-critical rendering tasks.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"security_eng_seb\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\",\"AppSec Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Docker\",\"Kubernetes\",\"AWS\",\"Vault\",\"Terraform\"],\"architecture\":[\"Microservices\",\"Cloud-Native\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nA fintech company is looking for a Senior Application Security Engineer to embed in product teams, conduct threat modeling, perform code review for vulnerabilities, and build secure SDLC tooling. The candidate should have experience with SAST or DAST tooling, familiarity with OWASP Top 10, and the ability to write security automation in Python or Go. Cloud security on AWS is a significant part of the role.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Senior seniority aligns with the role level\",\"Python and Go match the stated automation scripting languages\",\"AWS is present and relevant to the cloud security requirement\",\"Vault shows secrets management security awareness\",\"Kubernetes and Docker experience is relevant to cloud security posture\"],\"gaps\":[\"No explicit SAST, DAST, or application security tooling visible in profile\",\"No OWASP or vulnerability assessment experience signaled\",\"No secure SDLC tooling or threat modeling experience visible\",\"Profile reads more as DevOps or platform engineering than application security\"],\"explanation\":\"The candidate has cloud infrastructure security experience and the right automation languages, but the profile lacks direct signals of application security practice including SAST, DAST, OWASP knowledge, and threat modeling. The role requires an AppSec specialist mindset that is not clearly demonstrated.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elixir_elena\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Elixir\",\"JavaScript\",\"SQL\"],\"tech\":[\"Phoenix\",\"Docker\",\"AWS\",\"RabbitMQ\"],\"architecture\":[\"Event-Driven\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nA real-time collaboration platform is hiring a Senior Backend Engineer to build their Elixir and Phoenix backend. The role involves building real-time features using Phoenix Channels and LiveView, event-driven architectures, and PostgreSQL for persistence. Candidates should be comfortable with the BEAM ecosystem and have experience with fault-tolerant distributed system design. RabbitMQ or similar messaging experience is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Elixir is the primary language and matches exactly\",\"Phoenix is the stated framework and is present\",\"RabbitMQ satisfies the messaging experience bonus requirement\",\"Event-driven architecture experience is directly relevant\",\"PostgreSQL matches the persistence layer\",\"Redis adds caching capability\",\"Senior seniority fits the role level\",\"ExUnit demonstrates native Elixir testing practice\"],\"gaps\":[\"No explicit Phoenix Channels or LiveView experience visible in profile\"],\"explanation\":\"The candidate is a strong match with deep Elixir and Phoenix experience in an event-driven context. The only gap is the absence of explicit Phoenix Channels or LiveView signals, though these are core Phoenix features and a Phoenix-experienced senior engineer would be expected to have exposure to them.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"no_code_nolan\",\"languages\":[\"JavaScript\"],\"tech\":[\"WordPress\",\"Webflow\",\"Zapier\"]}\n\nJob Summary:\nA deep tech company is hiring a Staff Machine Learning Engineer to lead development of custom transformer architectures for computer vision tasks. The role requires expert-level PyTorch and CUDA experience, familiarity with distributed GPU training, and experience publishing or contributing to ML research. The candidate must be able to mentor senior engineers and drive the ML roadmap.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"No ML or AI experience of any kind\",\"No Python, PyTorch, or CUDA experience\",\"No machine learning frameworks or tooling\",\"No GPU training or distributed computing experience\",\"No research or academic ML background\",\"No seniority information and no signals of staff-level engineering leadership\",\"The entire technical profile is in web tooling with no overlap with the role\"],\"explanation\":\"There is no meaningful overlap between this candidate's profile and the requirements of a Staff ML Engineer role. The candidate works with no-code and web tools, while the role demands expert-level machine learning research engineering at the intersection of PyTorch, CUDA, and transformer architecture design.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nuxt_natasha\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\",\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Nuxt.js\",\"Vue.js\",\"Pinia\",\"Tailwind CSS\",\"Node.js\",\"Express.js\",\"Docker\",\"Vercel\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Cypress\"]}\n\nJob Summary:\nA media company is hiring a Senior Full Stack Engineer to work on a content delivery platform built with Nuxt.js, Vue.js, and a Node.js Express backend. The team uses Pinia for state management, PostgreSQL as the primary database, Tailwind CSS for styling, and Vercel for deployment. GitHub Actions handles CI. The candidate should be comfortable with SSR and SSG in Nuxt and have strong TypeScript skills.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Nuxt.js is the core framework and matches exactly\",\"Vue.js is the underlying library and is present\",\"Express.js covers the Node.js backend requirement\",\"Pinia matches the state management requirement\",\"PostgreSQL is the primary database and is present\",\"Tailwind CSS satisfies the styling requirement\",\"Vercel matches the deployment platform\",\"GitHub Actions satisfies the CI requirement\",\"TypeScript is present\",\"Vitest and Cypress cover unit and E2E testing\"],\"gaps\":[],\"explanation\":\"This candidate is a comprehensive match for the role with direct alignment on every stated technical requirement including framework, backend, state management, database, styling, deployment, CI, and testing. There are no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dbt_diana\",\"seniority\":\"Senior\",\"roles\":[\"Analytics Engineer\",\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"dbt\",\"Apache Airflow\",\"Databricks\",\"Pandas\",\"Great Expectations\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"Redshift\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nA global retail company is hiring a Senior Analytics Engineer to own their enterprise dbt project, enforce data quality standards, and build orchestration pipelines in Airflow. The team runs on Snowflake and BigQuery. Great Expectations or similar data quality tools are strongly preferred. The candidate should be comfortable mentoring junior data engineers and collaborating with BI stakeholders.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt ownership experience is implied by senior-level dbt listing\",\"Apache Airflow matches the orchestration requirement\",\"Snowflake and BigQuery are both present and match the warehouse stack\",\"Great Expectations directly satisfies the data quality tooling requirement\",\"Databricks adds additional data platform depth\",\"Senior seniority aligns with the mentoring and ownership expectations\",\"SQL and Python are the right analytical languages\"],\"gaps\":[\"No BI tooling such as Tableau or Looker visible for stakeholder collaboration\"],\"explanation\":\"The candidate aligns well on dbt, Airflow, and data quality tooling, but the absence of BI tool experience for stakeholder collaboration is a moderate gap for a role that explicitly involves presenting data findings to business stakeholders. The data engineering depth is strong but the analytics communication layer is unverified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"game_dev_gabriel\",\"seniority\":\"Mid\",\"roles\":[\"Game Developer\"],\"languages\":[\"C++\",\"C#\",\"Python\"],\"tech\":[\"Unity\",\"Unreal Engine\",\"Docker\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nA cloud infrastructure company is hiring a Mid-level Backend Engineer to build high-performance data processing services in C++. The role requires experience with distributed systems, REST API design, and PostgreSQL. CMake for build management and Docker for containerization are standard. The candidate should have production experience shipping C++ services in a cloud environment.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"C++ is the primary language and is present\",\"Docker is present and matches the containerization requirement\",\"GitHub Actions shows CI familiarity\",\"Mid-level seniority aligns with the role\"],\"gaps\":[\"Game development C++ experience may not transfer directly to distributed systems and cloud services\",\"No REST API or service design experience visible\",\"No PostgreSQL or database experience\",\"No CMake or build system experience beyond Unity and Unreal workflows\",\"No distributed systems or cloud service development signals\"],\"explanation\":\"While the candidate has C++ experience, the context is game engine development which is a meaningfully different domain from cloud-native distributed services. The absence of REST API, PostgreSQL, CMake, and distributed systems experience introduces significant uncertainty about the candidate's readiness for production cloud service development.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"flutter_dev_fatima\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"TypeScript\"],\"tech\":[\"Flutter\",\"Firebase\",\"Riverpod\",\"Docker\"],\"databases\":[\"Firestore\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"Flutter Test\",\"Mocktail\"]}\n\nJob Summary:\nA travel startup is hiring a Mid-level Mobile Engineer to build their cross-platform mobile app using Flutter and Dart. The team uses Riverpod for state management, Firebase and Firestore for backend services, and Fastlane for release automation. GitHub Actions handles CI. The candidate should be comfortable with Flutter testing and deploying to both the App Store and Google Play.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Flutter and Dart are the core mobile framework and language and both match\",\"Riverpod is the stated state management solution and is present\",\"Firebase and Firestore match the backend services requirement\",\"Fastlane covers the release automation requirement\",\"GitHub Actions satisfies the CI requirement\",\"Flutter Test and Mocktail demonstrate Flutter-native testing practice\",\"Mid-level seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"Every technical requirement in the job description is satisfied by this candidate's profile including framework, language, state management, backend services, CI, release tooling, and testing. This is an exact match with no gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"backend_billy_php\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"SQL\"],\"tech\":[\"Laravel\",\"MySQL\",\"Docker\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nA media company is hiring a Senior Backend Engineer to design and own their Python-based microservices platform on AWS. The role requires deep Python experience, familiarity with FastAPI or Django, Kubernetes for orchestration, and strong distributed systems knowledge. The candidate should be capable of mentoring junior engineers and driving architectural decisions",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Some backend web framework experience via Laravel\"],\"gaps\":[\"Junior seniority does not meet the Senior requirement\",\"No Python experience, which is the core language\",\"No FastAPI or Django experience\",\"No Kubernetes or container orchestration beyond Docker\",\"No AWS experience\",\"No distributed systems knowledge visible\",\"No mentoring or architectural leadership signals\",\"PHP and Laravel domain is orthogonal to the Python microservices stack\"],\"explanation\":\"The candidate is a junior PHP developer and lacks nearly every technical and experience requirement for this senior Python backend role. The seniority gap, language mismatch, and absence of cloud and orchestration tooling make this a very poor fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"staff_sre_samir\",\"seniority\":\"Staff\",\"roles\":[\"Site Reliability Engineer\",\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Prometheus\",\"Grafana\",\"Datadog\",\"AWS\",\"Helm\",\"Istio\",\"PagerDuty\"],\"architecture\":[\"Microservices\",\"Cloud-Native\",\"Service Mesh\"],\"databases\":[\"PostgreSQL\",\"Cassandra\"],\"ci_cd\":[\"Argo CD\",\"GitHub Actions\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nA global payments company is seeking a Staff SRE to lead reliability for a distributed platform processing millions of daily transactions. The role requires Kubernetes at scale, Prometheus and Grafana for observability, Datadog for APM, incident management with PagerDuty, and Istio service mesh experience. Terraform for IaC and Argo CD for GitOps are standard. Go or Python for automation is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Staff seniority matches the leadership expectation\",\"Kubernetes at scale experience is indicated by staff-level SRE background\",\"Prometheus and Grafana match the observability stack\",\"Datadog covers the APM requirement\",\"PagerDuty satisfies the incident management requirement\",\"Istio matches the service mesh requirement\",\"Terraform and Argo CD satisfy the IaC and GitOps requirements\",\"Go and Python cover the automation scripting languages\",\"k6 demonstrates performance and load testing discipline\"],\"gaps\":[],\"explanation\":\"This candidate meets every stated technical and leadership requirement for a Staff SRE at a payments company. The profile covers Kubernetes, observability, APM, incident management, service mesh, IaC, and automation languages comprehensively with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"aspnet_alex\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"C#\",\"TypeScript\",\"SQL\"],\"tech\":[\"ASP.NET\",\".NET Core\",\"React\",\"Docker\",\"Azure\",\"Entity Framework\"],\"architecture\":[\"Microservices\",\"Layered Architecture\"],\"databases\":[\"MS SQL Server\",\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"Azure DevOps\",\"GitHub Actions\"],\"testing\":[\"xUnit\",\"Mocha\"]}\n\nJob Summary:\nAn insurance enterprise is hiring a Senior Backend Engineer to maintain and extend their .NET Core and C# platform on Azure. The team uses Entity Framework for ORM, MS SQL Server as the primary database, Azure DevOps for CI/CD, and Docker for containerization. React is used for the admin portal. Senior experience with ASP.NET and Azure services is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"C# and ASP.NET and .NET Core all match the core language and framework requirements\",\"Azure is the stated cloud provider and is present\",\"Entity Framework satisfies the ORM requirement\",\"MS SQL Server is the stated primary database\",\"Azure DevOps matches the CI/CD requirement\",\"Docker is present\",\"React covers the admin portal frontend requirement\",\"Senior seniority fits the role level\"],\"gaps\":[\"No explicit Azure service-level experience such as Azure Service Bus or Azure Functions visible\"],\"explanation\":\"The candidate aligns with every core technical requirement for this .NET enterprise role including language, framework, ORM, database, cloud provider, and CI/CD. The only minor gap is the absence of deeper Azure-specific service experience beyond infrastructure, which may matter for integration work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nextjs_nakamura\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\",\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"Prisma\",\"tRPC\",\"Tailwind CSS\",\"Vercel\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nAn early-stage startup is hiring a Mid-level Full Stack Engineer to build their product from scratch using a modern TypeScript stack. The team uses Next.js, React, tRPC for type-safe APIs, Prisma as ORM, and PostgreSQL via Supabase. Vercel is used for deployment. Tailwind CSS for styling. GitHub Actions for CI. Testing with Vitest and Playwright is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and React match the core application framework\",\"tRPC satisfies the type-safe API requirement exactly\",\"Prisma matches the ORM requirement\",\"PostgreSQL and Supabase are both present and match the database layer\",\"Vercel is the stated deployment platform\",\"Tailwind CSS satisfies the styling requirement\",\"GitHub Actions matches the CI tooling\",\"Vitest and Playwright cover the testing requirements\",\"TypeScript is present throughout\",\"Mid-level seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"The candidate's stack is a precise match for this modern TypeScript startup role across every stated technical dimension. There are no gaps in framework, ORM, API layer, database, deployment, styling, CI, or testing.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"junior_react_jasmine\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Vite\",\"Zustand\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\"]}\n\nJob Summary:\nA productivity tool company is hiring a Junior Frontend Engineer to build features in their React and TypeScript application. The team uses Zustand for state management, Tailwind CSS for styling, and Vite for builds. GitHub Actions handles CI. Vitest is used for unit testing. The candidate does not need prior professional experience but should have a portfolio of shipped React work.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React is the core framework and matches\",\"TypeScript is present\",\"Zustand matches the state management tool exactly\",\"Tailwind CSS satisfies the styling requirement\",\"Vite matches the build tool\",\"GitHub Actions aligns with the CI requirement\",\"Vitest satisfies the unit testing requirement\",\"Junior seniority aligns with the role level\"],\"gaps\":[\"No explicit evidence of shipped portfolio work visible in profile metadata\"],\"explanation\":\"The candidate's technical stack is a complete match for this junior React role with alignment on every stated tool and framework. The only uncertainty is whether the profile reflects shipped portfolio work, which is the employer's primary evaluation criterion beyond technical fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"haskell_herbert\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Software Architect\"],\"languages\":[\"Haskell\",\"Scala\",\"Python\"],\"tech\":[\"Docker\",\"AWS\",\"Apache Kafka\"],\"architecture\":[\"Functional Programming\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Cassandra\"]}\n\nJob Summary:\nA fintech company is hiring a Senior Backend Engineer to build high-reliability APIs in Go. The team uses gRPC, Kubernetes, and PostgreSQL. Event-driven architecture with Kafka is core to the platform. The candidate should be comfortable with strongly-typed language paradigms and distributed system design. Familiarity with functional programming principles is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kafka covers the event-driven architecture requirement directly\",\"PostgreSQL is present and matches the database requirement\",\"Haskell and Scala background gives strong functional programming credentials, which is listed as a bonus\",\"Senior seniority fits the role level\",\"AWS and Docker show some infrastructure familiarity\",\"Event-Driven architecture experience is relevant\"],\"gaps\":[\"No Go experience visible, which is the primary language\",\"No Kubernetes experience\",\"No gRPC or inter-service API experience\",\"The language pivot from Haskell and Scala to Go is non-trivial\"],\"explanation\":\"The candidate has relevant architectural and domain experience including Kafka and PostgreSQL, and brings valuable functional programming depth that the employer values. However, the absence of Go, gRPC, and Kubernetes means a meaningful technical ramp-up would be required before full productivity.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devrel_dev_diana\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\",\"Backend Engineer\"],\"languages\":[\"Python\",\"TypeScript\",\"JavaScript\"],\"tech\":[\"FastAPI\",\"Next.js\",\"React\",\"Docker\",\"AWS\",\"OpenAI API\",\"LangChain\"],\"databases\":[\"PostgreSQL\",\"Pinecone\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Jest\"]}\n\nJob Summary:\nAn AI productivity company is hiring a Senior Full Stack Engineer to build LLM-powered workflow automation tools. The backend is FastAPI in Python, the frontend is Next.js and React in TypeScript, and the AI layer uses OpenAI API and LangChain for orchestration. Pinecone is used for vector search. AWS and Docker are the deployment environment. Strong testing discipline with pytest and Jest is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"FastAPI matches the backend framework exactly\",\"Next.js and React cover the frontend stack\",\"Python and TypeScript are both present as required\",\"OpenAI API satisfies the LLM provider requirement\",\"LangChain matches the AI orchestration requirement\",\"Pinecone satisfies the vector search requirement\",\"AWS and Docker match the deployment environment\",\"pytest and Jest satisfy the testing requirements\",\"Senior seniority aligns with the role level\"],\"gaps\":[],\"explanation\":\"The candidate is a comprehensive match for this full-stack AI engineering role with precise alignment across backend, frontend, AI orchestration, vector search, infrastructure, and testing. There are no meaningful gaps relative to the stated requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lead_frontend_lucas\",\"seniority\":\"Lead\",\"roles\":[\"Frontend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Storybook\",\"Tailwind CSS\",\"shadcn/ui\",\"Radix UI\",\"Framer Motion\",\"Webpack\",\"Turborepo\"],\"architecture\":[\"Monorepo\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"React Testing Library\",\"Playwright\"]}\n\nJob Summary:\nA B2C consumer app company is seeking a Lead Frontend Engineer to own their design system, drive component library development using React and Radix UI, and lead a team of four frontend engineers. Experience with Storybook for documentation, Turborepo for monorepo management, and Tailwind CSS is required. The candidate must be able to balance hands-on coding with engineering leadership and cross-functional collaboration.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Lead seniority matches the team leadership requirement\",\"React and Next.js cover the core application framework\",\"Radix UI directly matches the component library requirement\",\"Storybook satisfies the documentation requirement\",\"Turborepo and Monorepo experience address the monorepo management requirement\",\"Tailwind CSS and shadcn/ui demonstrate design system familiarity\",\"Vitest, React Testing Library, and Playwright show comprehensive testing discipline\",\"Framer Motion shows animation and interaction design capability\"],\"gaps\":[\"No backend experience, though the role appears primarily frontend-focused\"],\"explanation\":\"This candidate is an excellent fit for the Lead Frontend role with direct alignment on design system tooling, component libraries, monorepo management, testing, and the leadership level required. The profile reflects exactly the kind of hands-on technical leader this role needs.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pyspark_pradeep\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"PySpark\",\"Apache Airflow\",\"dbt\",\"Databricks\",\"Docker\"],\"databases\":[\"BigQuery\",\"Snowflake\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nA media company is seeking a Mid-level Data Engineer to build and maintain real-time streaming pipelines using Flink and Kafka. The role requires hands-on Flink or Spark Streaming experience, Python and SQL fluency, and familiarity with GCP and BigQuery. Airflow for batch orchestration is used alongside the streaming layer. Strong data modeling skills are expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PySpark shows familiarity with distributed data processing paradigms\",\"Apache Airflow matches the batch orchestration requirement\",\"BigQuery is present and aligns with the GCP data stack\",\"Python and SQL are both present\",\"dbt and Databricks show data platform depth\",\"Mid-level seniority aligns with the role\"],\"gaps\":[\"No Apache Flink experience, which is the primary streaming engine\",\"No Kafka experience for real-time ingestion\",\"No GCP experience beyond BigQuery, and no broader GCP platform familiarity\",\"Batch-focused profile may lack real-time streaming engineering depth\"],\"explanation\":\"The candidate has a solid batch data engineering foundation and BigQuery experience, but the role centers on real-time streaming with Flink and Kafka, which are absent from the profile. The gap between batch Spark and streaming Flink engineering represents a meaningful capability difference that would require deliberate upskilling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"intern_ios_ivan\",\"seniority\":\"Intern\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"Xcode\",\"Firebase\"]}\n\nJob Summary:\nAn edtech startup is hiring a Junior iOS Engineer to build learner-facing features in SwiftUI. The team is small and values engineers who can own small features independently. Firebase is used for authentication and data. Candidates should have shipped at least one App Store app. Swift and SwiftUI knowledge is required and the rest can be learned on the job.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Swift and SwiftUI match the stated language and framework requirements\",\"Firebase aligns with the authentication and data layer\",\"Xcode experience is fundamental to iOS development\"],\"gaps\":[\"Intern seniority is below the Junior level required\",\"No evidence of independently shipped App Store app, which is explicitly required\",\"No testing signals or CI/CD experience visible\"],\"explanation\":\"The candidate has the right foundational tools in Swift, SwiftUI, and Firebase, and the employer has signaled openness to learning on the job. The key uncertainty is whether the candidate has shipped an App Store app, which is explicitly required, and the intern-to-junior seniority gap may affect readiness for independent feature ownership.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"neo4j_nikolai\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Data Engineer\"],\"languages\":[\"Python\",\"Java\",\"SQL\"],\"tech\":[\"FastAPI\",\"Spring Boot\",\"Docker\",\"AWS\",\"Apache Kafka\"],\"databases\":[\"Neo4j\",\"PostgreSQL\",\"MongoDB\",\"Elasticsearch\"]}\n\nJob Summary:\nA fraud detection company is hiring a Senior Backend Engineer to build graph-based analytics pipelines. The team uses Neo4j extensively for relationship modeling, FastAPI for API services, Kafka for event ingestion, and AWS for infrastructure. Experience with graph query languages like Cypher is required. The candidate should have a strong understanding of graph data modeling.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Neo4j is the primary database and matches the core graph analytics requirement\",\"FastAPI is the stated API framework and is present\",\"Kafka covers the event ingestion requirement\",\"AWS matches the infrastructure requirement\",\"Python and Java provide backend service flexibility\",\"Elasticsearch adds full-text search capability as a bonus\",\"Senior seniority aligns with the role level\",\"Graph database experience is specialized and rare\"],\"gaps\":[\"No explicit Cypher query language experience signaled beyond Neo4j usage\"],\"explanation\":\"The candidate's Neo4j experience is a rare and direct match for this graph-analytics-focused role. Combined with FastAPI, Kafka, and AWS alignment, the technical overlap is strong. The only minor uncertainty is whether the candidate has production Cypher proficiency, which would typically accompany senior-level Neo4j use.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"python_data_patricia\",\"seniority\":\"Mid\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"scikit-learn\",\"PyTorch\",\"Pandas\",\"NumPy\",\"Weights & Biases\",\"Jupyter\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nAn online marketplace is hiring a Mid-level Data Scientist to build recommendation and pricing models. The role requires Python and scikit-learn or PyTorch for model development, SQL for feature extraction, and experience tracking experiments. The candidate should be comfortable working with data warehouses and presenting findings to business stakeholders. No MLOps or infrastructure experience required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Python is the primary language and matches\",\"scikit-learn and PyTorch both cover the model development requirement\",\"SQL satisfies the feature extraction requirement\",\"Weights and Biases covers the experiment tracking requirement\",\"Snowflake and PostgreSQL match the data warehouse and database requirements\",\"Pandas and NumPy demonstrate data manipulation competency\",\"Mid-level seniority aligns with the role\"],\"gaps\":[\"No explicit experience presenting to business stakeholders visible in profile\"],\"explanation\":\"The candidate's Python, scikit-learn, PyTorch, SQL, and experiment tracking background directly maps to the technical requirements of this data science role. The only soft gap is the absence of stakeholder communication signals, which is not a technical requirement but is mentioned in the posting.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"javi_codes\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"Node.js\",\"Tailwind CSS\",\"Prisma\"],\"architecture\":[\"Monolith\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nWe are a Series B fintech startup looking for a Senior Full Stack Engineer to own our customer-facing web platform. You will build and maintain Next.js frontends, design PostgreSQL schemas, and contribute to serverless backend functions deployed on Vercel. We value TypeScript-first development and expect strong testing discipline. Experience with Redis caching and CI/CD automation is a plus. Our stack is intentionally lean and modern.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and React directly match the customer-facing frontend requirement\",\"PostgreSQL and Redis experience aligns with the database and caching needs\",\"TypeScript-first profile matches the company's development philosophy\",\"Playwright and Jest demonstrate strong testing discipline\",\"Serverless architecture experience is directly relevant to Vercel deployment model\"],\"gaps\":[\"No explicit Vercel deployment experience listed, though serverless architecture knowledge partially covers this\"],\"explanation\":\"This candidate's stack is nearly a perfect match for the role, covering the frontend, backend, database, caching, and testing requirements explicitly. The only minor gap is no direct Vercel experience, but their serverless architecture background makes this a trivial ramp. They are a strong hire.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_pratyush\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"NumPy\",\"Hugging Face Transformers\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nA FAANG-adjacent AI lab is hiring a Machine Learning Engineer to fine-tune and evaluate large language models. The role requires hands-on experience with PyTorch, familiarity with Hugging Face ecosystems, and comfort working with distributed GPU training using CUDA. Candidates should have experience with experiment tracking tools like MLflow or Weights and Biases. Strong Python fundamentals are required. A background in NLP and transformer architectures is strongly preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch is the primary training framework used by the team\",\"Hugging Face Transformers experience is directly relevant to the LLM fine-tuning work\",\"Strong Python and data science foundation with Pandas and NumPy\",\"NLP background implied by Transformers usage\"],\"gaps\":[\"No CUDA or distributed GPU training experience listed, which is critical for the role\",\"No experiment tracking tools such as MLflow or Weights and Biases in the profile\",\"Mid-level seniority may be a concern for a research-heavy AI lab environment\"],\"explanation\":\"The candidate has solid ML foundations and relevant LLM tooling experience, but is missing two explicitly required signals: distributed GPU training with CUDA and experiment tracking. These are not minor gaps for a lab focused on LLM fine-tuning at scale. Conditional fit pending assessment of CUDA familiarity.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devops_daria\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\",\"Site Reliability Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Docker\",\"Prometheus\",\"Grafana\",\"Ansible\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitLab CI\",\"Argo CD\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nEnterprise SaaS company seeks a Senior SRE to manage a large-scale Kubernetes infrastructure on AWS. You will own observability pipelines using Prometheus and Grafana, automate infrastructure with Terraform and Ansible, and maintain GitOps workflows. Experience with Argo CD and Helm is required. We expect comfort with incident response, load testing, and cloud-native design patterns. Python or Go scripting skills are essential for automation tasks.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes expertise is central to the role and prominently listed\",\"Terraform and Ansible match the infrastructure automation requirements exactly\",\"Prometheus and Grafana cover the observability pipeline ownership requirement\",\"Argo CD and Helm are listed as required and both present in the profile\",\"Python and Go scripting for automation are both present\"],\"gaps\":[\"No explicit AWS-specific experience listed despite the role running on AWS; cloud-native background only partially covers provider-specific services\"],\"explanation\":\"This candidate satisfies nearly every stated technical requirement including Kubernetes, Terraform, Ansible, Prometheus, Argo CD, Helm, Python, and Go. The one open question is AWS-specific service familiarity, as the role is AWS-hosted and provider-specific knowledge often matters at enterprise scale. A high-confidence moderate with likely fast onboarding.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rookie_raymond\",\"seniority\":\"Intern\",\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"React\",\"Flask\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nGrowth-stage startup is hiring a Mid-level Backend Engineer to design and scale REST APIs handling millions of daily requests. The role requires deep experience with distributed systems, message queues such as Kafka or RabbitMQ, and cloud infrastructure on AWS. Candidates must have production experience with PostgreSQL at scale and familiarity with containerized deployments using Docker and Kubernetes. A minimum of three years of professional backend engineering experience is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is a relevant language for backend development\"],\"gaps\":[\"Intern seniority is far below the mid-level minimum requirement\",\"No distributed systems or message queue experience such as Kafka or RabbitMQ\",\"No AWS or cloud infrastructure experience listed\",\"PostgreSQL at scale is not present; only SQLite is listed\",\"No Docker or Kubernetes experience\",\"Flask is a lightweight framework not indicative of production API scale experience\"],\"explanation\":\"This candidate is at the very beginning of their career and lacks virtually every technical and experiential requirement for this role. The gap between an intern profile with SQLite and Flask and a mid-level distributed systems role handling millions of requests daily is substantial. Not a fit at this time.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ios_nadia\",\"seniority\":\"Senior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Xcode\"],\"architecture\":[\"Client-Server\",\"Modular Architecture\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nConsumer app company with 10M users is looking for a Senior iOS Engineer to lead feature development on their Swift-based mobile app. You will work primarily in SwiftUI with some legacy UIKit maintenance. Experience with Fastlane for automated app delivery and a modular architecture approach is expected. Firebase integration knowledge is a plus. We ship fast and require strong testing culture.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SwiftUI is the primary framework and is listed prominently in the profile\",\"UIKit experience ensures the candidate can handle legacy code maintenance\",\"Fastlane for automated app delivery is an exact requirement match\",\"Modular architecture directly aligns with the stated architectural expectation\",\"Firebase experience satisfies the listed plus requirement\",\"XCTest demonstrates testing culture alignment\"],\"gaps\":[\"No Kotlin Multiplatform or cross-platform signals, but these were not requirements\"],\"explanation\":\"The candidate's profile directly satisfies all stated requirements for this iOS role: SwiftUI, UIKit, Fastlane, modular architecture, and Firebase. Senior seniority is appropriate for a feature leadership role. This is a high-confidence match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"data_eng_felix\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Spark\",\"dbt\",\"Apache Airflow\",\"Pandas\"],\"databases\":[\"Snowflake\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nE-commerce enterprise is hiring a Data Engineer to build and maintain scalable ELT pipelines. The role centers on dbt for transformation logic, Airflow for orchestration, and Snowflake as the primary warehouse. Python is the scripting language of choice. Experience with data quality frameworks like Great Expectations is a strong plus. Candidates should be comfortable owning pipelines end to end in a cloud-native data stack.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt is explicitly required and is a primary tool in the candidate's profile\",\"Apache Airflow for orchestration is an exact match\",\"Snowflake as primary warehouse is directly present\",\"Python and SQL cover the scripting and query requirements\",\"Apache Spark adds bonus depth beyond what the role requires\"],\"gaps\":[\"No Great Expectations listed, which is flagged as a strong plus by the employer\"],\"explanation\":\"This candidate matches all core requirements of the role with explicit, relevant tools. The only gap is the absence of Great Expectations for data quality, which is a plus rather than a hard requirement. They are a strong and well-rounded fit for this data engineering position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"blockchain_oren\",\"seniority\":\"Mid\",\"roles\":[\"Blockchain Engineer\",\"Smart Contract Developer\"],\"languages\":[\"Solidity\",\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Ethers.js\",\"Hardhat\"],\"architecture\":[\"Distributed System\"],\"testing\":[\"Mocha\",\"Chai\"]}\n\nJob Summary:\nDeFi startup is hiring a Backend Engineer to build high-throughput REST APIs in Go. The stack includes PostgreSQL, Redis, and Kubernetes on GCP. Candidates must have strong experience in Go microservices and distributed systems. Knowledge of financial systems and low-latency architecture is required. No smart contract development is involved in this role.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Distributed systems architecture familiarity is marginally relevant\"],\"gaps\":[\"No Go or backend microservices experience listed\",\"No PostgreSQL, Redis, or Kubernetes experience\",\"No GCP or cloud infrastructure background\",\"Profile is centered on Solidity and Web3 tooling which are explicitly not part of this role\",\"REST API development at scale is not evidenced in the profile\"],\"explanation\":\"This candidate's experience is almost entirely in blockchain and smart contract development, which the job description explicitly excludes. The role requires Go, Kubernetes, and PostgreSQL at scale, none of which appear in the profile. This is a fundamental domain mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"k8s_kim\",\"seniority\":\"Lead\",\"roles\":[\"Platform Engineer\",\"DevOps Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Docker\",\"Terraform\",\"Helm\",\"Istio\",\"Vault\"],\"architecture\":[\"Cloud-Native\",\"Microservices\",\"Service Mesh\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\",\"Tekton\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nLarge enterprise is building out a Platform Engineering team and needs a Lead to design internal developer platforms on Kubernetes. The role involves service mesh implementation with Istio, secrets management with HashiCorp Vault, GitOps with Argo CD, and infrastructure as code with Terraform. Go is used for internal tooling. The team is cloud-native and operates at significant scale.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Lead seniority matches the leadership expectation of the role\",\"Kubernetes is the core platform and is a primary skill\",\"Istio for service mesh is explicitly required and present\",\"HashiCorp Vault for secrets management is an exact match\",\"Argo CD for GitOps is directly listed\",\"Terraform for infrastructure as code is present\"],\"gaps\":[\"Go is listed but the internal tooling depth for building custom Kubernetes controllers or operators is not evidenced in the profile\",\"No explicit indication of scale benchmarks or very large cluster management experience\"],\"explanation\":\"This candidate satisfies the major technical requirements: Kubernetes, Istio, Vault, Argo CD, and Terraform. Minor uncertainty around Go tooling depth for internal platform development and large-cluster operations experience at the scale implied by the enterprise context keeps this at Moderate rather than Strong. Still a very strong candidate.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"data_viz_amara\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"Python\",\"SQL\",\"R\"],\"tech\":[\"Pandas\",\"Tableau\",\"Metabase\"],\"databases\":[\"PostgreSQL\",\"MySQL\"]}\n\nJob Summary:\nMedia company is seeking a Data Analyst to produce dashboards and ad-hoc reports for the marketing and growth teams. Proficiency in SQL and at least one BI tool such as Tableau, Looker, or Metabase is required. Python for data manipulation is a plus. The role is individual contributor and does not require engineering or infrastructure skills. Familiarity with marketing metrics is helpful.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SQL proficiency is a core requirement and is present\",\"Tableau and Metabase both satisfy the BI tool requirement\",\"Python with Pandas satisfies the data manipulation plus requirement\",\"Junior seniority is appropriate for an individual contributor analyst role\"],\"gaps\":[\"No explicit marketing metrics or growth analytics experience evidenced\",\"R is listed but not relevant to this role's stack\",\"No Looker experience, though Tableau and Metabase are present alternatives\"],\"explanation\":\"The candidate meets the core technical requirements of the role with SQL, Tableau, and Python experience. The main uncertainty is around domain familiarity with marketing and growth metrics, which is not evidenced in the profile. A solid technical fit with an open question on domain context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"embedded_eric\",\"seniority\":\"Senior\",\"roles\":[\"Embedded Engineer\",\"Firmware Engineer\"],\"languages\":[\"C\",\"C++\",\"Python\"],\"tech\":[\"CMake\"],\"architecture\":[\"Client-Server\"]}\n\nJob Summary:\nHealthcare IoT company needs a Senior Full Stack Engineer to build React frontends and Node.js microservices with PostgreSQL. The team uses TypeScript exclusively. AWS deployment experience is required. CI/CD with GitHub Actions is expected. The role requires strong web development skills and comfort with modern JavaScript ecosystems.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is listed but is not relevant to this JavaScript-focused web role\"],\"gaps\":[\"No JavaScript or TypeScript experience listed despite it being the exclusive language requirement\",\"No React or any frontend framework experience\",\"No Node.js or web backend experience\",\"No AWS or cloud deployment background\",\"No PostgreSQL in the profile\",\"Profile is entirely embedded and firmware focused, which is a different engineering discipline\"],\"explanation\":\"This candidate specializes in embedded and firmware engineering, which is an entirely different domain from the full stack web role. There is no overlap in languages, frameworks, or deployment environments. This is a complete domain mismatch and not a viable fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sara_flutter\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"TypeScript\"],\"tech\":[\"Flutter\",\"Firebase\",\"React Native\"],\"databases\":[\"Firestore\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"Flutter test\"]}\n\nJob Summary:\nConsumer startup is hiring a Mid-level Mobile Engineer to build their cross-platform app in Flutter. The candidate should have production experience with Flutter and Dart, Firebase integration for auth and real-time data, and Fastlane for automated releases. Firestore as the primary database is expected. The team ships on both iOS and Android from a single codebase.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Flutter is the primary framework and is the candidate's most prominent skill\",\"Dart is Flutter's required language and is present\",\"Firebase and Firestore match the auth and real-time data requirements exactly\",\"Fastlane for automated releases is explicitly required and listed\",\"Cross-platform mobile experience is evidenced by both Flutter and React Native\"],\"gaps\":[\"No explicit state management solution listed such as Riverpod or BLoC, which cross-platform Flutter apps of this scale typically rely on\",\"Mid seniority may limit ability to own complex architecture decisions independently\"],\"explanation\":\"This candidate aligns well with the core Flutter, Dart, Firebase, and Fastlane requirements. The absence of a visible state management pattern in the profile is a mild concern for a consumer app with 10M users where architectural consistency matters. A solid fit pending confirmation of state management approach.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"backend_boris\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Python\"],\"tech\":[\"Spring Boot\",\"Apache Kafka\",\"Docker\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"Redis\"],\"ci_cd\":[\"Jenkins\",\"GitLab CI\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nFinancial services firm is hiring a Senior Backend Engineer for a Java-based microservices platform processing high-volume transactions. Spring Boot is the primary framework. The team relies heavily on Kafka for event streaming, PostgreSQL and Redis for data storage, and Docker for containerization. Strong testing culture with JUnit is expected. GitLab CI is used for pipelines. Experience with event-driven architecture is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Spring Boot is the primary framework and is the candidate's main tech\",\"Apache Kafka for event streaming is an exact requirement match\",\"PostgreSQL and Redis cover the dual storage requirement\",\"Docker for containerization is present\",\"JUnit and Mockito demonstrate the required testing culture\",\"GitLab CI matches the pipeline tooling\",\"Event-driven and microservices architecture experience are explicitly listed\"],\"gaps\":[\"Jenkins is listed in addition to GitLab CI which is not a gap but signals broader exposure\"],\"explanation\":\"This candidate is a near-perfect match for the role, checking every stated technical and architectural requirement. Java, Spring Boot, Kafka, PostgreSQL, Redis, Docker, JUnit, and GitLab CI are all present. Their event-driven microservices background is exactly what the financial services platform requires.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"php_legacy_lou\",\"seniority\":\"Mid\",\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"Laravel\",\"Vue.js\",\"Bootstrap\"],\"databases\":[\"MySQL\"],\"ci_cd\":[\"GitLab CI\"]}\n\nJob Summary:\nSaaS startup is building a new product from scratch in TypeScript using React, Next.js, and a GraphQL API backed by PostgreSQL. The team is serverless-first on AWS. Candidates should be comfortable with modern JavaScript ecosystems, Tailwind CSS, and containerized development. Prior experience with REST is acceptable but GraphQL is preferred. Strong TypeScript skills are required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"JavaScript experience provides some foundation for TypeScript transition\",\"Vue.js experience shows frontend SPA familiarity\"],\"gaps\":[\"No TypeScript experience despite it being a hard requirement\",\"No React or Next.js; candidate works in Vue.js which requires a framework shift\",\"No GraphQL experience\",\"No PostgreSQL; candidate uses MySQL\",\"No AWS or serverless experience\",\"No Tailwind CSS; uses Bootstrap instead\",\"PHP and Laravel are not relevant to this TypeScript-first stack\"],\"explanation\":\"This candidate's experience is rooted in a PHP and MySQL stack with Vue.js, which diverges significantly from the TypeScript, React, Next.js, GraphQL, and AWS-first requirements. The overlap is limited to general web development concepts. The gap in required technologies is too wide for a startup needing immediate productivity.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_ops_mia\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"Data Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"MLflow\",\"Apache Airflow\",\"Docker\",\"Ray\"],\"architecture\":[\"Microservices\",\"Cloud-Native\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"]}\n\nJob Summary:\nAI infrastructure company is hiring a Senior MLOps Engineer to build and maintain model training and serving pipelines. The role requires MLflow for experiment tracking, Ray for distributed training, Docker for containerization, and Airflow for orchestration. Python is the primary language. Experience with cloud-native and microservices patterns is a plus. PostgreSQL for metadata storage is used.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Apache Spark and PySpark are the core processing requirement and are both present\",\"Apache Kafka for real-time ingestion is an exact match\",\"Databricks is the stated platform and is in the profile\",\"SQL and Python are both present\",\"Airflow for orchestration satisfies the plus requirement\"],\"gaps\":[\"No explicit experience with petabyte-scale Spark tuning or cluster optimization evidenced\",\"Scala is listed as a secondary option but may not be preferred over Python for this team's workloads\"],\"explanation\":\"This candidate has a well-aligned data engineering stack covering Spark, Kafka, Databricks, Airflow, Python, and SQL. The main open question is depth of experience at petabyte-scale operations, which is a critical differentiator for a streaming media company at this data volume. A strong technical fit with scale-depth to be assessed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"junior_web_jess\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"Firebase\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAgency is looking for a Junior Frontend Engineer to build marketing and landing pages in React with Tailwind CSS. TypeScript proficiency is expected. The role involves working closely with designers to implement pixel-perfect UIs. Experience with Vite or similar build tools is helpful. Firebase or any BaaS experience is a plus. No backend work is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React is the primary framework and is present in the profile\",\"Tailwind CSS is an exact requirement match\",\"TypeScript proficiency is evidenced\",\"Vite satisfies the build tool plus requirement\",\"Firebase satisfies the BaaS plus requirement\",\"Junior seniority matches the role level\"],\"gaps\":[],\"explanation\":\"This candidate is a direct fit for the junior frontend role. Every stated requirement including React, Tailwind CSS, and TypeScript is present, and both listed plus factors, Vite and Firebase, are also covered. No gaps exist for this scope of work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"security_sven\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Docker\",\"Kubernetes\",\"Vault\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"]}\n\nJob Summary:\nFintech company is hiring an AppSec Engineer to integrate security into CI/CD pipelines, conduct threat modeling, and manage secrets with HashiCorp Vault. Experience with SAST and DAST tooling is required. Kubernetes and container security knowledge is expected. Python or Go scripting is required for automation. Familiarity with OWASP top 10 is a baseline expectation.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"HashiCorp Vault for secrets management is an exact requirement match\",\"Kubernetes and container security experience is present\",\"Python and Go scripting for automation are both covered\",\"CI/CD integration experience is evidenced by GitHub Actions and GitLab CI\"],\"gaps\":[\"No explicit SAST or DAST tooling listed in the profile\",\"No direct AppSec or threat modeling experience evidenced\",\"OWASP familiarity cannot be confirmed from GitHub-visible signals alone\"],\"explanation\":\"This candidate has solid infrastructure security foundations, particularly around Vault and container security, which are meaningful overlaps. However, the absence of any SAST, DAST, or threat modeling signals is a notable gap for an AppSec-focused role. They may be a strong infrastructure security engineer transitioning into AppSec.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"react_native_riya\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React Native\",\"Expo\",\"Redux\",\"React Query\"],\"databases\":[\"Firebase\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"Jest\",\"Detox\"]}\n\nJob Summary:\nHealthcare startup is looking for a Mid-level Mobile Engineer to build a React Native app with end-to-end testing via Detox. TypeScript is required. The team uses Expo for managed builds and Fastlane for deployment automation. State management with Redux is expected. Firebase is used for push notifications and analytics. A strong testing culture is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"MLflow for experiment tracking is explicitly required and present\",\"Ray for distributed training is an exact requirement match\",\"Apache Airflow for orchestration is directly listed\",\"Docker for containerization is present\",\"PyTorch confirms hands-on ML model experience\"],\"gaps\":[\"No explicit GPU cluster management or CUDA-level optimization experience listed, which AI infrastructure companies often expect at senior level\",\"No model serving framework listed such as Triton or TorchServe beyond Docker-based containerization\"],\"explanation\":\"This candidate covers the core MLOps tooling requirements well: MLflow, Ray, Airflow, and Docker. The gaps around GPU-level optimization and dedicated model serving infrastructure are worth exploring for an AI infrastructure company where those capabilities are often differentiating. A solid candidate with specific depth to assess.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"spark_seo\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"PySpark\",\"Apache Kafka\",\"dbt\",\"Apache Airflow\"],\"databases\":[\"Databricks\",\"Snowflake\",\"Cassandra\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nStreaming media company is hiring a Data Engineer to design real-time and batch pipelines at petabyte scale. The role requires Apache Spark or PySpark, Kafka for real-time ingestion, and Databricks as the processing platform. SQL and Python are essential. Experience with Airflow for orchestration and Scala as an alternative to Python is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Apache Spark and PySpark are the core processing requirement and are both present\",\"Apache Kafka for real-time ingestion is an exact match\",\"Databricks is the stated platform and is in the profile\",\"SQL and Python are both present\",\"Airflow for orchestration satisfies the plus requirement\",\"Scala satisfies the secondary language plus requirement\",\"Petabyte-scale experience is implied by the combination of Spark, Kafka, and Databricks\"],\"gaps\":[],\"explanation\":\"This candidate has a comprehensive, directly aligned data engineering stack that covers every core requirement and both stated plus factors. Their Spark, Kafka, and Databricks combination is precisely what the streaming media platform requires at scale.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"grad_student_gabe\",\"seniority\":\"Intern\",\"languages\":[\"Python\",\"R\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"NumPy\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nLarge bank is hiring a Senior Data Scientist to lead a team of analysts and data scientists, design ML models for credit risk, and deploy models to production using MLflow and cloud infrastructure on Azure. The role requires 5 or more years of experience, expertise in Python, strong knowledge of financial risk modeling, and experience with production ML deployment. Leadership and stakeholder communication are required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python with PyTorch and scikit-learn shows relevant ML foundations\"],\"gaps\":[\"Intern seniority is far below the senior level requirement with 5 or more years expected\",\"No MLflow or production ML deployment experience\",\"No Azure or cloud infrastructure background\",\"No leadership or team management experience evidenced\",\"No financial domain or credit risk modeling background\",\"No stakeholder communication context available from profile\"],\"explanation\":\"This candidate is an intern with a strong academic ML foundation but lacks every professional, leadership, and production deployment requirement the role demands. The seniority gap alone is disqualifying, and the absence of production tooling and domain experience compounds the mismatch significantly.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"go_greta\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Gin\",\"Docker\",\"gRPC\"],\"architecture\":[\"Microservices\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"CockroachDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Go testing\"]}\n\nJob Summary:\nInfrastructure startup is hiring a Senior Go Engineer to build distributed backend services using gRPC, PostgreSQL, and Redis. Docker is used for local development. Microservices architecture is the team's design pattern. CockroachDB experience is a notable plus. Strong testing culture and GitHub Actions for CI are expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React Native is the primary mobile framework and is the candidate's main skill\",\"Expo for managed builds is an exact requirement match\",\"Detox for end-to-end testing is explicitly required and present\",\"TypeScript is evidenced\",\"Redux for state management is directly listed\"],\"gaps\":[\"No explicit HIPAA compliance or healthcare data handling experience evidenced, which may be relevant given the healthcare startup context\",\"No custom native module development experience indicated, which healthcare apps often require for device integrations\"],\"explanation\":\"This candidate matches the core technical requirements: React Native, Expo, Detox, TypeScript, Redux, Fastlane, and Firebase. For a healthcare startup, the absence of healthcare-specific regulatory or device integration experience is worth assessing. A technically strong candidate with domain-fit to confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ruby_rodrigo\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"Ruby\",\"JavaScript\"],\"tech\":[\"Ruby on Rails\",\"React\",\"Sidekiq\",\"Bootstrap\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"CircleCI\"],\"testing\":[\"RSpec\",\"Jest\"]}\n\nJob Summary:\nSaaS company running a mature Rails monolith is hiring a Mid-level Full Stack Engineer. The role involves adding features to the Rails backend, maintaining the React frontend, and working with PostgreSQL and Redis. Background job processing with Sidekiq is part of the daily work. CircleCI is the CI tool. RSpec and Jest are used for testing.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Spring Boot is the primary framework and is the candidate's main tech\",\"Apache Kafka for event streaming is an exact requirement match\",\"PostgreSQL and Redis cover the dual storage requirement\",\"Docker for containerization is present\",\"JUnit and Mockito demonstrate the required testing culture\"],\"gaps\":[\"No explicit financial domain experience evidenced, which is often important in high-volume transaction processing contexts\",\"MongoDB is listed alongside PostgreSQL which may indicate schema flexibility use cases not aligned with strict financial data requirements\"],\"explanation\":\"This candidate covers the technical stack well: Spring Boot, Kafka, PostgreSQL, Redis, Docker, JUnit, and Mockito. For a financial services firm processing high-volume transactions, the absence of domain experience and the presence of MongoDB as a secondary database (less common in strict financial environments) are mild signals to explore in assessment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_newbie_nina\",\"seniority\":\"Junior\",\"languages\":[\"Python\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nAI product company is hiring a Mid-level LLM Engineer to build RAG pipelines, fine-tune transformer models using Hugging Face, and integrate LangChain into production applications. Experience with vector databases such as Pinecone or ChromaDB is required. Python is the primary language. Cloud deployment on AWS is expected. A minimum of 2 years working with LLMs or NLP systems is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is the required language and is present\",\"scikit-learn and Pandas show basic ML familiarity\"],\"gaps\":[\"No Hugging Face Transformers or LLM fine-tuning experience\",\"No LangChain or RAG pipeline experience\",\"No vector database experience such as Pinecone or ChromaDB\",\"No AWS or cloud deployment background\",\"Junior seniority is below the mid-level with 2 or more years LLM experience requirement\",\"No NLP or language model work evidenced in the profile\"],\"explanation\":\"This junior candidate has basic Python ML skills but lacks the LLM-specific tooling and experience the role requires. The gap between scikit-learn fundamentals and production RAG pipeline engineering with Hugging Face, LangChain, and vector databases is substantial. Not a fit at this stage of their career.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"frontend_faisal\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Zustand\",\"Tailwind CSS\",\"React Query\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"React Testing Library\"]}\n\nJob Summary:\nB2B SaaS company is hiring a Mid-level Frontend Engineer to build dashboard UIs in React and Next.js. TypeScript is required. Tailwind CSS is the styling system. State management is handled with Zustand. Data fetching uses React Query. The team values test coverage and uses React Testing Library and Jest. GitHub Actions is the CI pipeline.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Ruby on Rails is the primary backend framework and is the candidate's main skill\",\"React covers the frontend requirement\",\"PostgreSQL and Redis are both present\",\"Sidekiq for background job processing is an exact match\",\"CircleCI is the CI tool and is listed\"],\"gaps\":[\"RSpec is listed but Jest is not visible in the profile, introducing a minor uncertainty for the frontend testing coverage\",\"No explicit experience with large-scale Rails monolith performance optimization, which mature Rails apps often require\"],\"explanation\":\"This candidate has strong Rails monolith experience with the right supporting tools. The primary uncertainty is around Jest coverage for frontend testing and experience with Rails performance at scale, which becomes increasingly important in a mature SaaS product. A solid fit pending confirmation of those two areas.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"django_dev_diana\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"Celery\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nHealthtech startup is hiring a Backend Engineer to extend a Django REST API used by clinical workflows. The team processes asynchronous tasks with Celery backed by Redis. PostgreSQL is the primary database. Docker is used in development and staging. pytest is the testing framework. AWS deployment experience is preferred but not required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Django is the exact framework required\",\"Celery with Redis for async task processing is a direct match\",\"PostgreSQL is the primary database and is listed\",\"Docker for development and staging is present\",\"pytest satisfies the testing requirement\"],\"gaps\":[\"No AWS experience listed, which is a preferred qualification\",\"No REST API-specific frameworks like DRF are explicitly listed, though Django implies REST capability\"],\"explanation\":\"This candidate is a strong technical match for the core stack, hitting Django, Celery, Redis, PostgreSQL, Docker, and pytest. The only gap is the absence of AWS experience, which is a preference rather than a hard requirement. A solid fit that may need some cloud onboarding.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vue_victoria\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\",\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\",\"Node.js\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nEuropean e-commerce company is building their storefront using Nuxt.js and Vue.js. TypeScript is required. Pinia is the state management solution. Tailwind CSS is used for styling. The backend API is Node.js. GitLab CI handles pipelines. Vitest and Playwright are the testing tools. PostgreSQL is the primary database.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go is the required language and is the candidate's primary language\",\"gRPC is an exact requirement match\",\"PostgreSQL and Redis directly satisfy the storage requirements\",\"Docker for containerization is present\",\"Microservices and distributed systems architecture is explicitly listed\"],\"gaps\":[\"No explicit load testing or high-throughput benchmarking experience listed for an infrastructure startup where performance is likely a primary concern\",\"CockroachDB is listed as a notable plus and is present, but no specific distributed SQL experience depth is evidenced\"],\"explanation\":\"This candidate has strong Go, gRPC, PostgreSQL, and Redis fundamentals aligned with the role. For an infrastructure startup, the lack of visible high-throughput performance engineering work is a mild concern. CockroachDB familiarity is a useful bonus but the depth of distributed SQL experience remains to be assessed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"java_jerome\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Software Architect\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Hibernate\",\"Maven\",\"Docker\"],\"architecture\":[\"Layered Architecture\",\"Domain-Driven Design\"],\"databases\":[\"Oracle\",\"PostgreSQL\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nInsurance enterprise is modernizing a legacy Java platform and needs a Senior Backend Engineer. Spring Boot and Hibernate are the core technologies. Oracle is the production database. Jenkins handles CI. JUnit and Mockito are required for testing. The team practices domain-driven design. Kotlin familiarity is a nice to have.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Spring Boot and Hibernate are the core technologies and are both present\",\"Oracle is the production database and is listed\",\"Jenkins for CI is an exact match\",\"JUnit and Mockito satisfy the testing requirements exactly\",\"Domain-Driven Design is explicitly listed as an architecture approach\",\"Kotlin satisfies the nice-to-have factor\",\"Senior and Software Architect roles align with a modernization effort leadership need\"],\"gaps\":[],\"explanation\":\"This candidate aligns with every stated requirement including Spring Boot, Hibernate, Oracle, Jenkins, JUnit, Mockito, and DDD. Their architect background and Kotlin familiarity add additional value. An excellent fit for the enterprise modernization context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fresh_grad_frank\",\"seniority\":\"Junior\",\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"React\",\"Flask\",\"Pandas\"],\"databases\":[\"SQLite\",\"MySQL\"]}\n\nJob Summary:\nStartup is looking for a Mid-level Backend Engineer to design and own REST APIs in Node.js and TypeScript. The team uses MongoDB, Redis, and AWS Lambda for serverless functions. Docker is required for all development workflows. Jest is the testing framework. CI/CD runs on GitHub Actions. The candidate should be comfortable owning features end to end with minimal oversight.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"JavaScript provides a foundation for TypeScript and Node.js learning\"],\"gaps\":[\"No TypeScript or Node.js experience listed\",\"No MongoDB or Redis; candidate uses SQLite and MySQL\",\"No AWS Lambda or serverless experience\",\"No Docker in the profile\",\"No Jest or testing framework experience evidenced\",\"No GitHub Actions or CI/CD pipeline experience\",\"Junior seniority with limited production experience versus mid-level autonomous ownership requirement\"],\"explanation\":\"This junior candidate's profile does not overlap with the role's technical stack in any meaningful way. The combination of no TypeScript, no Node.js, no MongoDB, no Docker, and no serverless experience represents a fundamental skills gap. The expectation of autonomous feature ownership further disqualifies a junior-level candidate.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rustacean_reza\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"Go\",\"C++\"],\"tech\":[\"Axum\",\"Docker\",\"gRPC\"],\"architecture\":[\"Microservices\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nLow-latency trading infrastructure company is hiring a Senior Backend Engineer to build and maintain performance-critical services in Rust. The team uses Axum as the web framework, PostgreSQL and Redis for storage, gRPC for inter-service communication, and Docker for containerization. Distributed systems expertise is required. Go experience is a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Next.js are the primary frameworks and are both present\",\"TypeScript is required and evidenced\",\"Tailwind CSS is the styling system and is listed\",\"Zustand for state management is an exact match\",\"React Query for data fetching is directly present\"],\"gaps\":[\"No explicit B2B dashboard or data-intensive UI experience evidenced, which can require different performance optimization patterns than typical consumer apps\",\"No accessibility or i18n experience visible in the profile, which B2B SaaS products often require\"],\"explanation\":\"This candidate's technical stack precisely matches the role requirements. The gaps are around domain-specific experience in building complex B2B dashboards with high data density and accessibility requirements, which are common but not universal expectations. A technically strong match with domain experience to confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"analytics_arjun\",\"seniority\":\"Mid\",\"roles\":[\"Analytics Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Looker\",\"Apache Airflow\"],\"databases\":[\"BigQuery\",\"Snowflake\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nD2C consumer brand is hiring an Analytics Engineer to manage their dbt transformation layer on BigQuery, build Looker dashboards, and maintain Airflow DAGs for data orchestration. Python and SQL are required. The team is small and values ownership. Experience with Snowflake is a nice to have.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Spring Boot and Hibernate are the core technologies and are both present\",\"Oracle is the production database and is listed\",\"Jenkins for CI is an exact match\",\"JUnit and Mockito satisfy the testing requirements exactly\",\"Domain-Driven Design is explicitly listed as an architecture approach\"],\"gaps\":[\"No microservices migration experience explicitly evidenced; legacy modernization often requires specific strangler fig or decomposition patterns beyond general microservices knowledge\",\"Docker is listed but no Kubernetes or cloud deployment context is visible for the modernized architecture target\"],\"explanation\":\"This candidate covers the existing legacy stack requirements well: Spring Boot, Hibernate, Oracle, Jenkins, JUnit, and DDD. The modernization context introduces questions about their experience guiding teams through incremental service decomposition and the cloud infrastructure the modernized platform will run on. A strong existing-stack match with migration depth to assess.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"node_newbie_noah\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Express.js\",\"Docker\"],\"databases\":[\"MongoDB\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nB2C startup is looking for a Mid-level Backend Engineer to build Node.js microservices using NestJS and TypeScript. PostgreSQL and Redis are the datastores. Docker is used in development. Jest is required for unit testing. GitHub Actions for CI is expected. The role involves owning services independently with some mentorship available.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript is required and evidenced\",\"PostgreSQL is one of the datastores and is present\",\"Docker for development is listed\",\"Jest for unit testing is an exact match\",\"GitHub Actions for CI is present\",\"Node.js and Express.js background provides relevant backend foundation\"],\"gaps\":[\"No NestJS experience; candidate uses Express.js which is a different framework paradigm\",\"No Redis listed in the profile\",\"Junior seniority versus mid-level independent ownership expectation is a concern\"],\"explanation\":\"This candidate has relevant Node.js and TypeScript backend experience but uses Express.js rather than NestJS, which represents a framework transition. The absence of Redis and the junior-to-mid seniority gap are additional concerns for a role expecting independent service ownership. A possible fit with a short NestJS ramp period.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cloud_architect_cam\",\"seniority\":\"Principal\",\"roles\":[\"Solutions Architect\",\"Cloud Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"Terraform\",\"AWS\",\"Kubernetes\",\"Docker\",\"Ansible\",\"Pulumi\"],\"architecture\":[\"Cloud-Native\",\"Microservices\",\"Serverless\",\"Multi-Tenant\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nEnterprise cloud consulting firm is hiring a Principal Cloud Architect to design multi-tenant SaaS platforms on AWS. Terraform and Pulumi knowledge is required for IaC. Kubernetes and serverless patterns must both be in the candidate's toolkit. DynamoDB and PostgreSQL are used depending on workload. Python and Go scripting are expected. Argo CD for GitOps is used.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Principal seniority matches the architectural leadership level required\",\"AWS is the primary cloud and is present\",\"Terraform and Pulumi both satisfy the IaC requirement\",\"Kubernetes and serverless architecture are both listed\",\"Multi-tenant architecture is explicitly in the profile\",\"DynamoDB and PostgreSQL are both present\",\"Python and Go scripting are both covered\",\"Argo CD for GitOps is listed\"],\"gaps\":[],\"explanation\":\"This principal-level candidate satisfies every requirement of the role with exceptional breadth. IaC with both Terraform and Pulumi, multi-tenant cloud-native design, Kubernetes, serverless, DynamoDB, PostgreSQL, and Argo CD are all explicitly present. A top-tier match for a senior architecture role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"swift_simone\",\"seniority\":\"Junior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"Xcode\"],\"databases\":[\"Firebase\"]}\n\nJob Summary:\nHealthcare company is hiring a Senior iOS Engineer to lead architecture decisions, mentor junior developers, and build complex UIKit and SwiftUI hybrid features. Experience with Fastlane, HealthKit integration, and HIPAA-compliant data handling is required. The candidate must have at least 5 years of iOS development experience and a strong testing background with XCTest.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"SwiftUI experience is relevant to the hybrid feature work\"],\"gaps\":[\"Junior seniority is far below the senior with 5 or more years of experience requirement\",\"No UIKit experience listed, which is required for legacy hybrid work\",\"No Fastlane for automated releases\",\"No XCTest or testing background evidenced\",\"No HealthKit or HIPAA-compliant data handling experience\",\"No architecture or mentoring experience evidenced at this career stage\"],\"explanation\":\"This junior iOS developer has only foundational SwiftUI experience and lacks the seniority, UIKit knowledge, testing culture, and domain-specific healthcare integration skills required. The 5-year experience requirement alone creates an insurmountable gap at this stage of the candidate's career.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elixir_elena\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Elixir\",\"JavaScript\"],\"tech\":[\"Phoenix\",\"Oban\",\"Docker\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nSaaS communication platform is hiring a Senior Elixir Engineer to build real-time messaging features using Phoenix Channels. The team uses Oban for background jobs, PostgreSQL and Redis for data storage, and Docker for development. An event-driven and distributed systems mindset is expected. ExUnit is the testing framework.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Jetpack Compose is the primary UI framework and is present\",\"Kotlin is required and is the candidate's primary language\",\"Retrofit for API calls is an exact match\",\"Modular architecture is explicitly listed\",\"Fastlane for automated releases is present\"],\"gaps\":[\"No explicit experience with payment integrations or PCI-compliance relevant to a fintech app context\",\"Firebase is listed but no specific analytics or A/B testing framework experience is evidenced beyond general Firebase usage\"],\"explanation\":\"This candidate is technically well-aligned with the Android stack: Jetpack Compose, Kotlin, Retrofit, modular architecture, and Fastlane. For a fintech app, the absence of payment integration or compliance experience is worth exploring, and the depth of Firebase analytics implementation is a secondary question. A solid technical match with domain fit to confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"android_alex\",\"seniority\":\"Mid\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Retrofit\"],\"architecture\":[\"Modular Architecture\",\"Client-Server\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Espresso\"]}\n\nJob Summary:\nFintech app company is looking for a Mid-level Android Engineer to build features in Jetpack Compose with Kotlin. Retrofit is used for API calls. The team practices modular architecture. Firebase is used for remote config and analytics. Fastlane handles automated releases. JUnit and Espresso are required for testing.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Apache Flink is the primary stream processing engine and is present\",\"Apache Kafka for ingestion is an exact match\",\"Scala is the required language and is the candidate's primary language\",\"Cassandra as the time-series datastore is listed\"],\"gaps\":[\"No explicit experience with Flink stateful operators or complex event processing patterns, which streaming analytics at scale typically requires\",\"dbt and Databricks are present but batch workload depth relative to the streaming-first role is unclear\"],\"explanation\":\"This candidate has strong streaming credentials with Flink, Kafka, Scala, and Cassandra. The depth of Flink-specific patterns for stateful stream processing versus general Flink familiarity is the primary unknown for a streaming analytics company. A technically aligned candidate whose Flink depth should be assessed in technical screening.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"scala_stefan\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\",\"Backend Engineer\"],\"languages\":[\"Scala\",\"Python\",\"SQL\"],\"tech\":[\"Apache Spark\",\"Apache Kafka\",\"Apache Flink\",\"dbt\"],\"databases\":[\"Databricks\",\"Cassandra\",\"PostgreSQL\"],\"ci_cd\":[\"GitLab CI\"]}\n\nJob Summary:\nStreaming analytics company is hiring a Senior Data Engineer to build real-time pipelines. Apache Flink is the primary stream processing engine. Kafka is used for ingestion. Scala is the required language. Cassandra serves as the time-series datastore. The team also uses dbt and Databricks for batch workloads.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Apache Flink is the primary stream processing engine and is present\",\"Apache Kafka for ingestion is an exact match\",\"Scala is the required language and is the candidate's primary language\",\"Cassandra as the time-series datastore is listed\",\"dbt and Databricks are both present for batch workloads\",\"Apache Spark adds complementary processing depth\"],\"gaps\":[],\"explanation\":\"This candidate fulfills every stated requirement with high specificity: Flink, Kafka, Scala, Cassandra, dbt, and Databricks. Their combination of streaming and batch engineering experience makes them an ideal fit for this real-time analytics team.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rag_randy\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\",\"AI Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"LangChain\",\"Hugging Face Transformers\",\"ChromaDB\",\"FastAPI\",\"Docker\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"ChromaDB\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nLegaltech startup is hiring an AI Engineer to build retrieval-augmented generation pipelines for legal document search. LangChain and vector databases such as ChromaDB or Pinecone are required. Hugging Face for model integration is expected. FastAPI for serving endpoints is used. Docker and GitHub Actions for CI are the infrastructure tools.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LangChain for RAG pipelines is an exact requirement match\",\"ChromaDB satisfies the vector database requirement\",\"Hugging Face Transformers for model integration is directly listed\",\"FastAPI for serving endpoints is an exact match\",\"Docker and GitHub Actions cover the infrastructure requirements\",\"PostgreSQL provides relational storage capability\"],\"gaps\":[\"No Pinecone experience, though ChromaDB is an accepted alternative\"],\"explanation\":\"This candidate hits every core requirement for the RAG pipeline role: LangChain, ChromaDB, Hugging Face, and FastAPI. The one alternative vector DB option, Pinecone, is not listed but ChromaDB satisfies the requirement. A strong fit for the legaltech AI engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cms_carla\",\"seniority\":\"Junior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Next.js\",\"React\",\"Sanity\",\"Tailwind CSS\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nDigital agency is hiring a Junior Full Stack Developer to build content-driven websites using Next.js and Sanity CMS. TypeScript and Tailwind CSS are required. PostgreSQL is used for application data. The role involves working closely with the design team on pixel-perfect implementations. REST API integration experience is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js is the primary framework and is present\",\"Sanity CMS is an exact requirement match\",\"TypeScript and Tailwind CSS are both listed\",\"PostgreSQL covers the application data requirement\",\"Junior seniority matches the role level\"],\"gaps\":[\"No explicit REST API integration experience evidenced; the role requires comfort integrating third-party APIs which is not visible in a CMS-focused junior profile\"],\"explanation\":\"This candidate matches the core technologies for the junior role: Next.js, Sanity, TypeScript, Tailwind CSS, and PostgreSQL. The gap around REST API integration experience introduces mild uncertainty for a role that involves third-party data integration. A likely fit that would benefit from a brief technical screen around API patterns.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"infra_igor\",\"seniority\":\"Senior\",\"roles\":[\"Infrastructure Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Terraform\",\"Ansible\",\"Docker\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Cloud-Native\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"]}\n\nJob Summary:\nMedtech company is hiring a Senior DevOps Engineer with strong Kubernetes experience to manage container orchestration on Azure. Helm and Argo CD are required for GitOps deployments. The observability stack is Prometheus and Grafana. Terraform is used for infrastructure provisioning. Python scripting is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform for infrastructure provisioning is an exact match\",\"Prometheus and Grafana for observability are both present\",\"Python scripting is evidenced\",\"Docker provides container fundamentals\",\"Senior seniority aligns with the role level\"],\"gaps\":[\"No Kubernetes listed in the profile despite it being the core requirement\",\"No Helm or Argo CD experience for GitOps deployments\",\"No Azure cloud experience; cloud-native is listed but without a specific provider\"],\"explanation\":\"This candidate has solid infrastructure foundations with Terraform and observability tooling, but the absence of Kubernetes, Helm, and Argo CD represents a meaningful gap for a role where container orchestration and GitOps are the primary responsibilities. The missing Azure-specific experience is an additional concern.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"php_petra\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"SQL\"],\"tech\":[\"Laravel\",\"Symfony\",\"Docker\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nE-commerce company with a large Laravel monolith is hiring a Senior PHP Engineer. The team uses Symfony components alongside Laravel. MySQL and Redis are the datastores. Docker is used in development and production. GitLab CI handles pipelines. PHPUnit is required for testing. The company values clean code and SOLID principles.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Laravel is the primary framework and is the candidate's main technology\",\"Symfony is explicitly required and is also listed\",\"MySQL and Redis are both present\",\"Docker covers both development and production containerization\",\"GitLab CI is the pipeline tool and is listed\",\"PHPUnit satisfies the testing requirement exactly\",\"Senior seniority aligns with the role\"],\"gaps\":[],\"explanation\":\"This candidate precisely satisfies every technical requirement of the Laravel monolith role including Symfony, MySQL, Redis, Docker, GitLab CI, and PHPUnit. Their dual Laravel and Symfony experience is a particular strength for a team that uses both. A clear strong match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kotlin_kira\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Spring Boot\",\"Ktor\",\"Docker\",\"gRPC\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nFintec company is hiring a Mid-level Kotlin Backend Engineer to build microservices with Ktor. PostgreSQL is the primary database. Docker is used in development. gRPC is used for inter-service communication. JUnit and Mockito are the testing tools. GitHub Actions handles CI. Spring Boot experience is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React for the frontend is present as a primary skill\",\"FastAPI for the backend is an exact match\",\"PostgreSQL is the primary datastore and is listed\",\"Docker and Nginx are both present for deployment\",\"GitHub Actions for CI is listed\",\"pytest and Jest satisfy both testing requirements\",\"TypeScript is required and evidenced\"],\"gaps\":[\"No explicit experience with bootstrapped startup context requiring product judgment and self-direction, which is harder to assess from tooling profiles alone\",\"Nginx configuration and production deployment depth are not explicitly evidenced beyond listing the tool\"],\"explanation\":\"This candidate covers the technical stack requirements well: React, FastAPI, PostgreSQL, Docker, Nginx, pytest, and Jest. For a bootstrapped startup expecting full product ownership, the gaps are in demonstrated self-direction and production deployment depth rather than technology familiarity. A technically solid candidate whose product ownership style should be assessed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"svelte_sid\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"SvelteKit\",\"Svelte\",\"Tailwind CSS\",\"Vite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nMedia startup is building a content platform in SvelteKit with TypeScript and Tailwind CSS. Vitest and Playwright are the testing frameworks. Vite is the build tool. GitHub Actions handles CI. The team values fast iteration and clean component design.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SvelteKit is the primary framework and is the candidate's main skill\",\"TypeScript is required and evidenced\",\"Tailwind CSS is present\",\"Vitest and Playwright satisfy both testing requirements exactly\",\"Vite as the build tool is an exact match\",\"GitHub Actions for CI is listed\"],\"gaps\":[],\"explanation\":\"This candidate's profile is a direct and complete match for the role: SvelteKit, TypeScript, Tailwind CSS, Vitest, Playwright, Vite, and GitHub Actions are all present. No gaps exist for this frontend role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wasm_wade\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"C++\",\"Python\"],\"tech\":[\"Axum\",\"ONNX\",\"Docker\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"]}\n\nJob Summary:\nML infrastructure company is hiring a Senior Engineer to build model serving infrastructure in Python using FastAPI and TensorFlow. The candidate must have production experience with TensorFlow or PyTorch, ONNX model export, and REST API design. Kubernetes is required for orchestration. Docker is expected. PostgreSQL is used for metadata.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"ONNX experience is a direct requirement match for model export workflows\",\"Docker is listed\",\"PostgreSQL is present for metadata storage\",\"Rust and systems programming background may be valuable for performance-critical serving\"],\"gaps\":[\"No Python, FastAPI, TensorFlow, or PyTorch experience listed despite these being primary requirements\",\"No Kubernetes listed, which is required for orchestration\",\"The candidate's primary languages are Rust and C++, not Python which is the team's language\"],\"explanation\":\"This candidate brings relevant ONNX and infrastructure experience, and their systems programming depth is an asset. However, the absence of Python, FastAPI, and any deep learning framework means they lack the primary technical layer the team operates in. The missing Kubernetes experience is an additional gap for a Kubernetes-orchestrated deployment environment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fullstack_fiona\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"FastAPI\",\"Docker\",\"Nginx\"],\"architecture\":[\"Monolith\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\"]}\n\nJob Summary:\nBootstrapped SaaS startup needs a Senior Full Stack Engineer to own both the React frontend and FastAPI backend. PostgreSQL is the primary datastore. Docker and Nginx are used for deployment. GitHub Actions handles CI. pytest and Jest cover backend and frontend testing. TypeScript is required for frontend work.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React for the frontend is present as a primary skill\",\"FastAPI for the backend is an exact match\",\"PostgreSQL is the primary datastore and is listed\",\"Docker and Nginx are both present for deployment\",\"GitHub Actions for CI is listed\",\"pytest and Jest satisfy both testing requirements\",\"TypeScript is required and evidenced\",\"Senior seniority is appropriate for a full ownership role\"],\"gaps\":[],\"explanation\":\"This candidate satisfies every stated requirement including React, FastAPI, PostgreSQL, Docker, Nginx, GitHub Actions, pytest, and Jest. Their full stack TypeScript and Python background is ideal for a startup where a single engineer owns both layers. A perfect match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"backend_bea\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"SQLAlchemy\",\"Celery\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nHealthtech startup is hiring a Mid-level Backend Engineer to extend a Python REST API using FastAPI and SQLAlchemy. PostgreSQL is the primary database. Celery with Redis is used for async tasks. Docker is required in development. pytest is the testing framework. GitHub Actions handles CI. Kubernetes experience is a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI is the exact framework required\",\"SQLAlchemy for ORM is directly listed\",\"PostgreSQL is the primary database and is present\",\"Celery with Redis for async tasks is an exact match\",\"Docker is listed\",\"pytest satisfies the testing requirement\",\"GitHub Actions for CI is present\"],\"gaps\":[\"No Kubernetes experience, which is listed as a strong plus\"],\"explanation\":\"This candidate is a very strong match on all core technical requirements: FastAPI, SQLAlchemy, PostgreSQL, Celery, Redis, Docker, pytest, and GitHub Actions. The only gap is the absence of Kubernetes, which is a strong plus rather than a hard requirement. This is a high-confidence moderate leaning toward strong, pending Kubernetes assessment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"staff_eng_solomon\",\"seniority\":\"Staff\",\"roles\":[\"Software Architect\",\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\",\"Rust\"],\"tech\":[\"Kubernetes\",\"Kafka\",\"gRPC\",\"Istio\",\"Docker\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Service Mesh\",\"CQRS\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"Go testing\",\"k6\"]}\n\nJob Summary:\nTech unicorn is hiring a Staff Engineer to define microservices architecture standards, evaluate new technologies, and mentor senior engineers. The platform runs on Kubernetes with Istio service mesh. Kafka handles event streaming. gRPC is used for inter-service communication. Go is the primary language. CQRS and event-driven patterns are applied across services.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Staff seniority matches the architectural leadership level\",\"Go is the primary language and is the candidate's main language\",\"Kubernetes with Istio service mesh is explicitly present\",\"Apache Kafka for event streaming is directly listed\",\"gRPC for inter-service communication is an exact match\",\"CQRS and event-driven architecture are both explicitly listed\",\"Argo CD supports the GitOps practice implied by the role\",\"k6 demonstrates load testing capability for platform reliability\"],\"gaps\":[],\"explanation\":\"This staff-level candidate is an outstanding match, covering Go, Kubernetes, Istio, Kafka, gRPC, CQRS, and event-driven patterns. Their breadth across systems architecture and senior mentoring capacity is exactly what a tech unicorn engineering organization requires. No meaningful gaps are present.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"gatsby_grace\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"Gatsby\",\"React\",\"Bootstrap\"],\"databases\":[\"Firebase\"]}\n\nJob Summary:\nEnterprise software company is hiring a Senior Frontend Engineer to lead the migration of a large Angular codebase to React. The candidate must have deep Angular and React experience. TypeScript is required. The team uses Webpack and Jest. Experience with state management using NgRx or Redux is expected. The role involves architectural decision-making and mentoring junior engineers.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React experience is relevant to the migration target framework\"],\"gaps\":[\"No Angular experience despite it being the source codebase of the migration\",\"No TypeScript experience, which is required\",\"No Webpack configuration experience listed\",\"No Jest testing experience\",\"No NgRx or Redux state management experience\",\"Junior seniority versus senior architectural and mentoring expectations\",\"JavaScript-only without TypeScript is a fundamental gap for this role\"],\"explanation\":\"This junior developer has basic React skills but lacks virtually every other requirement for a senior migration leadership role: no Angular, no TypeScript, no Webpack, no Jest, and no state management experience. The seniority mismatch further disqualifies them from an architectural and mentoring role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nestjs_nikki\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"Express.js\",\"BullMQ\",\"Docker\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nEdtech startup is hiring a Mid-level Backend Engineer to build NestJS microservices in TypeScript. PostgreSQL and Redis are the datastores. BullMQ is used for job queues. Docker is used in development. Jest and Supertest are the testing tools. GitHub Actions handles CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS is the primary framework and is the candidate's main backend tool\",\"TypeScript is required and is the candidate's primary language\",\"PostgreSQL and Redis are both listed as datastores\",\"BullMQ for job queues is an exact match\",\"Docker is present\",\"Jest and Supertest satisfy both testing requirements exactly\",\"GitHub Actions for CI is listed\"],\"gaps\":[],\"explanation\":\"This candidate checks every box for the edtech backend role: NestJS, TypeScript, PostgreSQL, Redis, BullMQ, Docker, Jest, and Supertest. Mid-level seniority is appropriate and no technical gaps are present.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"data_warehouse_wendy\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Apache Airflow\",\"Great Expectations\",\"Polars\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"Redshift\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nRetail analytics company is hiring a Senior Data Engineer to design their cloud data warehouse strategy on Snowflake. dbt for transformation, Airflow for orchestration, and Great Expectations for data quality are required. Python and SQL are expected. Experience across multiple cloud warehouses is a plus. The role involves owning the full ELT pipeline from ingestion to dashboarding.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt for transformation is an exact requirement match\",\"Airflow for orchestration is directly listed\",\"Great Expectations for data quality is explicitly required and present\",\"Snowflake is the target platform and is the candidate's primary warehouse\",\"Python and SQL are both present\",\"BigQuery and Redshift satisfy the multi-cloud warehouse plus factor\",\"Polars adds modern data processing capability\"],\"gaps\":[],\"explanation\":\"This candidate satisfies every stated requirement including dbt, Airflow, Great Expectations, and Snowflake, plus the bonus of multi-cloud warehouse experience with BigQuery and Redshift. Their senior seniority is appropriate for full pipeline ownership. An exceptional match for this data warehouse leadership role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"terraform_tomas\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\",\"Cloud Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Terraform\",\"Docker\",\"AWS\",\"Ansible\"],\"architecture\":[\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"]}\n\nJob Summary:\nScale-up company is hiring a Mid-level DevOps Engineer with strong AWS experience. Terraform is used for all infrastructure provisioning. Ansible handles configuration management. Docker is used throughout the stack. GitHub Actions is the CI tool. Kubernetes experience is required for the container orchestration layer.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform for infrastructure provisioning is an exact match\",\"AWS is the required cloud and is present\",\"Ansible for configuration management is directly listed\",\"Docker is present\",\"GitHub Actions for CI is listed\",\"Mid-level seniority matches the role level\"],\"gaps\":[\"No Kubernetes experience listed despite it being a requirement for the container orchestration layer\"],\"explanation\":\"This candidate covers the majority of the role's requirements very well, including Terraform, AWS, Ansible, Docker, and GitHub Actions. The one clear gap is Kubernetes, which is explicitly required for container orchestration. Depending on the team's willingness to train, this could be a short onboarding gap or a disqualifying factor.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"csharp_charlie\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C#\",\"SQL\"],\"tech\":[\"ASP.NET\",\"Entity Framework\",\"Docker\"],\"architecture\":[\"Microservices\",\"Domain-Driven Design\"],\"databases\":[\"MS SQL Server\",\"Redis\"],\"ci_cd\":[\"Azure DevOps\"],\"testing\":[\"xUnit\"]}\n\nJob Summary:\nEnterprise logistics company is hiring a Senior .NET Backend Engineer. ASP.NET Core and Entity Framework are the primary frameworks. MS SQL Server is the production database. Redis is used for caching. Azure DevOps is the CI/CD platform. The team practices domain-driven design and microservices. xUnit is the testing framework.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"ASP.NET covers the ASP.NET Core requirement\",\"Entity Framework is an exact match\",\"MS SQL Server is the production database and is present\",\"Redis for caching is listed\",\"Azure DevOps is the CI/CD platform and is directly listed\",\"Domain-Driven Design and microservices architecture are both explicitly present\",\"xUnit satisfies the testing requirement\",\"C# is the required language and is the candidate's primary language\"],\"gaps\":[],\"explanation\":\"This candidate is a precise match for the enterprise .NET role, covering ASP.NET, Entity Framework, MS SQL Server, Redis, Azure DevOps, DDD, microservices, and xUnit. No meaningful gaps are present. A strong hire for the logistics platform.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sparse_sam\",\"seniority\":\"Mid\",\"languages\":[\"Python\"],\"tech\":[\"Django\"]}\n\nJob Summary:\nStartup is hiring a Mid-level Backend Engineer to build a Django REST API using PostgreSQL, Redis, and Celery. Docker and GitHub Actions are required. The candidate should be comfortable with testing using pytest and writing clean, documented code. AWS deployment experience is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Django is the required framework and is present\",\"Python is the required language and is listed\"],\"gaps\":[\"No PostgreSQL or Redis listed in a sparse profile\",\"No Celery experience evidenced\",\"No Docker listed\",\"No GitHub Actions or CI/CD experience\",\"No pytest or testing framework experience\",\"No AWS or deployment experience\"],\"explanation\":\"While this candidate works in the correct framework and language, their sparse profile offers no evidence of the surrounding tools that the role critically depends on. The absence of PostgreSQL, Redis, Celery, Docker, pytest, and AWS creates too many unresolved questions for a mid-level autonomous role. Not enough signal to proceed confidently.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fullstack_florence\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"FastAPI\",\"Tailwind CSS\",\"shadcn/ui\",\"Docker\"],\"architecture\":[\"Serverless\",\"Monolith\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nProductivity SaaS startup is hiring a Senior Full Stack Engineer to build and ship product features using Next.js on the frontend and FastAPI on the backend. Supabase is used for the database and auth layer. Tailwind CSS and shadcn/ui are the UI toolkit. Playwright and Jest cover E2E and unit testing. Docker is used in development. GitHub Actions handles CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js for the frontend is the primary framework and is present\",\"FastAPI for the backend is an exact match\",\"Supabase for database and auth is directly listed\",\"Tailwind CSS and shadcn/ui are both present as the UI toolkit\",\"Playwright and Jest satisfy both E2E and unit testing requirements\",\"Docker for development is listed\",\"GitHub Actions for CI is present\",\"pytest adds additional backend testing coverage\"],\"gaps\":[],\"explanation\":\"This candidate is a complete match for the SaaS startup role, covering every stated technology: Next.js, FastAPI, Supabase, Tailwind CSS, shadcn/ui, Playwright, Jest, Docker, and GitHub Actions. Their senior seniority and full stack depth make them an ideal fit for rapid product development.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hadoop_hector\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Java\",\"Python\",\"SQL\"],\"tech\":[\"Hadoop\",\"Apache Spark\",\"Apache Hive\"],\"databases\":[\"Cassandra\",\"HBase\"],\"ci_cd\":[\"Jenkins\"]}\n\nJob Summary:\nModern data startup is hiring a Senior Data Engineer to build streaming pipelines in dbt on Snowflake with orchestration in Prefect. Python is required. The team uses GitHub Actions for CI and Kafka for real-time ingestion. Experience with modern cloud-native data stack tools is expected. Legacy Hadoop expertise is not relevant to this role.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is required and is listed\",\"Apache Spark experience may provide some transferable foundation\"],\"gaps\":[\"No dbt experience despite it being the core transformation tool\",\"No Snowflake listed; candidate works with Hadoop and HBase\",\"No Prefect or modern orchestration tool experience\",\"No Kafka for real-time ingestion\",\"No GitHub Actions; candidate uses Jenkins\",\"Hadoop-centric stack is explicitly described as not relevant by the employer\",\"No cloud-native data stack experience evidenced\"],\"explanation\":\"This candidate's expertise is rooted in a legacy Hadoop ecosystem that the employer has explicitly marked as irrelevant. The modern stack the team uses, including dbt, Snowflake, Prefect, and Kafka, is entirely absent from the profile. This is a fundamental technology generation mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"typescript_theo\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"tRPC\",\"Prisma\",\"Next.js\",\"Tailwind CSS\"],\"architecture\":[\"Monolith\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nBootstrapped SaaS company is building a T3-style stack with Next.js, tRPC, Prisma, and TypeScript. Tailwind CSS is the styling system. PostgreSQL is the database. Vitest and Playwright are the testing tools. The candidate should be comfortable shipping full stack features autonomously. GitHub Actions handles CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js, tRPC, and Prisma precisely match the T3 stack requirement\",\"TypeScript is required and is the candidate's primary language\",\"Tailwind CSS is the styling system and is present\",\"PostgreSQL is the database and is listed\",\"Vitest and Playwright satisfy both testing requirements exactly\",\"GitHub Actions for CI is listed\",\"Serverless architecture background supports the deployment model\"],\"gaps\":[],\"explanation\":\"This candidate's profile is essentially built around the T3 stack the company uses: Next.js, tRPC, Prisma, TypeScript, Tailwind CSS, and PostgreSQL. Every single requirement is met with explicit experience. An ideal match for a full stack feature ownership role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"game_dev_grace\",\"seniority\":\"Mid\",\"roles\":[\"Game Developer\"],\"languages\":[\"C++\",\"C#\",\"Python\"],\"tech\":[\"Unity\",\"Unreal Engine\",\"CMake\"],\"architecture\":[\"Client-Server\"]}\n\nJob Summary:\nSocial network company is hiring a Mid-level Backend Engineer to build and scale REST APIs in Node.js and TypeScript. PostgreSQL and Redis are the primary datastores. Docker and Kubernetes are required for containerized deployments. Jest is the testing framework. GitHub Actions handles CI. Strong TypeScript skills are mandatory.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"C++ experience may offer minor systems programming familiarity\"],\"gaps\":[\"No TypeScript or JavaScript experience listed despite being mandatory\",\"No Node.js or web backend experience\",\"No PostgreSQL or Redis; no relevant datastore experience\",\"No Docker or Kubernetes experience\",\"No Jest or web testing experience\",\"Game development domain is entirely mismatched to a social network backend role\"],\"explanation\":\"This candidate's background is entirely in game development with C++, C#, and Unity or Unreal Engine, which has no meaningful overlap with the Node.js, TypeScript, PostgreSQL, and Kubernetes backend role. The domain mismatch is fundamental and no relevant technologies are shared.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"astro_amelia\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Astro\",\"React\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"Supabase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nContent publishing startup is building a statically generated marketing site and blog using Astro with TypeScript. Tailwind CSS is the styling system. Supabase powers the backend. Playwright and Vitest are used for testing. GitHub Actions handles CI. The candidate should be comfortable with component islands architecture and React integrations within Astro.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Astro is the primary framework and is the candidate's most prominent skill\",\"TypeScript is required and evidenced\",\"Tailwind CSS is the styling system and is present\",\"Supabase backend experience is an exact match\",\"Playwright and Vitest satisfy both testing requirements\"],\"gaps\":[\"No explicit experience with Astro's component islands architecture at production scale, which the team's pattern relies on\",\"GitHub Actions CI experience is not evidenced in the profile\"],\"explanation\":\"This candidate's stack aligns well on Astro, TypeScript, Tailwind CSS, and Supabase. The gaps around CI/CD experience and production-scale Astro island architecture introduce some uncertainty for a role where those patterns are central. A strong technical match with operational experience to confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"springcloud_sung\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Docker\",\"Maven\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nLogistics platform is hiring a Senior Java Backend Engineer to build microservices with Spring Boot on AWS EKS. Kafka is used for async messaging between services. PostgreSQL and Redis are the datastores. Docker and Kubernetes are required. GitLab CI handles pipelines. JUnit and Mockito are the testing tools.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Spring Boot is the primary framework and covers the Java backend requirement\",\"PostgreSQL and Redis match the datastore requirements\"],\"gaps\":[\"No Kubernetes listed despite it being required for EKS orchestration\",\"No Kafka experience for async inter-service messaging\",\"No GitLab CI; candidate uses Jenkins which requires pipeline migration\",\"No AWS experience for a role specifically on AWS EKS\"],\"explanation\":\"This candidate has strong Spring Boot and Java fundamentals but is missing four explicitly required technologies: Kubernetes, Kafka, GitLab CI, and AWS. These are not peripheral tools but core operational requirements of the platform. The gaps are too numerous and fundamental for a senior role expecting immediate productivity.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"qwik_quentin\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Qwik\",\"React\",\"Tailwind CSS\",\"Vite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\"]}\n\nJob Summary:\nPerformance-obsessed e-commerce company is building their storefront in Qwik with TypeScript. Tailwind CSS is used for styling. Vite is the build tool. Vitest for unit testing and GitHub Actions for CI are expected. The team values resumability patterns and lazy loading techniques inherent to the Qwik framework.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Qwik is the primary framework and is the candidate's lead technology\",\"TypeScript is required and evidenced\",\"Tailwind CSS for styling is an exact match\",\"Vite as the build tool is present\",\"Vitest for unit testing is directly listed\"],\"gaps\":[\"No E2E testing tool listed such as Playwright or Cypress, which performance-obsessed e-commerce teams often require for checkout flow coverage\",\"No database or backend experience, which may be expected for a full-featured storefront\"],\"explanation\":\"This candidate covers the core Qwik, TypeScript, Tailwind CSS, Vite, and Vitest requirements. The absence of E2E testing experience and any backend or data store familiarity are open questions for a production e-commerce storefront where end-to-end flow testing and data access are typical. A technically aligned candidate with scope to assess.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"infra_intern_ian\",\"seniority\":\"Intern\",\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"Ansible\"]}\n\nJob Summary:\nCloud consulting firm is hiring a Senior DevOps Engineer to design and operate multi-region Kubernetes clusters on GCP. Terraform is required for all infrastructure provisioning. Istio service mesh experience is expected. The candidate must be proficient in Go for tooling automation. Prometheus and Grafana are used for observability. At least 5 years of professional cloud infrastructure experience is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker provides basic containerization fundamentals\",\"Ansible shows early configuration management exposure\"],\"gaps\":[\"Intern seniority is far below the senior with 5 or more years of experience requirement\",\"No Kubernetes or multi-region cluster management experience\",\"No Terraform for infrastructure provisioning\",\"No GCP or cloud provider experience at scale\",\"No Istio service mesh knowledge\",\"No Go proficiency for tooling automation\",\"No Prometheus or Grafana for observability\"],\"explanation\":\"This intern profile has only the most foundational containerization exposure and lacks every substantive requirement of the senior DevOps role. The experience gap is severe: no Kubernetes, no Terraform, no cloud provider depth, and no service mesh familiarity. Not a viable candidate at this stage.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pyspark_priya\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"PySpark\",\"Apache Airflow\",\"dbt\",\"Apache Kafka\"],\"databases\":[\"Databricks\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nStreaming analytics company is hiring a Senior Data Engineer to build real-time ingestion pipelines with Kafka and batch transformation layers using PySpark on Databricks. dbt is used for SQL-level transformations. Airflow orchestrates all pipelines. Python and SQL are required. BigQuery is a secondary analytics store.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PySpark on Databricks is an exact match for the core processing requirement\",\"Apache Kafka for real-time ingestion is directly listed\",\"dbt for SQL-level transformations is present\",\"Apache Airflow for pipeline orchestration is an exact match\",\"Python and SQL are both evidenced\",\"BigQuery as the secondary analytics store is listed\",\"Scala adds additional processing language flexibility\"],\"gaps\":[],\"explanation\":\"This candidate satisfies every stated technical requirement with direct, explicit experience: PySpark, Databricks, Kafka, dbt, Airflow, Python, SQL, and BigQuery. Their combination of streaming and batch engineering skills is precisely what the role demands. An excellent match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"remix_rey\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Remix\",\"React\",\"Tailwind CSS\",\"Prisma\"],\"databases\":[\"PostgreSQL\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nSaaS startup is hiring a Mid-level Full Stack Engineer to build and maintain a Remix application with a PostgreSQL backend managed via Prisma. TypeScript is required. Tailwind CSS is the styling system. Vitest and Playwright cover testing. GitHub Actions is used for CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Remix is the primary framework and is the candidate's most prominent technology\",\"Prisma for ORM is an exact requirement match\",\"PostgreSQL is the backend database and is present\",\"TypeScript is required and evidenced\",\"Tailwind CSS is the styling system and is listed\"],\"gaps\":[\"No Vitest experience; candidate uses Vitest is listed but no CI-level testing infrastructure depth evidenced for a production SaaS context\",\"No deployment or cloud infrastructure experience listed which SaaS ownership typically implies\"],\"explanation\":\"This candidate covers the core technical stack of Remix, Prisma, PostgreSQL, TypeScript, and Tailwind CSS. The gaps are around production deployment context and infrastructure ownership which are expected at a mid-level SaaS role. A technically solid match with operational maturity to confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_sparse_mike\",\"seniority\":\"Mid\",\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"Pandas\"]}\n\nJob Summary:\nAI startup is hiring a Mid-level ML Engineer to build and deploy production inference pipelines using FastAPI and TensorFlow Serving. Candidates must have Docker and Kubernetes experience for containerized model deployment. MLflow is used for experiment tracking. AWS SageMaker is the cloud ML platform. Python is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is the required language and is present\",\"PyTorch shows hands-on deep learning model experience\"],\"gaps\":[\"No FastAPI or model serving API framework experience\",\"No TensorFlow or TensorFlow Serving experience\",\"No Docker or Kubernetes for containerized deployment\",\"No MLflow for experiment tracking\",\"No AWS SageMaker or cloud ML platform experience\",\"Profile is very sparse with no production deployment or MLOps tooling visible\"],\"explanation\":\"This candidate has basic ML foundations in PyTorch but the profile lacks every production-facing requirement the role depends on: serving frameworks, containerization, experiment tracking, and cloud ML infrastructure. The sparse profile makes it impossible to assess readiness for a production inference engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nuxt3_nadia\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\",\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Nuxt.js\",\"Vue.js\",\"Pinia\",\"Tailwind CSS\",\"Nitro\"],\"architecture\":[\"Serverless\",\"Modular Architecture\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nEuropean tech company is building a content platform with Nuxt 3 and TypeScript. Pinia is the state management solution. Tailwind CSS is used for styling. Supabase is the backend service. Vitest and Playwright are required for testing. GitHub Actions handles CI. Experience with Nuxt's Nitro server engine is a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Nuxt.js is the primary framework and is the candidate's core skill\",\"TypeScript is required and evidenced\",\"Pinia for state management is an exact requirement match\",\"Tailwind CSS is present\",\"Supabase backend experience is an exact match\",\"Nitro server engine experience satisfies the strong plus requirement\"],\"gaps\":[\"No explicit Nuxt 3 specific experience listed versus older Nuxt 2 patterns which differ meaningfully in architecture\",\"Senior seniority may introduce compensation expectations above what a Mid-level content platform team budget supports\"],\"explanation\":\"This candidate has strong Nuxt.js fundamentals and the full surrounding stack. The open question is depth in Nuxt 3 specifically versus prior Nuxt 2 patterns, as the composition API and server rendering model changed significantly. A likely fit pending confirmation of Nuxt 3 production experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"angular_aryan\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Angular\",\"NgRx\",\"RxJS\",\"Tailwind CSS\",\"Webpack\"],\"ci_cd\":[\"Azure DevOps\"],\"testing\":[\"Jest\",\"Karma\",\"Cypress\"]}\n\nJob Summary:\nEnterprise financial software company is hiring a Senior Angular Engineer to maintain and extend a large Angular monorepo. NgRx is used for state management. RxJS patterns are pervasive. The team uses Azure DevOps for CI/CD. Jest and Karma are the unit testing tools and Cypress handles E2E testing. TypeScript is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Angular is the primary framework and is the candidate's main technology\",\"NgRx for state management is an exact requirement match\",\"RxJS is explicitly listed, satisfying the pervasive patterns requirement\",\"Azure DevOps for CI/CD is a direct match\",\"Jest, Karma, and Cypress satisfy all three testing requirements exactly\",\"TypeScript is required and evidenced\",\"Webpack knowledge supports the monorepo build configuration work\"],\"gaps\":[],\"explanation\":\"This candidate is a textbook match for the enterprise Angular role, covering Angular, NgRx, RxJS, Azure DevOps, Jest, Karma, and Cypress with no gaps. Their experience with Webpack adds additional value for large monorepo configuration. An ideal hire for this context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"backend_basil\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"Celery\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nB2B SaaS company is hiring a Mid-level Backend Engineer to extend a Django REST API backed by PostgreSQL and Redis. Celery handles background task processing. Docker is used in development. pytest is the testing framework. GitHub Actions manages CI. The team is moving from monolith to modular services and values clean architecture patterns.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python is the required language and is present\",\"PostgreSQL and Redis are both listed as datastores\",\"Celery for background task processing is an exact match\",\"Docker for development is present\",\"pytest satisfies the testing requirement\",\"GitHub Actions for CI is listed\"],\"gaps\":[\"No Django experience; candidate uses FastAPI which follows a different architectural paradigm\",\"No explicit REST framework experience with DRF or Django REST conventions\",\"Monolith-to-modular migration context implies familiarity with Django's ORM and project structure that FastAPI experience may not provide\"],\"explanation\":\"This candidate has the right supporting stack: Celery, Redis, PostgreSQL, Docker, and pytest. The primary gap is the absence of Django experience, which is the team's primary framework. FastAPI and Django are meaningfully different in structure and conventions, and a migration context makes framework fluency more critical than usual.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devrel_dana\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"Express.js\",\"Gatsby\"],\"databases\":[\"MongoDB\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nFinancial data startup is hiring a Senior Backend Engineer to build high-performance REST and GraphQL APIs in Go. PostgreSQL is the primary datastore. Redis is used for caching. gRPC is used for internal service communication. Docker and Kubernetes are required. The candidate must have 5 or more years of Go experience.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"JavaScript and Python show general programming ability\"],\"gaps\":[\"No Go experience at all; the role requires 5 or more years of Go expertise\",\"No GraphQL experience listed\",\"No PostgreSQL; candidate uses MongoDB and Firebase\",\"No Redis for caching\",\"No gRPC experience\",\"No Kubernetes or Docker listed in the profile\",\"Profile is centered on React and Gatsby frontends, not backend services\"],\"explanation\":\"This candidate's background is primarily in JavaScript frontend and lightweight backend work, with no overlap with the Go, PostgreSQL, Redis, gRPC, and Kubernetes stack the role requires. The domain mismatch is fundamental and the Go experience gap alone is disqualifying for a role requiring 5 or more years.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"haskell_henrik\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Haskell\",\"Scala\",\"Python\"],\"tech\":[\"Apache Spark\",\"Docker\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Cassandra\"]}\n\nJob Summary:\nBlockchain infrastructure company is hiring a Senior Backend Engineer to build distributed ledger services in Scala using Akka actors and Akka Streams. Kafka is used for event streaming. PostgreSQL and Cassandra are the data stores. Docker is required. The team values strong functional programming backgrounds and distributed systems expertise.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Scala is the required language and is present\",\"PostgreSQL and Cassandra are both listed datastores and are exact matches\",\"Docker is present\",\"Distributed systems and event-driven architecture are explicitly listed\",\"Haskell background provides a strong functional programming foundation that the team values\",\"Apache Spark experience shows production Scala usage\"],\"gaps\":[\"No Akka actors or Akka Streams experience listed, which are the specific concurrency frameworks the team uses\",\"No Kafka experience despite it being required for event streaming\"],\"explanation\":\"This candidate has strong functional programming credentials and the right language in Scala, with matching data stores and distributed systems architecture. The gaps are around Akka and Kafka specifically, which are the team's primary concurrency and streaming tools. These are learnable for an experienced Scala developer but represent real onboarding overhead.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"drizzle_diana\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Next.js\",\"React\",\"Drizzle ORM\",\"Tailwind CSS\",\"tRPC\"],\"architecture\":[\"Serverless\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nBootstrapped SaaS company is hiring a Mid-level Full Stack Engineer to build features in their Next.js app using tRPC for type-safe APIs and Drizzle ORM for database access. PostgreSQL is the database. Tailwind CSS is the styling system. Vitest and Playwright cover testing. Supabase is used for auth and storage. GitHub Actions handles CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js is the primary framework and is the candidate's core technology\",\"tRPC for type-safe APIs is an exact requirement match\",\"Drizzle ORM is directly listed and is explicitly required\",\"PostgreSQL is the database and is present\",\"Tailwind CSS is the styling system and is listed\",\"Vitest and Playwright satisfy both testing requirements exactly\",\"Supabase for auth and storage is present\",\"GitHub Actions for CI is listed\"],\"gaps\":[],\"explanation\":\"Every technology in the job description is present in this candidate's profile: Next.js, tRPC, Drizzle ORM, PostgreSQL, Tailwind CSS, Vitest, Playwright, Supabase, and GitHub Actions. This is a complete and precise match for the SaaS stack described. An ideal candidate.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"flink_farida\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Java\",\"Python\",\"SQL\"],\"tech\":[\"Apache Flink\",\"Apache Kafka\",\"Apache Spark\",\"Apache Airflow\"],\"databases\":[\"Cassandra\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitLab CI\"]}\n\nJob Summary:\nTelco company is hiring a Senior Data Engineer to build real-time event processing pipelines with Flink and Kafka. Java is the primary language. Cassandra serves as the operational datastore. Airflow handles batch orchestration. GitLab CI is the pipeline tool. Experience with BigQuery for analytics is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Apache Flink is the primary stream processing engine and is the candidate's core tool\",\"Apache Kafka for event processing is an exact match\",\"Java is the primary language and is listed first\",\"Cassandra for the operational datastore is directly present\",\"Apache Airflow for batch orchestration is listed\"],\"gaps\":[\"No GitLab CI experience; candidate's CI tooling is not explicitly listed\",\"No explicit experience with telco-specific data volumes or carrier-grade reliability patterns which operational Telco contexts often require\"],\"explanation\":\"This candidate covers the core technical requirements of Flink, Kafka, Java, Cassandra, and Airflow well. The absence of explicit GitLab CI experience and telco domain context introduces uncertainty for an industry where regulatory and reliability constraints shape engineering decisions. A strong technical match with domain context to explore.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"junior_java_jojo\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\"],\"tech\":[\"Spring Boot\",\"Maven\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nInsurance enterprise is hiring a Senior Java Engineer to lead a team of four engineers in modernizing a mission-critical Spring Boot platform to microservices. Kubernetes and Docker are required for orchestration. Kafka handles inter-service messaging. PostgreSQL replaces the legacy Oracle database. Strong mentoring and architectural design skills are expected along with 7 or more years of Java experience.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Spring Boot experience is relevant to the platform being modernized\",\"Java is the required language and is present\"],\"gaps\":[\"Junior seniority versus senior leadership with 7 or more years of experience required\",\"No Kubernetes or Docker for microservices orchestration\",\"No Kafka for inter-service messaging\",\"No PostgreSQL; uses MySQL and no experience with the database migration context\",\"No architectural design or team leadership experience at this career stage\",\"No mentoring experience evidenced\"],\"explanation\":\"This junior candidate has foundational Spring Boot and Java experience but lacks every operational, leadership, and architectural requirement of the role. The 7-year experience expectation and team leadership responsibility alone create an insurmountable gap for a junior engineer.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"temporal_tanya\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Temporal\",\"gRPC\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nFintech platform is hiring a Senior Backend Engineer to build durable workflow orchestration using Temporal in Go. gRPC handles inter-service communication. Kubernetes runs all workloads. PostgreSQL and Redis are the datastores. GitHub Actions and Argo CD support the CI/CD pipeline. An event-driven microservices background is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Temporal for workflow orchestration is the core requirement and is the candidate's primary platform tool\",\"Go is the required language and is listed first\",\"gRPC for inter-service communication is an exact match\",\"Kubernetes for workload orchestration is present\",\"PostgreSQL and Redis cover the datastore requirements exactly\"],\"gaps\":[\"No explicit experience with durable workflow failure handling patterns at production fintech scale, where compliance and audit trail requirements shape Temporal usage\",\"Argo CD is listed but the GitOps maturity depth for a regulated fintech environment is unclear\"],\"explanation\":\"This candidate has the core Temporal, Go, gRPC, Kubernetes, PostgreSQL, and Redis requirements covered. The open question is experience with Temporal in a regulated fintech context where audit trails and idempotent compensation logic are non-negotiable operational requirements. A technically strong candidate whose fintech-specific Temporal depth should be confirmed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"react_rajesh\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Redux\",\"Webpack\",\"Sass\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"Jest\",\"Enzyme\"]}\n\nJob Summary:\nConsumer app company is hiring a Mid-level Frontend Engineer to build features in their React Native mobile app. TypeScript is required. State management uses Redux Toolkit. The team writes tests with Jest and React Testing Library. Expo manages the build pipeline. GitHub Actions handles CI. Fastlane is used for automated releases.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React experience provides some component familiarity transferable to React Native\",\"TypeScript is required and evidenced\"],\"gaps\":[\"No React Native experience despite it being the primary platform\",\"No Expo for managed build pipeline\",\"No Fastlane for automated releases\",\"Jenkins is used instead of the required GitHub Actions\",\"Enzyme used instead of React Testing Library\",\"No mobile development experience of any kind in the profile\"],\"explanation\":\"This web frontend engineer has TypeScript and React skills but no mobile development background whatsoever. The absence of React Native, Expo, Fastlane, and mobile testing experience means the candidate would be learning the primary delivery platform from scratch. This is a domain mismatch that goes beyond tool gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lead_lena\",\"seniority\":\"Lead\",\"roles\":[\"Full Stack Engineer\",\"Software Architect\"],\"languages\":[\"TypeScript\",\"Go\"],\"tech\":[\"Next.js\",\"React\",\"NestJS\",\"Kubernetes\",\"Docker\"],\"architecture\":[\"Microservices\",\"Domain-Driven Design\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"Jest\",\"Vitest\",\"Playwright\",\"k6\"]}\n\nJob Summary:\nScale-up marketplace is hiring a Lead Full Stack Engineer to define engineering standards, lead architecture decisions across frontend and backend, and mentor a growing team. The stack is Next.js and NestJS with TypeScript. PostgreSQL and Redis are the datastores. Kubernetes and Argo CD manage deployments. Domain-driven design and event-driven patterns are practiced.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Lead seniority with software architect role matches the standards-setting and architectural leadership expectation\",\"Next.js and NestJS are both the primary frameworks and are both present\",\"TypeScript is required and is the candidate's primary language\",\"PostgreSQL and Redis are both listed\",\"Kubernetes and Argo CD for deployment management are both present\",\"Domain-Driven Design and event-driven architecture are both explicitly listed\",\"k6 demonstrates load testing maturity relevant to a marketplace scale-up\"],\"gaps\":[],\"explanation\":\"This Lead-level candidate satisfies every stated technical and leadership requirement: Next.js, NestJS, TypeScript, PostgreSQL, Redis, Kubernetes, Argo CD, DDD, and event-driven architecture. Their software architect role history and broad testing expertise make them a compelling choice for a team-defining engineering leader.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_ops_omar\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"MLflow\",\"Docker\",\"FastAPI\",\"scikit-learn\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nRetail AI startup is hiring a Mid-level ML Engineer to build and deploy recommendation system models using PyTorch. MLflow is required for experiment tracking. FastAPI for model serving endpoints. Docker for containerization. AWS SageMaker for cloud training. Kubernetes for inference deployment. Python is the primary language.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"MLflow for experiment tracking is an exact requirement match\",\"FastAPI for model serving endpoints is directly listed\",\"Docker for containerization is present\"],\"gaps\":[\"No PyTorch experience; the role centers on deep learning recommendation models which scikit-learn cannot address\",\"No AWS SageMaker or cloud ML training platform experience\",\"No Kubernetes for inference deployment at scale\"],\"explanation\":\"While this candidate has MLflow, FastAPI, and Docker which are relevant, the absence of PyTorch is a fundamental gap for a recommendation system role where deep learning is the core modeling approach. SageMaker and Kubernetes are additional missing components for a production ML serving pipeline.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"senior_sre_saoirse\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Prometheus\",\"Grafana\",\"Terraform\",\"Docker\",\"Helm\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nStreaming platform is hiring a Senior SRE to own reliability and observability for a Kubernetes-based microservices system on AWS. Prometheus and Grafana are the observability tools. Helm and Argo CD manage deployments. Terraform handles infrastructure provisioning. Python or Go scripting is required. Load testing experience with k6 is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Site Reliability Engineer role designation matches exactly\",\"Kubernetes expertise is central to the role and prominently listed\",\"Prometheus and Grafana are the observability tools and are both present\",\"Helm and Argo CD for deployment management are both listed\",\"Terraform for infrastructure provisioning is present\",\"Go and Python scripting are both covered\",\"k6 satisfies the load testing plus factor\"],\"gaps\":[\"No explicit AWS experience listed; cloud-native background only partially covers provider-specific services\"],\"explanation\":\"This candidate satisfies every stated technical requirement including observability, deployment management, and infrastructure tooling. The one mild gap is the lack of explicit AWS experience, as the platform runs on AWS where provider-specific service knowledge can matter. A high-confidence match pending AWS familiarity confirmation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cheap_charlie_cc\",\"seniority\":\"Junior\",\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"React\",\"Flask\"]}\n\nJob Summary:\nCybersecurity firm is hiring a Mid-level Application Security Engineer to conduct penetration testing, integrate SAST and DAST tools into CI/CD pipelines, and perform secure code reviews for Go and Java services. Experience with tools like Burp Suite, Semgrep, or Snyk is required. Docker and Kubernetes security hardening knowledge is expected. A minimum of 3 years in AppSec or penetration testing is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Junior seniority is well below the mid-level with 3 or more years of AppSec experience required\",\"No security engineering or penetration testing experience evidenced\",\"No SAST or DAST tooling such as Burp Suite, Semgrep, or Snyk\",\"No Go or Java experience relevant to the code review requirement\",\"No Docker or Kubernetes security hardening background\",\"No CI/CD security integration experience\",\"Profile shows a general web development background with no security domain signals\"],\"explanation\":\"This junior candidate has no overlap with the application security domain. The role requires specialized penetration testing and DevSecOps expertise that is entirely absent from the profile. There are no meaningful technical signals relevant to the position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sveltekit_samir\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"SvelteKit\",\"Svelte\",\"Drizzle ORM\",\"Tailwind CSS\"],\"architecture\":[\"Serverless\"],\"databases\":[\"PostgreSQL\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nBootstrapped startup is hiring a Senior Full Stack Engineer to own their SvelteKit application end to end. TypeScript is required. Drizzle ORM connects to a PostgreSQL database. Tailwind CSS is the styling system. Vitest and Playwright are used for testing. GitHub Actions handles CI. Serverless deployment on Cloudflare Workers is the target environment.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SvelteKit is the primary framework and is the candidate's core skill\",\"TypeScript is required and evidenced\",\"Drizzle ORM is explicitly required and is directly present\",\"PostgreSQL is the database and is listed\",\"Tailwind CSS is the styling system and is present\",\"Vitest and Playwright satisfy both testing requirements exactly\",\"GitHub Actions for CI is listed\",\"Serverless architecture background supports the Cloudflare Workers deployment model\"],\"gaps\":[\"No explicit Cloudflare Workers or Cloudflare platform experience listed\"],\"explanation\":\"This candidate matches every core requirement precisely: SvelteKit, TypeScript, Drizzle ORM, PostgreSQL, Tailwind CSS, Vitest, Playwright, and GitHub Actions. The only minor gap is the lack of explicit Cloudflare Workers experience, though their serverless background provides a directly relevant foundation. A strong match overall.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"gcp_gabriel\",\"seniority\":\"Senior\",\"roles\":[\"Cloud Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"Google Cloud\",\"Terraform\",\"Kubernetes\",\"Docker\",\"Ansible\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Cloud Build\"]}\n\nJob Summary:\nMedia company is hiring a Senior Cloud Engineer to manage and extend their GCP infrastructure. Terraform is required for provisioning. Kubernetes is the container orchestration platform. Cloud Build and GitHub Actions are used in CI/CD. BigQuery is the analytics data warehouse. Python or Go scripting is expected. Ansible for configuration management is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Google Cloud is the primary cloud and is the candidate's main cloud platform\",\"Terraform for provisioning is an exact match\",\"Kubernetes for container orchestration is present\",\"Cloud Build and GitHub Actions both satisfy the CI/CD requirements\",\"BigQuery is the analytics warehouse and is listed\"],\"gaps\":[\"No explicit experience with media workload patterns such as transcoding pipelines, CDN integration, or large-scale asset storage which media company infrastructure often involves\",\"Ansible is listed as a plus but the configuration management depth for the media company's fleet size is unclear\"],\"explanation\":\"This candidate covers the GCP infrastructure requirements well: Terraform, Kubernetes, Cloud Build, BigQuery, Python, and Go. The open question is experience with media-specific workloads where streaming, CDN management, and high-volume asset pipelines introduce domain-specific infrastructure patterns beyond general cloud-native work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"outdated_otto\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"XML\"],\"tech\":[\"Apache Struts\",\"Hibernate\",\"Maven\",\"Apache Tomcat\"],\"architecture\":[\"Monolith\",\"Layered Architecture\"],\"databases\":[\"Oracle\",\"MySQL\"],\"ci_cd\":[\"Ant\"]}\n\nJob Summary:\nCloud-native startup is hiring a Senior Backend Engineer to build serverless microservices in Go on AWS Lambda. The team uses DynamoDB and PostgreSQL. Kafka handles async messaging. Docker and Kubernetes manage containerized workloads. GitHub Actions is the CI platform. The team moves fast and expects engineers to own features from design to production on a modern cloud-native stack.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Java background provides general JVM ecosystem familiarity\"],\"gaps\":[\"No Go experience despite it being the required language\",\"No serverless or AWS Lambda experience\",\"No DynamoDB or PostgreSQL; candidate uses Oracle and MySQL in a legacy monolith context\",\"No Kafka for async messaging\",\"No Docker or Kubernetes for containerized workloads\",\"No GitHub Actions; candidate uses Ant which is a legacy build tool\",\"Profile is entirely anchored in legacy Java enterprise technologies inconsistent with the cloud-native startup stack\"],\"explanation\":\"This candidate's technical profile is deeply rooted in legacy Java enterprise technologies that are fundamentally misaligned with the cloud-native Go and serverless stack. The mismatch spans language, deployment model, data stores, messaging, and tooling. This is a complete technology generation mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"payload_petra\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"Payload CMS\",\"Tailwind CSS\"],\"databases\":[\"MongoDB\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nDigital agency is hiring a Mid-level Full Stack Developer to build content-driven websites using Next.js and Payload CMS. TypeScript is required. Tailwind CSS is the styling system. MongoDB is the primary CMS datastore. Jest and Playwright cover testing. GitHub Actions handles CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js is the primary framework and is a core skill\",\"Payload CMS is explicitly required and is directly listed\",\"TypeScript is required and evidenced\",\"Tailwind CSS is the styling system and is present\",\"MongoDB as the primary CMS datastore is listed\",\"Jest and Playwright satisfy both testing requirements exactly\",\"GitHub Actions for CI is present\"],\"gaps\":[],\"explanation\":\"This candidate is a precise match for every stated requirement: Next.js, Payload CMS, TypeScript, Tailwind CSS, MongoDB, Jest, and Playwright. Payload CMS expertise is a specific and uncommon signal that directly satisfies the primary tooling requirement. No gaps exist for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"langchain_leila\",\"seniority\":\"Senior\",\"roles\":[\"AI Engineer\",\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"LangChain\",\"LangGraph\",\"Hugging Face Transformers\",\"FastAPI\",\"Docker\",\"Ollama\"],\"databases\":[\"PostgreSQL\",\"Qdrant\",\"ChromaDB\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAI product startup is hiring a Senior AI Engineer to build multi-agent LLM workflows using LangGraph and LangChain. Hugging Face is used for model integration. FastAPI serves the inference endpoints. Vector databases such as Qdrant or Weaviate are required. Docker is used in development. GitHub Actions handles CI. Local model inference experience with Ollama is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LangGraph and LangChain are both explicitly required and are the candidate's primary tools\",\"Hugging Face Transformers for model integration is an exact match\",\"FastAPI for inference endpoints is directly listed\",\"Qdrant satisfies the vector database requirement\",\"Docker for development is present\",\"GitHub Actions for CI is listed\",\"Ollama for local model inference satisfies the plus factor\"],\"gaps\":[\"No Weaviate listed, though Qdrant is an accepted alternative for the vector database requirement\"],\"explanation\":\"This candidate hits every core requirement with exceptional specificity: LangGraph, LangChain, Hugging Face, FastAPI, Qdrant, Docker, and GitHub Actions, plus the Ollama bonus. The LangGraph expertise in particular is a rare and high-value signal for a multi-agent workflow role. An excellent match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"junior_flutter_jaden\",\"seniority\":\"Junior\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"JavaScript\"],\"tech\":[\"Flutter\",\"Firebase\"],\"databases\":[\"Firestore\"]}\n\nJob Summary:\nConsumer fintech app is hiring a Mid-level Flutter Engineer to build payment and KYC flows in Flutter. The candidate must have experience with state management using Riverpod or BLoC, integration testing with Flutter integration tests, and Fastlane for automated releases. Firebase is used for analytics. The role requires 3 or more years of production Flutter development.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Flutter is the required framework and is the candidate's primary skill\",\"Firebase experience is relevant to the analytics requirement\"],\"gaps\":[\"Junior seniority is below the mid-level with 3 or more years of production Flutter experience required\",\"No Riverpod or BLoC state management experience listed\",\"No integration testing or Flutter testing framework experience evidenced\",\"No Fastlane for automated releases\",\"No experience with payment flows or KYC processes which are domain-specific requirements\"],\"explanation\":\"This junior candidate has foundational Flutter and Firebase exposure but lacks the state management, testing, release automation, and domain-specific fintech experience required for a mid-level payment application role. The experience gap and missing production tooling make this a poor fit at this stage.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pulumi_paulo\",\"seniority\":\"Senior\",\"roles\":[\"Platform Engineer\",\"Infrastructure Engineer\"],\"languages\":[\"TypeScript\",\"Python\",\"Go\"],\"tech\":[\"Pulumi\",\"Kubernetes\",\"Terraform\",\"Docker\",\"Helm\"],\"architecture\":[\"Cloud-Native\",\"Multi-Tenant\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nSaaS infrastructure company is hiring a Senior Platform Engineer to design internal developer platforms and manage multi-tenant Kubernetes infrastructure. Pulumi is used for infrastructure as code with TypeScript. Helm and Argo CD handle deployment management. Docker for containerization is expected. GitHub Actions manages CI pipelines. Terraform experience is a bonus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Pulumi with TypeScript is the primary IaC tool and is an exact match\",\"Kubernetes for multi-tenant infrastructure is a core skill\",\"Helm and Argo CD for deployment management are both present\",\"Docker for containerization is listed\",\"GitHub Actions for CI is present\"],\"gaps\":[\"No explicit experience designing internal developer platforms or golden path tooling, which is the primary responsibility beyond infrastructure management\",\"Multi-tenant architecture is listed but no evidence of tenant isolation patterns at the security or network layer\"],\"explanation\":\"This candidate has strong infrastructure tooling coverage with Pulumi, Kubernetes, Helm, and Argo CD. The gap is around internal developer platform product thinking, which is distinct from infrastructure management and requires understanding of developer experience and self-service tooling design. A solid infrastructure candidate whose platform product experience should be assessed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"backend_bridget\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"Django REST Framework\",\"Celery\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nEdtech startup is hiring a Mid-level Backend Engineer to build a GraphQL API in Python. The team uses Strawberry GraphQL on top of Django. PostgreSQL is the primary database. Redis and Celery handle async jobs. Docker is used in development. pytest is the testing framework. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Django is the base framework and is the candidate's primary tool\",\"PostgreSQL is the primary database and is listed\",\"Celery and Redis for async jobs are an exact match\",\"Docker for development is present\",\"pytest satisfies the testing requirement\",\"GitHub Actions for CI is listed\"],\"gaps\":[\"No GraphQL or Strawberry GraphQL experience listed; candidate has REST API experience via Django REST Framework\",\"Switching from REST to GraphQL conventions requires non-trivial schema design and resolver pattern learning\"],\"explanation\":\"This candidate is strong on the Django, PostgreSQL, Redis, and Celery stack. The meaningful gap is the absence of any GraphQL or Strawberry experience, which is the team's primary API layer. REST to GraphQL is a conceptual and tooling shift that introduces onboarding overhead for an otherwise well-aligned candidate.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"principal_priya\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\",\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\",\"Rust\"],\"tech\":[\"Kubernetes\",\"Kafka\",\"gRPC\",\"Terraform\",\"Docker\",\"Istio\"],\"architecture\":[\"Microservices\",\"CQRS\",\"Event Sourcing\",\"Service Mesh\",\"Domain-Driven Design\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\",\"CockroachDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\",\"Tekton\"],\"testing\":[\"Go testing\",\"k6\"]}\n\nJob Summary:\nTech unicorn is hiring a Principal Engineer to define distributed systems standards, evaluate emerging technologies, and lead cross-team architectural initiatives. Go is the primary language. The platform uses Kafka, Kubernetes with Istio, and gRPC. CQRS and event sourcing patterns are applied at scale. Terraform manages infrastructure. DDD guides service boundaries.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Principal seniority with software architect background matches the cross-team architectural leadership requirement\",\"Go is the primary language and is listed first\",\"Kafka, Kubernetes with Istio, and gRPC are all explicitly present and required\",\"CQRS and event sourcing are both explicitly listed as practiced architecture patterns\",\"Domain-Driven Design is listed for service boundary guidance\",\"Terraform for infrastructure management is present\",\"Argo CD and Tekton add GitOps and pipeline depth beyond the stated requirements\",\"CockroachDB and Cassandra depth signals distributed data systems expertise\"],\"gaps\":[],\"explanation\":\"This is an exceptional candidate for a principal-level distributed systems role. Every stated requirement from language to architecture patterns to tooling is explicitly present, and their additional Rust, Tekton, and CockroachDB experience signals broad systems depth. A top-tier architectural leader.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"table_tamar\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Tableau\",\"Power BI\",\"Pandas\"],\"databases\":[\"Snowflake\",\"MySQL\"]}\n\nJob Summary:\nHealthcare company is hiring a Mid-level Data Analyst to build clinical operations dashboards in Looker and write complex SQL queries against BigQuery. Python for data cleaning is a plus. The role requires understanding of healthcare metrics and experience with large healthcare datasets. Familiarity with dbt models is preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"SQL proficiency is a core requirement and is present\"],\"gaps\":[\"No Looker experience; uses Tableau and Power BI which have incompatible expression languages\",\"No BigQuery; uses Snowflake and MySQL in non-healthcare contexts\",\"No dbt model familiarity despite it being preferred\",\"No healthcare domain experience with clinical metrics or HIPAA-relevant data handling\"],\"explanation\":\"This candidate lacks three of the four primary technical tools the role requires: Looker, BigQuery, and dbt. The healthcare domain gap further reduces confidence for a clinical operations dashboard role where regulatory context shapes data access and presentation. A weak fit requiring significant tool and domain ramp.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nativescript_neal\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NativeScript\",\"Angular\",\"Firebase\"],\"databases\":[\"Firestore\",\"SQLite\"]}\n\nJob Summary:\nEnterprise company is hiring a Mid-level React Native Engineer to build cross-platform mobile apps in TypeScript. The team uses Redux Toolkit for state management, React Navigation for routing, and Detox for E2E testing. Fastlane handles automated releases. Firebase is used for push notifications. GitHub Actions is the CI tool.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript is required and evidenced\",\"Firebase experience is relevant to the push notification requirement\"],\"gaps\":[\"No React Native experience; candidate uses NativeScript with Angular which is a different framework and paradigm\",\"No Redux Toolkit or Redux state management experience\",\"No React Navigation experience\",\"No Detox for E2E testing\",\"No Fastlane for automated releases\",\"No GitHub Actions or CI/CD pipeline experience\"],\"explanation\":\"This candidate's mobile experience is in NativeScript with Angular, which is architecturally different from React Native. The absence of React Native, Redux Toolkit, Detox, and Fastlane means the candidate would need to rebuild their mobile tooling knowledge from the ground up. Firebase is the only meaningful overlap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mlflow_mario\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"Data Scientist\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"PyTorch\",\"MLflow\",\"FastAPI\",\"Docker\",\"Weights & Biases\"],\"databases\":[\"PostgreSQL\",\"Pinecone\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nAI-first enterprise is hiring a Senior ML Engineer to train and serve large language models. PyTorch is the training framework. MLflow and Weights and Biases are used for experiment tracking and model registry. FastAPI powers inference endpoints. Docker for containerization. Pinecone is the vector database for retrieval workflows. GitHub Actions for CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PyTorch is the training framework and is the candidate's primary ML tool\",\"MLflow is explicitly required and is present\",\"Weights and Biases satisfies the second experiment tracking requirement\",\"FastAPI for inference endpoints is an exact match\",\"Docker for containerization is listed\",\"Pinecone for vector database retrieval is directly present\",\"GitHub Actions for CI is listed\",\"pytest ensures testing discipline for ML code\"],\"gaps\":[],\"explanation\":\"This candidate precisely satisfies every requirement: PyTorch, MLflow, Weights and Biases, FastAPI, Docker, Pinecone, and GitHub Actions. The combination of training, tracking, and serving experience across the full ML lifecycle makes them an ideal candidate for the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"coldfusion_carl\",\"seniority\":\"Senior\",\"languages\":[\"ColdFusion\",\"JavaScript\"],\"tech\":[\"ColdFusion\",\"jQuery\"],\"databases\":[\"MS SQL Server\",\"MySQL\"]}\n\nJob Summary:\nFintec startup is hiring a Senior Full Stack Engineer to build microservices in Node.js and TypeScript with a React frontend. PostgreSQL and Redis are the datastores. Docker and Kubernetes are required. GraphQL is the API layer. GitHub Actions handles CI. Jest and Playwright are used for testing.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"JavaScript provides a minimal foundation for TypeScript and React transition\"],\"gaps\":[\"No TypeScript or Node.js experience despite being the primary backend language\",\"No React experience; candidate uses jQuery\",\"No PostgreSQL or Redis; candidate uses MS SQL Server and MySQL in a legacy context\",\"No Docker or Kubernetes experience\",\"No GraphQL experience\",\"No modern CI/CD tooling such as GitHub Actions\",\"ColdFusion is a legacy technology with no relevance to the modern microservices stack\"],\"explanation\":\"This candidate's skills are rooted in legacy ColdFusion and jQuery technologies with no overlap with the modern Node.js, TypeScript, React, and Kubernetes stack. The technology generation gap is severe across every dimension of the role including language, framework, deployment, and API architecture.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"solid_js_soren\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Solid.js\",\"React\",\"Tailwind CSS\",\"Vite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nPerformance-focused startup is building their product dashboard in Solid.js with TypeScript. Tailwind CSS is the styling layer. Vite is the build tool. Vitest and Playwright handle testing. GitHub Actions manages CI. The team values fine-grained reactivity patterns and pure component design.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Solid.js is the primary framework and is the candidate's most prominent skill\",\"TypeScript is required and evidenced\",\"Tailwind CSS is the styling layer and is present\",\"Vite as the build tool is an exact match\",\"Vitest and Playwright satisfy both testing requirements exactly\"],\"gaps\":[\"No backend or API integration experience listed, which a product dashboard role typically requires for data fetching and authentication flows\",\"No state management library listed beyond Solid.js's built-in reactivity, which may be insufficient for complex dashboard state\"],\"explanation\":\"This candidate's frontend stack is a precise match for Solid.js, TypeScript, Tailwind CSS, Vite, and testing requirements. For a product dashboard role, the absence of backend integration and complex state management experience introduces uncertainty around owning data-heavy features end to end. A technically aligned candidate with full-stack scope to assess.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cdk_constance\",\"seniority\":\"Senior\",\"roles\":[\"Cloud Engineer\",\"DevOps Engineer\"],\"languages\":[\"TypeScript\",\"Python\",\"Bash\"],\"tech\":[\"AWS\",\"Docker\",\"Kubernetes\",\"Terraform\"],\"architecture\":[\"Serverless\",\"Cloud-Native\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\"],\"ci_cd\":[\"GitHub Actions\",\"AWS CodePipeline\"]}\n\nJob Summary:\nE-commerce company is hiring a Senior AWS Cloud Engineer to manage multi-account AWS infrastructure. Terraform is the IaC tool. Kubernetes runs microservices on EKS. DynamoDB and PostgreSQL are the datastores. GitHub Actions and AWS CodePipeline handle CI/CD. Python and TypeScript scripting are required. Serverless Lambda experience is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"AWS is the primary cloud and is the candidate's main platform\",\"Terraform for IaC is an exact match\",\"Kubernetes on EKS is supported by the candidate's Kubernetes experience\",\"DynamoDB and PostgreSQL are both listed as datastores\",\"GitHub Actions and AWS CodePipeline both satisfy the CI/CD requirements\",\"Python and TypeScript scripting are both present\",\"Serverless architecture background satisfies the Lambda plus factor\"],\"gaps\":[],\"explanation\":\"This candidate covers every stated requirement: AWS, Terraform, Kubernetes, DynamoDB, PostgreSQL, GitHub Actions, AWS CodePipeline, Python, TypeScript, and serverless architecture. Their multi-dimensional AWS experience makes them an ideal match for the multi-account infrastructure management role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"htmx_hugo\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\",\"Backend Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Django\",\"HTMX\",\"Alpine.js\",\"Tailwind CSS\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nSmall SaaS startup is hiring a Senior Full Stack Engineer to build a lean web application using Django and HTMX with minimal JavaScript. Tailwind CSS is the styling system. PostgreSQL is the primary database. Redis is used for caching and sessions. Docker is required for local development. pytest is the testing framework. GitHub Actions handles CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Django is the primary backend framework and is the candidate's core technology\",\"HTMX is explicitly required for the minimal JavaScript approach and is directly listed\",\"Tailwind CSS is the styling system and is present\",\"PostgreSQL is the primary database and is listed\",\"Redis for caching and sessions is an exact match\"],\"gaps\":[\"No pytest experience listed despite it being the stated testing framework\",\"Docker is listed but no production deployment context such as hosting platform or server configuration is evidenced\"],\"explanation\":\"This candidate's Django and HTMX combination is a direct and uncommon match for the role's technical philosophy. The absence of pytest and limited production deployment context are the open questions for a senior full stack ownership role. A strong technical profile with operational depth to confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"trino_theo\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Spark\",\"dbt\",\"Apache Airflow\",\"Apache Kafka\"],\"databases\":[\"Snowflake\",\"PostgreSQL\",\"ClickHouse\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAnalytics company is hiring a Senior Data Engineer to optimize query performance on a ClickHouse-based analytics platform. dbt manages transformations. Python and SQL are required. Airflow orchestrates data pipelines. Kafka feeds real-time data into the warehouse. Snowflake is used for archival analytics. Apache Spark experience is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"ClickHouse is the primary analytics platform and is explicitly present in the profile\",\"dbt for transformations is an exact match\",\"Airflow for pipeline orchestration is directly listed\",\"Python and SQL are both present\",\"Kafka for real-time data ingestion is listed\",\"Snowflake for archival analytics is present\",\"Apache Spark satisfies the strong plus requirement\"],\"gaps\":[],\"explanation\":\"This candidate covers every requirement including the Spark strong plus: ClickHouse, dbt, Airflow, Python, SQL, Kafka, and Snowflake. Their broad analytics engineering stack directly matches the platform's technology choices. A highly aligned hire.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"expo_eleanor\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Expo\",\"React Native\",\"React Query\",\"Zustand\"],\"databases\":[\"Supabase\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"Jest\",\"Detox\"]}\n\nJob Summary:\nTravel app startup is hiring a Mid-level React Native Engineer. The stack is Expo with TypeScript. Zustand handles state management. React Query manages server state and data fetching. Supabase is used for auth and real-time data. Fastlane handles releases. Jest and Detox are the testing tools. GitHub Actions is the CI platform.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Expo and React Native are the primary frameworks and are both present\",\"TypeScript is required and evidenced\",\"Zustand for state management is an exact match\",\"React Query for server state and data fetching is directly listed\",\"Supabase for auth and real-time data is present\"],\"gaps\":[\"No explicit experience with travel domain features such as booking flows, real-time availability, or map integrations which travel app complexity often involves\",\"Fastlane and GitHub Actions are present but release management depth for a dual-platform consumer app is unclear\"],\"explanation\":\"This candidate covers the technical stack requirements well across Expo, React Native, TypeScript, Zustand, React Query, and Supabase. The open questions are around travel domain complexity and production release management depth for a consumer app with frequent dual-platform deployments. A technically strong match with domain and operational context to explore.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"deno_derek\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Deno\",\"Express.js\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nStartup is hiring a Mid-level Backend Engineer to build REST APIs and background services using Node.js with NestJS in TypeScript. PostgreSQL is the primary database. BullMQ is used for job queues backed by Redis. Docker is used in development. Jest covers unit and integration testing. GitHub Actions handles CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript is required and is the candidate's primary language\",\"PostgreSQL is the primary database and is present\",\"Redis is listed and supports the BullMQ job queue backend\",\"Docker for development is present\",\"Jest satisfies the testing requirement\",\"GitHub Actions for CI is listed\"],\"gaps\":[\"No NestJS experience; candidate uses Deno and Express.js which are different runtime and framework environments\",\"No BullMQ experience for job queue management\",\"Deno is a different JavaScript runtime from Node.js and has compatibility differences that require adjustment\"],\"explanation\":\"This candidate brings TypeScript, PostgreSQL, Redis, Docker, and Jest which are all relevant. The primary gaps are NestJS versus their Express.js and Deno background, and the absence of BullMQ. The Deno-to-Node.js runtime difference is a moderate adjustment, and the NestJS framework conventions require dedicated learning. A possible fit with a clear onboarding plan.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"minimal_mona\",\"seniority\":\"Junior\",\"languages\":[\"Python\"],\"tech\":[\"Flask\",\"Pandas\"]}\n\nJob Summary:\nData company is hiring a Junior Data Engineer to build and maintain ELT pipelines using dbt on Snowflake. Python is required. Airflow orchestrates all pipelines. The candidate should be comfortable writing SQL transformations and working with cloud data warehouses. GitHub Actions handles CI. Great Expectations is used for data quality checks.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is the required language and is present\"],\"gaps\":[\"No dbt experience despite it being the core transformation tool\",\"No Snowflake or cloud data warehouse experience\",\"No Airflow or pipeline orchestration experience\",\"No SQL transformation or ELT pipeline experience evidenced\",\"No GitHub Actions or CI/CD pipeline experience\",\"No Great Expectations for data quality\",\"Flask and Pandas indicate a general Python background, not data engineering tooling\"],\"explanation\":\"This junior candidate has only general Python experience with Flask and Pandas, with no overlap with the data engineering toolchain the role requires. dbt, Snowflake, Airflow, and Great Expectations are all absent, making this a profile that lacks both domain and tool-specific readiness for the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"spring_reactive_sofia\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Spring WebFlux\",\"Kafka\",\"Docker\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\",\"Testcontainers\"]}\n\nJob Summary:\nStreaming platform is hiring a Senior Java Backend Engineer to build reactive microservices using Spring WebFlux. Kafka is used for event streaming. PostgreSQL and Redis are the datastores. Docker is required. JUnit and Mockito cover unit testing. Testcontainers is used for integration testing. GitHub Actions handles CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Spring WebFlux is the primary reactive framework and is explicitly listed\",\"Kafka for event streaming is an exact match\",\"PostgreSQL and Redis are both present as datastores\",\"Docker is listed\",\"JUnit and Mockito cover unit testing requirements\"],\"gaps\":[\"No Testcontainers experience listed despite it being explicitly required for integration testing\",\"Reactive programming patterns in Spring WebFlux can vary significantly in production and depth of experience is hard to gauge from the profile alone\"],\"explanation\":\"This candidate covers Spring WebFlux, Kafka, PostgreSQL, Redis, Docker, JUnit, and Mockito. The notable gap is the absence of Testcontainers, which is an explicit integration testing requirement. Testcontainers is a specific tool that requires intentional adoption and its absence is a meaningful signal for a team that relies on it.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tableau_tobias\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\",\"Analytics Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Tableau\",\"dbt\",\"Great Expectations\",\"Pandas\"],\"databases\":[\"Snowflake\",\"BigQuery\"]}\n\nJob Summary:\nRetail company is hiring a Mid-level Analytics Engineer to build and maintain dbt models on Snowflake, implement data quality checks with Great Expectations, and build Tableau dashboards for business stakeholders. SQL and Python are required. BigQuery experience is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt for transformation modeling is an exact requirement match\",\"Snowflake is the primary platform and is the candidate's primary warehouse\",\"Great Expectations for data quality checks is explicitly required and present\",\"Tableau for business dashboards is directly listed\",\"SQL and Python are both present\",\"BigQuery satisfies the plus requirement\",\"Analytics Engineer role designation matches directly\"],\"gaps\":[],\"explanation\":\"This candidate covers every requirement with exact specificity: dbt, Snowflake, Great Expectations, Tableau, SQL, Python, and BigQuery. The match is complete across transformation, data quality, visualization, and platform layers. An excellent candidate for the retail analytics engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ios_intermediate_ivan\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Combine\"],\"architecture\":[\"Modular Architecture\",\"Client-Server\"],\"databases\":[\"CoreData\",\"Firebase\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"XCTest\",\"XCUITest\"]}\n\nJob Summary:\nSocial app company is hiring a Mid-level iOS Engineer to build and maintain features in Swift using SwiftUI and UIKit. Combine is used for reactive data flows. CoreData manages local persistence. Firebase handles push notifications. Fastlane and GitHub Actions manage CI/CD. XCTest and XCUITest are the testing frameworks. Modular architecture is practiced.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SwiftUI and UIKit are both present for the hybrid UI requirement\",\"Swift is the required language and is the candidate's primary language\",\"Combine for reactive data flows is an exact match\",\"CoreData for local persistence is directly listed\",\"Firebase for push notifications is present\"],\"gaps\":[\"No explicit social app domain experience with features like feeds, real-time messaging, or content discovery at 10M user scale\",\"XCTest and XCUITest are listed but test coverage depth for a high-velocity consumer social app is unclear\"],\"explanation\":\"This candidate has solid iOS technical fundamentals covering SwiftUI, UIKit, Combine, CoreData, and Firebase. For a social app company operating at significant scale, the absence of social feature domain experience and performance optimization context for high-concurrency mobile use cases are worth exploring in assessment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mlflow_mehdi\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\",\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"XGBoost\",\"MLflow\",\"Pandas\",\"NumPy\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nInsurtech startup is hiring a Senior Data Scientist to build and deploy actuarial risk models using PyTorch and TensorFlow. MLflow is required for tracking. The team runs model training on AWS SageMaker. Docker and Kubernetes are used for serving. Python is required. Experience with deep learning architectures is essential.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"MLflow for experiment tracking is present\",\"Python is the required language and is present\"],\"gaps\":[\"No PyTorch or TensorFlow experience despite deep learning being listed as essential\",\"No deep learning architecture knowledge for actuarial risk modeling\",\"No AWS SageMaker for cloud model training\",\"No Docker or Kubernetes for model serving infrastructure\"],\"explanation\":\"This candidate's classical ML background with scikit-learn and XGBoost is fundamentally misaligned with a role requiring deep learning for actuarial risk modeling. PyTorch and TensorFlow expertise is described as essential, and its absence combined with missing SageMaker and Kubernetes experience makes this a poor fit despite strong MLflow alignment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nest_ng_nora\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"NestJS\",\"Angular\",\"Prisma\",\"Tailwind CSS\",\"Docker\"],\"architecture\":[\"Monolith\",\"Domain-Driven Design\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Cypress\"]}\n\nJob Summary:\nEnterprise SaaS company is building an internal tooling platform using NestJS for the backend and Angular for the frontend, both in TypeScript. Prisma manages database access to PostgreSQL. Redis is used for caching. Docker is required. GitHub Actions handles CI. Jest and Cypress cover unit and E2E testing. Domain-driven design guides the architecture.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"NestJS is the primary backend framework and is the candidate's main tool\",\"Angular is the primary frontend framework and is directly listed\",\"TypeScript is the required language and is the candidate's primary language\",\"Prisma for database access is an exact match\",\"PostgreSQL is the primary database and is listed\"],\"gaps\":[\"No explicit enterprise internal tooling experience where access control, SSO integration, and audit logging are common non-functional requirements\",\"Redis caching is listed but the session and caching patterns for an enterprise internal platform introduce specific security constraints not evidenced in the profile\"],\"explanation\":\"This candidate has precise technical alignment with NestJS, Angular, TypeScript, Prisma, and PostgreSQL. For an enterprise internal platform, the gaps are around enterprise-specific patterns like RBAC, SSO, and compliance logging which are often required but not evidenced from public GitHub signals alone. A technically strong candidate whose enterprise context experience should be confirmed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dagster_dani\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Dagster\",\"dbt\",\"Polars\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAnalytics startup is hiring a Mid-level Data Engineer to build and orchestrate data pipelines using Dagster and dbt on Snowflake. Python and SQL are required. Docker is used in development. GitHub Actions handles CI. Polars or Pandas for data manipulation is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Dagster for pipeline orchestration is the primary requirement and is the candidate's core tool\",\"dbt for transformation is an exact match\",\"Snowflake is the primary warehouse and is listed\",\"Python and SQL are both present\",\"Docker for development is listed\",\"GitHub Actions for CI is present\",\"Polars satisfies the data manipulation requirement\"],\"gaps\":[],\"explanation\":\"This candidate satisfies every requirement precisely: Dagster, dbt, Snowflake, Python, SQL, Docker, GitHub Actions, and Polars. Dagster expertise is a specific and uncommon signal that directly satisfies the primary orchestration requirement. A complete and ideal match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"aws_lambda_ali\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\",\"Cloud Engineer\"],\"languages\":[\"Python\",\"TypeScript\"],\"tech\":[\"AWS Lambda\",\"AWS\",\"Docker\",\"FastAPI\"],\"architecture\":[\"Serverless\",\"Microservices\"],\"databases\":[\"DynamoDB\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"AWS CodePipeline\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nStartup is hiring a Mid-level Backend Engineer to build serverless APIs on AWS Lambda using Python. DynamoDB is the primary datastore. API Gateway fronts the Lambda functions. AWS CodePipeline and GitHub Actions handle CI/CD. pytest is the testing framework. Serverless and microservices architecture patterns are practiced.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"AWS Lambda is the primary compute and is the candidate's primary cloud service\",\"Python is the required language and is present\",\"DynamoDB is the primary datastore and is listed\",\"AWS CodePipeline and GitHub Actions both satisfy the CI/CD requirements exactly\",\"pytest satisfies the testing requirement\",\"Serverless and microservices architecture are both explicitly listed\",\"FastAPI experience complements Lambda-based API development\"],\"gaps\":[\"No explicit AWS API Gateway experience listed, though Lambda and AWS platform experience strongly implies familiarity\"],\"explanation\":\"This candidate is a precise match for the serverless AWS role: Lambda, Python, DynamoDB, AWS CodePipeline, GitHub Actions, and pytest are all present. The only minor gap is the absence of explicit API Gateway experience, which is trivially covered by their Lambda and AWS platform depth. A strong hire.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"supabase_samuel\",\"seniority\":\"Junior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"Supabase\",\"Tailwind CSS\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nConsumer app startup is hiring a Junior Full Stack Developer to build features in their Next.js application. Supabase handles auth, storage, and the PostgreSQL database. TypeScript is required. Tailwind CSS is the styling system. GitHub Actions is used for CI. Vitest or Jest is the testing framework.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js is the primary framework and is the candidate's core technology\",\"Supabase for auth, storage, and database is an exact match\",\"PostgreSQL is the underlying database and is listed\",\"TypeScript is required and evidenced\",\"Tailwind CSS is the styling system and is listed\"],\"gaps\":[\"No testing framework listed, which is a requirement (Vitest or Jest)\",\"No GitHub Actions or CI/CD pipeline experience evidenced\"],\"explanation\":\"This candidate matches the core stack well: Next.js, Supabase, TypeScript, Tailwind CSS, and PostgreSQL are all present. The gaps are in testing and CI/CD, which are both stated requirements. For a junior role, these are learnable but represent skills the team would need to actively develop in the candidate.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hasura_hana\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Hasura\",\"Next.js\",\"React\",\"FastAPI\",\"Docker\"],\"architecture\":[\"Serverless\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nB2C startup is hiring a Senior Full Stack Engineer to build features using Next.js and a Hasura GraphQL backend on PostgreSQL. FastAPI handles custom business logic endpoints. Redis is used for caching. Docker is required. GitHub Actions manages CI. Jest, Playwright, and pytest cover frontend, E2E, and backend testing respectively.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Hasura for GraphQL backend on PostgreSQL is an exact and specific match\",\"Next.js is the primary frontend framework and is present\",\"FastAPI for custom business logic is directly listed\",\"PostgreSQL is the underlying database and is present\",\"Redis for caching is listed\"],\"gaps\":[\"No explicit consumer-scale experience with real-time Hasura subscriptions under high concurrent user load which B2C apps often require\",\"Docker is present but no Kubernetes or production orchestration context is evidenced for a consumer-scale deployment\"],\"explanation\":\"This candidate's Hasura, Next.js, FastAPI, and PostgreSQL coverage is strong and specific. For a B2C startup expecting scale, the open questions are around high-concurrency Hasura subscription handling and production deployment orchestration beyond local Docker usage. A technically precise candidate with scale readiness to assess.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"arangodb_ava\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Express.js\",\"Node.js\",\"Docker\"],\"databases\":[\"ArangoDB\",\"Redis\",\"MongoDB\"],\"ci_cd\":[\"GitLab CI\"]}\n\nJob Summary:\nKnowledge graph company is hiring a Senior Backend Engineer to build graph traversal APIs on top of ArangoDB using Node.js and TypeScript. Redis is used for caching query results. Docker is required. GitLab CI handles pipelines. REST API design experience is expected. GraphQL support for the API layer is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"ArangoDB is the primary database and is the candidate's most relevant experience signal\",\"Node.js and TypeScript cover the language and runtime requirements\",\"Redis for caching is present\",\"Docker is listed\",\"GitLab CI is the pipeline tool and matches exactly\",\"REST API experience via Express.js is relevant\"],\"gaps\":[\"No TypeScript listed as primary; JavaScript is listed first and TypeScript is secondary, introducing uncertainty about TypeScript depth\",\"No GraphQL experience listed for the API plus requirement\",\"No explicit graph traversal or AQL query experience evidenced beyond ArangoDB listing\"],\"explanation\":\"This candidate has the most critical requirement in ArangoDB experience, along with supporting Node.js, Redis, Docker, and GitLab CI coverage. The gaps around TypeScript depth, AQL graph traversal specifics, and GraphQL are worth exploring but do not disqualify an otherwise relevant profile. A moderate fit with specific depth to be confirmed in technical screening.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"clickhouse_claire\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\",\"Analytics Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"ClickHouse\",\"dbt\",\"Apache Kafka\",\"Apache Airflow\"],\"databases\":[\"ClickHouse\",\"PostgreSQL\",\"Snowflake\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAdtech company is hiring a Senior Analytics Engineer to manage a ClickHouse analytics stack. dbt handles all transformation logic. Airflow orchestrates batch pipelines. Kafka feeds real-time ad event data. SQL and Python are required. GitHub Actions manages CI. Snowflake is a secondary data store.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"ClickHouse is the primary analytics platform and is the candidate's core database\",\"dbt for transformation logic is an exact match\",\"Airflow for batch pipeline orchestration is directly listed\",\"Kafka for real-time ad event data ingestion is present\",\"SQL and Python are both evidenced\"],\"gaps\":[\"No explicit adtech domain experience with impression tracking, click attribution, or bid stream data patterns which adtech analytics typically involves\",\"GitHub Actions CI experience is not explicitly evidenced in the profile\"],\"explanation\":\"This candidate's ClickHouse, dbt, Airflow, and Kafka stack is well-aligned with the technical requirements. The open question is adtech domain familiarity, where impression-level data modeling, attribution windows, and bid stream schema design introduce domain-specific complexity that is not visible in a general data engineering profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"frontend_fatima\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Framer Motion\",\"Radix UI\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nDesign-focused SaaS company is hiring a Mid-level Frontend Engineer to build polished UI components with React, Tailwind CSS, and Radix UI. TypeScript is required. Framer Motion is used for animations. Vitest and Playwright handle testing. GitHub Actions manages CI. Next.js is used for the application framework.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React is the primary component framework and is the candidate's core skill\",\"Tailwind CSS is explicitly required and is listed\",\"Radix UI is explicitly required and is directly present\",\"Framer Motion for animations is an exact match\",\"TypeScript is required and evidenced\",\"Vitest and Playwright satisfy both testing requirements\",\"GitHub Actions for CI is listed\",\"Next.js is the application framework and is present\"],\"gaps\":[],\"explanation\":\"This candidate matches every requirement precisely: React, Tailwind CSS, Radix UI, Framer Motion, TypeScript, Vitest, Playwright, GitHub Actions, and Next.js. The Radix UI and Framer Motion combination is a specific and uncommon signal that makes this candidate particularly well-suited for a design-focused product team. No gaps exist.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kotlin_mpp_kai\",\"seniority\":\"Senior\",\"roles\":[\"Mobile Engineer\",\"Backend Engineer\"],\"languages\":[\"Kotlin\",\"Swift\"],\"tech\":[\"Kotlin Multiplatform\",\"Jetpack Compose\",\"SwiftUI\",\"Ktor\"],\"architecture\":[\"Modular Architecture\",\"Client-Server\"],\"databases\":[\"SQLite\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"]}\n\nJob Summary:\nProductivity app company is hiring a Senior Mobile Engineer to build a cross-platform app using Kotlin Multiplatform. The shared business logic layer is in Kotlin. The iOS UI uses SwiftUI and Android uses Jetpack Compose. Ktor is used for the networking client. Fastlane and GitHub Actions manage CI/CD. Modular architecture is practiced.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kotlin Multiplatform is the core framework and is the candidate's primary mobile technology\",\"SwiftUI for the iOS UI layer is present\",\"Jetpack Compose for the Android UI layer is directly listed\",\"Ktor for the networking client is an exact match\",\"Kotlin is the shared logic language and is the candidate's primary language\",\"Fastlane and GitHub Actions satisfy the CI/CD requirements exactly\",\"Modular architecture is explicitly listed\"],\"gaps\":[],\"explanation\":\"This candidate is a precisely aligned match for every requirement: Kotlin Multiplatform, SwiftUI, Jetpack Compose, Ktor, Fastlane, and GitHub Actions. KMP expertise combined with native UI knowledge for both platforms is an exceptional and rare profile for this type of cross-platform role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"spark_streaming_sasha\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Spark\",\"PySpark\",\"Apache Airflow\",\"dbt\"],\"databases\":[\"Databricks\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nInsurance company is hiring a Mid-level Data Engineer to build batch ETL pipelines using dbt on Snowflake, orchestrated by Prefect. Python and SQL are required. The team is migrating away from a Spark-based architecture toward a dbt-native approach. GitHub Actions handles CI. Experience with data quality tooling is preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"dbt is present and is the team's primary transformation tool\",\"Python and SQL are both required and evidenced\"],\"gaps\":[\"No Snowflake experience; candidate works with Databricks which the team is migrating away from\",\"No Prefect experience; uses Airflow which is a different orchestration paradigm\",\"The team is explicitly migrating away from Spark, making the candidate's primary skill set strategically irrelevant\",\"No data quality tooling such as Great Expectations\"],\"explanation\":\"This candidate faces a compounding misalignment: their strongest skill, Spark on Databricks, is explicitly being deprecated by the hiring team. The orchestration mismatch with Prefect versus Airflow and the absence of Snowflake further compound the gap. A technically capable data engineer whose skills are pointed in the opposite direction from the team's trajectory.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"weaviate_walter\",\"seniority\":\"Mid\",\"roles\":[\"AI Engineer\",\"Backend Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"LangChain\",\"FastAPI\",\"Docker\",\"OpenAI API\"],\"databases\":[\"Weaviate\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nLegaltech company is hiring a Mid-level AI Engineer to build document search and summarization pipelines using LangChain, OpenAI API, and Weaviate as the vector store. FastAPI serves the inference endpoints. Docker is required. pytest is the testing framework. GitHub Actions manages CI. PostgreSQL stores document metadata.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"LangChain is the pipeline framework and is the candidate's primary tool\",\"OpenAI API integration experience is directly listed\",\"Weaviate is the vector store and is an exact match\",\"FastAPI for inference endpoints is an exact match\",\"Docker is present\"],\"gaps\":[\"No explicit legaltech domain experience with document structure, legal citation formats, or jurisdiction-specific processing which legaltech document pipelines often require\",\"No experiment tracking or model evaluation framework listed for iterating on summarization quality\"],\"explanation\":\"This candidate has strong technical coverage across LangChain, OpenAI API, Weaviate, FastAPI, and Docker. The gaps are around legaltech domain knowledge and model evaluation practices. Legal document processing involves highly specific document structures and accuracy expectations that benefit from domain familiarity not evidenced in the profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"go_fiber_gene\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Fiber\",\"Docker\",\"gRPC\",\"Redis\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Go testing\"]}\n\nJob Summary:\nE-commerce startup is hiring a Mid-level Go Backend Engineer to build REST APIs using Gin framework. PostgreSQL is the primary datastore. Redis is used for caching. Docker is required. gRPC is used for internal service calls. GitHub Actions handles CI. The team writes tests using Go's standard testing package.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go is the required language and is the candidate's primary language\",\"PostgreSQL is the primary datastore and is present\",\"Redis for caching is an exact match\",\"Docker is listed\",\"gRPC for internal service calls is an exact match\",\"GitHub Actions for CI is listed\",\"Go testing satisfies the testing requirement\"],\"gaps\":[\"No Gin framework experience; candidate uses Fiber which is a different Go web framework with a different API surface\",\"Gin versus Fiber is a minor but real framework transition requiring adjustment to routing, middleware, and handler patterns\"],\"explanation\":\"This candidate covers the core Go, PostgreSQL, Redis, Docker, gRPC, and testing requirements well. The only gap is the Fiber versus Gin framework difference, which is a moderate adjustment within the Go ecosystem. Both are high-performance web frameworks but have different API conventions that require some learning. A strong candidate pending Gin familiarity confirmation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"airflow_anya\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\",\"Platform Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Airflow\",\"dbt\",\"Docker\",\"Kubernetes\",\"Terraform\"],\"databases\":[\"Snowflake\",\"PostgreSQL\",\"Redshift\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"]}\n\nJob Summary:\nCloud data company is hiring a Senior Data Platform Engineer to manage and extend the Airflow orchestration infrastructure on Kubernetes, maintain dbt transformation pipelines on Snowflake, and provision cloud resources with Terraform. Python and SQL are required. Docker is used throughout. GitHub Actions handles CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Apache Airflow is the core orchestration tool and is the candidate's primary platform skill\",\"Kubernetes for running Airflow infrastructure is present\",\"dbt for transformation pipelines is an exact match\",\"Snowflake is the primary warehouse and is listed\",\"Terraform for cloud resource provisioning is an exact match\"],\"gaps\":[\"No explicit experience running Airflow at scale on Kubernetes with high task parallelism which is operationally complex and distinct from standard Airflow usage\",\"No observability tooling listed for pipeline monitoring and alerting, which data platform engineering requires for SLA management\"],\"explanation\":\"This candidate has strong alignment with Airflow, Kubernetes, dbt, Snowflake, and Terraform. The open questions are around operating Airflow at Kubernetes scale with high concurrency and the observability practices needed to manage pipeline SLAs in a production data platform. A technically well-aligned candidate whose operational depth should be assessed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"prefect_petra\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Prefect\",\"dbt\",\"Polars\",\"Docker\"],\"databases\":[\"Snowflake\",\"BigQuery\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAnalytics company is hiring a Mid-level Data Engineer to build data pipelines orchestrated by Apache Airflow on Databricks. dbt handles transformations. PySpark is used for large-scale data processing. SQL and Python are required. Docker is used in development. GitHub Actions handles CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt for transformations is an exact match\",\"Python and SQL are both required and present\",\"Docker for development is listed\",\"GitHub Actions for CI is present\",\"Polars and Prefect show strong data engineering tooling foundations\"],\"gaps\":[\"No Apache Airflow experience; candidate uses Prefect which is a different orchestration paradigm\",\"No Databricks or PySpark experience; candidate works with Snowflake and BigQuery\",\"Polars is a different data processing tool than PySpark; large-scale distributed processing patterns differ significantly\"],\"explanation\":\"This candidate has solid dbt, Python, and SQL foundations that are directly transferable. The key gaps are Airflow versus Prefect for orchestration and the absence of Databricks and PySpark for large-scale processing. These are non-trivial differences for a role where those specific tools are the primary compute and orchestration layer.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sparse_sven\",\"seniority\":\"Senior\",\"languages\":[\"TypeScript\"],\"tech\":[\"React\"]}\n\nJob Summary:\nGrowth-stage company is hiring a Senior Full Stack Engineer to own their Next.js frontend and NestJS backend. PostgreSQL is the primary database managed via Prisma. Redis and Celery handle async workloads. Docker and Kubernetes are required. TypeScript is the language throughout. Jest and Playwright cover testing. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript is the required language and is present\",\"React experience provides a foundation for Next.js work\"],\"gaps\":[\"No Next.js experience beyond implied React familiarity\",\"No NestJS or backend development experience evidenced\",\"No PostgreSQL or Prisma listed\",\"No Redis or async workload experience\",\"No Docker or Kubernetes for containerized deployments\",\"No Jest or Playwright testing experience\",\"No GitHub Actions or CI/CD pipeline background\",\"Sparse profile makes it impossible to assess senior-level depth in any area\"],\"explanation\":\"This senior candidate has an extremely sparse profile that only evidences React and TypeScript, with no backend, database, infrastructure, or testing signals. The role requires a full stack engineer with broad ownership across Next.js, NestJS, PostgreSQL, Redis, Docker, and Kubernetes. There is insufficient signal to assess fit for even half the role's requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"effect_ts_eli\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Effect-TS\",\"NestJS\",\"tRPC\",\"Docker\"],\"architecture\":[\"Microservices\",\"Domain-Driven Design\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\"]}\n\nJob Summary:\nFunctional programming startup is building a backend platform in TypeScript using Effect-TS for typed error handling and dependency injection. NestJS structures the service layer. tRPC connects to a Next.js frontend. PostgreSQL and Redis are the datastores. Docker is used in development. Vitest handles testing. GitHub Actions manages CI. Domain-driven design guides service boundaries.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Effect-TS is the core framework requirement and is the candidate's primary listed technology\",\"NestJS is the service layer framework and is directly present\",\"tRPC for frontend connectivity is an exact match\",\"PostgreSQL and Redis cover the datastore requirements exactly\",\"Domain-Driven Design is explicitly listed\"],\"gaps\":[\"No Next.js experience listed for the frontend layer that tRPC connects to\",\"Effect-TS is a rapidly evolving library and production depth at senior level may vary significantly; profile alone cannot confirm\"],\"explanation\":\"This candidate has the rare Effect-TS signal and the surrounding NestJS, tRPC, PostgreSQL, and Redis stack covered. The gaps are the absence of Next.js for the connected frontend and the need to validate production depth in Effect-TS which is evolving quickly. A strong technical signal with practical depth to assess.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"phoenix_liveview_lars\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\",\"Backend Engineer\"],\"languages\":[\"Elixir\",\"JavaScript\"],\"tech\":[\"Phoenix\",\"LiveView\",\"Oban\",\"Tailwind CSS\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nHealthcare SaaS company is hiring a Senior Elixir Engineer to build real-time clinical dashboards using Phoenix LiveView. Oban handles background job processing. PostgreSQL is the primary database and Redis is used for pub/sub. Tailwind CSS styles the LiveView components. GitHub Actions manages CI and ExUnit covers testing.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Phoenix LiveView is the primary framework and is explicitly listed\",\"Elixir is the required language and is the candidate's primary language\",\"Oban for background job processing is an exact match\",\"PostgreSQL is the primary database and is present\",\"Redis for pub/sub is directly listed\"],\"gaps\":[\"No explicit healthcare domain experience listed; clinical dashboard context introduces regulatory and data sensitivity requirements not visible from tooling signals\",\"Tailwind CSS is listed but the component styling depth for complex clinical UI workflows is unclear\"],\"explanation\":\"This candidate covers the core Elixir, Phoenix LiveView, Oban, PostgreSQL, and Redis stack well. For a healthcare SaaS context, the absence of regulatory or clinical domain experience is a meaningful open question. A technically strong match with healthcare domain context to confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"convex_chloe\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Next.js\",\"React\",\"Convex\",\"Tailwind CSS\",\"Clerk\"],\"databases\":[\"Convex\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nConsumer app startup is building with a full Next.js and Convex backend-as-a-service stack. TypeScript is used throughout. Clerk handles authentication. Tailwind CSS is the styling layer. Vitest and Playwright cover testing. GitHub Actions manages CI. The team values fast iteration with minimal infrastructure overhead.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js is the primary framework and is listed as a core skill\",\"Convex as the backend-as-a-service and database is an exact match\",\"TypeScript throughout is required and evidenced\",\"Clerk for authentication is an exact match\",\"Tailwind CSS is the styling layer and is present\"],\"gaps\":[\"No explicit experience with consumer app scale challenges such as real-time sync under high concurrent user load using Convex\",\"No observability or monitoring tooling visible for a consumer app expected to scale\"],\"explanation\":\"This candidate's Convex, Clerk, and Next.js stack alignment is precise and uncommon. The open questions are around production scale experience with Convex's real-time sync model under consumer app load and the observability practices needed for a growing product. A technically strong candidate with scale readiness to assess.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wasm_webrtc_wade\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"C++\",\"Go\"],\"tech\":[\"Axum\",\"Tokio\",\"Docker\",\"gRPC\"],\"architecture\":[\"Distributed System\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nVideo infrastructure company is hiring a Senior Rust Engineer to build low-latency media processing services using Axum and Tokio. gRPC handles inter-service communication. PostgreSQL and Redis are the datastores. Docker is required. GitHub Actions manages CI. Experience with distributed systems and WebRTC or media pipeline concepts is a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Rust is the required language and is the candidate's primary language\",\"Axum is the exact web framework required\",\"Tokio for async runtime is directly listed\",\"gRPC for inter-service communication is an exact match\",\"PostgreSQL and Redis cover the datastore requirements\",\"Docker is present\",\"GitHub Actions for CI is listed\",\"Distributed systems expertise is explicitly present\"],\"gaps\":[\"No WebRTC or media pipeline experience listed despite it being a strong plus for a video infrastructure role\",\"C++ background may provide media codec familiarity but this is not explicitly evidenced in the profile\"],\"explanation\":\"This candidate covers the core Rust, Axum, Tokio, gRPC, PostgreSQL, Redis, and Docker requirements precisely. The gap is the absence of WebRTC or media pipeline experience, which the video infrastructure context makes a meaningful differentiator. A technically strong match whose media domain depth should be confirmed in screening.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wordpress_wendy\",\"seniority\":\"Mid\",\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"WordPress\",\"WooCommerce\",\"jQuery\",\"MySQL\"]}\n\nJob Summary:\nFintech startup is hiring a Mid-level Backend Engineer to build event-driven microservices in Go using gRPC and Kafka. PostgreSQL is the primary datastore. Redis handles caching. Docker and Kubernetes are required. GitHub Actions manages CI. The team expects engineers to write thorough unit and integration tests. Strong Go experience is mandatory.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"No Go experience despite it being mandatory\",\"No event-driven microservices or gRPC experience\",\"No Kafka for event streaming\",\"No PostgreSQL; uses MySQL in a WordPress context\",\"No Docker or Kubernetes experience\",\"No testing experience evidenced\",\"No GitHub Actions or modern CI/CD tooling\",\"WordPress and jQuery stack has no relevance to the Go microservices backend role\"],\"explanation\":\"This candidate's background is entirely in WordPress and WooCommerce development, which has no meaningful overlap with the Go, gRPC, Kafka, Kubernetes microservices role. The domain and technology mismatch is complete across language, architecture, deployment, and tooling dimensions.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"opentelemetry_olga\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\",\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"OpenTelemetry\",\"Prometheus\",\"Grafana\",\"Jaeger\",\"Kubernetes\",\"Terraform\",\"Helm\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Elasticsearch\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nLarge e-commerce platform is hiring a Senior SRE to own distributed tracing and observability infrastructure. OpenTelemetry is the instrumentation standard. Jaeger handles trace storage and visualization. Prometheus and Grafana manage metrics. Kubernetes runs all workloads. Terraform provisions infrastructure. Argo CD manages GitOps deployments. Go scripting is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"OpenTelemetry is the primary instrumentation requirement and is the candidate's core observability tool\",\"Jaeger for trace storage and visualization is an exact match\",\"Prometheus and Grafana for metrics are both present\",\"Kubernetes for workload orchestration is directly listed\",\"Terraform for infrastructure provisioning is present\",\"Argo CD for GitOps deployments is an exact match\"],\"gaps\":[\"No explicit e-commerce domain experience with high-traffic seasonal load patterns which shape SRE priorities for retail platforms\",\"Elasticsearch is listed as a secondary database but no log aggregation pipeline tooling is evidenced\"],\"explanation\":\"This candidate's observability tooling coverage is excellent: OpenTelemetry, Jaeger, Prometheus, Grafana, Kubernetes, Terraform, and Argo CD are all present. The open questions are around e-commerce-specific SRE patterns like flash sale traffic management and the log aggregation pipeline beyond the metric and trace layers.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"neon_db_nina\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Next.js\",\"React\",\"tRPC\",\"Drizzle ORM\",\"Tailwind CSS\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\"]}\n\nJob Summary:\nDeveloper tools startup is building a Next.js application with tRPC and Drizzle ORM on Neon serverless PostgreSQL. TypeScript is required. Tailwind CSS is the styling system. Vitest handles unit testing. Playwright is used for E2E testing. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Next.js is the primary framework and is a core skill\",\"tRPC for type-safe APIs is an exact match\",\"Drizzle ORM is explicitly required and is listed\",\"TypeScript is required and evidenced\",\"Tailwind CSS is the styling system and is present\"],\"gaps\":[\"No Playwright experience despite it being a stated E2E testing requirement\",\"No explicit Neon serverless PostgreSQL experience; Neon-specific branching and connection pooling patterns require onboarding beyond standard PostgreSQL\"],\"explanation\":\"This candidate has strong alignment on the core stack: Next.js, tRPC, Drizzle ORM, TypeScript, and Tailwind CSS. However, Playwright is a stated requirement and is absent, and Neon's serverless-specific operational model introduces additional onboarding. For a developer tools startup where testing discipline is likely expected, the absent Playwright gap is more significant than it might be elsewhere.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hono_henrik\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Hono\",\"Cloudflare Workers\",\"Next.js\",\"Tailwind CSS\"],\"databases\":[\"Cloudflare D1\",\"Cloudflare KV\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\"]}\n\nJob Summary:\nEdge computing startup is hiring a Mid-level Engineer to build ultra-low-latency APIs on Cloudflare Workers using the Hono framework. Cloudflare D1 is the SQLite-compatible database and KV is used for session storage. TypeScript is required. Vitest handles testing. GitHub Actions manages CI. Next.js is used for the frontend deployed on Cloudflare Pages.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Hono is the exact edge framework required and is the candidate's primary tool\",\"Cloudflare Workers is the primary runtime and is the candidate's core platform\",\"Cloudflare D1 as the database is an exact match\",\"Cloudflare KV for session storage is directly listed\",\"TypeScript is required and evidenced\",\"Vitest for testing is present\",\"GitHub Actions for CI is listed\",\"Next.js for the frontend on Cloudflare Pages is covered\"],\"gaps\":[],\"explanation\":\"This candidate's profile is purpose-built for the Cloudflare edge stack: Hono, Cloudflare Workers, D1, and KV are all explicitly present. The combination of Hono and Cloudflare Workers experience is a rare and precise match that eliminates onboarding overhead. No gaps exist for this edge computing role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"clickhouse_curt\",\"seniority\":\"Junior\",\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Pandas\",\"Matplotlib\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nReal-time analytics company is hiring a Mid-level Data Engineer to build high-throughput ingestion pipelines into ClickHouse. dbt handles transformations. Kafka feeds real-time data. Python and SQL are required. Airflow orchestrates batch pipelines. Grafana visualizes ClickHouse queries. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and SQL are the required languages and are both present\"],\"gaps\":[\"Junior seniority is below the mid-level requirement\",\"No ClickHouse experience despite it being the primary database\",\"No Kafka for real-time ingestion\",\"No dbt for transformation layer\",\"No Airflow for pipeline orchestration\",\"No Grafana for visualization\",\"No GitHub Actions or CI/CD experience\",\"MySQL and Pandas experience is insufficient for high-throughput real-time analytics engineering\"],\"explanation\":\"This junior candidate has basic Python and SQL skills but lacks every tool the role requires: ClickHouse, Kafka, dbt, Airflow, Grafana, and CI/CD tooling. The gap between MySQL data analysis and production ClickHouse pipeline engineering is substantial in both experience level and tooling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kysely_kenya\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Fastify\",\"Kysely\",\"Docker\",\"Bull\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nSaaS platform is hiring a Senior Backend Engineer to build TypeScript microservices using Fastify. Kysely is the SQL query builder for PostgreSQL. Bull handles job queues backed by Redis. Docker is required. Jest and Supertest cover unit and integration testing. GitHub Actions manages CI. An event-driven microservices architecture is practiced.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Fastify is the primary framework and is the candidate's core backend tool\",\"Kysely as the SQL query builder is an exact match\",\"PostgreSQL is the primary database and is present\",\"Bull for job queues backed by Redis is an exact match\",\"Docker is listed\",\"Jest and Supertest satisfy both testing requirements exactly\"],\"gaps\":[\"No explicit multi-tenancy or SaaS isolation patterns evidenced, which SaaS platforms typically require at the data and API boundary level\",\"Event-driven architecture is listed but no message broker experience such as Kafka or RabbitMQ is visible\"],\"explanation\":\"This candidate covers the Fastify, Kysely, Bull, and Redis job queue stack precisely. For a SaaS platform, the gaps are around multi-tenant isolation patterns and message broker experience for truly event-driven service communication. A strong technical match with SaaS architecture depth to explore.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"crossplane_chris\",\"seniority\":\"Senior\",\"roles\":[\"Platform Engineer\",\"Cloud Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Docker\",\"Argo CD\"],\"architecture\":[\"Cloud-Native\",\"Multi-Tenant\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nCloud infrastructure startup is hiring a Senior Platform Engineer to build a multi-tenant Kubernetes control plane using Crossplane for cloud resource provisioning. Helm manages deployments. Argo CD handles GitOps. Terraform is used for bootstrapping. Go is required for controller development. Docker is expected throughout. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Kubernetes, Helm, Argo CD, and Terraform form a strong surrounding infrastructure foundation\",\"Go for controller development is evidenced\",\"Multi-tenant and cloud-native architecture are explicitly listed\"],\"gaps\":[\"No Crossplane experience despite it being the central provisioning technology and primary differentiator of the role\",\"Crossplane composite resource model, provider development, and XRD design are highly specialized and not covered by general Kubernetes platform experience\"],\"explanation\":\"While this candidate has strong Kubernetes, Helm, Argo CD, and Terraform skills, Crossplane is the defining technology of the role and is completely absent from the profile. General Kubernetes platform experience does not substitute for Crossplane-specific composite resource and provider design knowledge. This is a fundamental tool gap for the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tanstack_tomas\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"TanStack Query\",\"TanStack Router\",\"Zustand\",\"Tailwind CSS\",\"Vite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nB2B SaaS company is hiring a Mid-level Frontend Engineer to build a data-intensive admin dashboard using React with TanStack Query for server state and TanStack Router for client-side routing. TypeScript and Tailwind CSS are required. Vite is the build tool. Zustand manages local UI state. Vitest and Playwright cover testing. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React is the primary component framework and is a core skill\",\"TanStack Query for server state is an exact requirement match\",\"TanStack Router for client-side routing is directly listed\",\"TypeScript is required and evidenced\",\"Tailwind CSS is required and present\",\"Vite as the build tool is an exact match\"],\"gaps\":[\"No backend or API experience listed; a B2B admin dashboard typically requires tight integration with REST or GraphQL APIs and the candidate's profile is frontend-only\",\"No accessibility or internationalization experience evidenced, which enterprise B2B products often require\"],\"explanation\":\"This candidate has an exceptionally precise frontend stack match: TanStack Query, TanStack Router, Zustand, Tailwind CSS, and Vite are all present. For a B2B SaaS admin dashboard, the gaps are the absence of backend context and accessibility patterns that enterprise product teams typically expect. A frontend-strong candidate with full-stack scope to assess.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"r_analyst_rio\",\"seniority\":\"Mid\",\"roles\":[\"Data Scientist\"],\"languages\":[\"R\",\"Python\"],\"tech\":[\"tidyverse\",\"ggplot2\",\"Shiny\",\"scikit-learn\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nPharmaceutical company is hiring a Mid-level ML Engineer to build clinical trial outcome prediction models using PyTorch. The team uses MLflow for experiment tracking and Weights and Biases for model monitoring. Docker and Kubernetes are used for serving. SQL and Python are required. AWS SageMaker is the cloud training platform.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is the required language and is present\",\"scikit-learn shows basic ML familiarity\"],\"gaps\":[\"No PyTorch experience; clinical outcome models require deep learning which scikit-learn alone does not address\",\"No MLflow for experiment tracking\",\"No Weights and Biases for model monitoring\",\"No Docker or Kubernetes for model serving\",\"No AWS SageMaker or cloud ML training experience\",\"R and tidyverse are statistical analysis tools with no relevance to the PyTorch ML engineering stack\"],\"explanation\":\"This candidate has statistical analysis and classical ML foundations but lacks the production ML engineering stack the role requires. PyTorch, MLflow, Weights and Biases, Docker, Kubernetes, and SageMaker are all absent, and R-based statistical work does not transfer to deep learning model engineering for clinical predictions.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"encore_ts_eva\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"Go\"],\"tech\":[\"Encore\",\"Docker\",\"gRPC\"],\"architecture\":[\"Microservices\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Vitest\"]}\n\nJob Summary:\nDeveloper tooling startup is building their backend platform using Encore for TypeScript to handle microservice scaffolding, infrastructure, and API generation. PostgreSQL is the primary database. Redis is used for caching. Docker is used locally. GitHub Actions manages CI. Go experience is a plus for internal tooling work.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Encore is the core platform tool and is explicitly listed as the candidate's primary backend technology\",\"TypeScript is the required language and is the candidate's primary language\",\"PostgreSQL is the primary database and is present\",\"Redis for caching is listed\",\"Docker is present\"],\"gaps\":[\"No explicit experience with Encore's infrastructure-from-code model at production scale with multiple services and distributed tracing\",\"Go is listed as a plus but as a secondary language; production Go depth for internal tooling may be limited\"],\"explanation\":\"Encore experience is the primary differentiating signal and its presence is valuable. The open questions are around production-scale Encore deployment experience with multiple interconnected services and the depth of Go proficiency for internal tooling work. A technically aligned candidate with practical depth to confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ansible_tower_aden\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\",\"Infrastructure Engineer\"],\"languages\":[\"Python\",\"Bash\",\"YAML\"],\"tech\":[\"Ansible\",\"Terraform\",\"Docker\",\"Jenkins\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Cloud-Native\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"Jenkins\",\"GitLab CI\"]}\n\nJob Summary:\nEnterprise bank is hiring a Senior DevOps Engineer to manage on-premises Kubernetes clusters and automate server provisioning using Ansible and Terraform. Jenkins handles CI/CD pipelines. Prometheus and Grafana are used for observability. Python and Bash scripting are required. Docker is used throughout. No public cloud experience is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Ansible for server provisioning is an exact requirement match\",\"Terraform for infrastructure automation is directly listed\",\"Jenkins for CI/CD pipelines is present\",\"Prometheus and Grafana for observability are both listed\",\"Python and Bash scripting are both covered\",\"Docker is present\",\"Senior seniority matches the role level\"],\"gaps\":[\"No explicit on-premises Kubernetes experience listed; cloud-native background may imply managed Kubernetes rather than self-managed cluster operations\"],\"explanation\":\"This candidate covers every stated requirement: Ansible, Terraform, Jenkins, Prometheus, Grafana, Python, and Bash. The only mild uncertainty is whether their Kubernetes experience is in managed cloud environments versus the on-premises self-managed clusters the bank operates. A strong match with operational context to confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vite_plugin_vera\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Vite\",\"Pinia\",\"Tailwind CSS\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nE-learning platform is hiring a Senior Frontend Engineer to build interactive course interfaces with React and Next.js. TypeScript is required. TanStack Query manages server state. Tailwind CSS is the styling system. Jest and Cypress cover testing. GitHub Actions manages CI. Redux Toolkit handles global state.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript is required and evidenced\",\"Tailwind CSS is required and is present\",\"GitHub Actions for CI is listed\",\"Frontend engineering seniority and Vitest/Playwright testing culture are broadly transferable\"],\"gaps\":[\"No React or Next.js experience; candidate's primary frameworks are Vue.js and Nuxt.js which follow a different component and routing model\",\"No TanStack Query for server state management\",\"No Jest or Cypress; candidate uses Vitest and Playwright\",\"No Redux Toolkit for global state management\",\"Vue.js and React have fundamentally different mental models that require dedicated migration effort at senior level\"],\"explanation\":\"This candidate's Tailwind CSS and TypeScript experience transfers but every other primary technical requirement is mismatched. Vue.js to React is a significant framework migration for a senior engineer, and the state management, data fetching, and testing tools are entirely different from what the role requires. The breadth of mismatches makes this a weak fit despite frontend seniority.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"turso_tatiana\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"SvelteKit\",\"Svelte\",\"Hono\",\"Drizzle ORM\",\"Tailwind CSS\"],\"databases\":[\"Turso\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nBootstrapped startup is building an edge-first web app with SvelteKit on Cloudflare Pages and Hono APIs on Cloudflare Workers. Drizzle ORM connects to a Turso edge database. TypeScript is used throughout. Tailwind CSS is the styling system. Vitest and Playwright handle testing. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SvelteKit is the primary frontend framework and is the candidate's core skill\",\"Hono is the edge API framework and is directly listed\",\"Drizzle ORM is explicitly required and is present\",\"Turso edge database is an exact match\",\"TypeScript throughout is required and evidenced\",\"Tailwind CSS is the styling system and is present\",\"Vitest and Playwright satisfy both testing requirements\",\"GitHub Actions for CI is listed\"],\"gaps\":[],\"explanation\":\"This candidate's profile is a precise match for the edge-first stack: SvelteKit, Hono, Drizzle ORM, and Turso are all explicitly listed. Turso expertise is a rare and specific signal that directly satisfies the edge database requirement. No meaningful gaps exist for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pytorch_lightning_pete\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"MLflow\",\"Docker\",\"FastAPI\",\"CUDA\"],\"databases\":[\"PostgreSQL\",\"Pinecone\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAutonomous vehicle company is hiring a Senior ML Engineer to train and optimize perception models using PyTorch with CUDA GPU acceleration. MLflow tracks experiments. FastAPI serves model predictions. Docker containerizes training jobs. PostgreSQL stores metadata. GitHub Actions manages CI. Experience with computer vision or sensor fusion is strongly preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"PyTorch is the training framework and is the candidate's primary ML tool\",\"CUDA for GPU acceleration is an exact match\",\"MLflow for experiment tracking is directly listed\"],\"gaps\":[\"No computer vision or sensor fusion experience despite it being strongly preferred for an autonomous vehicle perception role\",\"Pinecone vector database usage suggests NLP or RAG domain focus rather than computer vision\",\"No perception model architecture experience such as YOLO, PointNet, or LiDAR processing pipelines\"],\"explanation\":\"While PyTorch, CUDA, and MLflow are present, the autonomous vehicle domain requires computer vision and sensor fusion expertise that is entirely absent from this candidate's NLP-oriented ML profile. For a perception engineering role where domain knowledge shapes model architecture choices daily, this domain mismatch is a fundamental gap beyond tooling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"graalvm_grace\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Quarkus\",\"Kafka\",\"Docker\",\"gRPC\",\"Hibernate\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Testcontainers\"]}\n\nJob Summary:\nCloud-native startup is hiring a Senior Java Engineer to build reactive microservices using Quarkus with native compilation via GraalVM. Kafka handles event streaming. gRPC is used for inter-service communication. PostgreSQL and Redis are the datastores. Docker is required. JUnit and Testcontainers cover testing. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Quarkus is the primary framework with GraalVM support and is the candidate's core technology\",\"Kafka for event streaming is an exact match\",\"gRPC for inter-service communication is directly listed\",\"PostgreSQL and Redis cover both datastore requirements\",\"Docker is present\",\"JUnit and Mockito satisfy both testing requirements\"],\"gaps\":[\"No GraalVM native image build experience explicitly evidenced beyond Quarkus listing; native compilation requires specific dependency and reflection configuration knowledge\",\"Hibernate is not listed which may affect ORM usage patterns within Quarkus\"],\"explanation\":\"This candidate's Quarkus, Kafka, gRPC, and testing stack is well-aligned. The gaps are around explicit GraalVM native image build experience, which is distinct from using Quarkus in JVM mode, and the absence of Hibernate for ORM. These are specific Quarkus depth areas worth exploring in technical screening.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"react_email_reed\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Next.js\",\"React\",\"Resend\",\"React Email\",\"Tailwind CSS\",\"Prisma\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nNotification infrastructure startup is hiring a Mid-level Full Stack Engineer to build and maintain a transactional email platform. The stack uses Next.js, React Email for template rendering, and Resend for delivery. Prisma manages PostgreSQL. Tailwind CSS styles templates. Jest and Playwright cover testing. Supabase handles auth. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React Email for template rendering is an exact and specific match\",\"Resend for email delivery is directly listed\",\"Next.js is the primary application framework and is present\",\"Prisma for PostgreSQL management is an exact match\",\"Tailwind CSS for template styling is listed\",\"Jest and Playwright satisfy both testing requirements\",\"Supabase for auth is present\",\"GitHub Actions for CI is listed\"],\"gaps\":[],\"explanation\":\"The combination of Resend and React Email is a highly specific and uncommon signal that makes this candidate a near-perfect match for the transactional email platform. Every requirement including Prisma, Supabase, Tailwind CSS, Jest, and Playwright is covered. No gaps exist.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"zod_zara\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Next.js\",\"React\",\"Tailwind CSS\",\"Prisma\",\"NextAuth.js\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nSaaS startup is building a Next.js application with server actions and Prisma on PostgreSQL. NextAuth.js handles authentication. Tailwind CSS and shadcn/ui compose the UI. TypeScript is required. Vitest replaces Jest for testing. Playwright covers E2E flows. GitHub Actions manages CI. The team values type safety and prefers Zod for validation.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Next.js is the primary framework and is the candidate's core technology\",\"Prisma for PostgreSQL management is an exact match\",\"NextAuth.js for authentication is an exact match\"],\"gaps\":[\"No shadcn/ui experience; the design system requires Radix UI primitives knowledge\",\"Uses Jest rather than the team's Vitest testing framework\",\"No Playwright for E2E testing\",\"No Zod validation experience despite it being a team preference\"],\"explanation\":\"This candidate has Next.js, Prisma, and NextAuth.js alignment but misses four specific tooling requirements: shadcn/ui, Vitest, Playwright, and Zod. While individually learnable, the simultaneous absence of multiple stated requirements makes this a weak fit for a team that has made deliberate choices about their tooling stack.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wundergraph_wilma\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"Go\",\"TypeScript\"],\"tech\":[\"WunderGraph\",\"GraphQL\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"API Gateway\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Go testing\",\"Jest\"]}\n\nJob Summary:\nAPI management company is hiring a Senior Engineer to build and extend a WunderGraph-based API federation layer. GraphQL is the primary API surface. Go handles backend services. Kubernetes orchestrates all workloads. PostgreSQL and Redis are the datastores. Docker is required. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"WunderGraph is the core federation technology and is the candidate's primary platform tool\",\"GraphQL is the primary API surface and is directly listed\",\"Go for backend services is the required language and is present\",\"Kubernetes for workload orchestration is an exact match\",\"PostgreSQL and Redis cover both datastore requirements\"],\"gaps\":[\"No explicit API federation or schema stitching experience beyond WunderGraph listing; federation design across multiple upstream schemas requires specific architectural patterns\",\"TypeScript is listed in the profile but the role's Go-centric backend may require deeper Go specialization than the profile suggests\"],\"explanation\":\"WunderGraph expertise is the most important signal and its presence is a strong indicator. The open questions are around federation architecture depth across complex multi-schema environments and the balance between Go and TypeScript focus for a primarily Go backend role. A technically distinctive candidate with federation design depth to confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"intern_ivo\",\"seniority\":\"Intern\",\"languages\":[\"Java\"],\"tech\":[\"Spring Boot\",\"MySQL\"]}\n\nJob Summary:\nE-commerce company is hiring a Mid-level Full Stack Engineer to own features in a large Next.js and Node.js codebase. TypeScript is required. PostgreSQL is the primary database. Docker and Kubernetes are used in production. Jest and Cypress handle testing. GitHub Actions manages CI. The candidate should be comfortable working autonomously across frontend and backend.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Spring Boot shows basic web framework familiarity\"],\"gaps\":[\"Intern seniority is far below the mid-level autonomous ownership expectation\",\"No TypeScript or JavaScript experience despite it being the required language\",\"No Next.js or Node.js experience\",\"No PostgreSQL; uses MySQL\",\"No Docker or Kubernetes experience\",\"No Jest or Cypress for testing\",\"No GitHub Actions or CI/CD experience\",\"Java and Spring Boot profile has no overlap with the JavaScript full stack role\"],\"explanation\":\"This intern candidate has only foundational Java and Spring Boot experience with no overlap in language, framework, database, infrastructure, or testing tooling with the JavaScript full stack role. The seniority and technology mismatch are both disqualifying.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"llamaindex_lina\",\"seniority\":\"Mid\",\"roles\":[\"AI Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"LlamaIndex\",\"LangChain\",\"FastAPI\",\"Docker\",\"Ollama\"],\"databases\":[\"Qdrant\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nEnterprise AI company is hiring a Mid-level AI Engineer to build document intelligence pipelines using LlamaIndex for retrieval and indexing. LangChain handles orchestration. FastAPI serves inference endpoints. Qdrant is the vector store. Docker is required. Ollama enables local model testing. pytest covers testing. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LlamaIndex is the primary indexing and retrieval framework and is the candidate's core tool\",\"LangChain for orchestration is an exact match\",\"FastAPI for inference endpoints is directly listed\",\"Qdrant as the vector store is an exact match\",\"Docker is present\",\"Ollama for local model testing is listed\",\"pytest satisfies the testing requirement\",\"GitHub Actions for CI is listed\"],\"gaps\":[],\"explanation\":\"This candidate covers every stated requirement with direct specificity: LlamaIndex, LangChain, FastAPI, Qdrant, Docker, Ollama, pytest, and GitHub Actions. The LlamaIndex and Qdrant combination is a precise and uncommon signal for document intelligence pipeline work. An ideal match with no gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"terraform_cdk_tom\",\"seniority\":\"Senior\",\"roles\":[\"Cloud Engineer\",\"DevOps Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Terraform\",\"AWS\",\"Docker\",\"Kubernetes\",\"Helm\"],\"architecture\":[\"Cloud-Native\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\"],\"ci_cd\":[\"GitHub Actions\",\"AWS CodePipeline\"]}\n\nJob Summary:\nGrowth-stage company is hiring a Senior Cloud Engineer to migrate infrastructure from Terraform to AWS CDK in TypeScript. The current stack runs on EKS with Helm. DynamoDB and PostgreSQL are the datastores. GitHub Actions and AWS CodePipeline handle CI/CD. Serverless Lambda patterns are used for async workloads. Docker is required throughout.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform proficiency makes the migration context directly relevant\",\"AWS is the primary cloud and is the candidate's main platform\",\"Kubernetes with Helm on EKS is directly covered\",\"DynamoDB and PostgreSQL are both present\",\"GitHub Actions and AWS CodePipeline satisfy the CI/CD requirements\",\"TypeScript is required for CDK and is the candidate's primary language\",\"Serverless and Docker are both listed\"],\"gaps\":[\"No AWS CDK experience despite it being the target IaC tool the migration is moving toward\",\"CDK's programmatic infrastructure model differs meaningfully from Terraform's declarative HCL approach and requires adjustment\"],\"explanation\":\"This candidate has strong AWS, Terraform, Kubernetes, and Helm foundations that are directly relevant to the migration context. The gap is the absence of AWS CDK experience, which is the role's primary target technology. TypeScript proficiency reduces the ramp-up time but CDK-specific constructs and design patterns require intentional learning.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"electric_sql_emeka\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Next.js\",\"React\",\"Electric SQL\",\"Drizzle ORM\",\"Tailwind CSS\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nLocal-first software startup is building a collaborative app using Electric SQL for real-time sync between PostgreSQL and client-side SQLite. Next.js is the frontend framework. Drizzle ORM manages the PostgreSQL schema. Tailwind CSS is the styling system. Vitest and Playwright cover testing. TypeScript is used throughout. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Electric SQL for real-time PostgreSQL sync is the core technology and is explicitly listed\",\"Next.js is the primary frontend framework and is present\",\"Drizzle ORM for schema management is an exact match\",\"PostgreSQL is the primary database and is listed\",\"Tailwind CSS is the styling system and is present\"],\"gaps\":[\"No explicit experience with client-side SQLite management and sync conflict resolution which Electric SQL's local-first model requires\",\"No offline-first or local-first application architecture experience evidenced beyond the Electric SQL listing\"],\"explanation\":\"Electric SQL expertise is a rare and high-value signal for this local-first startup role. The open questions are around experience with the full local-first sync model including client-side SQLite operations and conflict resolution strategies, which are the primary complexity of Electric SQL applications beyond initial setup. A technically aligned candidate with sync pattern depth to confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mojo_ml_miguel\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"C++\"],\"tech\":[\"PyTorch\",\"CUDA\",\"ONNX\",\"TensorRT\",\"Docker\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAI inference startup is hiring a Senior ML Engineer to optimize neural network inference latency. TensorRT is used for GPU-accelerated inference. ONNX handles model export and cross-framework portability. PyTorch is the training framework. CUDA for low-level GPU optimization is expected. Docker is used for reproducible environments. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TensorRT for GPU-accelerated inference is the primary optimization tool and is directly listed\",\"ONNX for model export and cross-framework portability is an exact match\",\"PyTorch is the training framework and is present\",\"CUDA for low-level GPU optimization is explicitly listed\",\"Docker for reproducible environments is present\"],\"gaps\":[\"No explicit latency benchmarking or profiling tooling experience listed beyond TensorRT, such as nsight or perf analyzers used in inference optimization workflows\",\"No serving framework experience such as Triton Inference Server which is commonly used alongside TensorRT in production inference pipelines\"],\"explanation\":\"This candidate's TensorRT, ONNX, PyTorch, and CUDA combination is well-aligned with inference optimization. The gaps are the absence of profiling tool experience and Triton Inference Server, which are common companions to TensorRT in production inference pipelines. A strong technical match with production serving depth to explore.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kafka_streams_kira\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Data Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Apache Kafka\",\"Kafka Streams\",\"Spring Boot\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Event-Driven\",\"Microservices\",\"CQRS\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Testcontainers\"]}\n\nJob Summary:\nFinancial analytics company is hiring a Senior Java Engineer to build real-time financial event processing using Kafka Streams. Spring Boot structures the service layer. PostgreSQL and Cassandra are the data stores. Redis handles caching. Docker and Kubernetes are used for deployment. CQRS and event-driven architecture patterns are practiced. JUnit and Testcontainers cover testing.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kafka Streams is the primary processing framework and is the candidate's specific Kafka tool\",\"Spring Boot for the service layer is an exact match\",\"PostgreSQL and Cassandra are both listed datastores\",\"Redis for caching is present\",\"CQRS and event-driven architecture are explicitly listed\",\"JUnit and Testcontainers satisfy both testing requirements\"],\"gaps\":[\"No explicit financial domain experience with regulatory reporting or trade data compliance patterns which financial analytics companies typically require\",\"Kafka Streams stateful processing at financial data volumes introduces specific windowing and state store design patterns not evidenced in the profile\"],\"explanation\":\"This candidate has strong Kafka Streams, Spring Boot, and testing stack coverage. For a financial analytics company, the gaps are around regulatory compliance context and stateful Kafka Streams design at financial data volumes and complexity. A technically precise candidate with financial domain depth to assess.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"directus_drew\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Directus\",\"Next.js\",\"React\",\"Tailwind CSS\"],\"databases\":[\"PostgreSQL\",\"MySQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nMedia company is hiring a Mid-level Full Stack Engineer to build editorial workflows using Directus as the headless CMS. Next.js renders the frontend with TypeScript. PostgreSQL is the primary database. Tailwind CSS is the styling system. Jest and Playwright cover testing. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Directus as the headless CMS is an exact and specific match\",\"Next.js is the primary frontend framework and is present\",\"TypeScript is required and evidenced\",\"PostgreSQL is the primary database and is listed\",\"Tailwind CSS is the styling system and is present\",\"Jest and Playwright satisfy both testing requirements\"],\"gaps\":[\"No explicit editorial workflow or content modeling experience for a media company context where role-based access and content staging are common CMS requirements\",\"MySQL is listed alongside PostgreSQL which may indicate multi-database experience but the PostgreSQL primary depth is unclear\"],\"explanation\":\"Directus experience is the key differentiating signal and its presence is a direct match. The open questions are around editorial workflow design and media-specific content modeling experience that media companies typically require for their CMS configurations. A technically strong candidate with media domain experience to confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devops_dakarai\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"Terraform\",\"Ansible\",\"Prometheus\"],\"architecture\":[\"Cloud-Native\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"]}\n\nJob Summary:\nStartup is hiring a Mid-level DevOps Engineer to manage a Kubernetes-first infrastructure on GCP. Helm manages chart deployments. Argo CD handles GitOps workflows. Terraform provisions cloud resources. Prometheus and Grafana are used for observability. Python scripting is expected. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Terraform for cloud resource provisioning is an exact match\",\"Python scripting is evidenced\",\"Docker provides basic container familiarity\"],\"gaps\":[\"No Kubernetes experience despite it being the core infrastructure platform for the role\",\"No Helm for chart deployment management\",\"No Argo CD for GitOps workflows\",\"No Grafana to complete the observability stack\",\"No GCP experience for the target cloud environment\"],\"explanation\":\"This candidate has Terraform and Docker skills but is missing Kubernetes, Helm, Argo CD, Grafana, and GCP, which together represent the entire operational core of the role. The breadth of missing tools is too wide to address without a major ramp period, making this a weak fit for an immediate-contribution DevOps hire.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vanna_ai_victor\",\"seniority\":\"Mid\",\"roles\":[\"AI Engineer\",\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"LangChain\",\"FastAPI\",\"Docker\",\"Pandas\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nAnalytics startup is hiring a Mid-level AI Engineer to build a natural language to SQL system using LLMs. LangChain handles the LLM orchestration layer. FastAPI serves the query translation endpoints. PostgreSQL and Snowflake are the target databases. Docker is required. pytest covers testing. GitHub Actions manages CI. Experience with prompt engineering and SQL query optimization is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LangChain for LLM orchestration is the core framework and is directly listed\",\"FastAPI for query translation endpoints is an exact match\",\"PostgreSQL and Snowflake are both target databases and are both present\",\"Python and SQL are both required and evidenced\",\"Docker is present\",\"pytest satisfies the testing requirement\",\"GitHub Actions for CI is listed\",\"Pandas background supports data manipulation around the SQL generation workflow\"],\"gaps\":[\"No explicit prompt engineering experience evidenced from GitHub signals alone\"],\"explanation\":\"This candidate covers every stated technical requirement: LangChain, FastAPI, PostgreSQL, Snowflake, Python, SQL, Docker, pytest, and GitHub Actions. The only gap is that prompt engineering depth is not directly visible from tooling profiles, though LangChain usage strongly implies hands-on LLM interaction. A strong match overall.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"micronaut_marta\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Micronaut\",\"Kafka\",\"Docker\",\"gRPC\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nCloud-native startup is hiring a Senior Java Engineer to build low-footprint microservices using Micronaut with GraalVM native image support. Kafka handles event streaming. gRPC is used for inter-service communication. PostgreSQL and Redis are the datastores. Docker is required. JUnit and Mockito cover testing. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Micronaut is the primary framework with GraalVM support and is the candidate's core technology\",\"Kafka for event streaming is an exact match\",\"gRPC for inter-service communication is directly listed\",\"PostgreSQL and Redis cover both datastore requirements\",\"Docker is present\",\"JUnit and Mockito satisfy both testing requirements\"],\"gaps\":[\"No GraalVM native image compilation experience explicitly evidenced; Micronaut supports it but usage requires specific AOT compilation configuration knowledge\",\"No Kubernetes or container orchestration experience for a cloud-native deployment context\"],\"explanation\":\"Micronaut expertise is an uncommon and valuable signal. The gaps are the absence of explicit GraalVM native compilation experience and Kubernetes for cloud-native deployment, which are both expected in a cloud-native startup context where low-footprint native images are deployed at scale. A strong framework match with deployment depth to assess.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"spring_graphql_suki\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Spring GraphQL\",\"Hibernate\",\"Docker\"],\"architecture\":[\"Microservices\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nRetail enterprise is hiring a Mid-level Java Backend Engineer to build REST APIs using Spring Boot and Hibernate with PostgreSQL. Redis handles caching. Docker is required. JUnit and Mockito cover testing. GitHub Actions manages CI. Kafka experience is a strong plus for async order processing workflows.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Spring Boot is the primary framework and is the candidate's core technology\",\"Hibernate for ORM is an exact match\",\"PostgreSQL is the primary database and is present\",\"Redis for caching is listed\",\"Docker is present\",\"JUnit and Mockito satisfy both testing requirements\",\"GitHub Actions for CI is listed\"],\"gaps\":[\"No Kafka experience despite it being a strong plus for async order processing workflows\",\"Spring GraphQL experience is listed but the role focuses on REST APIs, meaning the GraphQL knowledge is not directly applied\"],\"explanation\":\"This candidate covers the core Spring Boot, Hibernate, PostgreSQL, Redis, Docker, JUnit, and Mockito requirements well. The absence of Kafka is a notable gap for a retail platform where async order processing is a significant workload. A solid technical match with the Kafka gap being the primary area to assess.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sparse_sadie\",\"seniority\":\"Junior\",\"languages\":[\"Python\"],\"tech\":[\"Django\"]}\n\nJob Summary:\nAI research lab is hiring a Senior ML Engineer to design and run large-scale distributed training experiments using PyTorch on multi-GPU clusters with CUDA. The candidate must have deep experience with Hugging Face Transformers, RLHF pipelines, and experiment tracking with Weights and Biases. At least 5 years of production ML experience and a strong publication record or open source LLM contributions are required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Junior seniority is far below the senior with 5 or more years of production ML experience required\",\"No PyTorch or GPU training experience\",\"No CUDA or multi-GPU cluster familiarity\",\"No Hugging Face Transformers experience\",\"No RLHF pipeline experience\",\"No Weights and Biases or experiment tracking tools\",\"Django is irrelevant to ML research infrastructure\",\"No publication record or LLM open source contributions evidenced\"],\"explanation\":\"This junior candidate has only a basic Django background with no ML tooling, training infrastructure, or research credentials whatsoever. The role requires one of the most specialized and senior ML profiles in the industry, and this profile lacks every single relevant signal.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"durable_objects_dom\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Cloudflare Workers\",\"Cloudflare Durable Objects\",\"Hono\",\"Next.js\",\"Tailwind CSS\"],\"databases\":[\"Cloudflare D1\",\"Cloudflare KV\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nReal-time collaboration startup is building a stateful edge backend using Cloudflare Durable Objects for per-document state management. Hono structures the Workers API layer. Cloudflare D1 handles persistent storage and KV handles ephemeral data. Next.js powers the frontend. TypeScript throughout. Vitest and Playwright cover testing. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Cloudflare Durable Objects is the core stateful edge technology and is explicitly listed\",\"Cloudflare Workers is the execution runtime and is the candidate's primary platform\",\"Hono for the API layer is an exact match\",\"Cloudflare D1 for persistent storage is directly listed\",\"Cloudflare KV for ephemeral data is an exact match\"],\"gaps\":[\"No explicit experience with Durable Object hibernation APIs or WebSocket hibernation patterns which real-time collaboration at scale requires\",\"No experience with conflict-free replicated data types or operational transformation which collaborative document editing typically involves beyond Durable Object basics\"],\"explanation\":\"This candidate's Cloudflare Durable Objects expertise is the primary differentiating signal and a strong match. The open questions are around advanced collaboration patterns like WebSocket hibernation for idle connections and the document consistency models used in multi-user editing that go beyond basic Durable Object storage. Depth in collaborative editing patterns should be confirmed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"modal_ml_moe\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"FastAPI\",\"Docker\",\"Weights & Biases\",\"Hugging Face Transformers\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nML infrastructure company is hiring a Mid-level ML Engineer to deploy and scale model training jobs on Modal. PyTorch is the training framework. Weights and Biases tracks experiments. FastAPI serves model endpoints. Hugging Face Transformers are used for fine-tuning. Docker is used locally. pytest covers testing. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"PyTorch, Weights and Biases, FastAPI, and Hugging Face Transformers cover meaningful portions of the ML stack\",\"Docker provides basic containerization context\"],\"gaps\":[\"No Modal experience despite it being the primary platform for scaling training jobs\",\"Modal's serverless GPU compute model has unique deployment semantics, cold start management, and volume mounting patterns not covered by Docker or cloud provider experience\",\"No GPU cluster or distributed training experience evidenced beyond standard PyTorch usage\"],\"explanation\":\"This candidate has strong ML tooling coverage but lacks Modal, which is the defining deployment platform of the role. Modal's serverless GPU model is architecturally distinct from Docker-based or cloud ML platforms and requires intentional learning. Without Modal experience, the candidate cannot fulfill the primary job responsibility of scaling training jobs on the platform.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"starlette_steph\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"FastAPI\",\"SQLAlchemy\",\"Celery\",\"Docker\",\"Nginx\"],\"architecture\":[\"Microservices\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nHealthtech startup is hiring a Senior Backend Engineer to extend a Python API using FastAPI and SQLAlchemy with PostgreSQL. Celery and Redis handle async tasks. Docker and Nginx are used for deployment. pytest and Locust cover unit and performance testing. GitHub Actions manages CI. Familiarity with HIPAA data handling patterns is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"FastAPI is the primary framework and is the candidate's core technology\",\"SQLAlchemy for ORM is an exact match\",\"PostgreSQL is the primary database and is present\",\"Celery and Redis for async tasks are both present and match exactly\",\"Docker and Nginx for deployment are both listed\",\"pytest and Locust satisfy both testing requirements exactly\",\"GitHub Actions for CI is listed\"],\"gaps\":[\"No explicit HIPAA data handling experience evidenced, which is a plus requirement in the healthtech context\"],\"explanation\":\"This candidate covers every stated technical requirement: FastAPI, SQLAlchemy, PostgreSQL, Celery, Redis, Docker, Nginx, pytest, and Locust. Locust for performance testing is an uncommon signal that directly satisfies the load testing requirement. The only gap is the HIPAA plus factor, which is domain knowledge rather than a tooling gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"flux_cd_felix\",\"seniority\":\"Senior\",\"roles\":[\"Platform Engineer\",\"DevOps Engineer\"],\"languages\":[\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Flux\",\"Terraform\",\"Helm\",\"Docker\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Flux\"]}\n\nJob Summary:\nFintec company is hiring a Senior Platform Engineer to manage Kubernetes infrastructure using Flux for GitOps. Helm manages chart deployments. Terraform provisions AWS resources. Docker is used throughout. Go scripting supports automation. GitHub Actions manages CI. Multi-cluster management experience is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Flux for GitOps is the primary deployment tool and is the candidate's core CI/CD tool\",\"Kubernetes is the core platform and is a primary skill\",\"Helm for chart deployments is an exact match\",\"Terraform for AWS resource provisioning is present\",\"Docker is listed\",\"Go scripting for automation is evidenced\",\"GitHub Actions for CI is listed\"],\"gaps\":[\"No explicit multi-cluster management experience listed, which is flagged as a strong plus\"],\"explanation\":\"This candidate satisfies every stated requirement: Flux, Kubernetes, Helm, Terraform, Go, Docker, and GitHub Actions. Flux GitOps expertise is a specific signal that directly satisfies the primary deployment model. The only gap is multi-cluster management experience which is a plus rather than a hard requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ionic_ivan\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Ionic\",\"Angular\",\"Capacitor\",\"Firebase\"],\"databases\":[\"Firestore\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nHealthcare startup is hiring a Mid-level React Native Engineer to build patient-facing mobile features. The stack uses Expo for managed builds, Redux Toolkit for state management, and Detox for E2E testing. Firebase handles push notifications. TypeScript is required. Fastlane automates releases. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript is required and evidenced\",\"Firebase experience is relevant to the push notification requirement\",\"Mobile development experience in Ionic provides general cross-platform context\"],\"gaps\":[\"No React Native experience; candidate uses Ionic with Angular which follows a completely different component model\",\"No Expo for managed builds\",\"No Redux Toolkit for state management\",\"No Detox for E2E testing\",\"No Fastlane for automated releases\",\"Angular and React Native follow fundamentally different architectural paradigms requiring a full framework switch\"],\"explanation\":\"This candidate's Ionic and Angular background provides mobile development experience but no overlap with the React Native ecosystem the role requires. The absence of React Native, Expo, Redux Toolkit, Detox, and Fastlane means the candidate would need to rebuild their entire mobile tooling knowledge base, making this a poor fit for a role expecting immediate productivity.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"graph_db_greta\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Data Engineer\"],\"languages\":[\"Python\",\"Java\"],\"tech\":[\"Spring Boot\",\"FastAPI\",\"Docker\"],\"architecture\":[\"Microservices\"],\"databases\":[\"Neo4j\",\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"JUnit\"]}\n\nJob Summary:\nKnowledge graph startup is hiring a Senior Backend Engineer to build graph traversal and recommendation APIs on Neo4j. Python with FastAPI serves the API layer. PostgreSQL handles relational metadata. Redis caches graph query results. Docker is required. pytest covers testing. GitHub Actions manages CI. Cypher query optimization experience is essential.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Neo4j is the primary graph database and is the candidate's most specific database signal\",\"FastAPI for the API layer is an exact match\",\"Python is the required language and is present\"],\"gaps\":[\"No Cypher query optimization experience despite it being listed as essential; Neo4j listing alone does not confirm optimization proficiency\",\"Spring Boot is listed but the role uses Python with FastAPI, making Java experience irrelevant\",\"No explicit graph traversal algorithm experience beyond the Neo4j listing\"],\"explanation\":\"While Neo4j, FastAPI, and Python are present, Cypher query optimization is listed as essential and is not evidenced in the profile. Neo4j experience is a positive signal but does not confirm optimization depth. For a knowledge graph role where Cypher performance is central, this gap is significant.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"temporal_go_tom\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Gin\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Go testing\"]}\n\nJob Summary:\nInsurtech company is hiring a Mid-level Go Engineer to build durable workflow orchestration using Temporal. gRPC handles inter-service communication. PostgreSQL and Redis are the datastores. Kubernetes manages workloads. Docker is required. Go testing covers unit testing. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Go is the required language and is the candidate's primary language\",\"PostgreSQL and Redis cover both datastore requirements\",\"Kubernetes for workload management is present\"],\"gaps\":[\"No Temporal experience despite it being the primary workflow orchestration platform and the role's defining technology\",\"No gRPC for inter-service communication; Gin is an HTTP framework that does not address the gRPC requirement\",\"Temporal's durable execution model involves specific workflow, activity, and saga design patterns that are not transferable from general Go web service experience\"],\"explanation\":\"This candidate has Go, Kubernetes, and datastore coverage but lacks both Temporal and gRPC, which are the two primary inter-service and orchestration technologies of the role. Temporal's programming model is a specialized paradigm that requires dedicated learning, making the absence a fundamental gap for a role where durable workflow orchestration is the core responsibility.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"appwrite_ada\",\"seniority\":\"Junior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"Appwrite\",\"Tailwind CSS\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\"]}\n\nJob Summary:\nOpen source startup is hiring a Junior Full Stack Engineer to build features in their Next.js application backed by Appwrite for auth, storage, and database. TypeScript is required. Tailwind CSS is the styling system. Vitest handles testing. GitHub Actions manages CI. The team values open source contribution and familiarity with self-hosted infrastructure.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js is the primary application framework and is the candidate's core skill\",\"Appwrite for auth, storage, and database is an exact and specific match\",\"TypeScript is required and evidenced\",\"Tailwind CSS is the styling system and is present\",\"Vitest satisfies the testing requirement\",\"GitHub Actions for CI is listed\",\"Junior seniority matches the role level\"],\"gaps\":[\"No explicit self-hosted infrastructure experience evidenced, which the role mentions as valued\"],\"explanation\":\"This candidate matches every stated technical requirement: Next.js, Appwrite, TypeScript, Tailwind CSS, Vitest, and GitHub Actions. Appwrite experience is a specific and uncommon signal that directly satisfies the primary backend service requirement. The only mild gap is the lack of visible self-hosted infrastructure experience, which is a cultural fit factor rather than a hard technical requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"meltano_max\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Meltano\",\"dbt\",\"Apache Airflow\",\"Docker\"],\"databases\":[\"Snowflake\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nE-commerce company is hiring a Mid-level Data Engineer to build ELT pipelines using Singer taps and targets via Meltano. dbt handles transformations on Snowflake. Airflow orchestrates the pipeline schedule. Python and SQL are required. Docker is used in development. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Meltano for Singer-based ELT pipelines is the primary tool and is explicitly listed\",\"dbt for Snowflake transformations is an exact match\",\"Snowflake is the target data warehouse and is present\",\"Apache Airflow for pipeline orchestration is directly listed\",\"Python and SQL are both present\",\"Docker for development is listed\",\"GitHub Actions for CI is present\"],\"gaps\":[],\"explanation\":\"This candidate satisfies every stated requirement: Meltano, dbt, Snowflake, Airflow, Python, SQL, Docker, and GitHub Actions. Meltano experience is a specific and uncommon signal that directly satisfies the Singer-based ELT pipeline requirement. An excellent match with no gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"azure_functions_anya\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\",\"Cloud Engineer\"],\"languages\":[\"C#\",\"Python\"],\"tech\":[\"Azure\",\"ASP.NET\",\"Docker\",\"Entity Framework\"],\"architecture\":[\"Serverless\",\"Microservices\"],\"databases\":[\"MS SQL Server\",\"Redis\"],\"ci_cd\":[\"Azure DevOps\"],\"testing\":[\"xUnit\"]}\n\nJob Summary:\nEnterprise company is hiring a Mid-level .NET Engineer to build Azure Functions in C# with Azure Service Bus for async messaging. Entity Framework connects to MS SQL Server. Azure DevOps handles CI/CD. xUnit covers testing. Docker is used in development. Redis handles distributed caching. ASP.NET Core is used for synchronous API endpoints.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"C# is the required language and is the candidate's primary language\",\"ASP.NET covers the ASP.NET Core synchronous API requirement\",\"Entity Framework for MS SQL Server is an exact match\",\"MS SQL Server is the primary database and is present\",\"Redis for distributed caching is listed\",\"Azure DevOps for CI/CD is an exact match\",\"xUnit satisfies the testing requirement\",\"Docker is present\",\"Azure and serverless architecture background supports Azure Functions work\"],\"gaps\":[\"No explicit Azure Functions experience listed; serverless and Azure are present but Functions-specific development patterns are not evidenced\",\"No Azure Service Bus experience for async messaging\"],\"explanation\":\"This candidate covers the majority of requirements strongly: C#, ASP.NET, Entity Framework, MS SQL Server, Redis, Azure DevOps, and xUnit. The gaps are the absence of explicit Azure Functions and Azure Service Bus experience, which are specific Azure services with distinct programming models. These are learnable within the Azure ecosystem but represent real onboarding items for the role's async architecture.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"zep_memory_zane\",\"seniority\":\"Mid\",\"roles\":[\"AI Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"LangChain\",\"FastAPI\",\"Docker\",\"Hugging Face Transformers\"],\"databases\":[\"PostgreSQL\",\"Weaviate\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nAI assistant company is hiring a Mid-level AI Engineer to build long-term memory systems for conversational agents using LangChain and a vector store. FastAPI serves chat endpoints. Weaviate is the vector memory store. PostgreSQL stores conversation history. Hugging Face models are used for embedding generation. Docker is required. pytest covers testing. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"LangChain for conversational agent orchestration is the primary framework and is listed\",\"Weaviate as the vector memory store is an exact match\",\"FastAPI for chat endpoints is directly listed\",\"PostgreSQL for conversation history is present\",\"Hugging Face Transformers for embedding generation is an exact match\"],\"gaps\":[\"No explicit long-term memory architecture experience beyond tool listing; Zep or similar memory management systems use specific chunking, summarization, and retrieval patterns not evidenced\",\"No experience with conversation context window management strategies which long-term memory systems require to stay within LLM token limits\"],\"explanation\":\"This candidate has strong technical coverage across LangChain, Weaviate, FastAPI, PostgreSQL, and Hugging Face. The gaps are around the architectural patterns for long-term memory systems specifically: context window management, memory summarization, and retrieval strategies that distinguish a memory-augmented agent from a basic RAG pipeline.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cohere_cora\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"MLflow\",\"Docker\",\"CUDA\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nEdtech company is hiring a Senior ML Engineer to build and evaluate NLP models for automated essay scoring. PyTorch with Hugging Face Transformers is the modeling stack. MLflow tracks experiments. Docker containerizes training. CUDA enables GPU acceleration. PostgreSQL stores scoring metadata. GitHub Actions manages CI. Experience with text classification and regression tasks is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PyTorch with Hugging Face Transformers is the exact modeling stack required\",\"MLflow for experiment tracking is an exact match\",\"Docker for containerizing training is present\",\"CUDA for GPU acceleration is directly listed\",\"PostgreSQL for metadata storage is present\",\"GitHub Actions for CI is listed\",\"NLP and text processing experience is evidenced by the Transformers focus\"],\"gaps\":[],\"explanation\":\"This candidate covers every stated technical requirement: PyTorch, Hugging Face Transformers, MLflow, Docker, CUDA, PostgreSQL, and GitHub Actions. Their NLP-focused ML stack is precisely aligned with automated essay scoring which is an NLP text regression task. An excellent match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sst_sam\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\",\"Cloud Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"SST\",\"Next.js\",\"React\",\"Tailwind CSS\",\"tRPC\",\"AWS\"],\"architecture\":[\"Serverless\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nStartup is hiring a Mid-level Full Stack Engineer to build their product on SST with AWS as the cloud backbone. Next.js renders the frontend. tRPC provides type-safe APIs. Tailwind CSS styles the UI. DynamoDB and PostgreSQL serve different workloads. Vitest and Playwright cover testing. GitHub Actions manages CI. TypeScript is used throughout.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SST is the primary infrastructure framework and is explicitly listed as the candidate's core tool\",\"Next.js is the frontend framework and is present\",\"tRPC for type-safe APIs is an exact match\",\"AWS is the cloud backbone and is present\",\"DynamoDB and PostgreSQL cover both datastore requirements\",\"Vitest and Playwright satisfy both testing requirements\"],\"gaps\":[\"No explicit experience managing SST infrastructure at production scale with complex multi-stack configurations and staged deployments\",\"No IAM or AWS security architecture experience listed which SST-based production deployments require for least-privilege resource access\"],\"explanation\":\"SST experience is a specific and valuable signal for this role. The open questions are around SST production operations at scale including multi-environment staged deployments and the AWS IAM and security patterns that production SST stacks require. A technically well-aligned candidate with production infrastructure depth to assess.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"prisma_postgres_priti\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Express.js\",\"Prisma\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nB2B startup is hiring a Mid-level Backend Engineer to build and own REST APIs using NestJS in TypeScript. Prisma manages PostgreSQL. BullMQ handles job queues backed by Redis. Docker is required. Jest covers unit testing. GitHub Actions manages CI. The role expects autonomous feature delivery with minimal supervision.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript is the required language and is the candidate's primary language\",\"Prisma for PostgreSQL is an exact match\",\"PostgreSQL is the primary database and is present\",\"Docker is listed\",\"Jest satisfies the unit testing requirement\",\"GitHub Actions for CI is listed\"],\"gaps\":[\"No NestJS experience; candidate uses Express.js which is a different framework paradigm\",\"No BullMQ or Redis for job queue management\",\"Junior seniority versus mid-level autonomous delivery expectation is a concern\"],\"explanation\":\"This candidate has relevant TypeScript, Prisma, PostgreSQL, Docker, and Jest experience. The gaps are NestJS versus Express.js, the absence of BullMQ and Redis for job queues, and the junior-to-mid seniority gap for a role expecting autonomous delivery. A possible fit with a clear NestJS ramp and structured mentorship.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"appsync_alex\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Cloud Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"AWS\",\"AWS Lambda\",\"Docker\",\"FastAPI\"],\"architecture\":[\"Serverless\",\"Microservices\"],\"databases\":[\"DynamoDB\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"AWS CodePipeline\"]}\n\nJob Summary:\nMedia company is hiring a Senior Backend Engineer to build a GraphQL API layer using AWS AppSync with DynamoDB resolvers. Lambda functions handle custom business logic. AWS CodePipeline and GitHub Actions manage CI/CD. TypeScript is used throughout. PostgreSQL stores relational data. Docker is required. Serverless architecture patterns are practiced.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"AWS Lambda for custom business logic is an exact match\",\"DynamoDB and PostgreSQL cover the datastore requirements\",\"AWS CodePipeline and GitHub Actions satisfy the CI/CD requirements\"],\"gaps\":[\"No AWS AppSync experience despite it being the core GraphQL API layer of the platform\",\"No GraphQL experience at all; candidate uses FastAPI and REST API conventions throughout\",\"AppSync's resolver mapping templates, VTL expressions, and schema design require dedicated learning with no overlap in the candidate's REST background\"],\"explanation\":\"This candidate has useful AWS Lambda, DynamoDB, and CI/CD coverage but lacks AWS AppSync and GraphQL experience entirely. AppSync is the primary API layer of the platform and GraphQL schema design and resolver development are the core daily responsibilities. REST API experience does not transfer to AppSync's event-driven resolver model.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"liveblocks_leo\",\"siniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Next.js\",\"React\",\"Liveblocks\",\"Tailwind CSS\",\"Prisma\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nCollaborative document startup is building real-time multi-user editing features with Liveblocks for presence and storage. Next.js is the frontend framework. Prisma manages PostgreSQL. Tailwind CSS styles the UI. TypeScript is required throughout. Vitest and Playwright cover testing. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Liveblocks for real-time presence and storage is the core technology and is explicitly listed\",\"Next.js is the primary frontend framework and is present\",\"Prisma for PostgreSQL management is an exact match\",\"PostgreSQL is the primary database and is listed\",\"Tailwind CSS for styling is present\"],\"gaps\":[\"No explicit experience with collaborative editing conflict resolution or CRDT implementation patterns which document collaboration products typically build on top of Liveblocks\",\"No WebSocket or real-time communication debugging experience evidenced for a product where connection reliability is critical\"],\"explanation\":\"Liveblocks experience is a strong and specific match for this collaborative document startup. The open questions are around collaborative editing conflict resolution depth and real-time connection reliability patterns that production collaborative tools require beyond standard Liveblocks setup. A technically precise candidate with collaboration architecture depth to confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"trpc_tandem_thao\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Next.js\",\"tRPC\",\"Prisma\",\"Tailwind CSS\",\"shadcn/ui\",\"Zustand\"],\"architecture\":[\"Serverless\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nEnterprise productivity startup is hiring a Senior Full Stack Engineer to build and own their Next.js application. tRPC provides the API layer with Prisma on PostgreSQL. Redis is used for caching. Tailwind CSS and shadcn/ui compose the design system. Zustand manages UI state. Vitest and Playwright cover testing. GitHub Actions manages CI. TypeScript is used throughout.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js is the primary framework and is the candidate's core technology\",\"tRPC for the API layer is an exact match\",\"Prisma on PostgreSQL is an exact match\",\"Redis for caching is listed\",\"Tailwind CSS and shadcn/ui for the design system are both present\",\"Zustand for UI state management is directly listed\",\"Vitest and Playwright satisfy both testing requirements exactly\",\"GitHub Actions for CI is listed\",\"TypeScript throughout is required and evidenced\"],\"gaps\":[],\"explanation\":\"Every technology in the job description is present: Next.js, tRPC, Prisma, PostgreSQL, Redis, Tailwind CSS, shadcn/ui, Zustand, Vitest, Playwright, and GitHub Actions. This is a complete and precise match for the modern TypeScript full stack role. An ideal candidate with no gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"benthos_beatrice\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\",\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Redpanda\",\"Benthos\",\"Docker\",\"Kubernetes\",\"Terraform\"],\"architecture\":[\"Event-Driven\",\"Cloud-Native\"],\"databases\":[\"PostgreSQL\",\"ClickHouse\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nStreaming infrastructure company is hiring a Senior Data Platform Engineer to build real-time data pipelines using Redpanda as the Kafka-compatible streaming layer and Benthos for stream processing. Kubernetes manages workloads. Terraform provisions infrastructure. ClickHouse is the analytics store. Docker is required. Argo CD handles GitOps. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Redpanda as the Kafka-compatible streaming layer is an exact and specific match\",\"Benthos for stream processing is the core processing tool and is directly listed\",\"Kubernetes for workload management is present\",\"Terraform for infrastructure provisioning is an exact match\",\"ClickHouse as the analytics store is listed\",\"Docker is present\",\"Argo CD for GitOps is listed\",\"GitHub Actions for CI is present\",\"Event-driven and cloud-native architecture are both explicitly listed\"],\"gaps\":[],\"explanation\":\"The combination of Redpanda and Benthos is an exceptionally specific and rare match for this streaming infrastructure role. Kubernetes, Terraform, ClickHouse, Argo CD, and GitHub Actions are also all present. This candidate's profile is a complete and precise fit with no gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fresh_deno_fiona\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Fresh\",\"Deno\",\"Preact\",\"Tailwind CSS\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Deno testing\"]}\n\nJob Summary:\nDeveloper tools company is building their web product using the Deno stack with Fresh as the framework and Preact for UI components. Tailwind CSS styles the application. PostgreSQL is the primary database. Deno's built-in test runner handles testing. GitHub Actions manages CI. TypeScript is the only language used.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Fresh is the primary framework and is the candidate's core technology\",\"Deno is the required runtime and is the candidate's primary platform\",\"Preact for UI components is an exact match\",\"Tailwind CSS is the styling system and is present\",\"PostgreSQL is the primary database and is listed\"],\"gaps\":[\"No explicit island architecture or partial hydration experience beyond Fresh listing; Fresh's island model requires specific component boundary design thinking\",\"No production deployment experience with Deno Deploy or self-hosted Deno runtime which developer tools companies often use\"],\"explanation\":\"Fresh and Deno expertise is a rare and precise match for this developer tools role. The gaps are around Fresh's island architecture depth for complex interactive components and production Deno deployment experience beyond local development, which is the operational layer the company needs. A technically aligned candidate with deployment depth to confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"supabase_realtime_sara\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Next.js\",\"React\",\"Supabase\",\"Zustand\",\"Tailwind CSS\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nMarketplace startup is hiring a Mid-level Full Stack Engineer to build real-time bidding features in Next.js using Supabase Realtime channels for live updates. Zustand manages client-side state. Tailwind CSS is the styling system. TypeScript is required. Jest and Playwright cover testing. GitHub Actions manages CI. Stripe integration experience is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js is the primary framework and is listed as a core skill\",\"Supabase including Realtime capabilities is the backend and is directly listed\",\"Zustand for client-side state management is an exact match\",\"Tailwind CSS is the styling system and is present\",\"TypeScript is required and evidenced\",\"Jest and Playwright satisfy both testing requirements\",\"GitHub Actions for CI is present\"],\"gaps\":[\"No Stripe integration experience listed, which is a plus requirement for a marketplace context where payment flows are common\",\"No explicit experience with high-concurrency real-time features such as live bidding under load, which introduces specific Supabase Realtime channel management patterns\"],\"explanation\":\"This candidate covers the core technical stack well: Next.js, Supabase, Zustand, Tailwind CSS, TypeScript, Jest, and Playwright. The gaps are the missing Stripe experience which is a plus for a marketplace role, and the lack of demonstrated high-concurrency real-time feature experience which is the defining complexity of a live bidding system.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"graphite_geo\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\",\"Platform Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Vault\",\"Prometheus\",\"Grafana\",\"Docker\"],\"architecture\":[\"Cloud-Native\",\"Multi-Tenant\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Flux\"]}\n\nJob Summary:\nFintec company is hiring a Senior Platform Engineer to manage a multi-tenant Kubernetes platform on Azure. Vault handles secrets management. Helm and Flux implement GitOps. Terraform provisions Azure resources. Prometheus and Grafana cover observability. Docker is required throughout. Python and Go scripting support automation.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes for multi-tenant platform management is a primary skill\",\"Vault for secrets management is an exact match\",\"Helm and Flux both satisfy the GitOps requirements exactly\",\"Terraform for resource provisioning is present\",\"Prometheus and Grafana for observability are both listed\",\"Docker is present\",\"Python and Go scripting are both covered\",\"Multi-tenant architecture is explicitly listed\"],\"gaps\":[\"No explicit Azure experience listed; cloud-native background may reflect AWS or GCP experience rather than Azure-specific services\"],\"explanation\":\"This candidate satisfies every stated technical requirement except Azure-specific experience: Vault, Helm, Flux, Terraform, Prometheus, Grafana, Docker, Python, and Go are all present. The only uncertainty is whether the cloud-native background includes Azure familiarity, as provider-specific networking, identity, and storage services differ meaningfully from generic Kubernetes operations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pubsub_peter\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\"],\"tech\":[\"FastAPI\",\"Docker\",\"Kubernetes\",\"Celery\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nIoT platform startup is hiring a Mid-level Backend Engineer to build device telemetry ingestion services using MQTT and Google Cloud Pub/Sub. Go is the primary language for ingestion services. FastAPI handles REST management APIs in Python. PostgreSQL and Redis are the datastores. Kubernetes orchestrates all services. Docker is required. pytest covers testing. GitHub Actions manages CI.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"FastAPI for REST management APIs is an exact match\",\"PostgreSQL and Redis cover the datastore requirements\",\"Kubernetes and Docker are both present\"],\"gaps\":[\"No MQTT experience despite it being the device communication protocol for telemetry ingestion\",\"No Google Cloud Pub/Sub experience for the async messaging backbone of the IoT platform\",\"Go is listed as secondary to Python, introducing uncertainty about depth for the primary ingestion service language\"],\"explanation\":\"This candidate has relevant FastAPI, PostgreSQL, Redis, and Kubernetes skills but is missing MQTT and Google Cloud Pub/Sub, which are the two IoT-specific communication protocols central to the platform's device ingestion architecture. The secondariness of Go further limits the candidate's readiness for the primary ingestion service development.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pocketbase_pablo\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Go\"],\"tech\":[\"SvelteKit\",\"PocketBase\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nIndependent software company is hiring a Mid-level Full Stack Engineer to build and extend their SvelteKit application backed by PocketBase as the backend and database. TypeScript is required. Tailwind CSS is the styling system. Vitest and Playwright handle testing. GitHub Actions manages CI. Go knowledge is a plus for extending PocketBase with custom hooks.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SvelteKit is the primary frontend framework and is the candidate's core technology\",\"PocketBase as the backend and database is an exact match\",\"TypeScript is required and evidenced\",\"Tailwind CSS is the styling system and is present\",\"Vitest and Playwright satisfy both testing requirements\"],\"gaps\":[\"No explicit experience extending PocketBase with custom Go hooks, which the role flags as a plus but which Go being the candidate's secondary language suggests limited depth\",\"No production deployment or hosting experience for a PocketBase-based application listed\"],\"explanation\":\"This candidate's SvelteKit and PocketBase combination is a precise technical match. The gaps are around Go depth for PocketBase extension development, which the role treats as a plus, and production deployment experience. A strong technical match with Go depth and operational experience to confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sparse_sol\",\"seniority\":\"Mid\",\"languages\":[\"Python\",\"TypeScript\"],\"tech\":[\"React\",\"FastAPI\"]}\n\nJob Summary:\nFintec startup is hiring a Mid-level Site Reliability Engineer to manage Kubernetes infrastructure on AWS, build observability pipelines with OpenTelemetry, and implement incident response automation in Go. Terraform provisions all resources. Prometheus and Grafana handle metrics. Argo CD manages GitOps deployments. A strong systems background and Go scripting experience are required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is listed and may support scripting tasks peripherally\"],\"gaps\":[\"No Kubernetes experience despite it being the core infrastructure platform\",\"No OpenTelemetry or observability tooling experience\",\"No Go experience despite it being required for incident response automation\",\"No Terraform for infrastructure provisioning\",\"No Prometheus or Grafana for metrics\",\"No Argo CD for GitOps\",\"No AWS experience\",\"Sparse profile of React and FastAPI has no SRE or systems engineering relevance\"],\"explanation\":\"This candidate's sparse profile covers only React and FastAPI development with no systems, infrastructure, or SRE tooling signals. The role requires Go, Kubernetes, Terraform, OpenTelemetry, Prometheus, Grafana, Argo CD, and AWS, none of which are present. This is a fundamental domain and tooling mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rkapur_dev\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\",\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"Python\",\"SQL\"],\"tech\":[\"Next.js\",\"React\",\"FastAPI\",\"Docker\",\"Kubernetes\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nWe are a Series B fintech startup hiring a Senior Full Stack Engineer to own our customer-facing dashboard and backend APIs. Our stack is TypeScript, Next.js, and FastAPI backed by PostgreSQL. You will work closely with product and design, ship features end-to-end, and help define our service architecture as we scale. Experience with containerized deployments and automated testing is important. We value engineers who can operate with high autonomy in a fast-paced environment.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Exact stack match: TypeScript, Next.js, FastAPI, and PostgreSQL all present\",\"Microservices and Event-Driven architecture experience aligns with scaling goals\",\"Covers automated testing across frontend (Jest, Playwright) and backend (pytest)\",\"Kubernetes and ArgoCD signal production-grade deployment experience\"],\"gaps\":[\"No explicit product or design collaboration signals in profile\"],\"explanation\":\"The candidate's stack is a near-perfect match for the role with TypeScript, Next.js, FastAPI, and PostgreSQL all prominently listed. Architecture and CI/CD signals indicate they can operate at the scale the startup is heading toward. The only minor gap is the absence of explicit product collaboration signals, which is not a hard blocker.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mwangi_bytes\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"Firebase\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nFANG-adjacent company seeking a Senior Frontend Engineer to lead the migration of a legacy AngularJS application to React. The ideal candidate has deep experience with large-scale React codebases, state management libraries like Redux or Zustand, performance optimization, and mentoring junior engineers. You will own the migration roadmap and coordinate across multiple product teams.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React experience is present and relevant\"],\"gaps\":[\"Junior seniority \u2014 role requires Senior-level ownership and mentoring\",\"No AngularJS or migration project signals\",\"No state management libraries such as Redux or Zustand\",\"No cross-team coordination or leadership signals\",\"Testing experience is minimal for a large-scale codebase context\"],\"explanation\":\"While the candidate works in React, their junior seniority and thin profile fall significantly short of the Senior-level scope this role demands. The absence of state management, migration experience, and any mentoring signals makes this a poor fit. The role requires ownership and leadership the candidate's profile does not yet support.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priya_infra\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\",\"Platform Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Docker\",\"Ansible\",\"Prometheus\",\"Grafana\",\"AWS\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\",\"GitLab CI\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nEnterprise SaaS company looking for a Senior DevOps Engineer to manage and evolve our Kubernetes-based infrastructure on AWS. Responsibilities include writing Terraform modules, maintaining Helm charts, building observability pipelines with Prometheus and Grafana, and improving CI/CD reliability. We need someone comfortable operating multi-tenant cloud-native systems and collaborating with engineering teams to reduce toil.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Terraform, and Helm are all present and prominent\",\"AWS cloud experience matches hosting environment\",\"Prometheus and Grafana signal direct observability pipeline experience\",\"Multiple CI/CD platforms demonstrate reliability engineering breadth\",\"Cloud-Native and Microservices architecture align with multi-tenant system context\"],\"gaps\":[],\"explanation\":\"The candidate's profile is an exceptionally strong match, covering every technical requirement listed including Kubernetes, Terraform, Helm, AWS, Prometheus, and Grafana. Their architecture background in Cloud-Native and Microservices is exactly relevant to multi-tenant SaaS infrastructure. No meaningful gaps are apparent.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dlopez_ml\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"NumPy\",\"MLflow\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nGrowth-stage startup building recommendation systems for e-commerce. We are hiring a Machine Learning Engineer to train, evaluate, and deploy ranking models. Our stack is Python and PyTorch. Experience with experiment tracking, feature stores, and deploying models to production APIs is key. Familiarity with large-scale data processing using Spark or BigQuery is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch and scikit-learn directly match the modeling stack\",\"MLflow signals experiment tracking experience\",\"BigQuery experience aligns with large-scale data processing needs\",\"Docker indicates some awareness of production deployment\"],\"gaps\":[\"No evidence of ranking model or recommendation system work specifically\",\"No Spark or feature store signals\",\"No production API deployment stack such as FastAPI or BentoML\",\"Mid-level seniority may limit ownership of the full ML lifecycle\"],\"explanation\":\"The candidate has a solid ML foundation with PyTorch, MLflow, and BigQuery that covers several key requirements. However, the lack of recommendation system or ranking experience and absent feature store or serving infrastructure signals introduce meaningful uncertainty. They are a reasonable candidate to evaluate further but not a clear-cut fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tomek_backend\",\"seniority\":\"Lead\",\"roles\":[\"Backend Engineer\",\"Software Architect\"],\"languages\":[\"Java\",\"Kotlin\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Kafka\",\"Docker\",\"Kubernetes\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"CQRS\",\"Domain-Driven Design\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Elasticsearch\"],\"ci_cd\":[\"Jenkins\",\"GitLab CI\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nLarge European bank modernizing its core transaction processing platform. Seeking a Lead Backend Engineer with deep Java and Spring Boot experience to design event-driven microservices handling millions of daily transactions. You must be comfortable with Kafka, distributed data stores, and DDD. The team values rigorous testing practices and long-term architectural thinking.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Java, Spring Boot, and Kafka are all primary and prominent\",\"CQRS, DDD, and Event-Driven architecture signals are a direct match for the platform design\",\"Cassandra and Elasticsearch alongside PostgreSQL demonstrate distributed data store experience\",\"Lead-level seniority with Software Architect role matches the architectural ownership expected\",\"JUnit and Mockito indicate rigorous Java testing practices\"],\"gaps\":[\"No explicit financial domain or compliance-related signals\"],\"explanation\":\"This candidate's profile reads like it was built for this role, with Java, Spring Boot, Kafka, DDD, CQRS, and distributed databases all present at the lead level. Their architecture credentials strongly support the platform design responsibilities. The only minor note is the absence of financial domain signals, which is unlikely to be a dealbreaker for a technically focused role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sara_vue\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Tailwind CSS\",\"Pinia\",\"Vite\"],\"databases\":[\"Firebase\"],\"testing\":[\"Vitest\",\"Cypress\"]}\n\nJob Summary:\nB2B SaaS startup hiring a Mid-level Frontend Engineer to build and maintain a React-based design system and component library. The ideal candidate has experience with Storybook, accessibility standards, and TypeScript. Familiarity with CSS-in-JS solutions and contributing to shared component libraries across multiple product teams is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript experience is relevant\",\"Tailwind CSS and Vite indicate modern frontend tooling familiarity\"],\"gaps\":[\"Vue.js and Nuxt.js background \u2014 no React experience visible\",\"No Storybook or design system signals\",\"No accessibility or CSS-in-JS signals\",\"No experience contributing to shared component libraries across teams\"],\"explanation\":\"The candidate is an experienced Vue.js engineer, but the role is explicitly React-based and centered on design system work, which requires a different framework and specialized skills. With no React, Storybook, or component library signals visible, this is a weak match despite comparable seniority. A framework transition is a significant gap for a role where React proficiency is the core requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"akechi_data\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\",\"Analytics Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Spark\",\"dbt\",\"Apache Airflow\",\"Pandas\",\"Docker\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\",\"Redshift\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nEnterprise healthcare analytics company hiring a Senior Data Engineer to build and maintain ELT pipelines feeding our clinical data warehouse. Stack is dbt, Snowflake, and Airflow. We need someone who can model data rigorously, enforce data quality, and work with analysts to deliver trusted datasets. Python scripting for pipeline automation is expected. Experience with healthcare data standards is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt, Snowflake, and Airflow are all present and prominent \u2014 exact stack match\",\"Great Expectations signals data quality enforcement experience directly\",\"BigQuery and Redshift alongside Snowflake demonstrate multi-warehouse fluency\",\"pytest and Great Expectations together indicate rigorous pipeline testing discipline\",\"Apache Spark and distributed system architecture signal ability to handle large-scale clinical data\"],\"gaps\":[\"No healthcare data standards such as HL7 or FHIR signals visible\"],\"explanation\":\"The candidate's stack aligns with every core technical requirement: dbt, Snowflake, Airflow, Python, and data quality tooling via Great Expectations. Their multi-warehouse experience and distributed system architecture background are strong differentiators. The only gap is the absence of healthcare-specific data standards, which the job listed as a plus rather than a requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"felix_rust\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"C++\",\"Python\"],\"tech\":[\"Actix\",\"Docker\",\"Redis\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"]}\n\nJob Summary:\nDeep tech startup building high-performance networking infrastructure. Hiring a Backend Engineer with strong Rust or C++ skills to implement low-latency data pipelines and protocol handlers. Experience with systems-level programming, memory management, and performance profiling is essential. Familiarity with async Rust runtimes or DPDK is a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Rust and C++ are both present, directly matching the core language requirement\",\"Actix signals async Rust web/networking experience\",\"Systems-level background implied by the language stack\"],\"gaps\":[\"No explicit performance profiling or benchmarking tools visible\",\"No DPDK or low-latency networking protocol signals\",\"Mid-level seniority may be a stretch for the depth of systems expertise implied\",\"Sparse profile makes it difficult to assess depth of Rust experience\"],\"explanation\":\"The candidate's Rust and C++ background is directly relevant, and Actix suggests they work with async Rust in practice. However, the sparse profile makes it hard to assess depth, and the absence of profiling tools or networking protocol experience leaves meaningful uncertainty for a role this specialized. A technical screen would be needed to gauge real fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jnkimura\",\"seniority\":\"Intern\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"React\",\"Flask\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nFANG-style company hiring a Principal Engineer to define the technical vision for a distributed payments platform serving hundreds of millions of users. The role requires deep expertise in distributed systems, consensus protocols, and large-scale reliability engineering. You will mentor staff engineers and represent engineering in executive conversations.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Intern seniority \u2014 role requires Principal-level expertise\",\"No distributed systems or consensus protocol experience\",\"No reliability engineering or large-scale system design signals\",\"No mentoring or leadership indicators\",\"Stack is entry-level and does not approach the technical depth required\"],\"explanation\":\"This candidate is at the very beginning of their career and there is no dimension of their profile that approaches the Principal-level technical scope this role demands. The gap in seniority, system design depth, and leadership experience is fundamental. This is not a viable match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nadia_mobile\",\"seniority\":\"Senior\",\"roles\":[\"iOS Engineer\",\"Mobile Engineer\"],\"languages\":[\"Swift\",\"Kotlin\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Jetpack Compose\",\"React Native\",\"Firebase\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"Detox\",\"Appium\"]}\n\nJob Summary:\nConsumer startup hiring a Senior Mobile Engineer to lead development of their cross-platform app currently built in React Native. The team plans to gradually introduce native modules for performance-critical features. Experience with both iOS and Android native development alongside React Native is highly valued. CI/CD automation for mobile and strong testing practices are expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React Native experience directly matches the current app stack\",\"SwiftUI, UIKit, and Jetpack Compose demonstrate genuine native iOS and Android depth\",\"Fastlane and GitHub Actions indicate mobile-specific CI/CD automation experience\",\"Detox and Appium signal cross-platform mobile testing expertise\",\"Kotlin alongside Swift confirms true cross-platform native capability\"],\"gaps\":[\"No architecture or state management signals for large React Native codebases\"],\"explanation\":\"The candidate is a strong match with React Native as the current stack, native iOS and Android experience for the planned native module work, and mobile-specific CI/CD and testing tooling all present. The combination of cross-platform and native depth is rare and directly addresses the team's roadmap. The only minor gap is the absence of state management signals for React Native at scale.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"brendan_sre\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Prometheus\",\"Grafana\",\"Terraform\",\"AWS\",\"Datadog\",\"OpenTelemetry\"],\"architecture\":[\"Cloud-Native\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"]}\n\nJob Summary:\nE-commerce platform at scale hiring a Senior SRE to own reliability and observability for services processing over a billion events per day. Responsibilities include defining SLOs, building alerting pipelines, and driving incident response processes. Our stack is Go, Kubernetes, and AWS. Deep experience with distributed tracing and metrics platforms is critical.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go, Kubernetes, and AWS match the core stack precisely\",\"Prometheus, Grafana, Datadog, and OpenTelemetry demonstrate observability breadth\",\"Distributed System architecture aligns with billion-event-per-day scale\"],\"gaps\":[\"No SLO definition or error budget tooling signals\",\"No incident management platform signals such as PagerDuty or OpsGenie\",\"No on-call process or runbook signals for a role where incident response is central\",\"No capacity planning or reliability engineering methodology signals\"],\"explanation\":\"The candidate's technical stack is well-aligned with strong observability and infrastructure credentials. However, SRE roles at this scale center on SLO ownership and incident response process, and neither is evidenced in the profile. The distinction between a strong infrastructure engineer and a true SRE at billion-event scale lies in these operational practices, which are notably absent.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"grace_fullstack\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Express.js\",\"Django\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\"]}\n\nJob Summary:\nHealthtech startup seeking a Mid-level Full Stack Engineer to build HIPAA-compliant patient portal features. Stack is React, Django, and PostgreSQL. You will work across the full stack on new feature development, write unit and integration tests, and participate in code review. Experience with secure coding practices and healthcare data sensitivity is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React, Django, and PostgreSQL match the stated stack directly\",\"Jest and pytest cover frontend and backend testing needs\",\"Docker and GitHub Actions signal basic production workflow familiarity\",\"Full stack role and seniority alignment is appropriate\"],\"gaps\":[\"No HIPAA or healthcare compliance signals\",\"No security-focused tooling or secure coding practice indicators\",\"MongoDB present but not required \u2014 does not add meaningful signal here\"],\"explanation\":\"The candidate's core stack is a solid technical match for the role across React, Django, and PostgreSQL with appropriate testing coverage. However, the absence of any security or healthcare compliance signals is a noticeable gap for a HIPAA-regulated context. They are a reasonable candidate who would likely need onboarding support on the compliance and security dimensions.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amara_data_sci\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\",\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"NumPy\",\"Hugging Face Transformers\",\"MLflow\",\"Weights & Biases\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAI research lab hiring a Senior Machine Learning Engineer to develop and fine-tune large language models for domain-specific applications. The team uses PyTorch and Hugging Face extensively. Experience with training pipelines, experiment tracking, and distributed GPU training is required. Familiarity with RLHF or alignment techniques is a strong differentiator.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch and Hugging Face Transformers are both prominent and directly match the core stack\",\"MLflow and Weights and Biases signal mature experiment tracking practices\",\"Senior seniority aligns with the research engineer scope\",\"R and broad statistical background complement the research orientation\"],\"gaps\":[\"No CUDA or distributed training infrastructure signals\",\"No RLHF or alignment-specific signals visible\",\"No evidence of multi-GPU or cluster training experience\"],\"explanation\":\"The candidate has strong ML research credentials with PyTorch, Hugging Face, and mature experiment tracking, making them a solid foundation for this role. However, the absence of distributed GPU training signals and any RLHF or alignment experience represents a real gap for an LLM-focused research lab where those skills are differentiating requirements. They are a good fit on fundamentals but may require significant ramp-up on the infrastructure and alignment side.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kvon_embed\",\"seniority\":\"Senior\",\"roles\":[\"Embedded Engineer\",\"Firmware Engineer\"],\"languages\":[\"C\",\"C++\",\"Python\"],\"tech\":[\"Docker\",\"CMake\"],\"ci_cd\":[\"Jenkins\",\"GitLab CI\"]}\n\nJob Summary:\nIoT hardware company seeking a Senior Embedded Software Engineer to develop firmware for ARM Cortex-M microcontrollers. You will write real-time operating system code using FreeRTOS, implement hardware drivers, and work with RF communication protocols. Experience with JTAG debugging, static analysis tools, and low-power optimization techniques is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"C and C++ are the primary embedded languages and are present\",\"Senior seniority and Embedded and Firmware roles match exactly\",\"CMake is relevant for embedded build systems\",\"CI/CD pipeline experience suggests some level of firmware delivery process maturity\"],\"gaps\":[\"No FreeRTOS or RTOS signals visible\",\"No ARM or microcontroller-specific toolchain signals\",\"No RF protocol or hardware driver signals\",\"No JTAG, static analysis, or low-power optimization indicators\"],\"explanation\":\"The candidate's role and language background are appropriate for embedded work, but the profile lacks almost every domain-specific technical signal the role requires, including RTOS, ARM toolchains, hardware protocols, and debugging tools. It is possible they have this experience but it is not visible, making this a high-uncertainty moderate at best pending further validation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lchen_platform\",\"seniority\":\"Staff\",\"roles\":[\"Platform Engineer\",\"DevOps Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Istio\",\"AWS\",\"Vault\",\"Consul\"],\"architecture\":[\"Service Mesh\",\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\",\"Tekton\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nLate-stage startup building internal developer platform to improve engineering velocity across 30 product teams. Seeking a Staff Platform Engineer to design and operate a Kubernetes-based PaaS layer with service mesh, secrets management, and self-service tooling. Deep experience with Istio, Vault, and GitOps is essential. You will influence platform strategy and mentor senior engineers.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Istio, Vault, and Consul are all present and directly match core requirements\",\"ArgoCD and Tekton demonstrate strong GitOps and pipeline-as-code capabilities\",\"Service Mesh and Cloud-Native architecture signals are exact matches\",\"Staff seniority aligns with platform strategy and mentoring scope\",\"Helm and Terraform indicate infrastructure-as-code depth for self-service tooling\"],\"gaps\":[\"No explicit developer experience or internal tooling product signals\"],\"explanation\":\"The candidate's profile covers every hard technical requirement with Kubernetes, Istio, Vault, GitOps via ArgoCD, and Terraform all prominently listed at Staff level. Their architecture background in Service Mesh and Cloud-Native is directly relevant to the PaaS layer design. The only gap worth noting is the absence of explicit internal developer tooling or DX-focused product signals, which is minor given the depth of the infrastructure credentials.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"obi_rails\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"Ruby\",\"JavaScript\",\"SQL\"],\"tech\":[\"Ruby on Rails\",\"React\",\"Sidekiq\",\"Redis\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"CircleCI\"],\"testing\":[\"RSpec\"]}\n\nJob Summary:\nBootstrapped SaaS company looking for a Mid-level Backend Engineer to extend their Ruby on Rails API platform. You will build new API endpoints, improve background job reliability using Sidekiq, and work with PostgreSQL. The team is small and values engineers who write clean, well-tested code and can work autonomously.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Ruby on Rails and Sidekiq are the primary stack and match the role directly\",\"PostgreSQL and Redis align with the data layer\",\"RSpec signals Rails-native testing discipline\"],\"gaps\":[\"No explicit background job reliability engineering signals beyond Sidekiq listing\",\"No API design or REST endpoint development pattern signals\",\"No small-team or autonomous delivery signals to validate the working style fit\",\"Docker present but no production deployment context signals\"],\"explanation\":\"The candidate's Ruby on Rails and Sidekiq background aligns with the core stack, and RSpec confirms testing discipline. However, the role emphasizes clean, well-tested code and autonomous operation in a small team, and the profile does not provide enough depth signals to confirm either. Sidekiq reliability specifically is a nuanced skill that listing alone does not validate.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"irene_ux_dev\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\",\"CSS\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Framer Motion\",\"Storybook\",\"shadcn/ui\"],\"testing\":[\"Jest\",\"React Testing Library\"]}\n\nJob Summary:\nProduct design agency seeking a Mid-level Frontend Engineer with strong UI implementation skills. You will translate Figma designs into polished React components, contribute to a shared design system, and collaborate with designers daily. Experience with animation libraries and accessibility is valued. Storybook for component documentation is part of the workflow.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React, Tailwind CSS, and shadcn/ui indicate strong modern UI implementation capability\",\"Storybook and React Testing Library are directly relevant to the design system workflow\",\"Framer Motion signals animation library experience explicitly mentioned in the job\",\"Jest and React Testing Library show testing practice appropriate for the role\"],\"gaps\":[\"Junior seniority \u2014 role is scoped for Mid-level\",\"No explicit accessibility signals\",\"No Figma or design collaboration workflow signals visible\"],\"explanation\":\"The candidate's frontend tooling is highly relevant, particularly Storybook, Framer Motion, and shadcn/ui which directly match the role's workflow. However, their junior seniority is a meaningful gap for a mid-level position, and the absence of accessibility signals is notable for a design-forward agency. They are a strong candidate to watch but may need another 12 to 18 months of experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yusei_golang\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\",\"SQL\"],\"tech\":[\"Gin\",\"gRPC\",\"Docker\",\"Kubernetes\",\"Kafka\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"Cassandra\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nStreaming infrastructure company seeking a Senior Backend Engineer to build high-throughput data ingestion services in Go. The team uses Kafka and gRPC for inter-service communication and deploys on Kubernetes. Cassandra is used for time-series event storage. Engineers are expected to design microservices, write robust integration tests, and own services end to end.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go is the primary language and matches directly\",\"Kafka and gRPC are both present, matching inter-service communication requirements\",\"Cassandra experience maps precisely to the time-series event storage use case\",\"Microservices and Event-Driven architecture align with the service design expectations\",\"Kubernetes deployment experience is present\"],\"gaps\":[\"Testing signals are in pytest rather than Go-native testing tools \u2014 minor concern for Go integration test ownership\"],\"explanation\":\"The candidate's profile aligns with precision across Go, Kafka, gRPC, Cassandra, and Kubernetes. Their architecture background in Microservices and Event-Driven systems directly matches the domain. The only minor note is that testing signals are in Python rather than Go, which may mean their Go integration testing depth is less established, but this is a marginal concern.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ada_contract\",\"seniority\":\"Mid\",\"roles\":[\"Blockchain Engineer\",\"Smart Contract Developer\"],\"languages\":[\"Solidity\",\"TypeScript\",\"Python\"],\"tech\":[\"Hardhat\",\"Ethers.js\",\"IPFS\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nDeFi protocol seeking a Smart Contract Engineer to design and audit EVM-compatible contracts using Solidity. You will write and test contracts using Hardhat, integrate with frontend dApps via Ethers.js, and conduct internal security reviews. Familiarity with common vulnerabilities such as reentrancy and flash loan attacks is essential.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Solidity is the primary language and is directly present\",\"Hardhat and Ethers.js both match the development and integration tooling\",\"IPFS experience is relevant for decentralized storage in DeFi contexts\",\"TypeScript enables frontend dApp integration work\"],\"gaps\":[\"No formal security auditing or vulnerability analysis tool signals such as Slither or Echidna\",\"No explicit signals of reentrancy or flash loan vulnerability experience\",\"Mid-level seniority for a role that involves internal security reviews may be a stretch\"],\"explanation\":\"The candidate has the right core stack with Solidity, Hardhat, and Ethers.js all present. However, the security review requirement is a significant expectation that their profile does not directly support through any auditing tooling or security-specific signals. This makes them a reasonable developer candidate but an uncertain fit for the security responsibilities without further validation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pascal_monolith\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"SQL\",\"JavaScript\"],\"tech\":[\"Laravel\",\"Symfony\",\"Vue.js\",\"Redis\",\"Docker\"],\"architecture\":[\"Monolith\",\"Layered Architecture\"],\"databases\":[\"MySQL\",\"PostgreSQL\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nEstablished e-commerce company running a large Laravel monolith seeking a Senior PHP Engineer to extend and maintain the core platform. You will add new features, refactor legacy modules, improve test coverage, and mentor junior PHP developers. MySQL and Redis are core to the data layer. The team follows layered architecture principles.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Laravel is the core framework and is directly present\",\"Layered Architecture and Monolith signals match the architecture context exactly\",\"MySQL and Redis align with the stated data layer requirements\",\"PHPUnit indicates PHP-native testing discipline needed for improving test coverage\",\"Senior seniority supports the mentoring expectation\",\"Symfony background adds depth for a senior working on a large PHP codebase\"],\"gaps\":[\"No explicit mentoring or code review signals beyond seniority inference\"],\"explanation\":\"This candidate is a strong match with Laravel, PHP, MySQL, Redis, PHPUnit, and Layered Architecture all present and aligned to the role requirements. Their senior-level experience across Laravel and Symfony is particularly relevant for maintaining and extending a large PHP monolith. The only minor gap is the lack of explicit mentoring signals, which is common in profile data.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sophie_nlp\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\",\"Data Scientist\"],\"languages\":[\"Python\"],\"tech\":[\"Hugging Face Transformers\",\"spaCy\",\"NLTK\",\"scikit-learn\",\"Pandas\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nLegaltech company building contract analysis tools and hiring an NLP Engineer. You will fine-tune transformer models for named entity recognition and clause classification on legal text. Experience with Hugging Face, domain adaptation techniques, and evaluation of NLP models is required. Python is the primary language.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Hugging Face Transformers is present and directly relevant to fine-tuning transformer models\",\"spaCy and NLTK signal strong NLP foundations relevant to named entity recognition tasks\",\"scikit-learn and Pandas indicate ML pipeline and evaluation experience\",\"Python is the primary language as required\"],\"gaps\":[\"No experiment tracking tools like MLflow or Weights and Biases\",\"No domain adaptation or legal text processing signals\",\"No GPU training or model deployment infrastructure signals\",\"Mid-level seniority may limit depth of independent model development\"],\"explanation\":\"The candidate has solid NLP fundamentals with Hugging Face, spaCy, and NLTK, making them a reasonable fit for the core technical work. However, the lack of domain adaptation experience and any deployment or experiment tracking signals means meaningful gaps remain for a role requiring end-to-end model development on specialized legal text. A strong hiring signal would require evidence of applied fine-tuning projects.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mihai_cicd\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Jenkins\",\"Docker\",\"Ansible\",\"AWS\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"Jenkins\",\"CircleCI\"]}\n\nJob Summary:\nEnterprise software company seeking a Senior DevOps Engineer to modernize CI/CD infrastructure. The role requires migrating Jenkins pipelines to GitHub Actions, containerizing legacy applications, and improving observability with Prometheus and Grafana. Kubernetes experience is required. The candidate should be comfortable with Terraform for infrastructure provisioning.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Jenkins experience is directly relevant to the migration context\",\"Docker and Ansible indicate some infrastructure automation background\"],\"gaps\":[\"Mid-level seniority \u2014 role requires Senior-level ownership\",\"No Kubernetes experience visible\",\"No Terraform or infrastructure-as-code tooling beyond Ansible\",\"No Prometheus or Grafana observability tooling\",\"No GitHub Actions experience for the target CI/CD platform\"],\"explanation\":\"While the candidate has relevant background in Jenkins and Docker, they are missing the majority of the technical requirements including Kubernetes, Terraform, GitHub Actions, and observability tooling. Combined with the seniority gap, this profile is a weak match for a modernization role that demands depth across all of these areas simultaneously.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"chloe_svelte\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Svelte\",\"SvelteKit\",\"Tailwind CSS\",\"Vite\"],\"testing\":[\"Vitest\"]}\n\nJob Summary:\nEarly-stage startup building a developer tools product and seeking a Junior Frontend Engineer comfortable with SvelteKit. The role involves building UI components, working with REST APIs, and writing tests. The team is fully remote and values clear communication and self-direction.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SvelteKit is the primary framework and is directly present\",\"Tailwind CSS and Vite indicate a modern, compatible toolchain\",\"Vitest is appropriate for a SvelteKit project testing stack\",\"TypeScript experience adds type safety discipline\",\"Junior seniority matches the role level explicitly\"],\"gaps\":[\"No REST API integration signals visible beyond inferred usage\",\"Profile is sparse \u2014 limited signal on depth and project scale\"],\"explanation\":\"The candidate's stack is an exact match for this role with SvelteKit, Tailwind CSS, Vite, and Vitest all present at the right seniority level. For an early-stage startup explicitly hiring junior talent, this is a strong fit. The sparse profile is a minor uncertainty but not a disqualifier given the role level.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"enzo_architect\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\",\"Backend Engineer\"],\"languages\":[\"Java\",\"Go\",\"Python\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Kafka\",\"Kubernetes\",\"Terraform\",\"AWS\",\"Redis\",\"gRPC\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"CQRS\",\"Domain-Driven Design\",\"Hexagonal Architecture\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"DynamoDB\",\"Elasticsearch\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"JUnit\",\"Mockito\",\"k6\"]}\n\nJob Summary:\nPublic cloud provider hiring a Principal Engineer to design next-generation distributed data platform serving internal engineering teams. You will define service contracts, set architectural standards, evaluate emerging technologies, and mentor a team of senior and staff engineers. Deep expertise in distributed systems, polyglot persistence, and event-driven architecture is essential.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Principal seniority with Software Architect role directly matches the leadership scope\",\"CQRS, DDD, Hexagonal Architecture, and Distributed System signals demonstrate architectural depth\",\"Polyglot database experience across PostgreSQL, Cassandra, DynamoDB, and Elasticsearch is exceptional\",\"Kafka and gRPC address event-driven and service contract requirements explicitly\",\"k6 indicates performance and load testing awareness appropriate for platform-scale work\"],\"gaps\":[\"No explicit technical writing or RFC process signals for defining standards across teams\"],\"explanation\":\"This is an outstanding match for the role with Principal-level seniority, deep distributed systems architecture credentials, and rare polyglot persistence breadth. The candidate's architecture vocabulary is precisely what the role demands. The only minor note is the absence of explicit technical standards or RFC process signals, which is a soft expectation not always visible in profile data.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nkechi_wordpress\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"PHP\",\"JavaScript\",\"SQL\"],\"tech\":[\"WordPress\",\"React\",\"MySQL\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nFintech scale-up hiring a Mid-level Backend Engineer to build high-performance financial data APIs in Go. The team uses gRPC, Kafka, and PostgreSQL. You will design microservices, write integration tests, and contribute to architecture decisions. Strong Go proficiency and experience with event-driven systems is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Mid-level seniority is appropriate for the role level\"],\"gaps\":[\"No Go experience visible \u2014 role requires strong Go proficiency\",\"No Kafka or event-driven architecture signals\",\"No gRPC or microservices signals\",\"PostgreSQL not present \u2014 MySQL and WordPress background is misaligned\",\"WordPress-focused profile does not demonstrate the systems engineering depth required\"],\"explanation\":\"The candidate's technical background is centered on WordPress and PHP web development, which is fundamentally misaligned with a Go-based financial API engineering role requiring Kafka, gRPC, and microservices experience. Every core technical requirement is absent from the profile, making this a weak match regardless of seniority alignment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tariq_spark\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"Scala\",\"SQL\"],\"tech\":[\"Apache Spark\",\"PySpark\",\"Apache Airflow\",\"dbt\",\"Kafka\",\"Docker\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"Cassandra\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nMedia company building a real-time analytics platform handling streaming event data from millions of users. Seeking a Senior Data Engineer to design and operate Spark-based streaming pipelines, integrate Kafka topics, and ensure data quality at scale. Experience with Scala and distributed systems is strongly preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Apache Spark and PySpark are present and relevant to the streaming domain\",\"Kafka integration is listed\"],\"gaps\":[\"No explicit real-time streaming framework such as Spark Structured Streaming or Flink signals\",\"Role requires Scala for high-performance Spark jobs but Scala is secondary with no depth evidence\",\"No real-time platform or low-latency pipeline signals for a media streaming context\",\"Profile does not differentiate between batch and streaming Spark experience\"],\"explanation\":\"While the candidate lists Spark and Kafka, the role specifically targets a real-time streaming platform where low-latency and streaming-first Spark or Flink experience is critical. The profile does not distinguish batch from streaming work, and Scala depth is unconfirmed. For a media company handling millions of concurrent users, this uncertainty makes the candidate a weak fit without additional validation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leila_sec\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\",\"AppSec Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Docker\",\"Kubernetes\",\"AWS\",\"Vault\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"]}\n\nJob Summary:\nCloud security startup hiring a Senior Application Security Engineer to embed with product engineering teams. Responsibilities include threat modeling, code review for security vulnerabilities, SAST/DAST integration into CI/CD pipelines, and developer security training. Experience with OWASP, secure coding standards, and security tooling integration is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Senior AppSec Engineer role and seniority directly match the position\",\"Vault indicates secrets management and security infrastructure experience\",\"CI/CD pipeline experience is relevant to SAST/DAST integration requirements\",\"AWS and Kubernetes background supports cloud security context\"],\"gaps\":[\"No SAST or DAST tooling signals such as Semgrep, Snyk, or Burp Suite\",\"No threat modeling or OWASP framework signals visible\",\"No developer security training or security champion program indicators\",\"Security tooling integration experience is not directly evidenced\"],\"explanation\":\"The candidate's seniority and security-focused role are correctly aligned, but their profile lacks the specific AppSec tooling signals that this role centers on. Vault and CI/CD experience are relevant supporting signals, but the absence of SAST, DAST, OWASP, or threat modeling evidence makes it difficult to assess their application security depth. Additional evaluation would be needed before advancing.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hyun_nextjs\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\",\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"Tailwind CSS\",\"Prisma\",\"tRPC\"],\"architecture\":[\"Serverless\",\"Monolith\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nEarly-stage B2C startup building a social platform and seeking a Mid-level Full Stack Engineer. The team is using the T3 Stack: Next.js, TypeScript, tRPC, and Prisma backed by PostgreSQL. You will work across the full stack, own features end to end, and help establish engineering standards. Vercel is used for deployment.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js, TypeScript, tRPC, Prisma, and PostgreSQL form an exact T3 Stack match\",\"Serverless architecture aligns with Vercel deployment context\",\"Mid-level full stack scope and seniority are appropriate\"],\"gaps\":[\"No Vercel deployment or edge runtime signals\",\"No social platform or consumer product development signals\",\"No real-time feature signals such as WebSocket or Pusher for a social platform\",\"No scalability or performance signals for consumer-facing load patterns\"],\"explanation\":\"The candidate's T3 Stack alignment is technically strong with all core technologies present. However, a social platform has specific requirements around real-time interactions, consumer scale, and social graph data patterns that are not evidenced. The absence of Vercel deployment experience and any real-time feature signals are meaningful gaps for an early-stage product where these are likely day-one requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"olu_android\",\"seniority\":\"Mid\",\"roles\":[\"Android Engineer\",\"Mobile Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Firebase\",\"Retrofit\",\"Docker\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Espresso\"]}\n\nJob Summary:\nConsumer fintech app with 5 million users seeking a Mid-level Android Engineer. The role involves building new features in Jetpack Compose, working with REST APIs, improving app performance, and writing unit and UI tests. Kotlin is the primary language. CI/CD automation using Fastlane is part of the current workflow.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin, Jetpack Compose, Fastlane, JUnit, and Espresso all match stated requirements directly\",\"Retrofit signals REST API integration experience\",\"Mid-level Android Engineer role and seniority match exactly\"],\"gaps\":[\"No performance profiling tools such as Android Profiler, LeakCanary, or Systrace\",\"No app store release management or versioning signals\",\"No ProGuard or code shrinking signals for a production app at 5M users\"],\"explanation\":\"The candidate covers the core technical stack well with Kotlin, Jetpack Compose, Fastlane, and testing tooling all present. However, performance improvement is a stated responsibility for an app serving 5 million users, and no profiling or optimization tooling signals are visible. For a production app at this scale, performance tooling depth is a meaningful gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"matias_junior_py\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nEnterprise data platform company seeking a Staff Engineer to define the architecture for a multi-tenant data ingestion system processing petabytes per month. You will work across org boundaries, mentor senior engineers, and partner with engineering leadership. Deep expertise in distributed systems and multi-tenancy patterns is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and FastAPI show basic backend capability\"],\"gaps\":[\"Junior seniority \u2014 role requires Staff-level leadership and influence\",\"No distributed systems or multi-tenancy architecture signals\",\"No mentoring, cross-team, or organizational influence signals\",\"Profile is minimal and does not approach the technical depth required\",\"No data platform or large-scale ingestion system experience visible\"],\"explanation\":\"The candidate is a junior developer with a minimal profile, and no dimension of their background approaches the Staff-level technical scope, organizational influence, or distributed systems depth this role demands. This is not a viable match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"veronika_qa\",\"seniority\":\"Mid\",\"roles\":[\"Software Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\",\"Python\"],\"tech\":[\"Cypress\",\"Playwright\",\"Selenium\",\"Docker\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"],\"testing\":[\"Cypress\",\"Playwright\",\"Selenium\",\"Jest\",\"pytest\",\"k6\"]}\n\nJob Summary:\nSaaS platform seeking a Mid-level QA Automation Engineer to build and maintain the end-to-end test suite. The team uses Playwright for browser automation and k6 for load testing. You will improve test reliability, integrate tests into CI/CD pipelines, and work with developers to define testability standards.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Playwright is the primary automation tool and is directly present\",\"k6 for load testing matches the stated tooling exactly\",\"Cypress and Selenium signal broad browser automation depth beyond just Playwright\",\"GitHub Actions and GitLab CI confirm CI/CD pipeline integration experience\",\"pytest and Jest add backend and frontend unit testing coverage\",\"Mid-level seniority matches the role scope\"],\"gaps\":[\"No explicit test reliability engineering or flakiness analysis signals beyond tooling\"],\"explanation\":\"The candidate's testing profile is exceptionally well-aligned with Playwright, k6, strong CI/CD integration, and multi-framework coverage. They demonstrate a breadth of automation tooling that directly maps to every requirement stated. The match is strong across tooling, seniority, and integration experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dmitri_vue_sr\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\",\"Python\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\",\"Django\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Cypress\"]}\n\nJob Summary:\nScale-up marketplace building admin tooling and seeking a Senior Frontend Engineer. The stack is React, TypeScript, and Redux Toolkit backed by a Node.js API. You will own the admin dashboard, build reusable components, and improve frontend performance. Experience with React and complex state management is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript is present and relevant\",\"Senior seniority matches the role level\",\"Cypress and Vitest indicate testing discipline\"],\"gaps\":[\"No React experience \u2014 primary frontend framework is Vue.js\",\"No Redux or Redux Toolkit signals \u2014 state management is a core requirement\",\"No Node.js backend signals for API integration context\",\"Nuxt.js and Pinia are Vue ecosystem specific and do not transfer directly\"],\"explanation\":\"The candidate is an experienced senior frontend engineer, but their stack is firmly in the Vue.js ecosystem with no visible React or Redux experience. The role explicitly requires React and complex state management with Redux Toolkit. Framework depth does not trivially transfer, and the absence of the primary technical requirements makes this a weak match despite the seniority alignment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"aaliya_data_eng\",\"seniority\":\"Junior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"dbt\",\"Apache Airflow\",\"Pandas\"],\"databases\":[\"Snowflake\",\"PostgreSQL\"]}\n\nJob Summary:\nFinancial services firm hiring a Junior Data Engineer to maintain and extend dbt models, write SQL transformations, and support Airflow pipeline operations. Snowflake is the primary data warehouse. The team values data quality and documentation. Strong SQL skills and attention to detail are most important.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt, Airflow, and Snowflake match the core tooling requirements\",\"SQL and Python are the required languages and are present\",\"Junior seniority matches the role level\"],\"gaps\":[\"No data quality tooling such as Great Expectations visible\",\"Profile is very sparse \\u2014 no evidence of dbt model complexity or SQL query depth\",\"No documentation or data modeling pattern signals\"],\"explanation\":\"The candidate's core stack matches the role requirements with dbt, Airflow, Snowflake, SQL, and Python all present at the right seniority. However, the sparse profile makes it difficult to assess practical depth in any of these tools, and the absence of data quality tooling is a gap for a team that explicitly values it. A portfolio review would be needed to confirm readiness.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leon_elixir\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Elixir\",\"JavaScript\",\"SQL\"],\"tech\":[\"Phoenix\",\"Oban\",\"Docker\",\"Redis\",\"Nginx\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nReal-time collaboration platform seeking a Senior Backend Engineer with Elixir experience to build fault-tolerant, concurrent services using OTP. The team uses Phoenix and PostgreSQL. Experience with background job processing and WebSocket-based real-time features is expected. Strong testing discipline in the Elixir ecosystem is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Elixir and Phoenix are present and match the backend language and framework\",\"ExUnit signals Elixir-native testing discipline\"],\"gaps\":[\"No WebSocket or Phoenix Channels signals \\u2014 core to a real-time collaboration platform\",\"No OTP concurrency pattern or fault-tolerance-specific signals beyond architecture labels\",\"No collaborative or multiplayer session management signals\",\"Oban is a background job library and does not substitute for real-time communication experience\"],\"explanation\":\"The candidate works in Elixir and Phoenix, which are the right foundations, but WebSocket and real-time communication via Phoenix Channels are the central technical requirement for a collaboration platform and are entirely absent from the profile. For a role where real-time is the core product primitive, this gap is disqualifying without further evidence.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rin_flutter\",\"seniority\":\"Junior\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"JavaScript\"],\"tech\":[\"Flutter\",\"Firebase\",\"Expo\"],\"databases\":[\"Firebase\"]}\n\nJob Summary:\nConsumer startup building a cross-platform mobile app seeking a Junior Mobile Engineer. The app is built in Flutter using Dart. You will implement UI screens from Figma designs, integrate REST APIs, and write basic widget tests. Firebase is used for auth and real-time data.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Flutter and Dart are present and match the primary stack\"],\"gaps\":[\"No REST API integration signals visible despite it being a stated core task\",\"No widget testing signals \\u2014 stated as part of the role\",\"Profile is minimal with only two technologies and no project context\",\"Firebase is present but no depth on auth flow or real-time listener patterns\"],\"explanation\":\"The candidate uses Flutter and Dart, which are the right tools, but the profile is so minimal that it cannot confirm readiness for even a junior role. REST API integration and widget testing are explicitly required tasks, and neither is evidenced. The absence of any project or tooling context makes this a weak match that requires strong portfolio evidence to reconsider.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"bogdan_wp\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"PHP\",\"JavaScript\",\"SQL\"],\"tech\":[\"WordPress\",\"WooCommerce\",\"MySQL\",\"React\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nGlobal e-commerce agency seeking a Mid-level WooCommerce Developer to build custom plugins, extend WooCommerce functionality, and integrate third-party payment gateways. PHP and MySQL are the foundation. Experience with WordPress hooks, custom post types, and REST API extensions is important. Client-facing communication skills are valued.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"WordPress and WooCommerce are listed and relevant to the agency context\"],\"gaps\":[\"No WordPress hooks, custom post types, or plugin development signals\",\"No payment gateway integration signals \\u2014 a stated core requirement\",\"No REST API extension or WooCommerce REST customization signals\",\"No client-facing communication or agency workflow signals\",\"Profile infers WooCommerce context but provides no depth evidence\"],\"explanation\":\"The candidate lists WordPress and WooCommerce, but the agency role requires specific plugin development, WordPress hooks, and payment gateway integration expertise that are entirely absent from the profile. Listing a technology does not confirm the specialized skills required, and the absence of every domain-specific signal makes this a weak match for an expert agency context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yemi_lead_fe\",\"seniority\":\"Lead\",\"roles\":[\"Frontend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"GraphQL\",\"Apollo Client\",\"Tailwind CSS\",\"Storybook\",\"Redux\"],\"architecture\":[\"Microservices\",\"Modular Architecture\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"React Testing Library\",\"Cypress\"]}\n\nJob Summary:\nPublic tech company seeking a Lead Frontend Engineer to own the design system, mentor a frontend guild of 8 engineers, and drive the migration from a legacy class-based React app to a modern hooks-based architecture. GraphQL with Apollo Client is used for data fetching. Strong TypeScript and testing culture are expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React, TypeScript, and GraphQL with Apollo Client match the stated stack\",\"Storybook signals some design system familiarity\"],\"gaps\":[\"No guild leadership, team coordination, or people management signals beyond seniority label\",\"No design system ownership or design token architecture signals\",\"No class-to-hooks migration or React codebase modernization signals\",\"Redux experience is present but does not demonstrate hooks-first architecture competency\"],\"explanation\":\"The candidate's technical stack aligns with the role, but the position is primarily a leadership and ownership role \\u2014 leading a frontend guild of 8 engineers and owning a migration roadmap. There are no signals of people management, design system product ownership, or migration project leadership in the profile. The technical fit does not compensate for the leadership gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cam_data_analyst\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\",\"R\"],\"tech\":[\"Tableau\",\"Power BI\",\"Pandas\",\"dbt\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"]}\n\nJob Summary:\nRetail company seeking a Mid-level Data Analyst to build executive dashboards, write complex SQL queries against BigQuery, and support business stakeholders with ad hoc analysis. Tableau is the primary visualization tool. Familiarity with dbt for data modeling is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"BigQuery, Tableau, and dbt are all present and match the stated requirements\",\"SQL is confirmed across multiple platforms\",\"Mid-level seniority and Data Analyst role are appropriate matches\"],\"gaps\":[\"No stakeholder communication or business requirements gathering signals\",\"No ad hoc analysis workflow or self-service analytics signals\",\"No presentation or executive reporting signals for a dashboard-heavy role\"],\"explanation\":\"The candidate covers the technical stack well with BigQuery, Tableau, dbt, and SQL all present. However, the role is business-facing and involves working closely with executive stakeholders, which requires communication and requirements gathering skills that are not evidenced in the profile. This makes them a solid technical candidate with uncertain fit for the business partnership dimension.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pedro_node\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\",\"SQL\"],\"tech\":[\"Express.js\",\"NestJS\",\"Docker\",\"Redis\",\"Bull\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nHR tech startup hiring a Mid-level Backend Engineer to build and maintain REST APIs using NestJS and PostgreSQL. Background job processing is handled by BullMQ. You will also integrate with third-party HR platforms via webhooks. Experience with TypeScript and containerized deployments is important.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"NestJS, TypeScript, and PostgreSQL match the core stack\",\"Jest and Supertest signal REST API testing experience\"],\"gaps\":[\"No webhook integration signals \\u2014 a stated core requirement for HR platform integrations\",\"Bull is present but BullMQ is the specific library referenced in the job\",\"No third-party API integration or OAuth signals for HR platform connectivity\",\"No multi-tenant data isolation signals relevant to HR SaaS\"],\"explanation\":\"The candidate's core NestJS and PostgreSQL stack aligns, but webhook integration is a named requirement with no corresponding signal in the profile. Third-party HR platform integrations via webhooks are a specialized pattern that requires explicit experience, and the absence of that signal alongside the BullMQ version ambiguity makes this a weak fit for the integration-heavy scope of this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"faye_react_native\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\",\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React Native\",\"Expo\",\"Redux\",\"React Query\",\"Firebase\"],\"databases\":[\"Firebase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Detox\"]}\n\nJob Summary:\nSeries A startup building a fitness app and hiring a Mid-level React Native Engineer. The team uses Expo and TypeScript. You will build new features, integrate with a REST backend, and write automated tests using Detox. Redux is used for state management. Experience with app store deployment is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React Native, Expo, TypeScript, and Redux match the core requirements directly\",\"Detox is the stated testing tool and is present\",\"Mid-level seniority and mobile role are appropriate\"],\"gaps\":[\"No app store submission or release management signals \\u2014 listed as a plus\",\"No health or fitness app domain signals\",\"No REST backend integration signals beyond React Query inference\",\"No Expo managed versus bare workflow signals for production context\"],\"explanation\":\"The candidate's React Native, Redux, and Detox stack aligns well with the stated requirements. However, the app store deployment experience listed as a plus is absent, and there are no signals of fitness domain or REST integration depth for a consumer health product. The Expo workflow depth is also unclear, which matters for a production fitness app with complex native integrations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kwame_infra_jr\",\"seniority\":\"Junior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"GitHub Actions\",\"AWS\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nLate-stage startup hiring a Junior DevOps Engineer to support container builds, maintain GitHub Actions pipelines, and assist with AWS infrastructure. The team will mentor the right candidate. Bash scripting and basic Docker knowledge are the core technical requirements.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker and GitHub Actions are present and match the stated requirements\"],\"gaps\":[\"Extremely sparse profile \\u2014 only three technologies listed\",\"No depth signal for any listed technology\",\"No Kubernetes, Terraform, or observability tooling for broader infrastructure support\",\"AWS listed but no specific service or deployment experience signals\"],\"explanation\":\"While the candidate lists Docker, GitHub Actions, and AWS which match the stated requirements, the profile is so sparse that no meaningful confidence can be placed on their practical depth in any of these areas. A junior DevOps role still requires some evidence of real project application, and none is present here.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"marina_spring\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Hibernate\",\"Docker\",\"Redis\"],\"architecture\":[\"Layered Architecture\",\"Monolith\"],\"databases\":[\"MySQL\",\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nEnterprise logistics company maintaining a large Java Spring Boot monolith. Hiring a Senior Backend Engineer to add new features, optimize database queries, and improve code quality. MySQL is the primary database. The team values long-term maintainability and rigorous unit testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Java and Spring Boot are the primary stack and match directly\",\"Hibernate signals ORM and database query optimization experience relevant to MySQL\",\"Layered Architecture and Monolith signals align exactly with the codebase context\",\"JUnit and Mockito confirm rigorous unit testing discipline\",\"MySQL is the primary database and is present\",\"Senior seniority matches the maintainability and quality ownership expected\"],\"gaps\":[\"No modern CI/CD tooling \u2014 Jenkins is older but functional for this context\"],\"explanation\":\"The candidate's profile is an excellent fit for a Java Spring Boot monolith with Hibernate, MySQL, Layered Architecture, and strong testing tooling all present. The legacy architecture signals are particularly valuable here, as the role is about maintaining and improving an existing system rather than building new. Jenkins is dated but not a disqualifier for an enterprise logistics context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kenji_aiops\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Go\"],\"tech\":[\"PyTorch\",\"Kubeflow\",\"MLflow\",\"Apache Airflow\",\"Docker\",\"Kubernetes\",\"Prometheus\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"BigQuery\",\"Pinecone\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"]}\n\nJob Summary:\nAI infrastructure company building an MLOps platform for enterprise customers. Hiring a Senior ML Platform Engineer to design training pipeline infrastructure, model registries, and serving layers. Experience with Kubeflow, MLflow, and Kubernetes is required. Familiarity with vector databases for RAG architectures is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubeflow and MLflow are both present and match the platform tooling directly\",\"Kubernetes and Docker confirm container orchestration depth for pipeline infrastructure\",\"Pinecone signals vector database experience for RAG architectures \u2014 a stated strong plus\",\"PyTorch and Airflow add model development and pipeline orchestration depth\",\"ArgoCD and GitHub Actions indicate GitOps-based ML deployment practices\",\"Cloud-Native and Microservices architecture aligns with the platform product context\"],\"gaps\":[\"No explicit model serving framework signals such as BentoML, Triton, or Seldon\"],\"explanation\":\"The candidate's profile is an exceptional match for an MLOps platform role with Kubeflow, MLflow, Kubernetes, and Pinecone all present alongside strong infrastructure depth. The Pinecone experience directly addresses the RAG architecture plus that the job highlights. The only gap is the absence of an explicit model serving layer signal, which is a relatively minor concern given the overall platform engineering depth.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alba_intern_js\",\"seniority\":\"Intern\",\"roles\":[\"Software Engineer\"],\"languages\":[\"JavaScript\",\"HTML\",\"CSS\"],\"tech\":[\"React\"]}\n\nJob Summary:\nAgency seeking an intern or entry-level Frontend Engineer to assist with building landing pages and simple React components under supervision. HTML, CSS, and basic React are the requirements. The role includes code review participation and basic Git workflow.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React, JavaScript, HTML, and CSS are all present and match the requirements\",\"Intern seniority matches the stated role level\"],\"gaps\":[\"No Git or version control signals visible\",\"Profile is extremely sparse with no testing, tooling, or project depth signals\",\"No evidence of code review participation or collaborative workflow experience\"],\"explanation\":\"The candidate has the right core technologies for an intern role and the seniority is appropriate. However, the absence of any Git, tooling, or project signals beyond a bare stack list makes it difficult to assess readiness even at the intern level. This is a plausible but unconfirmed fit that would require a portfolio review or interview to validate.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lena_devrel\",\"seniority\":\"Senior\",\"roles\":[\"Software Engineer\",\"Full Stack Engineer\"],\"languages\":[\"Python\",\"JavaScript\",\"TypeScript\"],\"tech\":[\"FastAPI\",\"React\",\"Docker\",\"OpenAI API\",\"LangChain\",\"ChromaDB\"],\"architecture\":[\"RAG\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"ChromaDB\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAI developer tools startup hiring a Senior Engineer to build demo applications, write technical documentation, and contribute to an open-source SDK. Experience with LLM APIs, RAG pipelines, and Python is required. Familiarity with FastAPI for building demo backends and React for frontend demos is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"OpenAI API, LangChain, RAG, and ChromaDB directly match LLM and pipeline requirements\",\"FastAPI and React match the plus requirements explicitly\",\"Python is the primary language\"],\"gaps\":[\"No technical writing, blog, or documentation signals\",\"No open-source contribution or community engagement signals\",\"No developer relations or community presentation signals\"],\"explanation\":\"The candidate's LLM and RAG technical stack is strong and aligns well with the engineering side of the role. However, DevRel work is fundamentally communication and community-facing, and the profile contains no signals of technical writing, open-source contribution, or developer education. Without those signals, the candidate is a strong engineer but an uncertain DevRel fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jorge_csharp\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\",\"Software Engineer\"],\"languages\":[\"C#\",\"SQL\",\"TypeScript\"],\"tech\":[\".NET Core\",\"ASP.NET\",\"Entity Framework\",\"Docker\",\"Redis\"],\"architecture\":[\"Layered Architecture\",\"Microservices\"],\"databases\":[\"MS SQL Server\",\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"Azure DevOps\",\"GitHub Actions\"],\"testing\":[\"xUnit\",\"Mockito\"]}\n\nJob Summary:\nMicrosoft partner company building enterprise internal tools on Azure. Seeking a Mid-level .NET Backend Engineer to extend REST APIs built in ASP.NET Core, work with MS SQL Server, and maintain Azure DevOps pipelines. Experience with Entity Framework and clean, testable code is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"C#, ASP.NET, .NET Core, and Entity Framework match the core stack\",\"Azure DevOps is the stated CI/CD platform and is present\",\"MS SQL Server aligns with the primary database\"],\"gaps\":[\"Mockito in profile is a Java testing library \\u2014 raises a data accuracy concern\",\"No Azure-native service signals such as Azure Service Bus or Azure Functions\",\"No xUnit or MSTest signals despite testing being stated as important\",\"No enterprise security or authentication pattern signals for a Microsoft partner context\"],\"explanation\":\"The candidate's .NET and Azure DevOps stack aligns with the role requirements, but the presence of Mockito (a Java tool) in an otherwise C# profile raises a data quality concern that warrants verification. Additionally, there are no Azure-native service signals or .NET testing framework signals despite testing being a stated expectation, leaving meaningful uncertainty about depth.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sam_analytics_eng\",\"seniority\":\"Mid\",\"roles\":[\"Analytics Engineer\",\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Looker\",\"Metabase\",\"Pandas\"],\"databases\":[\"BigQuery\",\"Snowflake\"]}\n\nJob Summary:\nB2B SaaS company seeking a Mid-level Analytics Engineer to own dbt models, build Looker dashboards, and work closely with data scientists and product teams. BigQuery is the warehouse. Strong SQL skills and a collaborative working style are core requirements. Experience with data documentation and testing in dbt is valued.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt, Looker, and BigQuery are present and match the role exactly\",\"Mid-level Analytics Engineer seniority is correct\",\"SQL is confirmed as primary\"],\"gaps\":[\"No dbt testing (schema tests, data tests) or documentation signals\",\"No cross-functional collaboration signals with data scientists or product teams\",\"No data modeling pattern signals beyond tool presence\"],\"explanation\":\"The candidate's tool stack is an excellent match with dbt, Looker, and BigQuery all present. However, the role specifically values dbt testing and documentation discipline, which are not evidenced in the profile. Cross-functional collaboration signals are also absent for a role that requires close work with data scientists and product teams. They are a good technical candidate but an uncertain cultural fit without more context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ivan_game_dev\",\"seniority\":\"Mid\",\"roles\":[\"Game Developer\",\"Software Engineer\"],\"languages\":[\"C++\",\"C#\",\"Python\"],\"tech\":[\"Unity\",\"Unreal Engine\",\"WebGL\",\"Three.js\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAd tech company seeking a Mid-level Software Engineer to build interactive 3D web experiences and data visualizations using WebGL and Three.js. Some work may involve integrating with REST APIs and ensuring 60fps performance. Experience with browser-based rendering and JavaScript is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"WebGL and Three.js are both present and directly match the core rendering requirements\",\"Mid-level seniority and software engineer background are appropriate\",\"C++ and Unity/Unreal background implies strong graphics and performance programming intuition\"],\"gaps\":[\"No JavaScript or TypeScript signals visible for the browser-based rendering context\",\"No REST API integration signals\",\"Game engine background does not directly transfer to web production rendering workflows\",\"No frontend build tooling or web performance optimization signals\"],\"explanation\":\"The candidate has WebGL and Three.js experience which directly maps to the role, and their game development background in C++ and Unreal suggests strong graphics fundamentals. However, the absence of JavaScript or TypeScript and web production tooling signals raises uncertainty about their proficiency in a browser-first environment. The role would benefit from validation of their web JavaScript competency.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"diana_principal\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\",\"Backend Engineer\",\"Solutions Architect\"],\"languages\":[\"Python\",\"Java\",\"Go\",\"SQL\"],\"tech\":[\"Kafka\",\"Kubernetes\",\"Terraform\",\"AWS\",\"gRPC\",\"Redis\",\"Spark\"],\"architecture\":[\"Event-Driven\",\"CQRS\",\"Domain-Driven Design\",\"Microservices\",\"Distributed System\",\"Cloud-Native\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"DynamoDB\",\"Elasticsearch\",\"Snowflake\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\",\"Tekton\"],\"testing\":[\"pytest\",\"JUnit\",\"k6\"]}\n\nJob Summary:\nCloud-native startup building a global data mesh platform. Seeking a Principal Engineer to define technical strategy, drive cross-functional architecture decisions, evaluate data infrastructure tradeoffs, and mentor a distributed team of senior engineers. Deep experience in distributed systems, polyglot persistence, and event-driven architecture at global scale is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Principal seniority with Software Architect and Solutions Architect roles confirms strategic leadership scope\",\"DDD, CQRS, Event-Driven, Distributed System, and Cloud-Native architecture vocabulary is comprehensive\",\"Polyglot database experience across PostgreSQL, Cassandra, DynamoDB, Elasticsearch, and Snowflake is exceptional\",\"Kafka, gRPC, and Spark cover streaming, inter-service communication, and large-scale data processing\",\"Multi-language fluency in Python, Java, and Go reduces constraints in cross-team influence\",\"k6 signals performance and reliability testing awareness appropriate for global scale\"],\"gaps\":[\"No explicit data mesh architecture pattern signals or domain ownership framework references\"],\"explanation\":\"This candidate is among the strongest possible matches for a Principal-level distributed systems architecture role with rare breadth across languages, frameworks, architecture patterns, and persistence technologies. Their architecture vocabulary maps precisely to the data mesh domain. The only gap worth noting is the absence of explicit data mesh terminology, though the underlying architecture foundations are all present.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"svenlarsson_dev\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Scala\",\"Java\",\"SQL\"],\"tech\":[\"Apache Spark\",\"Kafka\",\"Akka\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Event-Driven\",\"Distributed System\",\"CQRS\"],\"databases\":[\"Cassandra\",\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Jenkins\"],\"testing\":[\"ScalaTest\",\"JUnit\"]}\n\nJob Summary:\nStreaming analytics company seeking a Senior Backend Engineer to build real-time data processing pipelines using Scala and Apache Spark. Kafka is our event bus. We use Akka for actor-based concurrency and Cassandra for time-series storage. You will design CQRS-based services, write ScalaTest unit tests, and deploy on Kubernetes. Experience with distributed systems at scale is essential.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Scala and Apache Spark are both primary and match the core stack exactly\",\"Akka signals actor-based concurrency experience directly stated in the job\",\"Cassandra for time-series storage is an explicit match\",\"CQRS and Event-Driven architecture align with the service design requirement\",\"ScalaTest is the stated testing tool and is present\",\"Kubernetes deployment experience confirmed\"],\"gaps\":[\"No explicit stream processing versus batch Spark distinction visible\"],\"explanation\":\"The candidate's profile is a near-perfect match covering every named technology: Scala, Spark, Akka, Kafka, Cassandra, CQRS, and ScalaTest. Their distributed systems architecture background is appropriate for the scale requirements. The only minor uncertainty is whether their Spark experience is streaming-first or primarily batch, which would need validation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amina_frontend\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Vite\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nEnterprise logistics company seeking a Staff Frontend Engineer to own the design system, define frontend architecture standards across 12 product teams, and mentor a guild of senior engineers. Deep React expertise, experience with micro-frontend architecture, and a track record of cross-org technical leadership are required. Familiarity with Module Federation is a strong differentiator.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and TypeScript are present and relevant\"],\"gaps\":[\"Junior seniority \u2014 role requires Staff-level technical leadership across 12 teams\",\"No design system ownership or architecture standards signals\",\"No micro-frontend or Module Federation experience\",\"No mentoring or cross-org influence signals\",\"Profile is sparse with no depth evidence for enterprise-scale work\"],\"explanation\":\"The candidate is a junior engineer with a minimal frontend profile, and no dimension of their background approaches the Staff-level organizational scope or micro-frontend architecture depth this role demands. The seniority gap alone is disqualifying, and the technical requirements for design system ownership and Module Federation are entirely absent.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mk_devops_pro\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\",\"Platform Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Terraform\",\"Pulumi\",\"AWS\",\"Docker\",\"Kubernetes\",\"Helm\",\"Datadog\",\"Prometheus\"],\"architecture\":[\"Cloud-Native\",\"Multi-Tenant\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\"],\"ci_cd\":[\"GitHub Actions\",\"CircleCI\",\"ArgoCD\"],\"testing\":[\"pytest\",\"Terratest\"]}\n\nJob Summary:\nCloud infrastructure startup building a multi-tenant SaaS developer platform. Seeking a Senior DevOps Engineer to write Terraform and Pulumi modules, manage Kubernetes clusters on AWS, and build observability pipelines using Datadog and Prometheus. GitOps via ArgoCD is central to our delivery model. Infrastructure testing with Terratest is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Terraform and Pulumi are both present \u2014 exact IaC match for both tools named\",\"Kubernetes and AWS confirm cluster management experience on the target platform\",\"Datadog and Prometheus cover the observability pipeline requirements explicitly\",\"ArgoCD confirms GitOps delivery experience as required\",\"Terratest is the stated infrastructure testing tool and is present\",\"Multi-Tenant architecture signal directly matches the SaaS platform context\"],\"gaps\":[\"No explicit developer experience or self-service portal signals for the developer platform product\"],\"explanation\":\"This candidate is an exceptional match with every named technology covered: Terraform, Pulumi, Kubernetes, AWS, Datadog, Prometheus, ArgoCD, and Terratest. The Multi-Tenant architecture signal is particularly relevant for a multi-tenant SaaS platform. The only gap is the absence of developer experience product signals, which is a minor soft requirement not central to the technical scope.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"natasha_ml\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"Flask\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nAutonomous vehicle startup hiring a Mid-level ML Engineer to develop perception models using PyTorch. You will work with LiDAR and camera sensor fusion datasets, train object detection models, and deploy inference pipelines on embedded hardware. Experience with CUDA, ONNX, and model optimization techniques such as quantization is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is the primary language and is present\",\"scikit-learn and Pandas indicate general ML pipeline experience\"],\"gaps\":[\"No PyTorch experience \u2014 primary modeling framework for the role\",\"No CUDA or GPU training signals\",\"No ONNX or model optimization signals\",\"No computer vision, object detection, or sensor fusion experience\",\"No embedded deployment or edge inference signals\",\"Flask-focused profile suggests web API work rather than perception ML\"],\"explanation\":\"The candidate's ML background is limited to classical machine learning with scikit-learn, which does not transfer to the deep learning perception pipeline this role requires. Every core technical requirement \u2014 PyTorch, CUDA, ONNX, and sensor fusion \u2014 is absent from the profile. This is a fundamental domain mismatch, not a seniority gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"p_singh_fullstack\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\",\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"Python\",\"SQL\"],\"tech\":[\"React\",\"NestJS\",\"FastAPI\",\"Docker\",\"Redis\",\"Stripe\"],\"architecture\":[\"Microservices\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\",\"Supertest\"]}\n\nJob Summary:\nSaaS billing platform startup seeking a Mid-level Full Stack Engineer. You will build subscription management features, integrate Stripe billing APIs, handle webhook events, and maintain a NestJS backend and React dashboard. PostgreSQL and Redis are the data layer. TypeScript across the stack is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Stripe is listed, indicating payment integration awareness\",\"NestJS and React match the stated full stack\",\"TypeScript is the primary language as required\",\"PostgreSQL and Redis match the data layer\"],\"gaps\":[\"No subscription lifecycle management or billing webhook handling signals\",\"No idempotency or payment failure retry pattern signals for a billing platform\",\"Stripe listing alone does not confirm billing API integration depth\",\"No metered billing or usage-based pricing pattern signals\"],\"explanation\":\"The candidate's stack aligns technically with NestJS, React, TypeScript, and the data layer, but a billing platform role requires deep Stripe integration knowledge \\u2014 webhooks, subscription states, invoice management \\u2014 that the profile does not evidence beyond listing the tool. Stripe listing without integration depth signals is insufficient for a product where billing correctness is the core product guarantee.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jarek_node\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\",\"SQL\"],\"tech\":[\"Express.js\",\"Koa\",\"Docker\",\"Redis\",\"RabbitMQ\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"Mocha\",\"Chai\",\"Supertest\"]}\n\nJob Summary:\nFintecch scale-up hiring a Senior Backend Engineer to rebuild their payments API using NestJS and TypeScript. Kafka will replace the current RabbitMQ setup for event streaming. PostgreSQL is the primary database. Strong TypeScript and REST API design experience is required. GraphQL knowledge is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript and Node.js backend experience are directly relevant\",\"RabbitMQ experience is relevant context for a Kafka migration\",\"PostgreSQL is the primary database and is present\",\"Event-Driven architecture aligns with the Kafka streaming direction\",\"REST API experience is confirmed through Supertest and backend roles\"],\"gaps\":[\"No NestJS experience \u2014 role specifically requires NestJS\",\"No Kafka experience \u2014 RabbitMQ is being replaced, not preserved\",\"No GraphQL signals for the stated plus requirement\",\"Mocha and Chai are older testing tools; role may expect Jest or Vitest\"],\"explanation\":\"The candidate has strong Node.js backend credentials and relevant architecture experience, but the role specifically requires NestJS and Kafka, neither of which is in the profile. RabbitMQ experience provides useful migration context but does not substitute for Kafka knowledge. They are a plausible candidate for growth but not a direct technical match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"celine_ios\",\"seniority\":\"Senior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Combine\",\"CoreData\",\"Firebase\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"XCTest\",\"XCUITest\"]}\n\nJob Summary:\nConsumer fintech app with 8 million users seeking a Senior iOS Engineer. You will build new features in SwiftUI, maintain Combine-based reactive data flows, and optimize app performance. CoreData is used for offline storage. Fastlane manages our release pipeline. XCTest is the testing standard. Objective-C legacy code exists and must be maintained.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SwiftUI, Combine, and CoreData are all present and match the stated requirements\",\"Fastlane and XCTest cover the release and testing requirements\",\"Objective-C is listed for legacy code maintenance\"],\"gaps\":[\"No performance profiling or Instruments tooling signals for an 8-million user app\",\"Objective-C depth is unconfirmed \\u2014 listing alone does not validate legacy codebase maintenance readiness\",\"No app size optimization or binary framework signals for a high-traffic consumer app\",\"No crash reporting or analytics SDK integration signals\"],\"explanation\":\"The candidate covers the core technical requirements with SwiftUI, Combine, CoreData, and Fastlane all present. However, for a consumer fintech app serving 8 million users, performance profiling and Objective-C depth are critical production concerns that the profile does not validate. Listing Objective-C without any evidence of legacy codebase migration or maintenance work leaves meaningful uncertainty.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tobias_react\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Redux\",\"styled-components\",\"Webpack\",\"Storybook\"],\"databases\":[\"Firebase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Enzyme\"]}\n\nJob Summary:\nE-learning startup seeking a Mid-level Frontend Engineer to migrate a legacy React and Redux codebase from class components to functional components with hooks. The team is moving from Webpack to Vite and from Enzyme to React Testing Library. Strong TypeScript and React fundamentals are required. Storybook is used for component documentation.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Redux experience directly relevant to the existing codebase\",\"TypeScript is confirmed as a primary language\",\"Storybook is present and matches the component documentation workflow\",\"Webpack experience is relevant to understanding the migration context\",\"Mid-level seniority is appropriate\"],\"gaps\":[\"Enzyme is the tool being replaced \u2014 no React Testing Library signals\",\"No Vite experience for the stated build tool migration\",\"No functional components or hooks-specific signals to confirm migration readiness\",\"Styled-components may be in tension with the team's direction if they are modernizing their CSS approach\"],\"explanation\":\"The candidate knows the legacy stack being migrated away from, which is a double-edged signal \u2014 they understand the existing code but may need to unlearn patterns as the team modernizes. The absence of React Testing Library and Vite, which are the target tools for both major migrations in progress, is a meaningful gap. They can contribute but will need ramp-up on the destination stack.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rav_data_platform\",\"seniority\":\"Staff\",\"roles\":[\"Data Engineer\",\"Platform Engineer\"],\"languages\":[\"Python\",\"Scala\",\"SQL\",\"Go\"],\"tech\":[\"Apache Spark\",\"Apache Flink\",\"Kafka\",\"dbt\",\"Apache Airflow\",\"Kubernetes\",\"Terraform\",\"AWS\"],\"architecture\":[\"Distributed System\",\"Event-Driven\",\"Cloud-Native\",\"Microservices\"],\"databases\":[\"Snowflake\",\"Cassandra\",\"DynamoDB\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\",\"GitLab CI\"],\"testing\":[\"pytest\",\"Great Expectations\",\"dbt test\"]}\n\nJob Summary:\nMedia company building a unified data platform for 200 engineers. Seeking a Staff Data Engineer to define the streaming and batch architecture, evaluate tooling, and set data engineering standards across multiple product teams. Flink and Kafka are the streaming layer. Snowflake and dbt for analytics. Experience mentoring senior engineers and influencing data platform strategy is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Apache Flink and Kafka are both present for the streaming layer requirements\",\"Snowflake and dbt match the analytics layer explicitly\",\"Staff seniority aligns with the cross-team standards and mentoring scope\",\"Distributed System, Event-Driven, and Cloud-Native architecture breadth supports platform strategy ownership\",\"Great Expectations and dbt test signal rigorous data quality standards\",\"Multi-cloud and multi-warehouse experience across Snowflake, BigQuery, and Cassandra demonstrates platform-level breadth\"],\"gaps\":[\"No explicit data governance or data catalog tooling signals\"],\"explanation\":\"The candidate's profile is exceptional for a Staff data platform role with Flink, Kafka, Snowflake, dbt, and comprehensive architecture credentials all present. Their multi-language fluency and staff-level seniority directly support the cross-team standards and mentoring responsibilities. The only minor gap is the absence of data governance tooling signals, which is a soft expectation for a platform of this scale.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"gabi_android_jr\",\"seniority\":\"Junior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Android SDK\",\"Firebase\",\"Retrofit\"],\"databases\":[\"SQLite\",\"Firebase\"]}\n\nJob Summary:\nEdtech startup hiring a Junior Android Engineer to build learning module screens using Jetpack Compose, integrate REST APIs via Retrofit, and write unit tests with JUnit. Kotlin is the primary language. Firebase is used for analytics and push notifications. The team is small and fast-moving.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin is the primary language and is present\",\"Retrofit matches the REST API integration tool explicitly\",\"Firebase aligns with the analytics and notifications data layer\",\"Junior seniority matches the role level\",\"Android SDK and Java provide foundational platform experience\"],\"gaps\":[\"No Jetpack Compose signals \u2014 the primary UI framework for the role\",\"No JUnit or testing signals visible\",\"No small-team or startup workflow signals\"],\"explanation\":\"The candidate's Kotlin and Retrofit experience are relevant, but the absence of Jetpack Compose is a meaningful gap since it is the stated UI framework for all new screen development. The lack of any testing signals is also notable for a team that names JUnit as part of the workflow. They are a plausible junior hire with ramp-up needs on the UI tooling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"xander_php\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"SQL\"],\"tech\":[\"Laravel\",\"MySQL\",\"Redis\",\"Docker\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nGrowth-stage startup building a real-time collaboration tool. Seeking a Mid-level Backend Engineer proficient in Go to design low-latency WebSocket services, build gRPC APIs, and operate services on Kubernetes. PostgreSQL and Redis are used for persistence. Experience with distributed systems and concurrent programming is important.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Redis experience is relevant to the persistence layer\",\"Mid-level seniority is appropriate for the role\"],\"gaps\":[\"No Go experience \u2014 role requires Go proficiency\",\"No WebSocket or real-time service signals\",\"No gRPC or protocol buffer signals\",\"No Kubernetes experience\",\"No distributed systems or concurrency signals\",\"PHP and Laravel background is fundamentally misaligned with the systems engineering scope\"],\"explanation\":\"The candidate's PHP and Laravel background is entirely misaligned with a Go-based systems engineering role requiring WebSocket, gRPC, and Kubernetes. Every core technical requirement is absent from the profile. Redis experience is the only marginal overlap and is insufficient to bridge the stack gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"isabel_sre\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Prometheus\",\"Grafana\",\"PagerDuty\",\"OpenTelemetry\",\"AWS\",\"Terraform\"],\"architecture\":[\"Cloud-Native\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nFintech platform seeking a Senior SRE to define SLOs, manage on-call rotations, build distributed tracing pipelines, and reduce mean time to recovery across services. We use Prometheus, Grafana, and OpenTelemetry for observability. PagerDuty handles alerting and incident management. Kubernetes on AWS is the infrastructure. Go is preferred for tooling.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Prometheus, Grafana, OpenTelemetry, and PagerDuty match the observability and incident stack\",\"Kubernetes and AWS confirm the infrastructure environment\",\"Go is listed for tooling development as preferred\"],\"gaps\":[\"No SLO definition tooling or error budget tracking signals\",\"No on-call rotation management or incident postmortem process signals\",\"No MTTR improvement methodology or reliability engineering framework signals\",\"No capacity planning or demand forecasting signals for a fintech platform\"],\"explanation\":\"The candidate has strong observability infrastructure credentials with the full monitoring and incident tooling stack present. However, SRE roles at fintech scale center on SLO ownership and measurable reliability engineering practices, which are not evidenced in the profile beyond tool listings. The distinction between operating monitoring infrastructure and defining and enforcing error budgets is meaningful for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kwabena_node_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\",\"SQL\"],\"tech\":[\"Express.js\",\"React\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nHealthcare data company hiring a Mid-level Backend Engineer to build FHIR-compliant REST APIs in NestJS. You will work with HL7 data formats, manage patient data pipelines in PostgreSQL, and integrate with third-party EHR systems. TypeScript is required. HIPAA compliance awareness is essential.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript is present and meets the language requirement\",\"PostgreSQL aligns with the patient data pipeline database\",\"Jest and Supertest cover REST API testing practices\",\"Docker confirms containerization experience for healthcare deployment context\"],\"gaps\":[\"No NestJS experience \u2014 role specifically requires NestJS\",\"No FHIR, HL7, or healthcare data standards signals\",\"No HIPAA compliance or healthcare security signals\",\"No third-party EHR integration experience visible\",\"Express.js background requires NestJS learning curve for this role\"],\"explanation\":\"The candidate has a solid Node.js TypeScript foundation and PostgreSQL experience, but the role requires NestJS specifically and centers on healthcare domain expertise \u2014 FHIR, HL7, and HIPAA \u2014 none of which appear in the profile. The healthcare compliance dimension alone represents a significant specialized knowledge gap beyond the framework switch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yuriy_infra_lead\",\"seniority\":\"Lead\",\"roles\":[\"Infrastructure Engineer\",\"DevOps Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Terraform\",\"Ansible\",\"Kubernetes\",\"Helm\",\"GCP\",\"Docker\",\"Vault\",\"Consul\"],\"architecture\":[\"Cloud-Native\",\"Service Mesh\",\"Multi-Tenant\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"Spanner\"],\"ci_cd\":[\"Cloud Build\",\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"pytest\",\"Terratest\"]}\n\nJob Summary:\nEnterprise SaaS company on GCP seeking a Lead Infrastructure Engineer. You will design and own the multi-tenant Kubernetes platform, manage service mesh configuration with Consul and Vault for secrets, and lead a team of three infrastructure engineers. Terraform and Terratest for IaC testing are required. Cloud Build is our CI/CD system.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"GCP, Consul, Vault, Terraform, and Terratest match the core technical requirements\",\"Multi-Tenant and Service Mesh architecture signals are direct matches\",\"Cloud Build is the CI/CD system and is present\",\"Lead seniority is appropriate for team ownership\"],\"gaps\":[\"No explicit team management, 1-on-1, or engineer mentoring signals\",\"Spanner is a Google database not mentioned in the job \\u2014 suggests experience outside the stated scope\",\"No self-service platform or developer experience product signals for the enterprise SaaS context\",\"No cost management or FinOps signals for a multi-tenant cloud platform\"],\"explanation\":\"The candidate's GCP and Kubernetes platform credentials are strong and align with the technical requirements. However, leading a team of three infrastructure engineers requires people management depth that is not visible in the profile, and the Spanner listing adds noise that suggests their GCP experience may be in a different product context than the one described. A leadership track record would need to be verified before advancing.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"aisha_nlp_sr\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"Data Scientist\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Hugging Face Transformers\",\"PyTorch\",\"LangChain\",\"spaCy\",\"MLflow\",\"FastAPI\",\"Docker\"],\"architecture\":[\"RAG\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Weaviate\",\"ChromaDB\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nLegaltech startup building a contract intelligence product. Hiring a Senior ML Engineer to fine-tune transformer models on legal text, build RAG pipelines for clause retrieval, and serve models via FastAPI. Weaviate is used as the vector store. LangChain orchestrates retrieval workflows. Python and PyTorch are required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Hugging Face Transformers and PyTorch match the fine-tuning stack exactly\",\"RAG architecture and Weaviate vector store are both directly present\",\"LangChain is the stated orchestration tool and is listed\",\"FastAPI matches the model serving framework requirement\",\"spaCy adds NLP preprocessing depth for legal text pipelines\",\"ChromaDB alongside Weaviate signals multi-vector-store practical experience\"],\"gaps\":[\"No legal domain or document parsing signals such as PDFMiner or Unstructured\"],\"explanation\":\"The candidate's ML stack is a precise match with Hugging Face, PyTorch, LangChain, Weaviate, and FastAPI all present and aligned with every stated requirement. The RAG architecture signal confirms they have worked on retrieval pipelines as a system rather than a theoretical concept. The only gap is the absence of legal document parsing tooling, which is a domain-specific detail that can be acquired.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"henrik_csharp\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C#\",\"SQL\"],\"tech\":[\".NET Core\",\"Entity Framework\",\"Docker\"],\"databases\":[\"MS SQL Server\"],\"ci_cd\":[\"Azure DevOps\"],\"testing\":[\"xUnit\"]}\n\nJob Summary:\nInsurance software company seeking a Senior .NET Backend Engineer to design and build microservices using ASP.NET Core, gRPC, and Azure Service Bus. You will work with Azure SQL and Cosmos DB. Strong C# skills, microservices architecture experience, and Azure cloud services knowledge are required. Experience with Clean Architecture patterns is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\".NET Core and C# are the primary stack and are present\",\"Entity Framework and MS SQL Server signal relational database experience relevant to Azure SQL\",\"xUnit is the appropriate .NET testing framework and is present\",\"Azure DevOps confirms Azure ecosystem familiarity\"],\"gaps\":[\"Mid-level seniority \u2014 role requires Senior-level architectural ownership\",\"No gRPC or Azure Service Bus signals\",\"No Cosmos DB experience\",\"No microservices architecture signals\",\"No Clean Architecture or DDD signals\",\"No ASP.NET Core REST or API design signals beyond .NET Core\"],\"explanation\":\"The candidate has a solid .NET foundation with C#, Entity Framework, and xUnit, but the role requires significant architectural depth \u2014 microservices, gRPC, Clean Architecture, and Azure-native services \u2014 that is absent from the profile. The seniority gap compounds the technical gaps, making this a candidate who could grow into the role but is not a fit today.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rosario_vue_ts\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\",\"Python\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Vite\",\"Tailwind CSS\",\"FastAPI\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"],\"testing\":[\"Vitest\",\"Playwright\",\"pytest\"]}\n\nJob Summary:\nB2B analytics startup hiring a Senior Full Stack Engineer. The stack is Vue.js, Nuxt.js, and FastAPI backed by PostgreSQL. You will build data visualization dashboards, design REST APIs, and maintain a Pinia-based state management layer. TypeScript is used throughout. Playwright is used for end-to-end testing.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Vue.js, Nuxt.js, Pinia, and FastAPI match the full stack exactly\",\"TypeScript is primary across the stack\",\"Playwright and pytest cover E2E and backend testing\",\"Vitest and pytest provide additional test coverage\"],\"gaps\":[\"No data visualization library signals such as D3.js, Chart.js, or ECharts for a dashboard-heavy role\",\"No BI integration or charting component signals\",\"No analytics dashboard domain signals or time-series data visualization experience\",\"No accessibility signals for complex data display components\"],\"explanation\":\"The candidate's full stack alignment is technically strong with Vue.js, Nuxt.js, Pinia, FastAPI, and TypeScript all present. However, the role centers on data visualization dashboards, and the absence of any charting or visualization library signals is a meaningful gap for an analytics product where the UI's primary purpose is rendering complex data. This warrants validation before treating as a full fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dmitri_spring_sr\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Software Architect\"],\"languages\":[\"Java\",\"Kotlin\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Spring\",\"Kafka\",\"Docker\",\"Kubernetes\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Hexagonal Architecture\",\"Domain-Driven Design\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"Elasticsearch\"],\"ci_cd\":[\"Jenkins\",\"GitLab CI\"],\"testing\":[\"JUnit\",\"Mockito\",\"Testcontainers\"]}\n\nJob Summary:\nEuropean e-commerce platform hiring a Senior Java Backend Engineer to evolve their event-driven microservices catalog and search service. Spring Boot is the framework. Kafka handles domain events. Elasticsearch powers product search. PostgreSQL is the source of truth. Hexagonal Architecture and DDD are the design standards. Testcontainers is used for integration testing.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Spring Boot, Kafka, Elasticsearch, and PostgreSQL match the stated stack\",\"Hexagonal Architecture and DDD are both present as design standards\",\"Testcontainers is the stated testing tool and is listed\"],\"gaps\":[\"No Elasticsearch relevance tuning, search index design, or full-text query optimization signals\",\"No event storming or collaborative DDD design signals for a domain that uses DDD workshops\",\"No schema evolution or Kafka topic versioning signals for an event-driven catalog service\",\"Kotlin listed alongside Java but no Kotlin-specific Spring Boot signals\"],\"explanation\":\"The candidate's stack is well-aligned with Spring Boot, Kafka, Elasticsearch, Hexagonal Architecture, and Testcontainers all present. However, the product search requirement demands Elasticsearch tuning depth \\u2014 relevance scoring, analyzers, and index management \\u2014 that is not evidenced beyond listing the database. Search tuning is a specialized skill that can be the difference between a functional and a competitive product search experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lin_frontend_intern\",\"seniority\":\"Intern\",\"roles\":[\"Software Engineer\"],\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"Flask\"]}\n\nJob Summary:\nStartup seeking an intern to help build and test React UI components, write Python scripts for data processing, and fix bugs under senior engineer supervision. Basic React and Python skills are all that is required. Git workflow participation is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React matches the primary UI framework\",\"Python matches the scripting language requirement\",\"Intern seniority aligns with the role level\",\"Flask indicates some Python backend familiarity beyond scripting\"],\"gaps\":[\"No Git or version control signals visible\",\"Profile is extremely sparse with no testing, tooling, or project context\",\"No evidence of collaborative workflow or code review participation\"],\"explanation\":\"The candidate has the right core technologies for an intern role and appropriate seniority. However, the complete absence of Git signals is a notable gap even at the intern level, and the sparse profile provides no confidence about practical readiness. A portfolio or code sample review would be necessary before advancing.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mo_data_eng_mid\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"dbt\",\"Apache Airflow\",\"Pandas\",\"Docker\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"dbt test\"]}\n\nJob Summary:\nRetail analytics company seeking a Mid-level Data Engineer to maintain and extend dbt models in BigQuery, orchestrate pipelines in Airflow, and improve data quality using dbt tests. Python scripting for pipeline automation is required. The team values clear data documentation and clean SQL practices.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"dbt and BigQuery are listed and relevant\",\"Python and SQL are the required languages\"],\"gaps\":[\"No dbt test signals despite data quality being a stated team value\",\"No data documentation tooling or practices visible\",\"Profile is very sparse with only four technologies \\u2014 depth in any is unconfirmed\",\"No pipeline reliability or monitoring signals for Airflow operations\"],\"explanation\":\"While the candidate lists the right tools, the profile is so sparse that it cannot confirm meaningful depth in dbt, Airflow, or data quality practices. The absence of dbt testing signals is particularly notable for a team that explicitly values data quality. Without a portfolio or project context to validate, this profile cannot be advanced with confidence.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ife_react_lead\",\"seniority\":\"Lead\",\"roles\":[\"Frontend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"TanStack Query\",\"Zustand\",\"Tailwind CSS\",\"Radix UI\",\"Storybook\"],\"architecture\":[\"Micro-Frontend\",\"Monorepo\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\",\"Vercel\"],\"testing\":[\"Vitest\",\"Playwright\",\"React Testing Library\"]}\n\nJob Summary:\nScale-up marketplace hiring a Lead Frontend Engineer to own the consumer-facing React and Next.js application, lead a team of four frontend engineers, and define micro-frontend boundaries as the team grows. TanStack Query for data fetching, Zustand for state, and Radix UI for accessible components are the current standards. Storybook and Vercel are part of the workflow.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React, Next.js, TanStack Query, Zustand, and Radix UI all match the stated standards\",\"Storybook and Vercel are present for the workflow tools\",\"Lead seniority is appropriate for the team ownership scope\"],\"gaps\":[\"No micro-frontend implementation signals such as Module Federation or single-spa beyond architecture label\",\"No cross-team API contract or design token system signals for a multi-team frontend\",\"No performance budget or Core Web Vitals optimization signals for a consumer marketplace\",\"No team hiring or engineering growth signals to support the team leadership claim\"],\"explanation\":\"The candidate's component-level tooling is a strong match, but the Micro-Frontend architecture label requires deeper validation \\u2014 the role involves defining micro-frontend boundaries as the team grows, which requires Module Federation or similar implementation experience not evidenced. Leadership depth for managing a team of four engineers also needs evidence beyond a seniority label.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"serge_mlops\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"PyTorch\",\"MLflow\",\"Weights & Biases\",\"FastAPI\",\"Docker\",\"Kubernetes\"],\"databases\":[\"PostgreSQL\",\"S3\"]}\n\nJob Summary:\nAd tech company hiring a Mid-level ML Engineer to train click-through rate prediction models, manage experiment tracking, and deploy models as real-time inference APIs. The team uses XGBoost and LightGBM for tabular models and MLflow for tracking. FastAPI serves model endpoints. Feature engineering from large Spark datasets is part of the workflow.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"MLflow matches the experiment tracking requirement explicitly\",\"FastAPI is the stated serving framework and is present\",\"Docker and Kubernetes confirm inference deployment capability\",\"PyTorch signals deep learning experience as complementary background\"],\"gaps\":[\"No XGBoost or LightGBM signals \u2014 the primary tabular modeling tools\",\"No Apache Spark or large-scale feature engineering signals\",\"CTR prediction and online advertising domain experience not evidenced\",\"Weights and Biases is a competitor to MLflow for tracking \u2014 presence alongside MLflow is slightly redundant\"],\"explanation\":\"The candidate has solid MLOps infrastructure skills with MLflow, FastAPI, and Kubernetes, but the role's core modeling work uses XGBoost and LightGBM for tabular click-through rate prediction with Spark-based feature engineering \u2014 none of which appears in the profile. They are a strong infrastructure fit but an uncertain modeling fit for this specific domain.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"preethi_fullstack\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\",\"SQL\"],\"tech\":[\"Angular\",\"NestJS\",\"Nx\",\"Docker\",\"Redis\"],\"architecture\":[\"Monorepo\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Azure Pipelines\"],\"testing\":[\"Jest\",\"Karma\",\"Jasmine\"]}\n\nJob Summary:\nEnterprise HR software company on Azure hiring a Mid-level Full Stack Engineer. The stack is Angular, NestJS, and PostgreSQL in a monorepo managed with Nx. Azure Pipelines is the CI/CD system. You will build new HR module features end to end, maintain shared libraries, and participate in code review. TypeScript across the stack is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Angular and NestJS match the core framework requirements\",\"Nx is the monorepo tool and is present\"],\"gaps\":[\"No Azure SQL or cloud database signals despite Azure being the platform\",\"No shared library publishing or cross-team component ownership signals\",\"Karma and Jasmine are legacy Angular testing tools \\u2014 team may expect Jest or Testing Library\",\"No TypeScript-first Angular patterns or standalone component signals for modern Angular\",\"No feature module or domain library architecture signals for a large enterprise monorepo\"],\"explanation\":\"The candidate has the correct base stack in Angular, NestJS, and Nx, but the enterprise Angular context requires deeper monorepo architecture skills and Azure-native database experience that are absent. Legacy testing tools and the absence of shared library patterns for a 12-team codebase raise meaningful concerns about readiness for the enterprise scope of this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"aleksei_rust_sys\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Embedded Engineer\"],\"languages\":[\"Rust\",\"C\",\"C++\"],\"tech\":[\"Axum\",\"Tokio\",\"Docker\"],\"architecture\":[\"Microservices\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Rust built-in tests\"]}\n\nJob Summary:\nCybersecurity firm building a network packet inspection tool in Rust. Hiring a Senior Systems Engineer to implement high-performance async network handlers using Tokio, write memory-safe parsing logic, and integrate with eBPF-based kernel modules. Experience with Linux networking internals and unsafe Rust is important.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Rust is the primary language and is directly present\",\"Tokio signals async Rust runtime experience relevant to high-performance network handlers\",\"C and C++ background supports systems-level and kernel interaction context\",\"Distributed System architecture signals imply network-aware service design\"],\"gaps\":[\"No eBPF experience or Linux kernel module signals\",\"No packet inspection, network protocol, or pcap tooling signals\",\"No unsafe Rust signals for memory-unsafe interop boundaries\",\"No Linux networking internals experience visible beyond general systems background\"],\"explanation\":\"The candidate's Rust and Tokio experience are relevant, and their C and C++ background supports systems-level reasoning. However, the role centers on eBPF integration and Linux networking internals, which are highly specialized domains with no corresponding signals in the profile. Axum is a web framework, which is a different context from network packet inspection infrastructure.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"femi_data_analyst\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Tableau\",\"Pandas\",\"Excel\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nE-commerce company seeking a Junior Data Analyst to build Tableau dashboards, write SQL queries against PostgreSQL, and support the marketing team with campaign performance analysis. Python for data wrangling is a plus. No advanced ML skills required. Strong attention to detail and data accuracy are most important.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Tableau is the primary visualization tool and is directly present\",\"SQL and PostgreSQL match the query and database requirements\",\"Python meets the stated plus requirement for data wrangling\",\"Pandas confirms Python data manipulation capability\",\"Junior seniority matches the role level explicitly\"],\"gaps\":[\"No marketing analytics or campaign performance domain signals\",\"No Excel automation or advanced formula signals despite Excel being listed\"],\"explanation\":\"The candidate covers all core technical requirements for this junior analyst role with Tableau, SQL, PostgreSQL, Python, and Pandas all present. The seniority is an exact match. The main uncertainty is the lack of marketing analytics domain experience, but the role does not require it as a prerequisite \u2014 just strong attention to data accuracy, which the technical tooling supports.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"oleg_principal_arch\",\"seniority\":\"Principal\",\"roles\":[\"Solutions Architect\",\"Software Architect\",\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\",\"Java\",\"TypeScript\",\"SQL\"],\"tech\":[\"Kubernetes\",\"Kafka\",\"Terraform\",\"AWS\",\"gRPC\",\"Istio\",\"Consul\",\"Vault\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Distributed System\",\"Cloud-Native\",\"Service Mesh\",\"CQRS\",\"Domain-Driven Design\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\",\"Cassandra\",\"Redis\",\"Elasticsearch\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\",\"Tekton\"],\"testing\":[\"pytest\",\"JUnit\",\"k6\"]}\n\nJob Summary:\nCloud infrastructure company seeking a Principal Engineer to lead the design of a next-generation API platform serving thousands of internal teams. You will define service mesh standards, evaluate API gateway solutions, shape the event-driven architecture, and mentor staff-level engineers. AWS is the target cloud. Experience with Istio, Consul, and Kafka at global scale is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Istio and Consul match the service mesh and service discovery requirements\",\"Kafka matches event-driven architecture\",\"AWS is the target cloud and is confirmed\",\"Principal seniority with Architect roles supports leadership scope\"],\"gaps\":[\"No specific API gateway product experience such as Kong, AWS API Gateway, or Envoy\",\"No RFC, ADR, or technical standards documentation process signals\",\"No internal developer platform or self-service tooling product signals for thousands of teams\",\"No cost optimization or infrastructure efficiency signals appropriate for a cloud provider context\"],\"explanation\":\"The candidate's architecture and infrastructure credentials are strong, but the role specifically requires API gateway evaluation and selection \\u2014 a decision that requires hands-on experience with gateway products, not just architecture familiarity. Additionally, the cross-team scale of thousands of internal teams requires demonstrated experience with platform adoption and standards governance that are not visible in the profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"claudia_django\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"Python\",\"JavaScript\",\"SQL\"],\"tech\":[\"Django\",\"Django REST Framework\",\"Celery\",\"Docker\",\"Redis\",\"React\"],\"architecture\":[\"Monolith\",\"Layered Architecture\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Django test client\"]}\n\nJob Summary:\nProptech company running a Python Django monolith seeking a Mid-level Backend Engineer to add REST endpoints, improve Celery task reliability, and maintain PostgreSQL schemas. Redis is used for caching and task queuing. The team values well-tested Python code and conventional Django patterns.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Django and Django REST Framework are present and relevant\",\"Celery is listed for background task context\"],\"gaps\":[\"No Celery reliability engineering signals such as retry strategies, dead letter queues, or task monitoring\",\"No PostgreSQL schema migration or versioning signals despite schema maintenance being a stated task\",\"No Redis configuration signals for the dual caching and queuing use case\",\"Profile depth is insufficient to confirm production-level Django API ownership\"],\"explanation\":\"The candidate lists the right tools but the role specifically requires improving Celery task reliability \\u2014 a nuanced operational concern that requires more than a tool listing to validate. Schema maintenance at a proptech company implies complex migrations that are not evidenced, and the overall sparseness of the profile makes it difficult to confirm readiness for production ownership.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nneka_ml_jr\",\"seniority\":\"Junior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"Jupyter\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nFinancial services firm hiring a Junior Data Scientist to build credit risk scoring models using scikit-learn, clean and analyze loan datasets with Pandas, and document findings in Jupyter notebooks. SQL queries against PostgreSQL for data extraction are part of the day-to-day. No production deployment experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"scikit-learn and Pandas are present and match the stated tools\",\"PostgreSQL is present for data extraction\"],\"gaps\":[\"No credit risk, financial modeling, or domain-specific statistical signals\",\"No Jupyter notebook or documented analysis workflow signals\",\"Profile is extremely sparse with only four technologies and no project context\",\"R is listed but no statistical modeling or financial analysis signals to contextualize it\",\"No SQL query writing signals beyond language listing\"],\"explanation\":\"While the candidate's tools technically align, the profile is too sparse to confirm practical readiness even at the junior level. Jupyter is listed in the job as a specific deliverable tool and is absent from the profile. The absence of any financial or credit risk domain signals and no evidence of notebook-based analysis workflows makes this a weak match requiring portfolio validation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ben_graphql\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\",\"SQL\"],\"tech\":[\"Apollo GraphQL\",\"NestJS\",\"Prisma\",\"Docker\",\"Redis\"],\"architecture\":[\"Microservices\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nSocial platform startup seeking a Senior Backend Engineer to design and build a GraphQL API using Apollo Server and NestJS. Prisma is the ORM and PostgreSQL is the database. Redis is used for caching and rate limiting. TypeScript is required. Experience with API gateway patterns and schema-first GraphQL design is important.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Apollo GraphQL is the stated API framework and is directly present\",\"NestJS and Prisma match the backend stack exactly\",\"PostgreSQL is the primary database and is present\",\"Redis matches both caching and rate limiting use cases\",\"API Gateway architecture signal aligns with the gateway pattern requirement\",\"TypeScript is confirmed as the primary language\"],\"gaps\":[\"No schema-first GraphQL design or schema registry signals specifically\"],\"explanation\":\"The candidate's profile is a precise match with Apollo GraphQL, NestJS, Prisma, PostgreSQL, and Redis all present and aligned. The API Gateway architecture signal directly supports the stated design pattern requirement. The only minor gap is the absence of explicit schema-first GraphQL development signals, which is a workflow nuance within an otherwise strong fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lara_spark_jr\",\"seniority\":\"Junior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Pandas\",\"dbt\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nStreaming video company hiring a Senior Data Engineer to design and operate real-time Flink pipelines, build Kafka consumer services, and own the data quality layer at petabyte scale. Scala and Python are both required. Experience with Iceberg table format and Trino for federated queries is expected. Must be comfortable making architecture decisions independently.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is present and meets part of the language requirement\",\"dbt signals some data transformation familiarity\"],\"gaps\":[\"Junior seniority \u2014 role requires Senior-level architectural independence\",\"No Apache Flink or Kafka signals\",\"No Scala experience\",\"No Iceberg or Trino signals\",\"No real-time or streaming pipeline experience\",\"No petabyte-scale data engineering signals\"],\"explanation\":\"The candidate is a junior data engineer with a basic Python and dbt profile that does not approach the Senior-level scope this role requires. Every named technical requirement \u2014 Flink, Kafka, Scala, Iceberg, and Trino \u2014 is absent. The seniority gap and complete technical mismatch make this a fundamentally incompatible application.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tomoya_golang_be\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\",\"SQL\"],\"tech\":[\"Gin\",\"gRPC\",\"Kafka\",\"Docker\",\"Kubernetes\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"Go built-in tests\",\"Testify\"]}\n\nJob Summary:\nB2B API platform company hiring a Senior Backend Engineer in Go to build high-throughput gRPC services, manage Kafka-based event flows, and contribute to API gateway design. PostgreSQL and DynamoDB are used for different persistence needs. Testing with Testify is standard. Kubernetes and ArgoCD manage deployments.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go, gRPC, and Kafka match the core backend stack\",\"Testify and ArgoCD are both present\",\"DynamoDB and PostgreSQL cover the mixed persistence requirements\"],\"gaps\":[\"No API rate limiting, quota management, or tenant isolation signals for a B2B API platform\",\"No OpenAPI specification or API versioning strategy signals\",\"No developer portal or API documentation tooling signals\",\"No multi-tenant API key management or authentication gateway signals\"],\"explanation\":\"The candidate's Go and gRPC credentials are directly relevant, but a B2B API platform has specific cross-cutting concerns \\u2014 rate limiting, quota enforcement, tenant isolation, and developer experience \\u2014 that go beyond backend service development. None of these platform-layer concerns are evidenced in the profile, which suggests experience building services rather than API infrastructure for external developers.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alinta_devops_mid\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"Ansible\",\"Jenkins\",\"AWS\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nHealthtech company seeking a Senior DevOps Engineer to lead the migration from Jenkins to GitHub Actions, containerize legacy Python services with Docker, and introduce Terraform for infrastructure provisioning. Kubernetes on AWS is the target state. Strong experience with infrastructure-as-code and cloud-native patterns is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Jenkins experience is directly relevant to the migration source system\",\"Docker is present for the containerization work\",\"GitHub Actions is listed, indicating some familiarity with the migration target\",\"AWS experience is relevant to the Kubernetes target environment\"],\"gaps\":[\"Mid-level seniority \u2014 role requires Senior-level ownership of the migration\",\"No Terraform or infrastructure-as-code signals beyond Ansible\",\"No Kubernetes experience for the target infrastructure state\",\"No cloud-native architecture or IaC patterns signals\",\"Ansible is the current tool but Terraform is the stated requirement\"],\"explanation\":\"The candidate has relevant context in Jenkins and Docker, and their AWS experience provides cloud familiarity. However, the seniority gap and the absence of Terraform, Kubernetes, and cloud-native IaC patterns are meaningful for a role that requires leading a full infrastructure modernization. They could contribute to the migration but are unlikely to lead it without significant support.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"chisom_react_mid\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Redux\",\"Tailwind CSS\",\"Webpack\"],\"databases\":[\"Firebase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Cypress\"]}\n\nJob Summary:\nMedia startup seeking a Mid-level Frontend Engineer to build a React and Next.js content delivery platform. Redux Toolkit is used for state management. Tailwind CSS is the styling system. Jest and Cypress are the testing stack. The team is migrating from Webpack to Vite. TypeScript is required throughout.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React, Next.js, and Redux match the core framework and state management requirements\",\"Tailwind CSS is the styling system and is present\",\"Jest and Cypress match the testing stack exactly\",\"TypeScript is confirmed as the primary language\",\"Mid-level seniority is appropriate\"],\"gaps\":[\"No Vite experience for the stated migration target\",\"Redux versus Redux Toolkit is a meaningful version gap \u2014 patterns differ significantly\",\"No content delivery, CDN, or media performance optimization signals\",\"Webpack experience is the source of the migration, not the target\"],\"explanation\":\"The candidate's core stack is mostly relevant but has meaningful version and tooling gaps. Redux Toolkit introduces different patterns from classic Redux, and the Webpack-to-Vite migration requires experience the candidate's profile places them on the wrong side of. They can contribute to the current stack but will need upskilling on both the Redux Toolkit patterns and the Vite migration target.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"oluwaseun_staff\",\"seniority\":\"Staff\",\"roles\":[\"Backend Engineer\",\"Software Architect\"],\"languages\":[\"Java\",\"Python\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Kafka\",\"Kubernetes\",\"Terraform\",\"AWS\",\"Redis\",\"gRPC\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"CQRS\",\"Domain-Driven Design\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\",\"Jenkins\"],\"testing\":[\"JUnit\",\"Testcontainers\",\"k6\"]}\n\nJob Summary:\nLarge fintech company hiring a Staff Engineer to design and govern the event-driven microservices platform handling 500 million daily transactions. You will set architecture standards, lead domain modeling workshops, and mentor senior engineers across three product teams. Java and Spring Boot are the core stack. Kafka and gRPC are central to service communication.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Java, Spring Boot, Kafka, and gRPC match the core stack\",\"CQRS and DDD signal domain modeling depth\",\"Staff seniority is appropriate for cross-team governance\",\"Testcontainers and k6 demonstrate operational rigor\"],\"gaps\":[\"No architecture decision record or RFC governance process signals\",\"No domain modeling workshop facilitation or event storming signals for the workshop leadership scope\",\"No cross-team technical alignment or org-wide standards adoption signals\",\"No explicit financial transaction compliance or audit trail signals for 500M daily transactions\"],\"explanation\":\"The candidate's technical stack is well-aligned with Java, Spring Boot, Kafka, gRPC, CQRS, and DDD all present at Staff level. However, the role requires leading domain modeling workshops and governing architecture standards across three product teams, which demands facilitation and organizational influence skills not evidenced in the profile. Technical depth alone is insufficient for the cross-team governance scope.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mariam_wordpress_dev\",\"seniority\":\"Junior\",\"roles\":[\"Software Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"WordPress\",\"MySQL\"]}\n\nJob Summary:\nFintech company seeking a Principal Engineer to lead the design of a fraud detection system processing 10 million events per day. You will define the streaming architecture, evaluate ML models for anomaly detection, and mentor a team of senior engineers. Deep distributed systems and real-time processing expertise is essential.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Junior seniority \u2014 role requires Principal-level leadership\",\"WordPress and PHP background is entirely misaligned with fraud detection system design\",\"No streaming architecture or distributed systems signals\",\"No machine learning or anomaly detection signals\",\"No mentoring or cross-team influence signals\",\"Profile is minimal and does not approach any dimension of the role requirements\"],\"explanation\":\"There is no meaningful overlap between this candidate's WordPress PHP junior profile and a Principal-level distributed systems and ML engineering role. The seniority gap is fundamental, the technical domains are entirely different, and the leadership scope is far beyond what any signal in the profile suggests. This is not a viable match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elliot_k8s\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\",\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Prometheus\",\"Grafana\",\"Terraform\",\"AWS\",\"EKS\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"pytest\",\"Terratest\"]}\n\nJob Summary:\nE-commerce platform seeking a Senior SRE to operate and evolve a managed Kubernetes environment on EKS. You will write Helm charts, manage Terraform modules for AWS infrastructure, and build observability pipelines with Prometheus and Grafana. Terratest is required for infrastructure testing. ArgoCD is used for GitOps delivery.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"EKS, Kubernetes, Helm, Terraform, Terratest, and ArgoCD all match stated requirements\",\"Prometheus and Grafana cover the observability pipeline\"],\"gaps\":[\"No EKS cluster upgrade, node group management, or managed node pool signals\",\"No on-call or production incident response process signals\",\"No cost optimization or FinOps signals for an EKS-managed environment\",\"No cluster autoscaling or workload resource tuning signals\"],\"explanation\":\"The candidate's tooling alignment is strong across EKS, Helm, Terraform, and ArgoCD. However, operating a managed Kubernetes environment at production scale requires deeper operational signals \\u2014 cluster lifecycle management, upgrade strategies, and on-call readiness \\u2014 that are absent from the profile. Tooling presence alone does not confirm the operational maturity needed for an SRE-adjacent platform role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mei_ling_ds\",\"seniority\":\"Mid\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"scikit-learn\",\"PyTorch\",\"XGBoost\",\"Pandas\",\"NumPy\",\"MLflow\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"]}\n\nJob Summary:\nHealthcare AI company hiring a Mid-level Data Scientist to build patient outcome prediction models using XGBoost and scikit-learn, manage experiments in MLflow, and collaborate with clinical teams to interpret results. BigQuery is the primary data source. Experience with survival analysis or medical statistics is a plus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"XGBoost and scikit-learn are present and match the modeling tools\"],\"gaps\":[\"No survival analysis, clinical statistics, or healthcare domain signals\",\"No MLflow experiment tracking signals \\u2014 only listed, no depth evidence\",\"No healthcare data handling, IRB, or clinical collaboration signals\",\"PyTorch adds complexity but is not required and may indicate a different modeling background\",\"No BigQuery query or large dataset handling signals beyond database listing\"],\"explanation\":\"While the candidate lists the required modeling tools, the role centers on patient outcome prediction in collaboration with clinical teams, requiring healthcare domain understanding and statistical methods like survival analysis that are entirely absent. MLflow is listed but without any experiment management depth signal, and the clinical collaboration requirement has no corresponding evidence in the profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jc_node_jr\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"SQL\"],\"tech\":[\"Express.js\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"]}\n\nJob Summary:\nE-commerce startup seeking a Senior Backend Engineer to architect a real-time inventory management service using Node.js and Redis Streams. You will design the event-driven pipeline, manage PostgreSQL schemas at scale, and lead code reviews. GraphQL and TypeScript are required. Experience with high-volume transactional systems is critical.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Express.js and PostgreSQL show basic Node.js backend familiarity\"],\"gaps\":[\"Junior seniority \u2014 role requires Senior-level architectural ownership\",\"No TypeScript experience\",\"No Redis or Redis Streams signals\",\"No GraphQL experience\",\"No real-time or event-driven system signals\",\"No high-volume transactional system experience\",\"No code review or technical leadership signals\"],\"explanation\":\"The candidate is a junior backend developer with a basic Express.js profile that falls significantly short of the Senior-level scope this role demands. TypeScript, Redis Streams, and GraphQL \u2014 all hard requirements \u2014 are entirely absent. The architectural and leadership expectations of this role are far beyond what any signal in the profile supports.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"zara_product_eng\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\",\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"Python\",\"SQL\"],\"tech\":[\"React\",\"Next.js\",\"FastAPI\",\"Stripe\",\"Resend\",\"Docker\",\"AWS\"],\"architecture\":[\"Serverless\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Supabase\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Vercel\"],\"testing\":[\"Vitest\",\"Playwright\",\"pytest\"]}\n\nJob Summary:\nB2C subscription startup hiring a Senior Full Stack Engineer to build payment flows using Stripe, transactional email pipelines, and a customer dashboard in React and Next.js. FastAPI serves backend APIs. PostgreSQL and Supabase are the data layer. Serverless deployment via Vercel is standard. TypeScript across the stack is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Stripe matches the payment flow integration requirement explicitly\",\"React and Next.js are the stated dashboard framework and are present\",\"FastAPI matches the backend API framework\",\"Supabase and PostgreSQL match the stated data layer\",\"Serverless architecture and Vercel confirm the deployment pattern\",\"Resend signals transactional email pipeline experience directly relevant to the role\"],\"gaps\":[\"No subscription lifecycle or billing webhook handling signals beyond Stripe presence\"],\"explanation\":\"The candidate's profile is a comprehensive match with Stripe, React, Next.js, FastAPI, Supabase, Serverless, and Vercel all present. The Resend listing is a particularly strong signal for a role that explicitly names transactional email pipelines \u2014 this is a rare specificity that directly validates the candidate's experience. The only minor gap is the absence of subscription webhook lifecycle signals.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ivan_ml_infra\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"Data Engineer\"],\"languages\":[\"Python\",\"Go\",\"SQL\"],\"tech\":[\"PyTorch\",\"Kubeflow\",\"MLflow\",\"Ray\",\"Docker\",\"Kubernetes\",\"Kafka\"],\"architecture\":[\"Cloud-Native\",\"Microservices\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"S3\",\"BigQuery\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"]}\n\nJob Summary:\nAI infrastructure company building distributed model training infrastructure. Hiring a Senior ML Platform Engineer to design multi-GPU training orchestration with Ray, manage ML pipelines with Kubeflow, and track experiments with MLflow. Go is used for internal tooling. Kubernetes and ArgoCD manage the platform. Kafka streams training telemetry.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Ray is the stated orchestration tool and is directly present\",\"Kubeflow and MLflow match the pipeline and tracking requirements\",\"Kubernetes and ArgoCD match the platform management stack\",\"Kafka aligns with the telemetry streaming requirement\"],\"gaps\":[\"No CUDA or GPU cluster management signals for multi-GPU training orchestration\",\"No distributed training job scheduling or resource allocation signals\",\"No model checkpoint storage or training resumption pattern signals\",\"No hardware-aware optimization or mixed-precision training signals\"],\"explanation\":\"The candidate's MLOps infrastructure stack is strong with Ray, Kubeflow, MLflow, and Kubernetes all present. However, multi-GPU training orchestration requires GPU cluster management and CUDA-level awareness that is absent from the profile. Orchestrating distributed training workloads is meaningfully different from orchestrating inference or pipeline services, and that specialization is not evidenced.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"felix_dbt_sr\",\"seniority\":\"Senior\",\"roles\":[\"Analytics Engineer\",\"Data Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Looker\",\"Airflow\",\"Great Expectations\",\"Pandas\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"dbt test\",\"Great Expectations\",\"pytest\"]}\n\nJob Summary:\nGrowth-stage SaaS company seeking a Senior Analytics Engineer to model revenue and product data in dbt on Snowflake, build Looker dashboards for executive reporting, and define data quality standards. Airflow orchestrates transformations. Great Expectations is the data quality framework. Strong SQL and dbt expertise are the most important qualifications.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"dbt and Snowflake are listed and match the primary tools\",\"Looker and Airflow are present\"],\"gaps\":[\"No revenue modeling, SaaS metric, or ARR/MRR calculation signals\",\"No executive reporting or stakeholder communication signals\",\"No dbt test depth signals beyond tool listing\",\"Great Expectations is listed but no data quality framework design signals\",\"No product analytics or funnel analysis signals for a growth-stage SaaS context\"],\"explanation\":\"The candidate lists the right tools but the role requires deep domain expertise in revenue and product analytics modeling for SaaS \\u2014 ARR, MRR, churn, and funnel metrics \\u2014 none of which are evidenced. Listing dbt and Snowflake is insufficient without signals of the specific analytical work this role centers on, and the executive reporting scope requires stakeholder communication skills not visible in the profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nour_flutter_mid\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\",\"Full Stack Engineer\"],\"languages\":[\"Dart\",\"TypeScript\",\"Python\"],\"tech\":[\"Flutter\",\"Firebase\",\"Riverpod\",\"Dio\",\"FastAPI\",\"Docker\"],\"databases\":[\"Firebase\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"Flutter test\",\"Mockito for Dart\"]}\n\nJob Summary:\nTravel startup hiring a Mid-level Flutter Engineer to build and maintain a cross-platform mobile app with complex state management. Riverpod is the state management solution. Dio handles HTTP requests. Firebase for auth and cloud functions. Fastlane for release automation. Flutter test and Mockito are the testing standard.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Flutter is the primary framework and is directly present\",\"Riverpod is the stated state management solution and is listed\",\"Dio is the HTTP client and is present\",\"Firebase matches the auth and cloud functions requirement\",\"Fastlane is the release automation tool and is present\",\"Flutter test and Mockito for Dart match the testing standards exactly\"],\"gaps\":[\"No travel domain or geolocation API integration signals\"],\"explanation\":\"The candidate's profile is a precise match for every stated technical requirement: Flutter, Riverpod, Dio, Firebase, Fastlane, and Flutter test with Mockito all present. This level of tool-by-tool alignment is rare and indicates direct prior experience with this exact stack. The only minor gap is the absence of travel or geolocation domain signals, which is not a technical blocker.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kobi_ts_backend\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\",\"SQL\"],\"tech\":[\"NestJS\",\"Prisma\",\"Docker\",\"Redis\",\"BullMQ\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nE-commerce platform seeking a Mid-level Backend Engineer to build order processing services in NestJS. BullMQ is used for async job queuing. PostgreSQL and Prisma are the persistence layer. TypeScript is required. The team follows microservices patterns and values well-tested APIs.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"NestJS and BullMQ are listed and match the stated stack\",\"PostgreSQL and Prisma are present\"],\"gaps\":[\"No order management, inventory, or e-commerce domain signals\",\"No payment processing or checkout flow signals for an e-commerce order service\",\"MongoDB in profile is unexplained and suggests inconsistency or unfocused experience\",\"No API contract testing or consumer-driven contract signals for a microservices context\",\"Profile depth signals are thin \\u2014 cannot confirm production NestJS service ownership\"],\"explanation\":\"While the stack listing matches, the e-commerce order processing domain requires specific knowledge of transactional workflows, idempotency, and payment integrations that are entirely absent. The unexplained MongoDB presence alongside PostgreSQL and the overall sparseness of the profile make it difficult to assess whether the NestJS and BullMQ experience is at a production depth appropriate for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"bianca_ux_eng\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Framer Motion\",\"Tailwind CSS\",\"Storybook\",\"Radix UI\",\"CSS Modules\"],\"databases\":[\"Supabase\"],\"ci_cd\":[\"GitHub Actions\",\"Vercel\"],\"testing\":[\"Vitest\",\"Playwright\",\"React Testing Library\"]}\n\nJob Summary:\nDesign-led product company hiring a Senior Frontend Engineer to implement pixel-perfect UI from Figma designs, maintain a shared design system in Storybook, and build accessible component primitives using Radix UI. Framer Motion handles animations. Tailwind CSS is the styling approach. TypeScript and Vercel are standard.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Radix UI and Storybook match the design system and accessible component requirements exactly\",\"Framer Motion is the stated animation library and is present\",\"Tailwind CSS is the styling approach and is confirmed\",\"TypeScript is the standard language and is primary in the profile\",\"Vercel matches the deployment standard\",\"React Testing Library and Vitest signal component-level testing discipline\"],\"gaps\":[\"No explicit accessibility audit or WCAG compliance tooling signals beyond Radix UI\"],\"explanation\":\"The candidate's profile is an exceptional match for a design-led product company with Radix UI, Storybook, Framer Motion, Tailwind CSS, TypeScript, and Vercel all present. The combination of accessible component primitives via Radix UI and animation via Framer Motion alongside a comprehensive testing stack is exactly what a pixel-perfect UI engineering role requires. This is a strong and well-rounded fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"adaobi_security\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Semgrep\",\"Snyk\",\"Vault\",\"Kubernetes\",\"AWS\",\"Burp Suite\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"]}\n\nJob Summary:\nFintech company hiring a Senior Application Security Engineer to perform threat modeling, integrate SAST tools into CI/CD pipelines, conduct penetration testing, and run a developer security champion program. Semgrep and Snyk are the SAST tools. Burp Suite is used for manual penetration testing. OWASP Top 10 knowledge is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Semgrep and Snyk are the stated SAST tools and both are directly present\",\"Burp Suite is the stated penetration testing tool and is listed\",\"Vault signals secrets management and security infrastructure depth\",\"CI/CD pipeline experience supports SAST tool integration workflows\",\"Kubernetes and AWS confirm cloud-native security context\",\"Senior seniority supports the developer champion program ownership scope\"],\"gaps\":[\"No explicit OWASP Top 10 or threat modeling methodology signals\"],\"explanation\":\"The candidate's profile is a strong match with Semgrep, Snyk, Burp Suite, and Vault all present alongside CI/CD pipeline integration experience. The specific tooling alignment \u2014 especially the rare combination of SAST and manual penetration testing tools \u2014 directly validates the candidate for both automated and manual security work. The only gap is the absence of explicit OWASP or threat modeling framework signals, which is a methodology gap rather than a tooling gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"marcus_java_jr\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Docker\"],\"databases\":[\"MySQL\",\"PostgreSQL\"]}\n\nJob Summary:\nEnterprise software company seeking a Staff Engineer to define the Java backend architecture for a distributed financial reporting platform. You will lead domain modeling, establish testing standards using Testcontainers and JUnit 5, and mentor a cross-functional team. Deep expertise in CQRS, event sourcing, and Spring ecosystem internals is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Java and Spring Boot are the correct technology choices\",\"PostgreSQL is relevant to the data layer\"],\"gaps\":[\"Junior seniority \u2014 role requires Staff-level architectural leadership\",\"No CQRS or Event Sourcing signals\",\"No Testcontainers or advanced JUnit 5 signals\",\"No mentoring or cross-functional team leadership signals\",\"No distributed systems or financial domain experience\",\"Profile is too sparse to support any architectural ownership expectations\"],\"explanation\":\"While the candidate uses Java and Spring Boot, which are the right technologies, they are at the very beginning of their career. The Staff-level architectural depth required \u2014 CQRS, event sourcing, Testcontainers, and cross-functional mentoring \u2014 is entirely absent from the profile. The seniority gap alone is disqualifying for this type of role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yuna_k8s_platform\",\"seniority\":\"Senior\",\"roles\":[\"Platform Engineer\",\"DevOps Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"Prometheus\",\"Grafana\",\"AWS\",\"Docker\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"pytest\",\"Terratest\"]}\n\nJob Summary:\nGaming company seeking a Senior Platform Engineer to manage a global Kubernetes platform across three AWS regions, write and maintain Helm charts, provision infrastructure with Terraform, and improve observability using Prometheus and Grafana. GitOps delivery via ArgoCD. Terratest for infrastructure validation. Go for internal tooling development.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes and AWS match the global platform infrastructure requirements\",\"Helm is the stated chart management tool and is directly listed\",\"Terraform and Terratest cover IaC provisioning and validation requirements exactly\",\"Prometheus and Grafana match the observability improvement requirement\",\"ArgoCD confirms GitOps delivery experience\",\"Go is confirmed for internal tooling development\"],\"gaps\":[\"No multi-region Kubernetes federation or cross-region failover signals\"],\"explanation\":\"The candidate's profile covers every named technical requirement: Kubernetes, Helm, Terraform, Terratest, Prometheus, Grafana, ArgoCD, AWS, and Go. The precision of the tooling match is strong across infrastructure, observability, and GitOps. The only minor gap is the absence of explicit multi-region federation signals, which would be expected for a gaming platform spanning three AWS regions.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tolu_react_sr\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"TanStack Query\",\"Tailwind CSS\",\"shadcn/ui\",\"FastAPI\"],\"architecture\":[\"Serverless\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\",\"Vercel\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nHRtech startup seeking a Senior Full Stack Engineer to build an employee experience platform using React, Next.js, and FastAPI. TanStack Query for server state. Tailwind CSS and shadcn/ui for the design system. Supabase for database and auth. Vercel for deployment. TypeScript across the stack.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React, Next.js, and FastAPI match the full stack requirements exactly\",\"TanStack Query is the stated server state tool and is directly listed\",\"Tailwind CSS and shadcn/ui match the design system components\",\"Supabase aligns with both the database and auth requirements\",\"Vercel confirms the deployment environment\",\"TypeScript is the primary language as required\"],\"gaps\":[\"No HR domain or employee experience product signals\"],\"explanation\":\"The candidate's profile is a comprehensive match with React, Next.js, FastAPI, TanStack Query, Tailwind CSS, shadcn/ui, Supabase, and Vercel all present and precisely aligned. Every named tool in the job summary appears in the profile. The only gap is the absence of HR domain signals, which is a soft requirement for a technically focused role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"anya_bigdata\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"Java\",\"SQL\"],\"tech\":[\"Apache Spark\",\"Kafka\",\"Hadoop\",\"Docker\",\"Airflow\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"Cassandra\",\"HDFS\",\"PostgreSQL\"]}\n\nJob Summary:\nDigital bank hiring a Senior Data Engineer to build real-time fraud scoring pipelines using Flink, consume Kafka events, and maintain data quality in a Snowflake warehouse using dbt. Python is required. The team is actively migrating from a Hadoop-based batch system to a streaming-first architecture.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kafka experience is directly relevant to the event streaming requirements\",\"Python is the required language and is present\",\"Hadoop experience provides migration context \u2014 they know the legacy system being replaced\",\"Event-Driven architecture aligns with the streaming-first direction\",\"Apache Spark experience supports data processing pattern understanding\"],\"gaps\":[\"No Apache Flink experience \u2014 the primary streaming engine for this role\",\"No Snowflake experience for the warehouse layer\",\"No dbt experience for the data quality and transformation layer\",\"Cassandra and HDFS are legacy-aligned, not the target stack\"],\"explanation\":\"The candidate's Kafka and Python skills are relevant, and their Hadoop background provides migration context. However, the role centers on Flink, Snowflake, and dbt \u2014 the streaming-first target architecture \u2014 none of which appear in the profile. They understand where the system is coming from but not where it is going, making them a moderate fit with significant ramp-up required.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"camille_ml_ops\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"MLflow\",\"Docker\",\"FastAPI\",\"Kubernetes\"],\"architecture\":[\"Microservices\",\"Cloud-Native\"],\"databases\":[\"PostgreSQL\",\"S3\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nSaaS startup building document understanding tools and hiring a Mid-level ML Engineer. You will fine-tune transformer models for document classification, serve predictions via FastAPI, and track experiments with MLflow. AWS S3 stores training data. Docker and Kubernetes for deployment. Python is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Hugging Face Transformers and PyTorch are present for the fine-tuning stack\",\"FastAPI is the serving framework and is listed\"],\"gaps\":[\"No document parsing, OCR, or layout analysis tooling signals for document understanding\",\"No classification model training signals specific to document or text classification tasks\",\"No S3 data pipeline or training data management signals beyond database listing\",\"MLflow is listed but no experiment comparison or model versioning depth evidenced\",\"No document intelligence domain signals \\u2014 profile suggests general NLP rather than document AI\"],\"explanation\":\"The candidate's transformer and FastAPI experience are relevant, but document understanding is a specialized subdomain that requires document parsing, layout analysis, and classification pipeline experience that are absent from the profile. Listing Hugging Face Transformers indicates NLP capability but does not confirm document AI specialization, and the role requires immediate contribution without significant domain ramp-up.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"stefan_neo4j\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Data Engineer\"],\"languages\":[\"Python\",\"JavaScript\",\"SQL\"],\"tech\":[\"FastAPI\",\"Neo4j\",\"Kafka\",\"Docker\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"API Gateway\"],\"databases\":[\"Neo4j\",\"PostgreSQL\",\"Redis\",\"Elasticsearch\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nCybersecurity intelligence company building a knowledge graph platform for threat actor attribution. Seeking a Senior Backend Engineer to develop graph query APIs using Neo4j and FastAPI, ingest threat intelligence events via Kafka, and power search with Elasticsearch. Python is required. Experience with graph database modeling and Cypher query language is essential.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Neo4j is the primary graph database and is directly present\",\"FastAPI matches the API framework requirement\",\"Kafka matches the threat intelligence event ingestion requirement\",\"Elasticsearch is the stated search engine and is present\",\"Python is the required language and is confirmed\",\"Event-Driven architecture aligns with the streaming intelligence ingestion context\"],\"gaps\":[\"No explicit Cypher query language or graph modeling depth signals beyond Neo4j presence\"],\"explanation\":\"The candidate's profile is a strong match with Neo4j, FastAPI, Kafka, Elasticsearch, and Python all present and aligned. Neo4j experience in particular is a rare and direct signal for a knowledge graph platform role. The only gap is the absence of explicit Cypher or graph modeling signals to confirm depth of Neo4j expertise beyond the tool listing.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"divya_mobile_lead\",\"seniority\":\"Lead\",\"roles\":[\"Mobile Engineer\",\"iOS Engineer\"],\"languages\":[\"Swift\",\"Kotlin\",\"TypeScript\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Jetpack Compose\",\"React Native\",\"Firebase\",\"Expo\"],\"architecture\":[\"Microservices\",\"Modular Architecture\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\",\"Bitrise\"],\"testing\":[\"XCTest\",\"JUnit\",\"Detox\"]}\n\nJob Summary:\nConsumer super-app company seeking a Lead Mobile Engineer to define the mobile platform architecture, set standards for both iOS and Android, and lead a team of six mobile engineers. The team ships React Native for cross-platform features and native Swift and Kotlin for performance-critical flows. Bitrise and Fastlane manage CI/CD. Experience with modular mobile architecture is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React Native alongside native Swift and Kotlin covers the exact cross-platform and native blend required\",\"Modular Architecture signal directly matches the mobile architecture standard-setting requirement\",\"Bitrise and Fastlane are both present for the CI/CD stack\",\"Lead seniority aligns with the team leadership and standards-setting scope\",\"XCTest, JUnit, and Detox provide platform-specific testing coverage across iOS, Android, and React Native\",\"SwiftUI, UIKit, and Jetpack Compose demonstrate deep native UI expertise\"],\"gaps\":[\"No explicit super-app or mini-app framework signals for complex app-within-app patterns\"],\"explanation\":\"The candidate's profile is an exceptional match for a Lead Mobile role with React Native, native Swift and Kotlin, Bitrise, Fastlane, Modular Architecture, and comprehensive testing tooling all present. The combination of cross-platform and native depth at Lead level is precisely what a super-app requiring both paradigms demands. This is a strong and well-rounded fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rami_infra_sr\",\"seniority\":\"Senior\",\"roles\":[\"Infrastructure Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Terraform\",\"Ansible\",\"AWS\",\"Docker\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"]}\n\nJob Summary:\nGlobal logistics company migrating to a cloud-native Kubernetes-based platform on GCP. Seeking a Senior Infrastructure Engineer to write Terraform for GCP, manage GKE clusters, implement service mesh with Istio, and adopt GitOps with ArgoCD. Experience with Pulumi or Helm is a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform experience is relevant to the IaC requirement even on a different cloud provider\",\"Senior seniority is appropriate for the role level\",\"Docker provides containerization foundation for the GKE migration\",\"AWS-to-GCP migration experience may provide useful cross-cloud context\"],\"gaps\":[\"No GCP or GKE experience \u2014 role is GCP-specific\",\"No Kubernetes experience for the cluster management requirement\",\"No Istio or service mesh signals\",\"No ArgoCD or GitOps signals\",\"No Helm or Pulumi signals for the stated plus requirements\"],\"explanation\":\"The candidate has relevant Terraform and Docker foundations, but the role requires GCP, GKE, Istio, and ArgoCD \u2014 none of which appear in the profile. AWS-to-GCP is a significant platform transition, and the absence of Kubernetes cluster management experience is a fundamental gap for a role centered on GKE operations. They are a candidate with transferable foundations but substantial ramp-up needs.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cass_elixir_ph\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Elixir\",\"JavaScript\",\"SQL\"],\"tech\":[\"Phoenix\",\"LiveView\",\"Oban\",\"Docker\",\"Redis\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nStartup building a real-time collaborative tool seeking a Mid-level Elixir Engineer. Phoenix LiveView is the primary interface layer. Oban handles background processing. PostgreSQL and Redis are the data layer. The team values OTP patterns and fault-tolerant design. ExUnit is the testing framework.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Elixir and Phoenix are present and match the core language and framework\",\"ExUnit is the testing framework and is listed\"],\"gaps\":[\"No OTP concurrency, supervision tree, or fault-tolerance design signals \\u2014 central to the role's values\",\"LiveView is listed but no real-time collaboration pattern signals such as presence, channels, or PubSub\",\"No Oban depth signals \\u2014 background job reliability patterns are unconfirmed\",\"Mid-level seniority for a role expecting OTP-level design expertise may be a stretch\",\"No concurrent user session management signals for a collaborative tool\"],\"explanation\":\"The candidate lists the correct Elixir and Phoenix stack, but the role's core value proposition \\u2014 OTP-based fault-tolerance and real-time collaboration via LiveView \\u2014 requires depth that is not evidenced beyond tool listings. Real-time collaboration has specific LiveView PubSub and presence patterns that are absent, and OTP supervision tree design is a non-trivial skill that a sparse profile cannot confirm.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kim_frontend_sr\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Redux\",\"Webpack\",\"Bootstrap\",\"jQuery\"],\"databases\":[\"MySQL\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"Jasmine\",\"Karma\"]}\n\nJob Summary:\nFintecch startup building a modern investment platform hiring a Senior Frontend Engineer. The stack is React, Next.js, Tailwind CSS, and Zustand for state management. TypeScript is required. CI/CD via GitHub Actions. Testing with Vitest and Playwright. Strong performance optimization and Core Web Vitals experience is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and TypeScript experience are present and foundational\",\"Senior seniority is appropriate for the role level\"],\"gaps\":[\"No Next.js experience \u2014 core framework for the role\",\"No Tailwind CSS \u2014 design system approach is entirely different from Bootstrap\",\"No Zustand \u2014 uses Redux which follows different state patterns\",\"No Vitest or Playwright \u2014 testing stack requires full replacement\",\"No GitHub Actions \u2014 Jenkins is the legacy CI/CD tool\",\"No Core Web Vitals or performance optimization tooling signals\",\"jQuery and Bootstrap signal a legacy web era background misaligned with the modern stack\"],\"explanation\":\"While the candidate has React and TypeScript experience, almost every other technical requirement in this role points in a different direction \u2014 Next.js, Tailwind CSS, Zustand, Vitest, Playwright, and GitHub Actions are all absent. The legacy toolchain of jQuery, Bootstrap, Jenkins, and Karma signals a background rooted in a much earlier frontend era. The gap between the candidate's stack and the role's target stack is too wide to bridge easily.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tunde_swe_gen\",\"seniority\":\"Mid\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\",\"SQL\"],\"tech\":[\"Django\",\"React\",\"Docker\",\"Redis\"],\"architecture\":[\"Monolith\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"]}\n\nJob Summary:\nCivic tech nonprofit hiring a Mid-level Software Engineer to maintain and extend a Django and React application, write Python scripts for data import pipelines, and improve test coverage. PostgreSQL is the database. The team is small and values clean code over over-engineering. No advanced infrastructure experience required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Django and React match the primary application stack\",\"Python covers the scripting requirement for data pipelines\",\"PostgreSQL is the primary database and is present\",\"Monolith architecture aligns with the existing system context\",\"Mid-level seniority is appropriate\",\"Docker signals basic environment reproducibility\"],\"gaps\":[\"No testing framework signals despite test coverage improvement being a stated goal\",\"No data pipeline tooling signals beyond Python scripting inference\",\"No civic tech or public sector domain signals\"],\"explanation\":\"The candidate's core stack is technically aligned with Django, React, PostgreSQL, and Python all present. However, the absence of any testing framework signals is a notable gap for a role that explicitly prioritizes improving test coverage. The profile is sparse enough that depth across any of the listed technologies cannot be confirmed without further evaluation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pieter_devops_sr\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"AWS\",\"Docker\",\"Prometheus\",\"Grafana\",\"Datadog\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"CircleCI\",\"ArgoCD\"],\"testing\":[\"pytest\",\"Terratest\"]}\n\nJob Summary:\nB2B SaaS company seeking a Senior DevOps Engineer to manage Kubernetes clusters on AWS, improve observability with Prometheus, Grafana, and Datadog, write Terraform modules, and maintain Helm charts. ArgoCD handles GitOps deployments. The role involves on-call for infrastructure incidents and improving deployment reliability.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes and AWS match the cluster management environment\",\"Prometheus, Grafana, and Datadog cover the full observability stack stated\",\"Terraform and Terratest match IaC provisioning and testing requirements\",\"Helm is present for chart management\",\"ArgoCD confirms GitOps deployment experience\",\"Cloud-Native and Microservices architecture aligns with the SaaS infrastructure context\"],\"gaps\":[\"No explicit on-call or incident response process signals\"],\"explanation\":\"The candidate's profile is a comprehensive match with Kubernetes, AWS, Prometheus, Grafana, Datadog, Terraform, Helm, and ArgoCD all present and aligned. The full observability stack coverage \u2014 including Datadog alongside Prometheus and Grafana \u2014 is a strong differentiator for a role that names all three. The only gap is the absence of explicit on-call incident management signals.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"saoirse_backend\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Software Architect\"],\"languages\":[\"Python\",\"Go\",\"SQL\"],\"tech\":[\"FastAPI\",\"gRPC\",\"Kafka\",\"Docker\",\"Kubernetes\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Clean Architecture\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nHealthtech platform seeking a Senior Backend Engineer to build and evolve patient data APIs using FastAPI and Python. gRPC handles inter-service communication. Kafka manages health event streams. PostgreSQL and Cassandra are used for relational and time-series patient data respectively. Clean Architecture principles are applied across services. Locust is used for load testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"FastAPI and Python match the API development stack exactly\",\"gRPC is the stated inter-service protocol and is present\",\"Kafka matches the health event stream management requirement\",\"PostgreSQL and Cassandra both present for the mixed data storage requirements\",\"Clean Architecture is the stated design principle and is directly listed\",\"Locust is the stated load testing tool and is present\"],\"gaps\":[\"No healthcare data compliance or HIPAA signals visible\"],\"explanation\":\"The candidate's profile is a precise match with FastAPI, gRPC, Kafka, PostgreSQL, Cassandra, Clean Architecture, and Locust all present and aligned. The Cassandra experience is particularly relevant for time-series patient data storage. The only meaningful gap for a healthcare context is the absence of HIPAA or clinical data compliance signals, which may require additional validation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wendell_haskell\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Haskell\",\"Scala\",\"SQL\"],\"tech\":[\"Akka\",\"Kafka\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Event-Driven\",\"CQRS\",\"Distributed System\"],\"databases\":[\"Cassandra\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"HUnit\",\"QuickCheck\"]}\n\nJob Summary:\nFinancial derivatives trading firm seeking a Senior Functional Engineer. The core platform is built in Haskell and Scala with Akka for concurrent actor systems. Event sourcing and CQRS are applied across all domain services. Kafka handles trade event streams and Cassandra stores tick data. Comfort with property-based testing using QuickCheck is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Haskell and Scala are both present as primary languages and match the core platform directly\",\"Akka signals actor-based concurrency experience as required\",\"CQRS and Event-Driven architecture are present and match the domain service design\",\"Kafka and Cassandra both align with the trade event streaming and tick data storage requirements\",\"QuickCheck is the stated property-based testing tool and is directly listed\"],\"gaps\":[\"No event sourcing framework signals such as EventStoreDB beyond CQRS architecture label\"],\"explanation\":\"The candidate's profile is an exceptional match with Haskell, Scala, Akka, CQRS, Kafka, Cassandra, and QuickCheck all present and aligned. Haskell and QuickCheck expertise are rare signals that strongly differentiate this candidate for a functional programming environment. The only minor gap is the absence of an explicit event sourcing infrastructure signal beyond the CQRS label.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"temi_shopify_jr\",\"seniority\":\"Junior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"Ruby\",\"SQL\"],\"tech\":[\"React\",\"Ruby on Rails\",\"PostgreSQL\",\"Tailwind CSS\"],\"databases\":[\"PostgreSQL\"],\"testing\":[\"RSpec\",\"Jest\"]}\n\nJob Summary:\nE-commerce agency hiring a Junior Full Stack Engineer to build custom Shopify storefronts and checkout extensions. The role requires experience with Shopify Liquid templating, the Storefront API, and React. Remix is used for app development. Familiarity with GraphQL and Shopify CLI is expected. TypeScript preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React is present and relevant to Shopify storefront development\",\"Junior seniority matches the role level\"],\"gaps\":[\"No Shopify Liquid, Storefront API, or Shopify CLI experience\",\"No Remix experience for Shopify app development\",\"No GraphQL signals\",\"No TypeScript signals \u2014 listed as preferred\",\"Ruby on Rails background does not transfer directly to Shopify app development patterns\"],\"explanation\":\"While the candidate has React and some Rails experience, the role centers entirely on Shopify-specific tooling \u2014 Liquid, the Storefront API, Remix, and Shopify CLI \u2014 none of which appear in the profile. This is a domain mismatch rather than a seniority gap, and every hard technical requirement is absent from the candidate's visible stack.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mireille_devex\",\"seniority\":\"Senior\",\"roles\":[\"Platform Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Go\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"FastAPI\",\"Kubernetes\",\"Terraform\",\"Docker\",\"Backstage\"],\"architecture\":[\"Cloud-Native\",\"Microservices\",\"Monorepo\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"Vitest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nLarge tech company building an internal developer portal using Backstage. Seeking a Senior Platform Engineer to extend Backstage plugins in TypeScript and React, integrate with internal Kubernetes and Terraform APIs, and build custom scaffolder templates. Go is used for backend CLI tooling. ArgoCD is the deployment layer. Strong TypeScript and React skills are essential.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Backstage is directly listed, a rare and relevant signal\",\"TypeScript and React meet the plugin development language requirements\",\"Kubernetes, Terraform, Go, and ArgoCD confirm the integration surface\"],\"gaps\":[\"No Backstage plugin authoring, catalog entity, or scaffolder template signals beyond tool listing\",\"No internal developer platform product ownership or adoption metrics signals\",\"No API specification or contract design signals for Backstage plugin backend APIs\"],\"explanation\":\"The candidate's broad platform engineering stack is relevant, and Backstage listing is a strong differentiating signal. However, Backstage plugin development is a specialized skill that requires knowledge of the plugin system, entity model, and scaffolder API \\u2014 none of which are visible beyond the tool listing. The role requires hands-on plugin engineering rather than Backstage administration, and that depth cannot be confirmed without a portfolio review.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"raj_tableau_analyst\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Tableau\",\"Power BI\",\"Pandas\",\"Excel\"],\"databases\":[\"MySQL\",\"PostgreSQL\"]}\n\nJob Summary:\nGlobal manufacturing company seeking a Senior Business Intelligence Engineer to design and build enterprise data models in dbt on Snowflake, own Looker LookML development, and set BI standards across regional teams. Deep dbt and Snowflake expertise required. SQL optimization for high-volume datasets is essential. Looker Studio experience is a plus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"SQL is a primary skill and relevant to the data modeling work\",\"Tableau and Power BI demonstrate BI tool experience in adjacent platforms\"],\"gaps\":[\"Mid-level seniority \u2014 role requires Senior-level ownership\",\"No dbt experience \u2014 the primary data transformation framework\",\"No Snowflake experience \u2014 the target warehouse\",\"No Looker or LookML experience \u2014 the stated BI platform\",\"No enterprise data modeling or BI standards-setting signals\",\"MySQL and PostgreSQL experience does not transfer directly to Snowflake optimization\"],\"explanation\":\"The candidate has BI tool experience but the wrong set of tools \u2014 the role requires dbt, Snowflake, and Looker, none of which appear in the profile. Tableau and Power BI experience does not transfer to LookML development. The seniority gap compounds the technical mismatch, making this a weak fit on every relevant dimension.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"finn_svelte_mid\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Svelte\",\"SvelteKit\",\"Tailwind CSS\",\"Drizzle ORM\",\"Vite\"],\"architecture\":[\"Serverless\",\"Monolith\"],\"databases\":[\"PostgreSQL\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Vercel\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nDeveloper tools startup building a documentation platform. Seeking a Mid-level Full Stack Engineer to work primarily in SvelteKit and TypeScript, build REST and tRPC endpoints, manage a PostgreSQL schema with Drizzle ORM, and ship features end to end. Vercel is the hosting platform. Playwright is used for end-to-end testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SvelteKit is the primary framework and is directly present\",\"Drizzle ORM and PostgreSQL match the data layer requirements exactly\",\"Vercel is the hosting platform and is confirmed\",\"Playwright is the stated E2E testing tool and is present\",\"TypeScript is primary and meets the language requirement\",\"Serverless architecture aligns with Vercel deployment patterns\"],\"gaps\":[\"No tRPC signals \u2014 listed alongside REST as an endpoint style\"],\"explanation\":\"The candidate's profile is a strong match with SvelteKit, Drizzle ORM, PostgreSQL, Vercel, and Playwright all present and aligned. Drizzle ORM in particular is a specific and relatively uncommon library whose presence directly validates relevant experience. The only minor gap is the absence of explicit tRPC signals, which is a secondary endpoint style alongside REST.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yolanda_dba\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Data Engineer\"],\"languages\":[\"SQL\",\"Python\",\"Bash\"],\"tech\":[\"PostgreSQL\",\"Redis\",\"Docker\"],\"architecture\":[\"Layered Architecture\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MySQL\",\"Oracle\"]}\n\nJob Summary:\nEnterprise SaaS company seeking a Senior Data Engineer to build dbt models on BigQuery, orchestrate pipelines with Apache Airflow, and manage data quality with Great Expectations. Python is required. Experience with streaming data using Pub/Sub and partitioned BigQuery tables is important. Familiarity with Terraform for infrastructure provisioning is a plus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and SQL are the required languages and are present\",\"Strong multi-database SQL background is relevant to query authoring\"],\"gaps\":[\"No dbt experience\",\"No BigQuery or cloud data warehouse experience\",\"No Apache Airflow or pipeline orchestration signals\",\"No Great Expectations or data quality framework signals\",\"No Pub/Sub or streaming data signals\",\"No Terraform signals for the IaC plus requirement\"],\"explanation\":\"The candidate has strong relational database skills but is oriented toward traditional database administration rather than modern cloud data engineering. Every named technical requirement \u2014 dbt, BigQuery, Airflow, Great Expectations, and Pub/Sub \u2014 is absent from the profile. This is a domain mismatch rather than a depth gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kosta_wasm\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Software Engineer\"],\"languages\":[\"Rust\",\"C\",\"JavaScript\"],\"tech\":[\"Axum\",\"Tokio\",\"Docker\",\"WebGL\"],\"architecture\":[\"Microservices\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nBrowser-native CAD startup building a 3D modeling tool that compiles to WebAssembly. Hiring a Senior Engineer to write Rust code targeting WASM, implement geometry algorithms, and integrate with a Three.js frontend via WASM bindings. Experience with wasm-bindgen, wasm-pack, and 3D math is essential. Rust memory safety and performance optimization are critical.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Rust is the primary language and is directly present\",\"WebGL experience suggests familiarity with 3D rendering concepts useful alongside Three.js\",\"Tokio and Axum signal production-grade async Rust experience\",\"Memory safety and performance-oriented Rust background is implied by the language choice\"],\"gaps\":[\"No WASM, wasm-bindgen, or wasm-pack signals \u2014 the central compilation target\",\"No Three.js integration or JavaScript FFI signals\",\"No 3D geometry algorithm or computational geometry signals\",\"No CAD or 3D modeling domain experience visible\"],\"explanation\":\"The candidate has strong Rust credentials but the role is specifically about WebAssembly compilation and browser integration, which are entirely absent from the profile. WebGL experience provides adjacent 3D familiarity but does not substitute for wasm-bindgen or geometry algorithm experience. Rust proficiency is a necessary but insufficient condition for this highly specialized role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nneka_k8s_sr\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\",\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"GCP\",\"Prometheus\",\"Grafana\",\"OpenTelemetry\",\"PagerDuty\"],\"architecture\":[\"Cloud-Native\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Spanner\"],\"ci_cd\":[\"Cloud Build\",\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"pytest\",\"Terratest\"]}\n\nJob Summary:\nGCP-native SaaS platform seeking a Senior SRE to define and enforce SLOs, manage Cloud Spanner and PostgreSQL reliability, operate a Kubernetes-based infrastructure, and build observability with OpenTelemetry and Prometheus. PagerDuty manages alerting. Cloud Build and ArgoCD handle CI/CD. Go for internal tooling.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"GCP is the stated cloud and is confirmed\",\"Cloud Spanner is a named database requirement and is directly present\",\"OpenTelemetry and Prometheus match the observability stack exactly\",\"PagerDuty is the stated alerting tool and is present\",\"Cloud Build and ArgoCD match the CI/CD pipeline\",\"Go is confirmed for internal tooling development\",\"Terratest confirms infrastructure validation practice\"],\"gaps\":[\"No explicit SLO tooling or error budget tracking signals beyond operational role inference\"],\"explanation\":\"The candidate's profile is a precise match with GCP, Cloud Spanner, OpenTelemetry, Prometheus, PagerDuty, Cloud Build, and ArgoCD all present and aligned. Cloud Spanner experience is an unusual and directly validating signal for this specific stack. The only minor gap is the absence of explicit SLO definition tooling, which is expected to follow from the operational depth evidenced.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"layla_mlops_mid\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"PyTorch\",\"XGBoost\",\"LightGBM\",\"MLflow\",\"Prefect\",\"Docker\",\"FastAPI\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nInsurtech startup hiring a Mid-level ML Engineer to build actuarial risk scoring models using XGBoost and LightGBM, manage experiment lifecycle with MLflow, orchestrate pipelines with Prefect, and serve predictions via FastAPI. BigQuery is the feature data source. Python is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"XGBoost and LightGBM are the stated modeling tools and both are directly present\",\"MLflow matches the experiment lifecycle management requirement\",\"Prefect is the stated pipeline orchestration tool and is listed\",\"FastAPI is the serving framework and is confirmed\",\"BigQuery is the feature data source and is present\",\"Mid-level seniority and ML Engineer role are exact matches\"],\"gaps\":[\"No actuarial or insurance domain signals specifically\"],\"explanation\":\"The candidate's profile covers every named technical tool: XGBoost, LightGBM, MLflow, Prefect, FastAPI, and BigQuery all present and precisely matched. This level of tool-by-tool alignment is strong evidence of directly relevant experience. The only gap is the absence of actuarial or insurance domain signals, which was not listed as a hard requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"arjun_react_jr\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Vite\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nEarly-stage B2B SaaS startup hiring a Junior Frontend Engineer. The team uses React, TypeScript, and Tailwind CSS. You will build new dashboard features, integrate REST APIs, and write unit tests with Jest. Vite is the build tool. The role is fully remote and requires strong communication skills.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and TypeScript are present and relevant\"],\"gaps\":[\"Profile is extremely sparse with only three technologies listed\",\"No REST API integration signals despite it being a core daily task\",\"No project context or depth evidence in any listed technology\",\"No remote communication or async workflow signals for a remote-first role\"],\"explanation\":\"While the candidate lists the right base technologies, the profile is too sparse to confirm practical readiness for even a junior role. REST API integration is a stated daily responsibility with no corresponding signal, and the absence of any project context or tooling depth makes it impossible to assess whether the React and TypeScript experience is meaningful. A portfolio review would be required before advancing.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fatou_platform_staff\",\"seniority\":\"Staff\",\"roles\":[\"Platform Engineer\",\"DevOps Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"AWS\",\"Crossplane\",\"Backstage\",\"Docker\"],\"architecture\":[\"Cloud-Native\",\"Multi-Tenant\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\",\"Tekton\"],\"testing\":[\"pytest\",\"Terratest\"]}\n\nJob Summary:\nLarge enterprise seeking a Staff Platform Engineer to lead adoption of Crossplane for cloud resource provisioning, maintain a Backstage internal developer portal, and evolve multi-tenant Kubernetes infrastructure on AWS. You will mentor senior engineers and influence platform strategy across 50 product teams. Terraform and ArgoCD are the IaC and GitOps standards.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Crossplane is directly listed for the cloud provisioning requirement\",\"Backstage is present for the developer portal\",\"Terraform, ArgoCD, and Multi-Tenant architecture are all aligned\",\"Staff seniority supports the mentoring scope\"],\"gaps\":[\"No Crossplane provider development or composite resource definition signals\",\"No developer experience metrics or platform adoption measurement signals across 50 teams\",\"No platform onboarding, documentation, or self-service workflow design signals\",\"No org-wide standards governance or RFC process signals at the scale of 50 product teams\"],\"explanation\":\"The candidate's tooling alignment is strong with Crossplane, Backstage, Terraform, and ArgoCD all present. However, leading platform adoption across 50 product teams requires organizational influence, developer experience design, and standards governance that go far beyond infrastructure operation. Crossplane listing does not confirm provider development depth, and the absence of adoption or governance signals leaves meaningful uncertainty for this scale of influence.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jorge_android_mid\",\"seniority\":\"Mid\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Hilt\",\"Room\",\"Retrofit\"],\"architecture\":[\"Modular Architecture\",\"Clean Architecture\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Mockito\",\"Espresso\"]}\n\nJob Summary:\nFintech mobile app with 3 million users hiring a Mid-level Android Engineer. The tech stack is Kotlin, Jetpack Compose, and Hilt for dependency injection. Room handles local persistence. Clean Architecture and modular project structure are enforced. Retrofit for API calls. CI/CD via Fastlane and GitHub Actions. JUnit and Mockito for testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kotlin, Jetpack Compose, and Hilt match the stated stack exactly\",\"Room is the local persistence library and is directly present\",\"Clean Architecture and Modular Architecture are both listed as enforced standards and are confirmed\",\"Retrofit matches the API communication requirement\",\"JUnit, Mockito, and Espresso cover unit, mock, and UI testing\",\"Fastlane and GitHub Actions match the CI/CD pipeline\"],\"gaps\":[\"No explicit performance profiling or memory optimization signals for a 3M-user fintech app\"],\"explanation\":\"The candidate's profile is a precise match for every technical requirement with Kotlin, Jetpack Compose, Hilt, Room, Clean Architecture, Modular Architecture, Retrofit, and the full testing and CI/CD stack all present. This level of alignment across architecture patterns and tooling is exceptional. The only minor gap is the absence of performance optimization signals for a production fintech app at scale.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"suki_devops_jr\",\"seniority\":\"Junior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"GitHub Actions\",\"Terraform\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nSaaS startup seeking a Junior DevOps Engineer to maintain GitHub Actions pipelines, write Terraform scripts for AWS resource provisioning, containerize services with Docker, and assist with Kubernetes cluster operations. Python scripting for automation is expected. Mentorship provided.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"GitHub Actions is the stated CI/CD platform and is present\",\"Terraform matches the IaC scripting requirement\",\"Docker is present for containerization work\",\"Python is the stated scripting language and is confirmed\",\"Junior seniority with mentorship offered is an appropriate match\"],\"gaps\":[\"No Kubernetes signals for the cluster operations assistance requirement\",\"No AWS-specific service experience signals beyond Terraform inference\",\"Profile is sparse \u2014 depth in any tool is unconfirmed\"],\"explanation\":\"The candidate covers the primary tools \u2014 GitHub Actions, Terraform, Docker, and Python \u2014 which is a solid technical match for a junior role with mentorship. However, the absence of any Kubernetes signals is a gap for a role that includes cluster operations, and the overall profile sparseness makes it difficult to assess practical readiness. This is a plausible hire contingent on portfolio or interview validation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"evgen_principal_be\",\"seniority\":\"Principal\",\"roles\":[\"Backend Engineer\",\"Software Architect\"],\"languages\":[\"Go\",\"Rust\",\"Python\",\"SQL\"],\"tech\":[\"gRPC\",\"Kafka\",\"Kubernetes\",\"Terraform\",\"AWS\",\"Envoy\",\"Consul\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Distributed System\",\"Service Mesh\",\"CQRS\",\"Domain-Driven Design\"],\"databases\":[\"PostgreSQL\",\"CockroachDB\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"Go built-in tests\",\"k6\",\"Testcontainers\"]}\n\nJob Summary:\nCloud database company hiring a Principal Engineer to design the next-generation distributed transaction layer. You will define consensus protocols, evaluate CockroachDB and Cassandra trade-offs, set architectural standards, and mentor a team of staff engineers. Envoy and Consul manage service mesh. Deep distributed systems expertise and CQRS experience are essential.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"CockroachDB is listed, directly matching the distributed database evaluation requirement\",\"Envoy and Consul are both present for the service mesh requirement\",\"CQRS and Distributed System architecture signals are confirmed\",\"Principal seniority with Architect roles supports staff mentoring and standards-setting scope\",\"Go and Rust signal systems-level language depth appropriate for a transaction layer\",\"k6 and Testcontainers demonstrate load and integration testing at the platform level\"],\"gaps\":[\"No consensus protocol or Raft/Paxos-specific signals beyond distributed systems architecture label\"],\"explanation\":\"The candidate's profile is an exceptional match with CockroachDB, Envoy, Consul, CQRS, and Principal-level seniority all present and aligned. CockroachDB experience is a specific and rare signal that directly validates the distributed database evaluation requirement. The only gap is the absence of explicit consensus protocol implementation signals, which is a highly specialized area that requires direct confirmation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"chloe_qa_auto\",\"seniority\":\"Mid\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Selenium\",\"Appium\",\"Docker\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"Selenium\",\"Appium\",\"pytest\"]}\n\nJob Summary:\nFintech company rebuilding its QA automation infrastructure. Seeking a Mid-level QA Automation Engineer to migrate from Selenium to Playwright, introduce k6 for performance testing, integrate tests into GitHub Actions pipelines, and build API tests with Supertest. TypeScript is the target language for the new test suite.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Selenium experience is directly relevant as the migration source system\",\"pytest and Docker signal automation framework and containerization familiarity\",\"Mid-level seniority is appropriate\",\"Python scripting background supports test automation development\"],\"gaps\":[\"No Playwright experience \u2014 the migration target tool\",\"No k6 performance testing signals\",\"No GitHub Actions experience \u2014 Jenkins is the legacy tool\",\"No Supertest or API testing signals\",\"No TypeScript signals for the target test suite language\"],\"explanation\":\"The candidate has relevant Selenium background which provides migration context, but the role centers on moving to Playwright, k6, GitHub Actions, and TypeScript \u2014 the entire target stack is absent from the profile. Knowing the legacy tool is useful but insufficient when every migration destination requires new skills. This is a moderate fit with significant ramp-up needed on all target tooling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ibrahim_mleng_sr\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"C++\",\"SQL\"],\"tech\":[\"PyTorch\",\"CUDA\",\"TensorRT\",\"ONNX\",\"Docker\",\"Kubernetes\",\"Triton Inference Server\"],\"architecture\":[\"Microservices\",\"Cloud-Native\"],\"databases\":[\"PostgreSQL\",\"S3\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAutonomous driving startup hiring a Senior ML Engineer to optimize deep learning inference pipelines for real-time performance on embedded hardware. The team uses PyTorch for training and TensorRT and ONNX for model conversion and optimization. Triton Inference Server manages production serving. CUDA kernel profiling and quantization techniques are required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PyTorch, TensorRT, and ONNX are all present and match the model conversion and optimization stack\",\"CUDA signals kernel profiling and GPU programming depth\",\"Triton Inference Server is the production serving tool and is directly listed\",\"C++ provides low-level systems programming capability for embedded optimization\",\"Docker and Kubernetes confirm production deployment experience\"],\"gaps\":[\"No quantization or pruning technique signals beyond inference optimization tools\",\"No embedded hardware or edge device deployment signals\"],\"explanation\":\"The candidate's inference optimization stack is an exceptional match with PyTorch, TensorRT, ONNX, CUDA, and Triton all present. The combination of CUDA and C++ signals genuine low-level GPU and systems programming depth. The gaps are the absence of explicit quantization methodology signals and embedded hardware deployment experience, which are important specifics for an autonomous driving context but may be confirmed through project history.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ana_go_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\",\"SQL\"],\"tech\":[\"Gin\",\"Docker\",\"Redis\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Go built-in tests\",\"Testify\"]}\n\nJob Summary:\nHealthtech startup building a lab results platform. Seeking a Mid-level Backend Engineer in Go to build REST APIs with the Echo framework, process HL7 FHIR messages from Kafka, and store patient results in PostgreSQL. Testify for testing. Docker and GitHub Actions for deployment. TypeScript for a small internal admin tool is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go is the primary language and is present\",\"Kafka is listed for the message processing requirement\",\"PostgreSQL matches the patient data storage database\",\"Testify is the stated testing library and is confirmed\",\"Docker and GitHub Actions match the deployment stack\"],\"gaps\":[\"No Echo framework experience \u2014 role specifies Echo, not Gin\",\"No HL7 FHIR or healthcare messaging protocol signals\",\"No healthcare compliance or patient data sensitivity signals\",\"No TypeScript signals for the admin tool plus requirement\"],\"explanation\":\"The candidate's Go and Kafka background is relevant, but the role requires the Echo framework specifically rather than Gin, and centers on HL7 FHIR message processing \u2014 a specialized healthcare protocol with no corresponding signal in the profile. Healthcare domain requirements around FHIR are non-trivial, and the framework mismatch adds a second gap. They are a plausible Go backend candidate who needs domain ramp-up.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pat_react_native_sr\",\"seniority\":\"Senior\",\"roles\":[\"Mobile Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\",\"Python\"],\"tech\":[\"React Native\",\"Expo\",\"Redux\",\"React Query\",\"Firebase\",\"FastAPI\"],\"architecture\":[\"Microservices\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\",\"Bitrise\"],\"testing\":[\"Jest\",\"Detox\"]}\n\nJob Summary:\nConsumer marketplace app with 10 million installs seeking a Senior React Native Engineer to lead performance optimization initiatives, architect new feature modules using Expo, and manage Fastlane and Bitrise CI/CD automation. Redux for state management. Detox for end-to-end testing. The team is growing and will require the candidate to mentor two junior engineers.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React Native and Expo are both present and match the core framework requirements\",\"Fastlane and Bitrise are both listed for the CI/CD automation requirement\",\"Redux is the stated state management library and is confirmed\",\"Detox is the E2E testing tool and is present\",\"Senior seniority is appropriate for the role scope\"],\"gaps\":[\"No performance profiling or React Native performance optimization signals for a 10M-install app\",\"No mentoring or junior engineer development signals beyond seniority inference\",\"No app store optimization or release management signals at consumer scale\",\"No native module bridge experience signals for performance-critical feature work\"],\"explanation\":\"The candidate's React Native, Expo, Fastlane, Bitrise, Redux, and Detox stack aligns with the technical requirements. However, the role specifically centers on performance optimization at 10 million installs and engineering mentorship, neither of which is evidenced in the profile beyond the tooling match. Performance optimization at consumer scale is a specialized discipline requiring more than framework presence.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sona_spark_sr\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\",\"Backend Engineer\"],\"languages\":[\"Python\",\"Scala\",\"SQL\"],\"tech\":[\"Apache Spark\",\"PySpark\",\"Delta Lake\",\"Apache Airflow\",\"dbt\",\"Kafka\",\"Docker\"],\"architecture\":[\"Distributed System\",\"Event-Driven\",\"Cloud-Native\"],\"databases\":[\"Databricks\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nMedia streaming company building a lakehouse architecture on Databricks. Hiring a Senior Data Engineer to build Delta Lake pipelines, orchestrate with Airflow, write dbt models on top of the lakehouse, and enforce data quality with Great Expectations. Scala and PySpark are required for Spark jobs. Kafka ingests real-time events.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Delta Lake, Databricks, Airflow, dbt, Great Expectations, Scala, and PySpark are all present\",\"Kafka aligns with real-time event ingestion\"],\"gaps\":[\"No Databricks Unity Catalog or data lineage governance signals\",\"No Delta Live Tables or Databricks-specific workflow signals beyond Delta Lake\",\"No streaming versus batch Spark job distinction signals for a lakehouse streaming context\",\"No schema evolution or Delta Lake merge pattern signals for production lakehouse management\"],\"explanation\":\"The candidate's core tooling is well-aligned with Delta Lake, Databricks, Airflow, dbt, and Great Expectations all present. However, operating a production lakehouse architecture on Databricks requires Unity Catalog governance, Delta Live Tables workflow patterns, and schema evolution strategies that are absent from the profile. The depth of Databricks-specific production experience is unconfirmed beyond platform and framework listings.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"linh_php_backend\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"SQL\",\"JavaScript\"],\"tech\":[\"Symfony\",\"MySQL\",\"Redis\",\"Docker\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nLogistics SaaS startup seeking a Mid-level Backend Engineer to build microservices using NestJS and TypeScript. Kafka handles order event streaming. PostgreSQL and Redis are the data layer. The team follows Domain-Driven Design. Jest and Supertest are the testing standards. Experience with containerized deployments is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Redis experience is relevant to the caching layer\",\"Docker signals some containerization experience\",\"Mid-level seniority is appropriate\"],\"gaps\":[\"No TypeScript or NestJS experience \u2014 the primary language and framework\",\"No Kafka or event streaming signals\",\"No PostgreSQL experience \u2014 MySQL background does not directly transfer\",\"No Domain-Driven Design signals\",\"No Jest or Supertest experience \u2014 PHPUnit is PHP-native and does not transfer\",\"Symfony and PHP background is fundamentally misaligned with a TypeScript microservices role\"],\"explanation\":\"The candidate's Symfony and PHP background is entirely misaligned with a TypeScript and NestJS microservices role. Every core technical requirement \u2014 NestJS, TypeScript, Kafka, PostgreSQL, and DDD \u2014 is absent from the profile. Redis and Docker provide marginal overlap but are insufficient to bridge the stack gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yaw_cloudarch\",\"seniority\":\"Lead\",\"roles\":[\"Cloud Engineer\",\"Solutions Architect\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"AWS\",\"Terraform\",\"CDK\",\"Lambda\",\"API Gateway\",\"SQS\",\"SNS\",\"Docker\"],\"architecture\":[\"Serverless\",\"Event-Driven\",\"Microservices\",\"API Gateway\"],\"databases\":[\"DynamoDB\",\"RDS\",\"ElastiCache\"],\"ci_cd\":[\"GitHub Actions\",\"AWS CodePipeline\"],\"testing\":[\"pytest\",\"Terratest\"]}\n\nJob Summary:\nRetail technology company hiring a Lead Cloud Architect to design a serverless event-driven order processing system on AWS. You will architect Lambda functions, design SQS and SNS messaging topologies, provision infrastructure with CDK, and ensure cost efficiency. DynamoDB and RDS are the persistence layer. Experience with AWS API Gateway and event-driven patterns at scale is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Lambda, SQS, SNS, and API Gateway are all present for the serverless event-driven architecture\",\"AWS CDK is the stated IaC tool and is directly listed\",\"DynamoDB and RDS match the stated persistence layer\",\"Serverless and Event-Driven architecture signals align with the order processing system design\",\"Lead seniority and Solutions Architect role support the design ownership scope\",\"Terratest confirms IaC testing discipline\"],\"gaps\":[\"No explicit cost optimization or AWS Cost Explorer signals for the cost efficiency requirement\"],\"explanation\":\"The candidate's AWS serverless stack is a precise match with Lambda, SQS, SNS, API Gateway, CDK, DynamoDB, and RDS all present and aligned. The CDK listing in particular is a specific and differentiating signal over generic Terraform for AWS-native infrastructure-as-code. The only gap is the absence of explicit cost optimization tooling signals, which is a stated requirement beyond architecture design.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mercy_ds_intern\",\"seniority\":\"Intern\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"Jupyter\"]}\n\nJob Summary:\nConsumer analytics company seeking a Data Science intern to clean and explore datasets, run basic regression and classification models with scikit-learn, visualize findings in Jupyter, and present insights to the data team. Python is required. No production deployment experience expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"scikit-learn and Pandas are listed and relevant to the role\"],\"gaps\":[\"No data visualization library signals such as matplotlib or seaborn \\u2014 required for presenting findings in Jupyter\",\"Profile is extremely sparse with only four tools listed and no project context\",\"No statistical understanding or exploratory data analysis signals\",\"Jupyter is absent from the profile despite being the primary work environment stated\",\"R is listed without any context suggesting it has been applied to data analysis problems\"],\"explanation\":\"The candidate lists scikit-learn and Pandas but the profile is too sparse to confirm practical readiness. Jupyter is the stated work environment for presenting findings and is absent from the profile. The absence of data visualization tooling for an intern whose primary output is visualized insights is a meaningful gap that would need to be addressed before the candidate could contribute meaningfully.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vlad_backend_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Hibernate\",\"Docker\",\"Redis\"],\"architecture\":[\"Layered Architecture\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nFintecch company migrating from a Java Spring Boot monolith to Kafka-based microservices. Seeking a Mid-level Backend Engineer to decompose domain services, implement event-driven communication with Kafka, and work with PostgreSQL as the new service databases. DDD principles apply. Kubernetes and Helm are the deployment target. Testcontainers for integration testing.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Java and Spring Boot are the legacy stack and match the starting point of the migration\",\"Hibernate and JUnit/Mockito signal existing Java testing discipline\",\"Docker indicates containerization familiarity relevant to the Kubernetes migration target\"],\"gaps\":[\"No Kafka experience for the event-driven migration target\",\"No PostgreSQL experience \u2014 MySQL does not directly transfer for the new service databases\",\"No Kubernetes or Helm signals for the deployment target\",\"No Domain-Driven Design signals\",\"No Testcontainers experience for the integration testing standard\",\"No microservices design or service decomposition signals\"],\"explanation\":\"The candidate knows the legacy Java Spring Boot stack being migrated from, which is useful context, but the migration target stack \u2014 Kafka, PostgreSQL, Kubernetes, DDD, and Testcontainers \u2014 is entirely absent from the profile. They would be valuable in the early phases of decomposition but would need significant upskilling to own the event-driven microservices destination.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"roh_iosdev\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"CoreData\",\"Combine\",\"XCTest\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"Fastlane\",\"Bitrise\"],\"testing\":[\"XCTest\",\"XCUITest\"]}\n\nJob Summary:\nB2B enterprise app seeking a Mid-level iOS Engineer to build UIKit-based interfaces for a legacy codebase, implement CoreData persistence, and write XCTest unit and UI tests. Fastlane handles distribution. The codebase is primarily Objective-C with some Swift interoperability. Bitrise is the CI system.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"UIKit is a named requirement and is directly present\",\"CoreData matches the persistence library requirement\",\"XCTest and XCUITest cover unit and UI testing as required\",\"Objective-C is the primary codebase language and is confirmed\",\"Fastlane is the distribution tool and is present\",\"Bitrise is the CI system and is listed\"],\"gaps\":[\"SwiftUI and Combine are modern additions that are underutilized in a primarily Objective-C legacy codebase\"],\"explanation\":\"The candidate's iOS stack covers every stated requirement: UIKit, CoreData, Objective-C, XCTest, Fastlane, and Bitrise are all present and aligned. Objective-C proficiency alongside Swift is a relatively rare combination that is directly relevant for a legacy codebase with Swift interoperability. The only minor note is that the candidate's modern SwiftUI and Combine experience may be underutilized in this legacy-first role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ade_terraform_sr\",\"seniority\":\"Senior\",\"roles\":[\"Infrastructure Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"Terraform\",\"Ansible\",\"AWS\",\"Docker\",\"Kubernetes\",\"Helm\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Jenkins\"],\"testing\":[\"pytest\",\"Terratest\"]}\n\nJob Summary:\nEnterprise company transitioning from Azure to AWS. Seeking a Senior Infrastructure Engineer to design the AWS landing zone using Terraform, define networking with AWS VPC and Transit Gateway, configure IAM policies and SCPs for multi-account governance, and automate provisioning. Kubernetes on EKS is the compute target. Helm for workload deployment.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform and Terratest are present for IaC and IaC testing\",\"AWS is the target cloud and is confirmed\",\"Kubernetes and Helm align with the EKS compute target\",\"Terratest signals infrastructure validation discipline\"],\"gaps\":[\"No AWS-specific networking signals such as VPC, Transit Gateway, or Direct Connect\",\"No IAM, SCP, or multi-account governance signals\",\"No AWS Organizations or Control Tower signals for landing zone design\",\"No Azure experience to provide migration context\",\"EKS specifically is not confirmed \u2014 generic Kubernetes experience may differ\"],\"explanation\":\"The candidate has Terraform and AWS experience relevant to the role, but AWS landing zone design requires deep AWS-specific networking and governance expertise \u2014 VPC, Transit Gateway, IAM, SCPs \u2014 that are entirely absent from the profile. Generic Terraform and Kubernetes experience is a starting point but does not confirm the AWS-native specialization needed to design a secure multi-account landing zone from scratch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"milos_microbe\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Django\",\"React\",\"Celery\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nBiotech startup building a genomics data pipeline platform. Seeking a Senior Backend Engineer to architect Python-based REST APIs handling large biological file formats, integrate with AWS S3 and Batch for compute-heavy workflows, and design a Celery task queue for long-running bioinformatics jobs. PostgreSQL is the metadata store. Experience with scientific Python libraries and containerized HPC workflows is valued.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python and Django are the backend stack and are present\",\"Celery is listed for background job processing relevant to long-running jobs\",\"PostgreSQL matches the metadata store requirement\",\"Docker indicates containerization familiarity\"],\"gaps\":[\"Mid-level seniority \u2014 role requires Senior-level architectural ownership\",\"No AWS S3 or AWS Batch signals for cloud compute integration\",\"No scientific Python libraries such as BioPython, NumPy for bioinformatics, or similar\",\"No HPC or bioinformatics workflow signals\",\"No large biological file format handling signals\"],\"explanation\":\"The candidate has a relevant Django and Celery foundation, and PostgreSQL aligns with the metadata store requirement. However, the Senior-level architectural scope, AWS cloud integration, scientific Python domain knowledge, and bioinformatics workflow experience are all absent. This is a candidate who could contribute to the Python work but is not equipped to lead the architecture of a specialized genomics platform.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tanaka_fullstack_sr\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\",\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"Python\",\"SQL\"],\"tech\":[\"React\",\"Next.js\",\"Django\",\"FastAPI\",\"Docker\",\"Kubernetes\",\"Redis\"],\"architecture\":[\"Microservices\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"CircleCI\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nEdtech platform seeking a Senior Full Stack Engineer to build React and Next.js learning interfaces, maintain FastAPI backend APIs, and manage PostgreSQL schemas. Playwright is used for end-to-end testing. Docker and Kubernetes handle deployments. TypeScript and Python are required across the stack.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React, Next.js, FastAPI, PostgreSQL, Playwright, Docker, and Kubernetes are all present\",\"TypeScript and Python are both confirmed as primary languages\"],\"gaps\":[\"No edtech domain, LMS integration, or learning content delivery signals\",\"No Redis caching signals despite it being common for edtech API response optimization\",\"No video streaming or media delivery signals for a learning platform\",\"No user progress tracking or adaptive learning data model signals\",\"MongoDB in profile may indicate experience in contexts misaligned with this edtech schema\"],\"explanation\":\"The candidate's technical stack aligns well across React, Next.js, FastAPI, and PostgreSQL. However, an edtech platform has specific domain concerns \\u2014 LMS integrations, content delivery, progress tracking, and possibly video streaming \\u2014 that are not evidenced in the profile. The technical fit is solid but the absence of any learning domain signals introduces uncertainty about the candidate's ability to contribute immediately to the product's core educational features.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"bex_scala_data\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Scala\",\"Python\",\"SQL\"],\"tech\":[\"Apache Spark\",\"Kafka\",\"Apache Flink\",\"dbt\",\"Docker\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"Snowflake\",\"Cassandra\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ScalaTest\",\"pytest\"]}\n\nJob Summary:\nGlobal payments company building a real-time transaction monitoring system. Seeking a Senior Data Engineer to implement Apache Flink streaming jobs in Scala, consume Kafka transaction events, write dbt models on Snowflake for offline analysis, and ensure data quality. ScalaTest for pipeline testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Apache Flink is directly present for the streaming job implementation requirement\",\"Scala is the stated language for Flink jobs and is primary\",\"Kafka matches the transaction event consumption requirement\",\"dbt and Snowflake match the offline analysis layer requirements\",\"ScalaTest is the stated testing tool and is confirmed\",\"Event-Driven and Distributed System architecture aligns with transaction monitoring context\"],\"gaps\":[\"No data quality framework signals such as Great Expectations alongside dbt\"],\"explanation\":\"The candidate's profile is a precise match with Apache Flink, Scala, Kafka, dbt, Snowflake, and ScalaTest all present and aligned. Flink in Scala is a specific and high-value combination that directly validates the core pipeline engineering requirement. The only gap is the absence of an explicit data quality framework signal beyond the dbt foundation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priya_cto_lvl\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\",\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"Django\",\"Docker\"],\"architecture\":[\"Monolith\",\"Layered Architecture\"],\"databases\":[\"PostgreSQL\",\"MySQL\"]}\n\nJob Summary:\nMedical device company seeking a Principal Embedded Systems Engineer to define safety-critical firmware architecture for IEC 62443 and IEC 62304 compliant devices. The team uses C and C++ for bare-metal and RTOS development. You will lead threat modeling, define coding standards, and mentor hardware engineers writing firmware. Deep embedded safety standards knowledge required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Principal seniority matches the role level\"],\"gaps\":[\"No C or C++ experience \u2014 the required embedded programming languages\",\"No embedded systems, firmware, or RTOS signals\",\"No IEC 62443, IEC 62304, or any safety standard signals\",\"No threat modeling or hardware security signals\",\"Web-focused JavaScript and Django background is entirely misaligned with embedded systems engineering\",\"No hardware interface or device communication protocol signals\"],\"explanation\":\"Despite Principal-level seniority, the candidate's background is entirely web-focused with JavaScript, React, and Django, which is fundamentally misaligned with safety-critical embedded firmware engineering. Every domain-specific requirement \u2014 C, C++, RTOS, IEC standards \u2014 is absent. Seniority alone does not bridge a domain gap this fundamental.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"claudette_dbt\",\"seniority\":\"Mid\",\"roles\":[\"Analytics Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Looker\",\"Apache Airflow\",\"Pandas\",\"Great Expectations\"],\"databases\":[\"Snowflake\",\"BigQuery\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"dbt test\",\"Great Expectations\"]}\n\nJob Summary:\nB2B SaaS company hiring a Mid-level Analytics Engineer to own dbt model development on Snowflake, build Looker dashboards and LookML explores, enforce data quality with Great Expectations, and orchestrate transformations using Airflow. SQL optimization and documentation best practices are expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt and Snowflake are the primary tools and both present\",\"Looker is listed for the dashboard platform\",\"Great Expectations and Airflow match data quality and orchestration\",\"Mid-level Analytics Engineer role is an exact match\"],\"gaps\":[\"No LookML Explore, dimension, or measure development signals beyond Looker listing\",\"No Looker PDT or derived table optimization signals\",\"No stakeholder dashboard delivery or self-service analytics enablement signals\",\"SQL optimization depth is unconfirmed for high-volume Snowflake datasets\"],\"explanation\":\"The candidate covers the core tooling with dbt, Snowflake, Great Expectations, and Airflow all present. However, LookML development is a specialized skill distinct from dashboard consumption and is a primary responsibility in this role. Listing Looker as a tool does not confirm LookML authoring experience, and that depth \\u2014 Explores, derived tables, and PDTs \\u2014 is a meaningful gap that requires direct validation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"gus_rust_embedded\",\"seniority\":\"Senior\",\"roles\":[\"Embedded Engineer\",\"Firmware Engineer\"],\"languages\":[\"Rust\",\"C\",\"C++\"],\"tech\":[\"FreeRTOS\",\"Docker\",\"CMake\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nIoT startup building Rust-based firmware for ARM Cortex-M embedded devices. Seeking a Senior Embedded Engineer to write no-std Rust, implement hardware abstraction layers, and integrate with FreeRTOS for task scheduling. ARM toolchain and JTAG debugging experience required. Experience with probe-rs or OpenOCD is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Rust is the primary language and is directly present\",\"C and C++ provide systems-level embedded programming depth\",\"FreeRTOS is the stated RTOS and is directly listed\",\"Senior seniority and Embedded and Firmware roles match exactly\"],\"gaps\":[\"No no-std Rust or embedded Rust ecosystem signals such as embassy or rtic\",\"No ARM toolchain or ARM Cortex-M specific signals\",\"No JTAG debugging signals\",\"No probe-rs or OpenOCD signals for the plus requirement\",\"No hardware abstraction layer or register-level hardware interaction signals\"],\"explanation\":\"The candidate has Rust and FreeRTOS experience which are directly relevant, but the role requires embedded Rust specifically \u2014 no-std, hardware abstraction layers, and ARM toolchain integration \u2014 none of which are visible in the profile. FreeRTOS knowledge is a strong signal but embedded Rust development is a distinct specialization from general Rust or even C-based embedded work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"seun_react_sr\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Zustand\",\"TanStack Query\",\"Tailwind CSS\",\"shadcn/ui\",\"Radix UI\"],\"architecture\":[\"Micro-Frontend\",\"Serverless\"],\"databases\":[\"Supabase\"],\"ci_cd\":[\"GitHub Actions\",\"Vercel\"],\"testing\":[\"Vitest\",\"Playwright\",\"React Testing Library\"]}\n\nJob Summary:\nConsumer fintech company seeking a Senior Frontend Engineer to build and own the investment dashboard in React and Next.js. Zustand for state management, TanStack Query for server state, and shadcn/ui with Radix UI for accessible components. TypeScript required. Playwright and Vitest for testing. Vercel deployment. The team values accessibility and Core Web Vitals performance.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React, Next.js, Zustand, and TanStack Query match the full state management stack\",\"shadcn/ui and Radix UI are both present for the accessible components requirement\",\"Playwright and Vitest match the testing stack\",\"Vercel confirms the deployment platform\",\"TypeScript is primary as required\",\"Micro-Frontend architecture signals familiarity with modular frontend design\"],\"gaps\":[\"No Core Web Vitals optimization or Lighthouse auditing signals\",\"No financial data visualization signals for an investment dashboard context\"],\"explanation\":\"The candidate's profile is a comprehensive match with React, Next.js, Zustand, TanStack Query, shadcn/ui, Radix UI, Playwright, Vitest, and Vercel all present and aligned. The accessible components requirement is directly addressed by the Radix UI and shadcn/ui combination. The gaps around Core Web Vitals performance tooling and financial data visualization are minor considerations for an otherwise strong fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mo_k8s_intern\",\"seniority\":\"Intern\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"Go\"],\"tech\":[\"Docker\",\"Kubernetes\",\"Prometheus\"]}\n\nJob Summary:\nCloud infrastructure company seeking an intern to assist with writing Kubernetes YAML manifests, monitor cluster health with Prometheus, automate routine ops tasks in Python and Go, and document runbooks. Basic Kubernetes and Docker skills required. Mentorship provided.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Kubernetes and Docker are listed and relevant\"],\"gaps\":[\"Profile is extremely sparse \\u2014 only three technologies with no depth or project context\",\"No Kubernetes YAML manifest writing signals beyond tool listing\",\"No Python or Go scripting project signals despite both being stated as required\",\"No monitoring or observability workflow signals for Prometheus usage\",\"No runbook documentation or operational workflow signals\"],\"explanation\":\"The candidate lists Kubernetes, Docker, and Prometheus but the profile is so minimal that no confidence can be placed on practical competency in any of these tools. Writing Kubernetes manifests and automating ops tasks in Go are non-trivial for an intern, and the absence of any project or scripting evidence makes it impossible to assess readiness without a portfolio or coding exercise.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nadia_rag_eng\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"Backend Engineer\"],\"languages\":[\"Python\",\"TypeScript\"],\"tech\":[\"LangChain\",\"LangGraph\",\"OpenAI API\",\"Weaviate\",\"FastAPI\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"RAG\",\"Microservices\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"Weaviate\",\"ChromaDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nEnterprise AI company building a multi-agent document processing system. Seeking a Senior AI Engineer to design LangGraph-based multi-agent workflows, integrate retrieval pipelines with Weaviate, serve agent APIs with FastAPI, and containerize services for Kubernetes. Python is required. Experience with LangChain and OpenAI API is valued.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LangGraph is the stated workflow framework and is directly present\",\"Weaviate is the stated vector store and is listed\",\"LangChain and OpenAI API confirm the full LLM orchestration stack\",\"FastAPI is the serving framework and is present\",\"Kubernetes and Docker match the containerization requirements\",\"RAG architecture signal confirms retrieval pipeline experience\"],\"gaps\":[\"No multi-agent coordination pattern or agent evaluation signals beyond LangGraph listing\"],\"explanation\":\"The candidate's profile is a precise match with LangGraph, Weaviate, LangChain, OpenAI API, FastAPI, and Kubernetes all present and aligned. LangGraph is a specific and relatively new framework whose presence directly validates multi-agent workflow design experience. The only gap is the absence of agent evaluation or testing methodology signals, which is a specialized concern for production multi-agent systems.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lena_react_mid\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Redux\",\"Sass\",\"Webpack\",\"Bootstrap\"],\"ci_cd\":[\"CircleCI\"],\"testing\":[\"Jest\",\"Enzyme\"]}\n\nJob Summary:\nInsurtech company undergoing a frontend modernization. Seeking a Mid-level Frontend Engineer to migrate from a class component React codebase to functional components with hooks, adopt Tailwind CSS over Sass, migrate from Webpack to Vite, and replace Enzyme with React Testing Library. TypeScript required throughout.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and TypeScript are present and relevant to the existing codebase\",\"Redux experience provides state management context\",\"Mid-level seniority is appropriate\",\"Webpack experience is useful for understanding the migration source\"],\"gaps\":[\"No Vite experience \u2014 the target build tool\",\"No Tailwind CSS \u2014 the target styling approach replacing Sass\",\"No React Testing Library \u2014 Enzyme is being replaced\",\"No functional components or hooks-specific signals to confirm migration readiness\",\"CircleCI is the current CI \u2014 no GitHub Actions or modern CI target signals\"],\"explanation\":\"The candidate knows the legacy stack being migrated away from, which provides useful context but positions them on the wrong side of every migration decision. Tailwind CSS, Vite, React Testing Library, and functional components are all absent, meaning the candidate would need to learn every target technology while working on the migration. They can contribute context but need significant upskilling on the destination stack.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hiro_spring_staff\",\"seniority\":\"Staff\",\"roles\":[\"Backend Engineer\",\"Software Architect\"],\"languages\":[\"Java\",\"Kotlin\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Kafka\",\"gRPC\",\"Kubernetes\",\"Docker\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Domain-Driven Design\",\"CQRS\",\"Hexagonal Architecture\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"MongoDB\",\"Elasticsearch\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\",\"Jenkins\"],\"testing\":[\"JUnit\",\"Testcontainers\",\"Mockito\",\"k6\"]}\n\nJob Summary:\nGlobal travel marketplace hiring a Staff Engineer to lead the backend architecture for a fare search and booking platform handling 200 million monthly requests. Java and Kotlin on Spring Boot are the core stack. Kafka and gRPC for service communication. Cassandra for fare storage. Elasticsearch for search. Hexagonal Architecture and DDD are enforced. Testcontainers for integration testing.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Java, Kotlin, Spring Boot, Kafka, gRPC, Cassandra, Elasticsearch, Hexagonal Architecture, DDD, and Testcontainers all present at Staff level\",\"k6 demonstrates load testing rigor for high-volume platforms\"],\"gaps\":[\"No travel industry protocol signals such as NDC, GDS integration, or fare caching patterns\",\"No high-frequency read optimization signals for a fare search requiring sub-second latency\",\"No payment or booking transaction signals for the booking platform scope\",\"No architectural decision record or standards documentation process signals\"],\"explanation\":\"The candidate's technical depth is exceptional across the core stack, but travel fare search is a latency-sensitive domain with specific caching, read-path optimization, and GDS integration requirements that are absent from the profile. A Staff role building a system handling 200 million monthly fare searches requires these domain-specific patterns alongside the architectural depth evidenced. The gap is domain specificity rather than technical capability.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cynthia_bi_jr\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Tableau\",\"Pandas\",\"Excel\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nLogistics company hiring a Senior Data Analytics Engineer to design the enterprise dimensional data model on Redshift, build complex dbt transformations, develop LookML models in Looker, and set analytics engineering standards across five business units. Deep SQL and dbt expertise required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"SQL is a primary skill relevant to the data modeling work\"],\"gaps\":[\"Junior seniority \u2014 role requires Senior-level standards ownership\",\"No dbt experience\",\"No Redshift or cloud data warehouse experience\",\"No Looker or LookML experience\",\"No dimensional modeling or data warehousing design signals\",\"No enterprise analytics standards or multi-team governance experience\",\"Tableau and MySQL background is significantly misaligned with the modern analytics stack\"],\"explanation\":\"The candidate is a junior analyst whose profile does not approach any dimension of a Senior Analytics Engineering role. Every required technology \u2014 dbt, Redshift, Looker, and dimensional modeling \u2014 is absent. The seniority gap alone is disqualifying, and the technical mismatch across every core requirement makes this a fundamentally incompatible application.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"oyin_python_be\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"Celery\",\"Docker\",\"Redis\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nB2B API startup hiring a Mid-level Backend Engineer to build REST APIs in FastAPI, process asynchronous background jobs with Celery and Redis, manage PostgreSQL schemas, and write pytest test suites. Docker for containerization. GitHub Actions for CI. Python is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"FastAPI, Celery, Redis, and PostgreSQL match the core technical requirements\"],\"gaps\":[\"No OpenAPI documentation or API versioning signals for a B2B API product where these are standard\",\"No multi-tenant authentication or API key management signals\",\"No rate limiting or quota enforcement signals for a B2B API context\",\"No client-facing API design or consumer developer experience signals\",\"Microservices architecture listed but no inter-service communication or service boundary signals\"],\"explanation\":\"The candidate's internal service tooling is well-aligned, but a B2B API startup has specific cross-cutting requirements \\u2014 OpenAPI documentation, API versioning, multi-tenant auth, and rate limiting \\u2014 that are the core product concerns and are entirely absent from the profile. Listing FastAPI and Celery confirms the execution layer but does not validate the B2B API platform specialization required to own a customer-facing API product.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yuki_infosec\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Terraform\",\"AWS\",\"Kubernetes\",\"Vault\",\"Falco\",\"OPA\"],\"architecture\":[\"Cloud-Native\",\"Zero-Trust\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"]}\n\nJob Summary:\nCloud-native startup seeking a Senior Cloud Security Engineer to implement zero-trust networking, enforce policy-as-code with OPA, monitor runtime security with Falco, manage secrets with Vault, and harden AWS infrastructure with Terraform. Experience with Kubernetes security contexts and RBAC is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"OPA and Falco are listed for policy enforcement and runtime monitoring\",\"Vault is present for secrets management\"],\"gaps\":[\"No Kubernetes RBAC or Pod Security Standard configuration signals\",\"No network policy or zero-trust networking implementation signals beyond architecture label\",\"No security audit trail or compliance reporting signals for cloud security posture\",\"No penetration testing or vulnerability assessment experience signals\",\"No AWS security services such as GuardDuty, Security Hub, or SCPs signals\"],\"explanation\":\"While OPA, Falco, and Vault are relevant listings, the role requires deep Kubernetes security contexts and RBAC implementation alongside AWS-specific security hardening that are entirely absent from the profile. Zero-trust as an architecture label does not confirm implementation experience, and the absence of AWS security service signals means the infrastructure hardening requirement is unvalidated. The profile depth is insufficient for a Senior Cloud Security role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rosa_dataviz\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"D3.js\",\"Vite\",\"Tailwind CSS\",\"Recharts\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"React Testing Library\"]}\n\nJob Summary:\nAnalytics platform startup hiring a Mid-level Frontend Engineer to build interactive data visualization components using D3.js and Recharts inside a React application. TypeScript required. Tailwind CSS for styling. The team integrates with REST and GraphQL APIs. Vitest and React Testing Library are the testing standards.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"D3.js and Recharts are present for the visualization library requirements\",\"React and TypeScript are confirmed\"],\"gaps\":[\"No GraphQL client signals \\u2014 REST and GraphQL APIs are both used and GraphQL is absent\",\"No real-time data update or WebSocket signals for live dashboard updates\",\"No large dataset rendering optimization signals for analytics platform scale\",\"No accessible charting or WCAG compliance signals for a data-heavy UI\",\"Vitest testing does not confirm visualization component testing patterns\"],\"explanation\":\"The candidate has D3.js and Recharts experience, but the role requires GraphQL integration alongside REST, and the profile shows no GraphQL signals. For an analytics platform where data freshness may require real-time updates, the absence of WebSocket or streaming signals is also meaningful. The combination of these gaps \\u2014 GraphQL, real-time, and accessible charting depth \\u2014 makes this a weak fit for a visualization-specialized product role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kwesi_nosql_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"JavaScript\",\"SQL\"],\"tech\":[\"Flask\",\"MongoDB\",\"Redis\",\"Docker\"],\"databases\":[\"MongoDB\",\"Redis\",\"PostgreSQL\"]}\n\nJob Summary:\nEnterprise data company seeking a Senior Backend Engineer to design high-throughput REST APIs using FastAPI, manage a CockroachDB distributed database cluster, implement caching with Redis, and write integration tests with pytest and Testcontainers. Python and TypeScript are required. Experience with distributed SQL databases is essential.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is present and meets part of the language requirement\",\"Redis experience is relevant to the caching layer\"],\"gaps\":[\"Mid-level seniority \u2014 role requires Senior-level system design ownership\",\"No FastAPI experience \u2014 Flask is the legacy framework\",\"No CockroachDB or distributed SQL database experience\",\"No TypeScript experience\",\"No pytest or Testcontainers signals for the integration testing requirement\",\"MongoDB background is NoSQL and does not transfer to distributed SQL patterns\"],\"explanation\":\"The candidate's Python and Redis background provides marginal overlap, but the role requires Senior-level design ownership with FastAPI, CockroachDB, TypeScript, and Testcontainers \u2014 none of which appear in the profile. The NoSQL MongoDB experience is misaligned with distributed SQL, which requires different consistency and transaction modeling knowledge. The seniority gap compounds the technical mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sol_android_lead\",\"seniority\":\"Lead\",\"roles\":[\"Android Engineer\",\"Mobile Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Hilt\",\"Room\",\"Retrofit\",\"Coroutines\",\"Firebase\"],\"architecture\":[\"Clean Architecture\",\"Modular Architecture\",\"MVVM\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\",\"Bitrise\"],\"testing\":[\"JUnit\",\"Mockito\",\"Espresso\",\"Robolectric\"]}\n\nJob Summary:\nEnterprise fleet management company hiring a Lead Android Engineer to define the Android architecture for a new driver-facing app, enforce Clean Architecture and modular patterns, lead a team of three Android engineers, and own the Bitrise and Fastlane CI/CD pipeline. Kotlin and Jetpack Compose required. Room for offline persistence. Coroutines for async work.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kotlin, Jetpack Compose, Room, and Coroutines are all named requirements and all present\",\"Clean Architecture and Modular Architecture are the stated patterns and are confirmed\",\"Bitrise and Fastlane are both present for the CI/CD ownership requirement\",\"Lead seniority supports team leadership and architecture definition scope\",\"Hilt confirms dependency injection depth alongside Clean Architecture\",\"Robolectric and Espresso add test coverage breadth beyond JUnit and Mockito\"],\"gaps\":[\"No fleet management or logistics domain signals\"],\"explanation\":\"The candidate's profile is an exceptional match with Kotlin, Jetpack Compose, Room, Coroutines, Clean Architecture, Modular Architecture, Bitrise, and Fastlane all present and aligned at the Lead level. The architecture pattern coverage is particularly strong \u2014 Clean Architecture with modular structure and Hilt dependency injection is exactly the stack the role enforces. The only gap is the absence of fleet management domain signals, which is a soft requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elspeth_swe_jnr\",\"seniority\":\"Junior\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"PostgreSQL\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nHealthtech startup hiring a Junior Backend Engineer to build REST APIs in FastAPI, write SQL queries against PostgreSQL, and assist with pytest test coverage. Python is required. Docker experience is a plus. Mentorship provided by senior engineers.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python is the required language and is primary\",\"PostgreSQL is the stated database and is confirmed\",\"SQL proficiency is relevant to the query writing requirement\",\"Junior seniority with mentorship offered is appropriate\"],\"gaps\":[\"No FastAPI experience \u2014 Django is the known framework, not FastAPI\",\"No pytest signals for the test coverage requirement\",\"No Docker signals for the stated plus requirement\",\"Profile is very sparse with only two technologies listed\"],\"explanation\":\"The candidate has the right language and database background with Python and PostgreSQL present, but the role requires FastAPI specifically and names pytest and Docker as technical expectations. Django familiarity does not transfer directly to FastAPI patterns. The sparse profile makes it difficult to assess practical readiness, and the absence of testing signals is notable for a role that explicitly mentions test coverage improvement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tomas_nestjs_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\",\"SQL\"],\"tech\":[\"NestJS\",\"Prisma\",\"React\",\"Docker\",\"Redis\",\"GraphQL\"],\"architecture\":[\"Microservices\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nAgritech startup hiring a Mid-level Backend Engineer to extend a NestJS and PostgreSQL API platform with GraphQL resolvers, implement Redis caching strategies, and write integration tests with Supertest. Prisma is the ORM. TypeScript is required across the stack. Docker for containerization.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS is the primary API framework and is directly present\",\"GraphQL matches the resolver development requirement\",\"Prisma and PostgreSQL match the ORM and database requirements\",\"Redis is listed for caching strategy implementation\",\"Supertest is the stated integration testing tool and is confirmed\",\"TypeScript is the required language and is primary\",\"Docker matches the containerization requirement\"],\"gaps\":[\"No agritech domain or IoT sensor data signals\"],\"explanation\":\"The candidate's profile covers every named technical requirement: NestJS, GraphQL, Prisma, PostgreSQL, Redis, Supertest, TypeScript, and Docker all present and precisely matched. This is a clean and comprehensive technical alignment. The only gap is the absence of agritech domain signals, which is a soft requirement not typically visible in profile data.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fran_java_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"SQL\"],\"tech\":[\"Spring Boot\",\"JPA\",\"Docker\",\"Redis\"],\"architecture\":[\"Layered Architecture\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nLegaltech company building a contract management platform. Seeking a Senior Java Backend Engineer to design a document processing pipeline using Spring Boot and Apache PDFBox, implement Kafka-based event streaming for contract lifecycle events, and manage PostgreSQL schemas. Clean Architecture is enforced. Kubernetes for deployment. Testcontainers for integration testing.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Java and Spring Boot match the core backend stack\",\"JUnit and Mockito provide Java testing discipline\",\"Docker indicates containerization familiarity for the Kubernetes migration context\"],\"gaps\":[\"Mid-level seniority \u2014 role requires Senior-level architecture ownership\",\"No Kafka or event streaming signals\",\"No PostgreSQL experience \u2014 MySQL does not directly substitute\",\"No Testcontainers signals for integration testing\",\"No Clean Architecture or architectural pattern signals beyond Layered Architecture\",\"No Apache PDFBox or document processing signals\"],\"explanation\":\"The candidate has a relevant Java and Spring Boot foundation, but every specialized requirement of this role \u2014 Kafka, PostgreSQL, Testcontainers, Clean Architecture, and document processing \u2014 is absent from the profile. The seniority gap compounds the technical gaps, making this a candidate who would need substantial upskilling before contributing meaningfully to the described architecture.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alix_cloudnative_sr\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\",\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"Azure\",\"Docker\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"CosmosDB\"],\"ci_cd\":[\"Azure Pipelines\",\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"pytest\",\"Terratest\"]}\n\nJob Summary:\nEnterprise company on Azure seeking a Senior DevOps Engineer to manage AKS clusters, write Terraform modules for Azure resources, build observability pipelines with Prometheus and Grafana, and maintain Azure Pipelines. CosmosDB and PostgreSQL are the databases. ArgoCD for GitOps delivery. Go for automation tooling.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Azure and Azure Pipelines are present\",\"Prometheus and Grafana match the observability stack\"],\"gaps\":[\"No AKS-specific cluster lifecycle or upgrade management signals\",\"CosmosDB is listed but no partitioning strategy, consistency model, or query optimization signals\",\"No Azure networking signals such as VNet, Private Endpoints, or NSG configuration\",\"No Azure-native security signals such as Azure AD, Managed Identity, or Key Vault\",\"No cost management or Azure Policy signals for enterprise governance context\"],\"explanation\":\"While the candidate lists Azure and CosmosDB, a Senior DevOps role on Azure requires deep Azure-native specialization \\u2014 AKS cluster management, Azure networking, and Azure governance \\u2014 that is not evidenced in the profile beyond surface-level tool listings. CosmosDB listing without partitioning or consistency model signals is particularly concerning for a database listed as a named requirement. The profile does not validate the Azure depth needed for an enterprise cloud role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ben_graphql_jr\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Express.js\",\"Apollo GraphQL\",\"Prisma\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nB2B SaaS company seeking a Junior Backend Engineer to extend a GraphQL API built with Apollo Server and Prisma on PostgreSQL. TypeScript is required. Docker for development. Jest for unit testing. GitHub Actions for CI. The team is remote-first and values async documentation.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Apollo GraphQL and Prisma are both present and match the API stack directly\",\"PostgreSQL is the stated database and is confirmed\",\"TypeScript is the required language and is present\",\"Docker is present for development environment work\",\"Junior seniority is appropriate for the role\"],\"gaps\":[\"No Jest signals for the stated unit testing requirement\",\"No GitHub Actions for the CI requirement\",\"No async documentation or remote-first workflow signals\",\"Profile is sparse \u2014 depth of GraphQL resolver development is unconfirmed\"],\"explanation\":\"The candidate has the right core stack with Apollo GraphQL, Prisma, PostgreSQL, and TypeScript all present. However, the absence of Jest and GitHub Actions for the explicitly stated testing and CI requirements is notable, and the sparse profile makes it difficult to confirm GraphQL resolver development depth. A portfolio review or technical screen would be necessary before advancing.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mia_data_gov\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\",\"Analytics Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Apache Airflow\",\"Great Expectations\",\"Atlan\",\"Monte Carlo\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nFinancial services firm building a data governance and observability layer. Seeking a Senior Data Engineer to define data quality standards using Monte Carlo and Great Expectations, manage dbt models on Snowflake, orchestrate with Airflow, and catalog assets with Atlan. Python and SQL are required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Monte Carlo, Great Expectations, Atlan, dbt, Snowflake, and Airflow are all present and aligned\",\"Senior seniority and data engineering background fit the governance design scope\"],\"gaps\":[\"No data lineage, column-level lineage, or impact analysis workflow signals\",\"No data governance policy authoring or classification signals beyond tooling presence\",\"No data contract or data product ownership signals for a financial services governance context\",\"No cross-team data stewardship or data quality escalation process signals\"],\"explanation\":\"The candidate's tooling alignment is strong with Monte Carlo, Atlan, Great Expectations, dbt, and Snowflake all present. However, a financial services data governance program requires policy authoring, data classification, lineage enforcement, and cross-team stewardship that go beyond deploying governance tooling. The profile validates tool familiarity but does not confirm the organizational governance design experience central to this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"joel_react_intern\",\"seniority\":\"Intern\",\"roles\":[\"Software Engineer\"],\"languages\":[\"JavaScript\",\"HTML\",\"CSS\"],\"tech\":[\"React\",\"Vite\"]}\n\nJob Summary:\nAgency hiring an intern to assist in building React UI components from Figma designs, writing basic unit tests, and participating in code review. HTML, CSS, and React knowledge is required. Git workflow participation expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React is the stated framework and is directly present\",\"HTML and CSS are named requirements and are confirmed\",\"JavaScript is the required base language\",\"Intern seniority and the role level match\"],\"gaps\":[\"No Git or version control signals visible\",\"No testing signals despite basic unit tests being listed as a task\",\"Profile is extremely sparse with no project context or tooling depth\"],\"explanation\":\"The candidate has the core front-end technologies aligned with React, HTML, CSS, and JavaScript all present at the intern level. However, the complete absence of Git signals is a gap even for an intern role, and no testing signals are present despite unit testing being listed as a day-one task. A portfolio review is needed to assess practical readiness.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"olumide_mlops_sr\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"PyTorch\",\"MLflow\",\"BentoML\",\"Seldon\",\"Kubernetes\",\"Docker\",\"Prefect\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"S3\",\"BigQuery\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"]}\n\nJob Summary:\nHealthtech AI company building an ML serving platform. Hiring a Senior MLOps Engineer to deploy and monitor models using BentoML and Seldon Core, orchestrate retraining pipelines with Prefect, track experiments with MLflow, and manage Kubernetes-based inference infrastructure. Python required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"BentoML and Seldon are both present, matching the model serving platform tools directly\",\"MLflow is the stated experiment tracking tool and is confirmed\",\"Prefect is the pipeline orchestration tool and is present\",\"Kubernetes matches the inference infrastructure management requirement\",\"ArgoCD confirms GitOps-based deployment practice\",\"Cloud-Native architecture aligns with the Kubernetes-based platform context\"],\"gaps\":[\"No model monitoring or data drift detection tooling signals such as Evidently or WhyLogs\"],\"explanation\":\"The candidate's profile is a precise match with BentoML, Seldon, MLflow, Prefect, and Kubernetes all present and aligned. BentoML and Seldon together are specific and rare model serving tools that directly validate the platform engineering requirement. The only gap is the absence of model monitoring tooling signals, which is expected for a serving platform focused on production reliability.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fiona_scraper\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Scrapy\",\"Playwright\",\"Redis\",\"Docker\",\"FastAPI\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"]}\n\nJob Summary:\nMarket intelligence company building a real-time data collection platform. Seeking a Senior Backend Engineer to design distributed web scraping infrastructure using Scrapy and Playwright, implement proxy rotation and anti-detection systems, build REST APIs in FastAPI, and store structured data in PostgreSQL. Redis for job queue management.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Scrapy and Playwright are both present, directly matching the web scraping infrastructure tools\",\"FastAPI matches the REST API framework requirement\",\"Redis is listed for job queue management as stated\",\"PostgreSQL matches the structured data storage requirement\",\"Docker confirms containerization experience\"],\"gaps\":[\"Mid-level seniority \u2014 role requires Senior-level distributed system design\",\"No proxy rotation, IP rotation, or anti-detection system signals\",\"No distributed scraping architecture or rate limiting signals\",\"No task queue or worker orchestration signals beyond Redis listing\"],\"explanation\":\"The candidate has the right foundational tooling with Scrapy, Playwright, FastAPI, Redis, and PostgreSQL all present. However, the role requires Senior-level design of distributed scraping infrastructure including anti-detection systems and proxy rotation \u2014 specialized concerns not evidenced in the profile. The seniority gap compounds the absence of distributed architecture signals.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"victor_deno\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\",\"SQL\"],\"tech\":[\"Deno\",\"Fresh\",\"React\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"SQLite\"]}\n\nJob Summary:\nEnterprise company seeking a Senior Backend Engineer to architect high-availability REST APIs using Node.js and Express, manage a PostgreSQL cluster with read replicas, implement caching with Redis, and lead a team of three engineers. TypeScript required. Microservices architecture with Kubernetes deployment.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript is the required language and is present\",\"PostgreSQL is the primary database and is confirmed\"],\"gaps\":[\"Mid-level seniority \u2014 role requires Senior-level team leadership\",\"No Node.js or Express signals \u2014 Deno and Fresh are different runtimes\",\"No Redis signals for the caching requirement\",\"No Kubernetes signals for the deployment target\",\"No microservices architecture signals\",\"No team leadership or mentoring signals\"],\"explanation\":\"Despite TypeScript and PostgreSQL alignment, Deno is a different runtime from Node.js and Fresh is not Express \u2014 the architectural patterns and ecosystem differ meaningfully. The candidate also lacks the Senior-level team leadership, Redis, Kubernetes, and microservices experience required. The seniority gap and runtime mismatch make this a weak fit despite surface-level language overlap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"camila_golang_be\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\",\"SQL\"],\"tech\":[\"Echo\",\"gRPC\",\"Kafka\",\"Docker\",\"Kubernetes\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"CockroachDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"Go built-in tests\",\"Testify\",\"k6\"]}\n\nJob Summary:\nLogistics automation startup building a fleet routing API platform. Seeking a Senior Backend Engineer to build Go services using the Echo framework, implement Kafka-based event flows for route updates, integrate gRPC inter-service calls, and manage CockroachDB for distributed routing data. k6 for load testing. Kubernetes and ArgoCD for deployment.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Go, Echo, gRPC, and Kafka are present and match the stated stack\"],\"gaps\":[\"No geospatial, routing algorithm, or logistics domain signals for a fleet routing platform\",\"CockroachDB is listed but no distributed transaction, serializable isolation, or schema migration signals to confirm depth\",\"No real-time route optimization or event-driven routing update signals\",\"No fleet management protocol or GPS/telematics data ingestion signals\",\"k6 confirms load testing but no API contract testing signals for a complex routing API\"],\"explanation\":\"While the candidate's Go and Kafka stack aligns at the framework level, a fleet routing API platform is a domain-specific product where geospatial algorithms, distributed transaction management, and real-time route optimization are the core engineering challenges. None of these domain requirements are evidenced, and CockroachDB listing alone does not confirm distributed transaction depth. The profile validates general Go microservices experience but not the specialized routing platform engineering required.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ravi_dotnet_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C#\",\"SQL\"],\"tech\":[\".NET Core\",\"ASP.NET\",\"Entity Framework\",\"Docker\"],\"databases\":[\"MS SQL Server\",\"Redis\"],\"ci_cd\":[\"Azure DevOps\"],\"testing\":[\"xUnit\",\"Moq\"]}\n\nJob Summary:\nHealthcare SaaS company on Azure seeking a Mid-level .NET Backend Engineer to build HL7 FHIR-compliant APIs in ASP.NET Core, manage Azure SQL and CosmosDB, integrate Azure Service Bus for event messaging, and write xUnit tests. Entity Framework Core for ORM. HIPAA compliance awareness required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"ASP.NET, .NET Core, and Entity Framework match the core framework requirements\",\"xUnit is the stated testing framework and is confirmed\",\"Azure DevOps confirms Azure ecosystem familiarity\",\"C# is the primary language and matches\"],\"gaps\":[\"No HL7 FHIR or healthcare messaging standard signals\",\"No CosmosDB experience \u2014 only MS SQL Server is in profile\",\"No Azure Service Bus or event messaging signals\",\"No HIPAA compliance or healthcare data sensitivity signals\",\"Azure SQL versus MS SQL Server is a meaningful platform difference\"],\"explanation\":\"The candidate has a solid ASP.NET and Entity Framework foundation aligned with the role, but the healthcare domain requirements \u2014 FHIR APIs, HIPAA compliance, and CosmosDB \u2014 are entirely absent. Azure Service Bus for event messaging is also not evidenced. The .NET technical alignment is real but incomplete for a healthcare-regulated context where domain compliance knowledge is a hard requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"simone_data_jnr\",\"seniority\":\"Junior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"dbt\",\"Apache Airflow\",\"Pandas\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"]}\n\nJob Summary:\nDirect-to-consumer brand hiring a Junior Data Engineer to write dbt transformations on BigQuery, schedule Airflow DAGs, and clean data with Python and Pandas. SQL and Python are the core skills. No streaming or real-time requirements. Mentorship provided.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt and BigQuery are the primary tools and are both directly present\",\"Airflow is the stated scheduler and is present\",\"Python and Pandas match the data cleaning requirements\",\"SQL is confirmed as a primary skill\",\"Junior seniority with mentorship offered is an exact match\",\"Docker indicates basic environment awareness\"],\"gaps\":[\"No data quality testing signals such as dbt test despite transformation work being central\"],\"explanation\":\"The candidate covers every stated technical requirement with dbt, BigQuery, Airflow, Python, and Pandas all present at the right seniority level. The role explicitly requires no streaming experience, which removes the most common gap for junior data engineers. The only minor gap is the absence of dbt test signals for data quality validation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alexmorgan92\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\"],\"tech\":[\"Django\",\"FastAPI\",\"Docker\",\"Kubernetes\",\"Redis\",\"AWS\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nWe are a Series B fintech startup building real-time payment infrastructure. We need a senior backend engineer with deep Python or Go experience, strong knowledge of microservices and event-driven systems, and hands-on experience deploying on AWS with Kubernetes. The ideal candidate has worked with PostgreSQL at scale and understands CI/CD pipelines. Experience with Redis for caching and distributed locking is a plus. We move fast and expect engineers to own features end to end.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Python and Go match the primary language requirements directly\",\"Microservices and Event-Driven architecture align with the payment infrastructure design\",\"Kubernetes and AWS experience covers the deployment stack\",\"PostgreSQL and Redis usage matches the data and caching requirements\",\"pytest and Locust show backend testing and load testing discipline\"],\"gaps\":[\"No visible Apache Kafka or message queue experience for real-time payment event streaming\"],\"explanation\":\"This candidate's profile aligns closely with the job's technical requirements across languages, infrastructure, and architecture. The combination of FastAPI, Kubernetes, and event-driven design makes them a strong fit for fintech backend work. The only marginal gap is the absence of explicit streaming or message broker experience, which may be expected in real-time payment pipelines.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jlee_codes\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"Firebase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"React Testing Library\"]}\n\nJob Summary:\nFast-growing e-commerce startup looking for a mid to senior frontend engineer with strong React and Next.js skills. The candidate must have experience with TypeScript, Tailwind CSS, and state management libraries like Redux or Zustand. Familiarity with performance optimization, accessibility standards, and a component-driven workflow using Storybook is expected. We work with a design system and need someone who can collaborate closely with designers and ship polished UI fast.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React, Next.js, TypeScript, and Tailwind CSS all directly match the job's core frontend stack\"],\"gaps\":[\"Junior seniority does not meet the mid-to-senior level requirement\",\"No state management library such as Redux or Zustand visible in profile\",\"No Storybook experience for the component-driven workflow requirement\",\"No evidence of accessibility or performance optimization work\"],\"explanation\":\"While the candidate has the right foundational stack, their junior seniority and missing state management and Storybook experience represent significant gaps for this role. The job expects a more seasoned engineer capable of owning design system integration and performance-critical UI. This profile is underpowered for what is being asked.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"data_dan_w\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Spark\",\"Apache Airflow\",\"dbt\",\"Pandas\"],\"architecture\":[\"Distributed System\"],\"databases\":[\"BigQuery\",\"PostgreSQL\",\"Snowflake\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nData-driven media company building a modern lakehouse architecture needs a mid-level data engineer comfortable with dbt, BigQuery, and Airflow. You will design and maintain ELT pipelines, write data quality tests, and collaborate with analysts and ML teams. Proficiency in Python and SQL is essential. Experience with Snowflake or BigQuery is required, and knowledge of data modeling best practices will set you apart. We value clean, well-tested pipelines and good documentation habits.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt, BigQuery, and Airflow are a direct match to the core stack\",\"Snowflake experience adds additional data warehouse depth\",\"Great Expectations demonstrates data quality testing culture\",\"Python and SQL proficiency confirmed\",\"Distributed systems awareness fits the lakehouse architecture context\"],\"gaps\":[\"No explicit data modeling or lakehouse-specific tooling such as Delta Lake or Iceberg visible\"],\"explanation\":\"This candidate covers the essential stack almost entirely, with dbt, BigQuery, Airflow, Snowflake, and data quality tooling all present. Their mid-level seniority matches the role grade and their testing habits align with the team's values. The only marginal gap is the absence of lakehouse-native formats, which may not be critical depending on the stack maturity.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"carlos_ml\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"TensorFlow\",\"scikit-learn\",\"MLflow\",\"Pandas\",\"NumPy\",\"Docker\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAI startup building LLM-powered products is looking for a senior ML engineer with hands-on experience fine-tuning large language models, working with Hugging Face Transformers, and deploying models via APIs. Familiarity with RAG pipelines, vector databases, and LangChain is strongly preferred. Experience with PyTorch is required. The role involves productionizing models, building evaluation pipelines, and collaborating with product teams on AI features.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Strong classical ML background with TensorFlow, scikit-learn, and MLflow\",\"Docker experience supports model deployment workflows\"],\"gaps\":[\"No PyTorch experience, which is explicitly required\",\"No Hugging Face Transformers or LLM fine-tuning experience visible\",\"No RAG pipeline or vector database knowledge demonstrated\",\"No LangChain or LLM orchestration tooling in profile\"],\"explanation\":\"The candidate has a solid traditional ML engineering background but lacks the LLM-specific stack this role demands. PyTorch is a hard requirement and is absent, and there is no evidence of experience with Hugging Face, RAG, or vector databases. This profile is better suited for classical ML or MLOps roles than LLM product engineering.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nina_ios\",\"seniority\":\"Senior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Xcode\",\"Firebase\"],\"architecture\":[\"Client-Server\"],\"databases\":[\"Firestore\",\"SQLite\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nConsumer app company with 5 million users is looking for a senior iOS engineer to own the core app experience in SwiftUI. You will work on performance optimization, app architecture improvements, and deep integration with REST APIs. Experience with Fastlane for automated releases, XCTest for testing, and Firebase for analytics and crash reporting is expected. The role involves mentoring junior engineers and contributing to architectural decisions. Swift proficiency is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SwiftUI and Swift are a direct match for the primary technical requirement\",\"Fastlane and GitHub Actions cover the automated release pipeline\",\"Firebase and XCTest align with analytics and testing expectations\",\"UIKit experience adds depth for legacy and hybrid UI work\",\"Senior seniority fits the mentoring and architecture contribution expectations\"],\"gaps\":[\"No explicit REST API integration work visible beyond client-server architecture tag\"],\"explanation\":\"The candidate's profile maps closely to the role's requirements with SwiftUI, Fastlane, Firebase, and XCTest all present. Their senior background and iOS-focused history make them well-suited for both the technical depth and the mentoring responsibilities. The only minor uncertainty is the depth of their REST API integration experience, which is a meaningful part of the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mkwon_data\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"Python\",\"SQL\",\"R\"],\"tech\":[\"Pandas\",\"Tableau\",\"NumPy\"],\"databases\":[\"PostgreSQL\",\"MySQL\"]}\n\nJob Summary:\nGrowth-stage startup hiring a mid-level data analyst to own dashboards, define metrics, and run ad hoc analyses for the product and marketing teams. The candidate should be proficient in SQL and Python, experienced with Tableau or Looker, and comfortable writing complex queries against BigQuery or Redshift. Familiarity with dbt for data transformation and experience communicating insights to non-technical stakeholders is expected. This is a cross-functional role requiring strong analytical and communication skills.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SQL, Python, and Tableau directly match core analytical requirements\",\"R adds statistical depth relevant to ad hoc analysis\",\"Pandas and NumPy indicate solid data manipulation capability\"],\"gaps\":[\"Junior seniority is below the mid-level requirement\",\"No BigQuery or Redshift experience, only PostgreSQL and MySQL\",\"No dbt experience for the data transformation workflow\",\"No Looker experience as an alternative to Tableau in this stack\"],\"explanation\":\"The candidate has the right analytical toolkit in terms of Python, SQL, and Tableau, but their junior seniority and absence of cloud data warehouse and dbt experience are meaningful gaps. They could grow into this role but would require ramp-up time on the data stack. A moderately qualified profile for a role that expects more independence and infrastructure familiarity.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rustam_backend\",\"seniority\":\"Staff\",\"roles\":[\"Backend Engineer\",\"Software Architect\"],\"languages\":[\"Java\",\"Kotlin\",\"Python\"],\"tech\":[\"Spring Boot\",\"Kafka\",\"Docker\",\"Kubernetes\",\"AWS\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"CQRS\",\"Domain-Driven Design\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"DynamoDB\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Testcontainers\"]}\n\nJob Summary:\nLarge enterprise fintech company is hiring a staff backend engineer to lead architecture decisions across several microservices teams. Deep Java and Spring Boot experience required. The candidate must understand event-driven systems with Kafka, CQRS, and DDD at a practical level. Kubernetes and AWS are the deployment standard. We need someone who can mentor senior engineers, drive technical roadmaps, and ensure reliability at scale. Cassandra or DynamoDB experience for high-throughput storage is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Java and Spring Boot are a direct match for the primary language and framework\",\"Kafka, CQRS, and DDD experience covers the event-driven architecture requirements precisely\",\"Cassandra and DynamoDB address the high-throughput storage plus\",\"Kubernetes and AWS align with the deployment standard\",\"Staff seniority and Software Architect role match the leadership and roadmap expectations\"],\"gaps\":[],\"explanation\":\"This is a near-perfect match. The candidate's staff-level seniority, Spring Boot expertise, event-driven architecture knowledge with Kafka and CQRS, and hands-on DDD experience all directly address what the enterprise is looking for. Their dual role as engineer and architect further supports the technical leadership expectations of this position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"grace_frontend\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Vite\",\"Tailwind CSS\"],\"databases\":[\"Firebase\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"Vitest\",\"Cypress\"]}\n\nJob Summary:\nEuropean travel tech company is looking for a mid-level frontend engineer with React and Next.js experience to build customer-facing booking flows. TypeScript proficiency is required. The team uses Redux Toolkit for state management and React Query for data fetching. Experience with accessibility standards and internationalization is highly valued. We deploy on Vercel and use GitHub Actions for CI/CD. Candidates should be comfortable with a component-driven workflow.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript proficiency is confirmed and directly required\",\"Mid-level seniority matches the role grade\",\"Strong testing habits with Vitest and Cypress\",\"Vite and Tailwind CSS indicate modern frontend tooling familiarity\"],\"gaps\":[\"Vue.js and Nuxt.js background does not map to the React and Next.js stack required\",\"No Redux Toolkit or React Query experience visible\",\"No GitHub Actions experience, only GitLab CI\",\"No evidence of accessibility or internationalization work\"],\"explanation\":\"The candidate is a capable mid-level frontend engineer but their stack is Vue-based rather than React-based, which is a significant mismatch for this role. While TypeScript and testing habits transfer well, they would need to ramp up on React, Next.js, and the state management tooling. Depending on the team's timeline, this could work with onboarding investment but is not an immediate fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devops_felix\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"Terraform\",\"AWS\",\"GitHub Actions\",\"Nginx\"],\"ci_cd\":[\"GitHub Actions\",\"CircleCI\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nSeries A startup building developer tooling needs a mid-level DevOps engineer to own CI/CD pipelines, manage AWS infrastructure using Terraform, and maintain Docker-based deployment workflows. Familiarity with GitHub Actions is essential. Experience with Kubernetes for container orchestration is strongly preferred. Scripting in Python or Bash for automation tasks is expected. Monitoring with Prometheus and Grafana would be a bonus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform and AWS directly match the infrastructure management requirements\",\"Docker experience aligns with the deployment workflow\",\"GitHub Actions and CircleCI cover the CI/CD pipeline requirement\",\"Python and Bash meet the automation scripting expectations\"],\"gaps\":[\"No Kubernetes experience, which is strongly preferred for container orchestration\",\"No Prometheus or Grafana experience for monitoring\"],\"explanation\":\"The candidate covers the core DevOps requirements well with Terraform, Docker, AWS, and GitHub Actions all present. The notable gap is Kubernetes, which the job strongly prefers and is a standard skill at this level in modern cloud environments. They are a solid moderate fit who could contribute quickly on CI/CD and IaC but would need to develop container orchestration skills.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"intern_sam_js\",\"seniority\":\"Intern\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"HTML\",\"CSS\"],\"tech\":[\"React\",\"Tailwind CSS\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nStartup looking for a junior to mid-level frontend engineer with at least one year of professional experience working in React. Candidate should be comfortable with TypeScript, state management, and writing tests. Familiarity with REST API integration and Git workflows is expected. We value clean code and collaborative pull request culture. Next.js experience is a bonus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and Tailwind CSS are relevant to the job stack\",\"Jest usage shows basic testing awareness\"],\"gaps\":[\"Intern seniority does not meet the junior-to-mid professional experience requirement\",\"No TypeScript experience, which is expected\",\"No state management library visible in profile\",\"No REST API integration or Next.js experience shown\"],\"explanation\":\"While the candidate has made a start with React and Jest, their intern-level profile falls significantly short of the professional experience and technical breadth required for this role. The absence of TypeScript and state management are concrete gaps that would require meaningful mentorship to bridge. This is not a match for the described expectations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"bogdan_platform\",\"seniority\":\"Lead\",\"roles\":[\"Platform Engineer\",\"DevOps Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Docker\",\"Prometheus\",\"Grafana\",\"Google Cloud\",\"Istio\"],\"architecture\":[\"Cloud-Native\",\"Service Mesh\",\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"Argo CD\",\"GitHub Actions\",\"Tekton\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nGlobal SaaS company scaling its platform team is looking for a lead platform engineer to design and operate a Kubernetes-based developer platform on GCP. The candidate must have deep expertise in Terraform, Helm, and service mesh technologies like Istio. Observability with Prometheus and Grafana is required. GitOps with Argo CD is the deployment standard. Go or Python scripting for platform tooling is expected. This person will lead a team of three and set engineering standards.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Terraform, Helm, and Istio are all present and directly required\",\"Prometheus and Grafana cover the observability mandate\",\"Argo CD demonstrates GitOps workflow experience\",\"Google Cloud aligns with the GCP deployment environment\",\"Lead seniority matches the team leadership responsibility\",\"Go and Python cover the platform scripting expectations\"],\"gaps\":[],\"explanation\":\"This is an exceptional match. The candidate's profile covers every technical requirement in the job description with precision, including Istio for service mesh, Argo CD for GitOps, and GCP as the cloud provider. Their lead-level experience and platform engineering focus directly align with the team leadership and standards-setting expectations of the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mina_flutter\",\"seniority\":\"Junior\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"JavaScript\"],\"tech\":[\"Flutter\",\"Firebase\"],\"databases\":[\"Firestore\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nHealthtech startup is looking for a mid-level mobile engineer with React Native experience to build a cross-platform patient-facing app. TypeScript proficiency is required. The candidate should understand REST API integration, offline-first data patterns, and mobile performance optimization. Experience with Expo or native module bridging is a plus. Familiarity with HIPAA-related data handling practices would be strongly valued.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Cross-platform mobile development experience with Flutter shows relevant mobile foundations\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement\",\"Flutter and Dart background does not transfer to the React Native and TypeScript stack required\",\"No REST API integration patterns visible\",\"No offline-first or performance optimization experience shown\",\"No HIPAA or healthcare data handling familiarity\"],\"explanation\":\"The candidate has mobile development experience but in the wrong framework. Flutter and React Native are distinct ecosystems requiring different tooling and language skills, making this a weak technical match. Combined with their junior seniority and the absence of healthcare data sensitivity, this profile does not meet the role's expectations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"oscar_php\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"Laravel\",\"Vue.js\",\"Redis\",\"Docker\",\"Nginx\"],\"architecture\":[\"Monolith\",\"REST\"],\"databases\":[\"MySQL\",\"PostgreSQL\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nDigital agency with enterprise clients is looking for a senior full stack developer with strong Laravel and Vue.js experience. Candidates should be comfortable building REST APIs, writing PHPUnit tests, and deploying with Docker. MySQL and Redis are the primary data stores. The team uses GitLab for version control and CI/CD. This role involves client-facing communication and technical decision-making on projects.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Laravel and Vue.js are a direct stack match for this full stack agency role\",\"PHPUnit experience aligns with the testing expectations\",\"MySQL, Redis, and Docker are all present in the profile\",\"GitLab CI covers the CI/CD requirement\",\"REST API experience fits the primary API design pattern\"],\"gaps\":[\"No explicit mention of client-facing or communication-oriented project work\"],\"explanation\":\"This candidate's technical profile is a strong match for the agency's stack, with every core tool and framework aligned. Their senior seniority positions them well for technical decision-making responsibilities. The only marginal gap is the absence of visible client-facing experience, which is important for an agency environment but may exist outside their GitHub profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"haruto_embedded\",\"seniority\":\"Mid\",\"roles\":[\"Embedded Engineer\"],\"languages\":[\"C\",\"C++\",\"Python\"],\"tech\":[\"CUDA\",\"CMake\"],\"architecture\":[\"Client-Server\"]}\n\nJob Summary:\nAutonomous vehicle software company is looking for a senior backend engineer proficient in Python and Go to build distributed data pipelines for sensor ingestion. Experience with Apache Kafka, Docker, and Kubernetes is required. Familiarity with cloud infrastructure on AWS or GCP is expected. The role does not involve embedded or firmware development. Strong Python backend skills and distributed systems thinking are the primary requirements.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python proficiency is present and relevant to the backend requirements\"],\"gaps\":[\"Mid-level seniority falls below the senior level required\",\"Embedded engineering background does not match the distributed backend role\",\"No Go experience, which is a core language for this position\",\"No Kafka, Docker, or Kubernetes experience visible\",\"No cloud infrastructure experience with AWS or GCP\"],\"explanation\":\"Despite having Python skills, this candidate's background is in embedded systems, which is explicitly not what this role requires. The absence of Go, Kafka, Kubernetes, and cloud infrastructure experience means they would need to rebuild their skill set from the ground up for this position. This is a significant mismatch in domain and tooling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yemi_data_sci\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"NumPy\",\"Weights & Biases\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nRetail analytics company is looking for a senior data scientist to build and deploy recommendation and personalization models. Candidates must be proficient in Python and scikit-learn or PyTorch. Experience tracking experiments with MLflow or Weights and Biases is expected. SQL proficiency and BigQuery experience are required for data access. The role involves working with the data engineering team and deploying models as REST APIs. Familiarity with A/B testing frameworks is a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch, scikit-learn, and Python directly match the modeling requirements\",\"Weights and Biases covers the experiment tracking expectation\",\"BigQuery and SQL are present for the data access requirements\",\"Senior seniority aligns with the level of ownership expected\"],\"gaps\":[\"No model deployment or REST API serving experience visible\",\"No explicit A/B testing framework experience\",\"No MLflow experience as the alternative tracking tool\"],\"explanation\":\"The candidate is strong on the modeling and experimentation side but shows no evidence of model deployment as REST APIs, which is explicitly required in this role. A/B testing framework familiarity is also absent. These are operationally important skills for a data scientist expected to ship production models in a retail context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"zoe_ux_engineer\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Storybook\",\"Framer Motion\",\"Tailwind CSS\",\"shadcn/ui\",\"Radix UI\"],\"architecture\":[\"Monorepo\"],\"ci_cd\":[\"Vercel\",\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\",\"React Testing Library\"]}\n\nJob Summary:\nProduct company building a design-forward SaaS platform is looking for a senior frontend engineer who can lead component library development. Must have deep React and Next.js experience, strong TypeScript skills, and experience with headless UI libraries like Radix UI or shadcn. Storybook for component documentation is essential. Playwright for end-to-end testing and React Testing Library for unit tests are used. The role involves working closely with design and owning the frontend architecture.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React, Next.js, and TypeScript directly match the core stack\",\"Radix UI and shadcn/ui are an exact match for the headless UI library requirement\",\"Storybook is present and explicitly required\",\"Playwright and React Testing Library cover the testing stack precisely\",\"Framer Motion and Tailwind CSS add design-oriented frontend depth\"],\"gaps\":[],\"explanation\":\"This candidate's profile is a precise match for a design-forward frontend role. Every technology called out in the job description is present in the candidate's stack, including the less common combination of Radix UI, shadcn, and Storybook. Their senior seniority and monorepo experience further support the architectural ownership expectations of this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nikolai_go\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Gin\",\"gRPC\",\"Docker\",\"AWS\",\"Redis\"],\"architecture\":[\"Microservices\",\"REST\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nStreaming infrastructure company building real-time video delivery systems is looking for a mid-level backend engineer in Go. Candidates should have experience with gRPC, microservices, and high-concurrency design patterns. Docker and AWS are the deployment standards. Familiarity with Redis for pub/sub or caching is expected. The team values clean API design and systematic testing. Experience with WebSockets or streaming protocols is a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go with Gin and gRPC directly matches the language and RPC requirements\",\"Microservices architecture aligns with the distributed infrastructure approach\",\"Docker and AWS cover the deployment stack\",\"Redis is present for caching and pub/sub requirements\",\"Mid-level seniority matches the role grade\"],\"gaps\":[\"No WebSocket or streaming protocol experience visible, which is a strong plus for this domain\",\"Testing is only shown in Python via pytest, with no Go testing evidence\"],\"explanation\":\"The candidate has strong foundational Go backend experience with gRPC, Gin, and microservices that aligns well with this streaming infrastructure role. The absence of WebSocket or streaming protocol experience is a notable gap for a video delivery context. Go-specific testing experience is also not clearly demonstrated, which may be a concern for a team that values systematic testing.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yusuf_infra\",\"seniority\":\"Mid\",\"roles\":[\"Cloud Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"AWS\",\"Terraform\",\"Docker\"],\"ci_cd\":[\"GitHub Actions\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nInsurtech company scaling its cloud infrastructure is looking for a mid-level cloud engineer with multi-cloud experience. Candidates should be comfortable with AWS and Azure or GCP. Terraform for IaC and Kubernetes for container orchestration are required. Monitoring with Datadog is expected. Python or Bash scripting is needed for automation. Security and compliance posture management experience is strongly preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"AWS and Terraform match part of the cloud and IaC requirements\",\"Docker provides a foundation for understanding containerized workloads\",\"Python and Bash meet the scripting automation expectation\"],\"gaps\":[\"No Azure or GCP experience, which is required for multi-cloud capability\",\"No Kubernetes experience for container orchestration\",\"No Datadog or monitoring tooling visible\",\"No security or compliance posture management experience\"],\"explanation\":\"The candidate covers the basics of cloud infrastructure with AWS and Terraform, but misses several key requirements including multi-cloud support, Kubernetes, and observability tooling. The absence of security and compliance experience is also a notable gap for an insurance company with regulatory obligations. This profile would need significant upskilling to meet the full scope of the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sophie_principal\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\",\"Backend Engineer\"],\"languages\":[\"Java\",\"Go\",\"Python\"],\"tech\":[\"Spring Boot\",\"Kafka\",\"Kubernetes\",\"Istio\",\"Terraform\",\"AWS\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Microservices\",\"Domain-Driven Design\",\"Event-Driven\",\"CQRS\",\"Hexagonal Architecture\",\"Service Mesh\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"DynamoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\",\"Jenkins\"],\"testing\":[\"JUnit\",\"k6\",\"Playwright\"]}\n\nJob Summary:\nPublicly traded enterprise software company is seeking a principal engineer to drive technical direction across multiple product lines. Deep backend engineering expertise is required, with Java and Spring Boot being the primary stack. The candidate must have experience with DDD, CQRS, and event-driven architecture using Kafka. Kubernetes and Istio for service mesh are the deployment standards. Familiarity with GitOps and multiple CI/CD systems is valued. This is a thought leadership and hands-on architecture role.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Java, Spring Boot, Kafka, CQRS, and DDD are all directly required and present\",\"Kubernetes and Istio cover the service mesh deployment standard precisely\",\"Argo CD demonstrates GitOps experience alongside Jenkins and GitHub Actions\",\"Principal seniority and Software Architect role match the thought leadership expectation\",\"DDD, Hexagonal Architecture, and Event-Driven demonstrate architectural breadth\"],\"gaps\":[],\"explanation\":\"This candidate is an exceptional match for a principal-level architecture role. Their profile demonstrates mastery of every technical domain the job requires, from DDD and CQRS to Kafka, Istio, and multi-tool CI/CD experience. The depth and breadth of their architecture patterns combined with principal seniority make them precisely suited for a technical direction and thought leadership role at an enterprise company.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"paul_wordpress_dev\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"WordPress\",\"Nginx\",\"Docker\"],\"architecture\":[\"Monolith\",\"REST\"],\"databases\":[\"MySQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nSeries C startup building a real-time analytics platform is looking for a mid-level backend engineer proficient in Python or Go. The candidate should have experience with event-driven microservices, Apache Kafka for streaming, and PostgreSQL or ClickHouse for analytics workloads. Kubernetes and Docker are the deployment standard. Strong API design skills and experience with distributed system patterns are expected. This is a high-growth environment requiring adaptability and systems thinking.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker and GitHub Actions provide basic infrastructure familiarity\"],\"gaps\":[\"No Python or Go experience, which are the required languages for this role\",\"WordPress and PHP background does not align with analytics platform or distributed systems work\",\"No Kafka or event-driven microservices experience\",\"No PostgreSQL or ClickHouse experience for analytics workloads\",\"No Kubernetes experience for container orchestration\"],\"explanation\":\"This candidate's background is heavily oriented toward CMS and PHP development, which is a significant domain mismatch for a real-time analytics platform role. The required languages, frameworks, and distributed systems experience are all absent from the profile. A career transition of this magnitude would require substantial reskilling before this candidate could contribute to such a role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"isabel_dbt\",\"seniority\":\"Mid\",\"roles\":[\"Analytics Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Looker\",\"Metabase\",\"Pandas\"],\"databases\":[\"BigQuery\",\"Snowflake\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Great Expectations\"]}\n\nJob Summary:\nGrowth-stage marketplace company is looking for a mid-level analytics engineer to own the data transformation layer using dbt on BigQuery. You will build and maintain Looker dashboards, define and document data models, and work closely with product and marketing analysts. SQL proficiency is required. Experience with data quality testing and a strong understanding of business metrics are expected. Python for automation is a bonus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt and BigQuery are a direct match for the core transformation stack\",\"Looker experience aligns with the dashboard tooling\",\"Great Expectations covers the data quality testing expectation\",\"SQL proficiency is confirmed as the primary analytical language\",\"Python adds automation capability as the job suggests is a bonus\"],\"gaps\":[\"Metabase may introduce BI tool redundancy but does not reflect a gap\"],\"explanation\":\"This candidate is a strong and direct fit for an analytics engineering role centered on dbt and Looker. Their BigQuery experience, SQL fluency, and Great Expectations usage all map precisely to the job's core expectations. The Python bonus is also covered. This profile aligns well with both the technical requirements and the collaborative, metrics-focused nature of the team.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"felix_sveltekit\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Svelte\",\"SvelteKit\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nBootstrapped startup building a developer productivity tool is looking for a mid-level frontend engineer with React experience. TypeScript is required. Candidates should be comfortable with Next.js, Tailwind CSS, and state management. The team is small and values engineers who can also contribute to the Node.js backend. Testing with Jest or Vitest is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript proficiency is confirmed and required\",\"Tailwind CSS is present and used by the team\",\"Vitest and Playwright demonstrate solid testing discipline\",\"Mid-level seniority matches the role grade\"],\"gaps\":[\"Svelte and SvelteKit background does not map to the React and Next.js stack required\",\"No state management library experience visible\",\"No Node.js backend experience shown despite the expectation of backend contributions\"],\"explanation\":\"The candidate has solid TypeScript and testing fundamentals, but their SvelteKit focus is a framework mismatch for a React and Next.js team. While TypeScript and Tailwind transfer, they would need to ramp up on React, Next.js, state management, and Node.js backend work. This represents a moderate fit with notable onboarding requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"riku_mlops\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"MLflow\",\"Weights & Biases\",\"FastAPI\",\"Docker\",\"Kubernetes\",\"AWS\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nRetail recommendation engine company is looking for a senior MLOps engineer to own the full model lifecycle from training to deployment. Candidates must have experience with MLflow or Weights and Biases for experiment tracking, Docker and Kubernetes for model serving, and FastAPI for building model APIs. CI/CD with GitOps tooling is required. AWS as the cloud provider and Python as the primary language. Experience with feature stores or data versioning tools is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"MLflow and Weights and Biases both present for experiment tracking\",\"FastAPI, Docker, and Kubernetes directly match the model serving stack\",\"Argo CD demonstrates GitOps CI/CD experience\",\"AWS and Python are both confirmed\",\"PyTorch adds model development credibility alongside the MLOps tooling\"],\"gaps\":[\"No feature store or data versioning tool experience visible\"],\"explanation\":\"This candidate's profile aligns closely with the MLOps lifecycle requirements, covering experiment tracking, containerized model serving, API development, and GitOps deployment. The dual presence of MLflow and Weights and Biases is particularly strong. The only gap is the absence of feature store experience, which the job lists as a plus rather than a requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cleo_junior_py\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"Flask\",\"Docker\"],\"databases\":[\"PostgreSQL\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nB2C subscription startup building a wellness platform is looking for a senior backend engineer with Python and Django experience. The candidate should have deep knowledge of REST API design, Celery for async task processing, Redis for caching, and PostgreSQL for relational data. Experience with AWS and Kubernetes for cloud deployments is required. The role involves mentoring junior developers and leading backend technical decisions.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and PostgreSQL are relevant to the tech stack\",\"pytest demonstrates basic testing discipline\"],\"gaps\":[\"Junior seniority does not meet the senior-level requirement\",\"Flask experience does not substitute for the Django requirement\",\"No Celery or async task processing experience visible\",\"No Redis for caching\",\"No AWS or Kubernetes experience for cloud deployments\",\"No evidence of mentoring or technical leadership\"],\"explanation\":\"While the candidate has Python and PostgreSQL experience, they fall significantly short of the senior backend requirements in terms of both seniority and technical depth. The absence of Django, Celery, Redis, AWS, and Kubernetes are concrete gaps that would prevent them from contributing independently in this role. The mentoring and technical leadership expectations are also beyond this candidate's current profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"andrei_nest\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"Express.js\",\"Prisma\",\"Docker\",\"AWS\",\"Redis\",\"BullMQ\"],\"architecture\":[\"Microservices\",\"REST\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nSaaS startup building a notification and communication platform is looking for a mid-level backend engineer. NestJS is the primary framework. Candidates should have experience with BullMQ for job queuing, Redis for caching, and PostgreSQL as the primary database. TypeScript proficiency is required. Docker and AWS deployments are standard. REST API design and event-driven architecture understanding are valued. Jest for testing is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS is the exact framework used by the team\",\"BullMQ and Redis directly match the job queuing and caching requirements\",\"PostgreSQL is the primary database and is present\",\"TypeScript is confirmed and required\",\"Docker and AWS cover the deployment expectations\",\"Jest and Supertest demonstrate backend API testing practices\",\"Event-Driven architecture background aligns with a notification platform\"],\"gaps\":[],\"explanation\":\"This candidate is a precise technical match for the role. Every technology named in the job description is present in their profile, with NestJS, BullMQ, Redis, and PostgreSQL being particularly strong signal points. Their event-driven architecture background is especially relevant for a notification and communication platform. There are no gaps to note.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hana_security\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\",\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"AWS\",\"Terraform\",\"Docker\",\"Vault\",\"Prometheus\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nCybersecurity SaaS company is looking for a senior security engineer to own application security, cloud security posture management, and secrets management using HashiCorp Vault. Candidates must have experience with AWS security controls, Terraform for infra as code, and scripting in Python or Bash. Familiarity with threat modeling, SAST/DAST tooling, and secure SDLC practices is expected. Go knowledge is a plus for internal tooling contribution.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"HashiCorp Vault directly matches the secrets management requirement\",\"AWS, Terraform, Python, and Bash cover the infrastructure and scripting requirements\",\"Go knowledge addresses the internal tooling plus\",\"Senior seniority aligns with the ownership expectations\"],\"gaps\":[\"No SAST or DAST tooling experience visible in profile\",\"No threat modeling or secure SDLC methodology evidence\",\"No explicit application security engineering background beyond general security role label\"],\"explanation\":\"The candidate has a solid cloud security and infrastructure background with Vault, AWS, and Terraform, but the job places significant weight on application security practices like threat modeling and SAST/DAST tooling, which are not visible in the profile. These are core expectations for a cybersecurity SaaS company and represent a meaningful skills gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"omar_kmp\",\"seniority\":\"Senior\",\"roles\":[\"Mobile Engineer\",\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Swift\",\"Dart\"],\"tech\":[\"Kotlin Multiplatform\",\"Jetpack Compose\",\"SwiftUI\",\"Flutter\",\"Ktor\"],\"architecture\":[\"Client-Server\",\"Modular Architecture\"],\"databases\":[\"SQLite\",\"Firestore\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"JUnit\",\"XCTest\"]}\n\nJob Summary:\nMobile-first fintech company is looking for a senior mobile engineer to lead cross-platform development using Kotlin Multiplatform. The candidate must be proficient in Kotlin, with Jetpack Compose for Android UI and SwiftUI for iOS. Ktor is used for the shared networking layer. Modular architecture is how the codebase is organized. Experience with Fastlane for release automation and JUnit or XCTest for testing is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kotlin Multiplatform is directly required and present as the primary technology\",\"Jetpack Compose and SwiftUI cover both platform UI requirements\",\"Ktor is used for the networking layer and is confirmed in the profile\",\"Modular Architecture aligns with the codebase organization approach\",\"Fastlane, JUnit, and XCTest all match the release and testing expectations\",\"Senior seniority supports the leadership expectations of this role\"],\"gaps\":[],\"explanation\":\"This candidate's profile is an exact match for a Kotlin Multiplatform mobile engineering role. Their experience spans the full KMP stack including Ktor, Jetpack Compose, and SwiftUI, which is a rare and valuable combination. The modular architecture and release tooling alignment further strengthen their fit for a fintech team that ships to both platforms.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jade_nuxt\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\"],\"databases\":[\"Firebase\"],\"testing\":[\"Vitest\"]}\n\nJob Summary:\nDigital product agency is looking for a mid-level Vue.js developer to join a client-facing team. Candidates should be proficient in Vue 3 with the Composition API, Nuxt.js for SSR, and Pinia for state management. TypeScript is required. Tailwind CSS is the styling framework. Experience with REST API integration and working on multiple concurrent client projects is expected. At least two years of professional Vue.js experience is preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Vue.js, Nuxt.js, Pinia, and Tailwind CSS are all directly aligned with the job stack\",\"TypeScript proficiency is confirmed\",\"Vitest demonstrates testing familiarity in the Vue ecosystem\"],\"gaps\":[\"Junior seniority falls below the mid-level and two-year professional experience expectation\",\"No REST API integration experience visible\",\"No evidence of multi-project or client-facing delivery experience\"],\"explanation\":\"The candidate's technical stack is a strong match for a Vue-focused agency role, with Nuxt, Pinia, and Tailwind all aligned. However, their junior seniority and the absence of REST API and client-facing project experience mean they are not yet at the level the agency expects for independent delivery. They could be a strong fit with additional mentorship and experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tamar_analytics\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Tableau\",\"Pandas\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nGrowth analytics team at a FAANG-adjacent adtech company is hiring a mid to senior data analyst. Candidates must be proficient in SQL and Python, with experience analyzing petabyte-scale datasets in BigQuery or Redshift. Looker for dashboarding and Amplitude or Mixpanel for product analytics are in use. Candidates should have experience running A/B tests and building statistically rigorous measurement frameworks. This is a high-impact, autonomous role requiring strong communication and stakeholder management.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"SQL and Python proficiency are present and required\",\"Tableau shows BI dashboard experience, though not with the tools used\"],\"gaps\":[\"Junior seniority does not meet the mid-to-senior expectation\",\"No BigQuery or Redshift experience for petabyte-scale analytics\",\"No Looker, Amplitude, or Mixpanel experience\",\"No A/B testing or statistical measurement framework experience visible\",\"No evidence of stakeholder management or autonomous analytical ownership\"],\"explanation\":\"The candidate has the foundational analytical skills but is significantly underprepared for the scope and scale of this role. The absence of cloud data warehouse experience, product analytics tooling, and A/B testing methodology represents a substantial gap. The seniority mismatch further compounds these deficiencies. This is not a match for a high-autonomy, FAANG-adjacent environment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"benedikt_elixir\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Elixir\",\"JavaScript\",\"Python\"],\"tech\":[\"Phoenix\",\"Docker\",\"AWS\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"CouchDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nReal-time communications startup is looking for a senior backend engineer with Elixir experience to build and maintain high-concurrency messaging infrastructure. Phoenix framework experience is required. Candidates should understand OTP principles and be comfortable with distributed Elixir patterns. PostgreSQL is the primary database. Redis for caching and pub/sub. Docker and AWS for deployments. A strong understanding of fault-tolerant system design is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Elixir and Phoenix are directly required and present\",\"Event-Driven architecture demonstrates concurrency and distributed systems thinking\",\"PostgreSQL and Redis both match the data and caching requirements\",\"Docker and AWS cover the deployment stack\",\"ExUnit demonstrates Elixir-native testing discipline\"],\"gaps\":[\"No explicit OTP or distributed Elixir pattern work visible beyond the implied experience from Elixir usage\"],\"explanation\":\"This candidate is a strong fit for a high-concurrency Elixir messaging platform. Their Phoenix background, event-driven architecture experience, and the matching data stack make them well-positioned for the role. The only uncertainty is the depth of their OTP and distributed Elixir patterns experience, which is central to fault-tolerant system design in this domain.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sara_intern_ml\",\"seniority\":\"Intern\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nRobotics company is looking for a mid-level machine learning engineer to develop perception and control models. Candidates must have experience with PyTorch, CUDA for GPU acceleration, and OpenCV for computer vision tasks. Familiarity with ROS or embedded deployment of ML models is strongly preferred. Production ML experience with at least two years deploying models to real hardware is required. C++ for performance-critical modules is a plus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"scikit-learn and Python demonstrate foundational ML knowledge\"],\"gaps\":[\"Intern seniority significantly below the mid-level requirement with two years of production ML experience\",\"No PyTorch, which is required for deep learning model development\",\"No CUDA or GPU computing experience\",\"No OpenCV or computer vision experience\",\"No ROS or embedded ML deployment experience\",\"No C++ knowledge for performance-critical modules\"],\"explanation\":\"This is a poor match. The candidate's intern-level, scikit-learn-based profile is in an entirely different tier from what a robotics company requires for hardware-deployed perception models. The job demands PyTorch, CUDA, OpenCV, and ideally ROS experience, none of which are present. This candidate is at the beginning of an ML career and not ready for production robotics engineering.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"obi_game_dev\",\"seniority\":\"Junior\",\"roles\":[\"Game Developer\"],\"languages\":[\"C++\",\"C#\"],\"tech\":[\"Unity\",\"WebGL\"],\"architecture\":[\"Client-Server\"]}\n\nJob Summary:\nAdtech platform company is looking for a mid-level backend engineer to build programmatic advertising systems. Python or Go is required. Experience with real-time bidding protocols, Kafka for event streaming, and PostgreSQL or Cassandra for high-volume storage is expected. Docker and Kubernetes for deployment. REST API design and low-latency system optimization are core requirements. This is not a game or graphics engineering role.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"C++ background suggests some understanding of performance-critical system design\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement\",\"No Python or Go experience, which are the required languages\",\"Game development background does not transfer to programmatic advertising systems\",\"No Kafka, PostgreSQL, or Cassandra experience\",\"No Docker or Kubernetes experience\",\"No REST API or backend service development experience\"],\"explanation\":\"This candidate's background in Unity and WebGL game development has minimal overlap with a backend adtech engineering role. The required languages, data systems, and distributed infrastructure are all absent. Their junior seniority adds to the mismatch. This is a substantial domain and technical gap that cannot be bridged without significant reskilling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"layla_nextjs\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"Tailwind CSS\",\"Prisma\",\"Node.js\"],\"architecture\":[\"Serverless\",\"REST\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"Vercel\",\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nClimate tech startup building carbon tracking software for enterprises is hiring a mid-level full stack engineer. Next.js, React, and TypeScript are the frontend standards. Node.js and Prisma with PostgreSQL for the backend. Supabase for auth and realtime features. Vercel for deployment. The team values clean code, well-tested features, and engineers who can take ownership of full product areas. Experience with data visualization is a nice-to-have.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js, React, and TypeScript directly match the frontend requirements\",\"Node.js and Prisma with PostgreSQL cover the backend and data layer\",\"Supabase is present and used for auth and realtime in this stack\",\"Vercel and GitHub Actions align with the deployment setup\",\"Jest and Playwright demonstrate strong testing discipline\"],\"gaps\":[\"No data visualization library experience visible, which is a nice-to-have\"],\"explanation\":\"This candidate's profile aligns with the startup's stack across every major dimension, from the Next.js and TypeScript frontend to Prisma, PostgreSQL, and Supabase on the backend. Their serverless experience on Vercel and testing coverage with Jest and Playwright match the team's quality expectations. The only marginal gap is the absence of data visualization tooling, which is listed as a nice-to-have.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dmitri_platform\",\"seniority\":\"Senior\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"Google Cloud\",\"Prometheus\",\"Grafana\",\"Docker\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"Argo CD\",\"GitHub Actions\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nMedia streaming company running on AWS is looking for a senior platform engineer to manage EKS clusters, write Terraform modules, and maintain CI/CD pipelines. AWS is the primary cloud provider. Helm and Kubernetes experience are required. Prometheus and Grafana for observability. Argo CD for GitOps. Go scripting for internal tooling. The candidate will own the developer platform experience and collaborate with dozens of engineering teams.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes, Helm, Terraform, Prometheus, Grafana, and Argo CD are all directly required and present\",\"Go scripting meets the internal tooling expectation\",\"Cloud-native and microservices architecture background is relevant\",\"Senior seniority aligns with the ownership expectations\"],\"gaps\":[\"Primary cloud experience is Google Cloud, not AWS, which is the required provider\",\"No EKS-specific experience visible, as AWS Kubernetes may differ from GKE workflows\"],\"explanation\":\"This candidate has strong platform engineering fundamentals with all the required tooling except the cloud provider. Their experience is GCP-centric rather than AWS-centric, which creates uncertainty around AWS-specific services like EKS and the broader AWS ecosystem used by the media company. This is a moderate fit where the platform skills transfer but the cloud provider context requires validation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ana_mlresearcher\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"Data Scientist\"],\"languages\":[\"Python\",\"Julia\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"CUDA\",\"Weights & Biases\",\"NumPy\",\"scikit-learn\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAI research lab seeking a senior ML researcher and engineer hybrid to develop novel NLP model architectures and run large-scale training experiments. Deep PyTorch expertise required. Experience with Hugging Face Transformers for model development and fine-tuning is essential. CUDA proficiency for low-level GPU optimization. Weights and Biases for experiment tracking. Publication or open-source research contributions in NLP or ML are strongly valued. Distributed training with multi-GPU setups is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PyTorch and Hugging Face Transformers are both directly required and present\",\"CUDA proficiency covers the low-level GPU optimization requirement\",\"Weights and Biases is the experiment tracking tool in use\",\"Senior ML researcher and engineer profile aligns with the hybrid research and engineering role\",\"Julia adds rare computational research depth valued in research environments\"],\"gaps\":[\"No explicit distributed or multi-GPU training experience visible\"],\"explanation\":\"This candidate's profile is a strong match for an NLP research engineering role, covering the full PyTorch, Hugging Face, CUDA, and Weights and Biases stack. Their Julia experience adds research computing credibility. The only notable gap is the absence of visible multi-GPU distributed training experience, which is an explicit requirement for large-scale training experiments at a research lab.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tony_cms\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"PHP\"],\"tech\":[\"WordPress\",\"React\",\"Nginx\",\"Docker\"],\"architecture\":[\"Monolith\",\"REST\"],\"databases\":[\"MySQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nDigital publishing company is looking for a mid-level developer with strong WordPress and React experience to build and maintain a headless CMS architecture. Candidates should know the WordPress REST API or WPGraphQL, be comfortable with React for the frontend, and have experience with MySQL and Docker. ACF, custom post types, and plugin development experience are expected. GitHub Actions for CI. Nginx for server configuration.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"WordPress and React directly match the headless CMS architecture requirements\",\"MySQL and Docker are present and required\",\"Nginx experience addresses the server configuration expectation\",\"GitHub Actions covers the CI requirement\",\"REST architecture aligns with the WordPress REST API usage pattern\"],\"gaps\":[\"No explicit WPGraphQL experience mentioned\",\"No visible ACF, custom post type, or plugin development experience in the profile\"],\"explanation\":\"The candidate has the right foundational combination of WordPress and React for a headless CMS role, with supporting infrastructure skills in Nginx and Docker. However, the absence of visible ACF and plugin development experience is a meaningful gap for a publishing company that likely relies heavily on these WordPress customization patterns. They are a moderate fit with room to validate deeper WordPress CMS expertise.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"aditi_ddd\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Software Architect\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Kafka\",\"Docker\",\"Kubernetes\",\"AWS\"],\"architecture\":[\"Domain-Driven Design\",\"Hexagonal Architecture\",\"Microservices\",\"Event Sourcing\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nEnterprise logistics company building a next-generation order management system is seeking a senior backend engineer with deep Java and Spring Boot experience. DDD and hexagonal architecture are the design standards. Event sourcing with Kafka is used for the order event log. Kubernetes and AWS for deployment. The candidate should mentor junior developers and contribute to architecture reviews. Mockito and JUnit for testing. Strong understanding of bounded contexts and aggregate design is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Java and Spring Boot are directly required and present\",\"DDD and Hexagonal Architecture are both confirmed in the profile\",\"Event Sourcing and Kafka directly match the order event log architecture\",\"Kubernetes and AWS cover the deployment stack\",\"JUnit and Mockito are the testing framework pair used by the team\",\"Senior architect background supports the mentoring and architecture review expectations\"],\"gaps\":[],\"explanation\":\"This candidate's profile is an excellent match for a DDD and event sourcing-driven enterprise backend role. Every design pattern, framework, and infrastructure tool named in the job description is present. Their dual background as engineer and architect, combined with Kafka-based event sourcing experience, makes them particularly well-suited for an order management system requiring strong bounded context and aggregate design thinking.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jules_ts_backend\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Express.js\",\"Prisma\",\"Docker\"],\"architecture\":[\"REST\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nB2B workflow automation company is hiring a mid-level backend engineer with Node.js and TypeScript experience. Candidates should have working knowledge of NestJS or Express.js, Prisma or TypeORM for the ORM layer, and PostgreSQL for the database. Docker and AWS are the deployment standards. BullMQ for background jobs and Redis for caching are part of the stack. Familiarity with REST API design patterns and basic microservices understanding is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript and Express.js are present and relevant to the backend stack\",\"Prisma and PostgreSQL directly match the ORM and database requirements\",\"Docker addresses part of the deployment stack\",\"REST architecture experience aligns with the API design patterns\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement\",\"No AWS experience for the cloud deployment standard\",\"No BullMQ or Redis experience for background jobs and caching\",\"No microservices understanding demonstrated beyond the REST tag\"],\"explanation\":\"The candidate has a strong foundation in the TypeScript, Express, Prisma, and PostgreSQL stack, which covers a meaningful portion of the role's requirements. However, their junior seniority, along with the absence of AWS, BullMQ, and Redis experience, means they are not yet ready for independent mid-level ownership. They could be a strong junior-to-mid track hire with targeted mentorship.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nina_senior_fe\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Redux\",\"React Query\",\"Tailwind CSS\",\"Webpack\",\"Vite\"],\"architecture\":[\"Micro Frontend\",\"Monorepo\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"React Testing Library\",\"Playwright\"]}\n\nJob Summary:\nFinteh platform scaling to enterprise customers is looking for a senior frontend engineer to lead micro-frontend architecture work. React and TypeScript are required. Experience with Redux or Zustand for state management and React Query for data fetching is expected. Monorepo management with Nx or Turborepo is preferred. Strong testing culture with Jest, React Testing Library, and Playwright. Webpack or Vite for bundling. The candidate will work closely with product and own major feature areas.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React, TypeScript, Redux, and React Query all directly match the state and data management requirements\",\"Tailwind CSS, Webpack, and Vite cover the styling and build tooling stack\",\"Micro Frontend and Monorepo architecture background aligns with the primary architectural challenge\",\"Jest, React Testing Library, and Playwright match the testing stack precisely\",\"Senior seniority supports the feature ownership and leadership expectations\"],\"gaps\":[\"No Nx or Turborepo experience for monorepo management, only general Monorepo exposure\"],\"explanation\":\"This candidate's profile covers the core requirements of a senior frontend role at a fintech company with micro-frontend architecture needs. The combination of Redux, React Query, Webpack, Vite, and the full testing stack is a strong alignment. The minor gap is the absence of specific Nx or Turborepo monorepo tooling, though their general monorepo experience suggests the foundational understanding is present.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mateus_backend\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\"],\"tech\":[\"FastAPI\",\"Docker\",\"Kubernetes\",\"Redis\",\"AWS\",\"Celery\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nSeries C logistics startup building real-time shipment tracking infrastructure needs a senior backend engineer. Python or Go required. Must have microservices and event-driven architecture experience, Kubernetes and AWS deployment skills, and PostgreSQL at scale. Redis for caching and distributed coordination is a plus. Celery or similar task queue experience expected. CI/CD with GitOps tooling preferred. Engineers own features end to end in a fast-moving environment.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Python and Go match the primary language requirement directly\",\"FastAPI, Kubernetes, and AWS cover the core backend serving and deployment stack\",\"Microservices and Event-Driven architecture align precisely with real-time tracking system design\",\"Celery and Redis address the task queue and caching requirements explicitly\",\"Argo CD demonstrates GitOps CI/CD experience\"],\"gaps\":[\"No explicit Apache Kafka or streaming broker experience for real-time event pipelines\"],\"explanation\":\"This candidate's profile maps closely to every technical dimension of the role, from language and framework to infrastructure and architecture patterns. The Celery and Redis pairing is a direct match for the coordination and task queue expectations. The only marginal gap is the absence of a dedicated event streaming tool, which may or may not be required depending on pipeline depth.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sre_kiran\",\"seniority\":\"Lead\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Prometheus\",\"Grafana\",\"PagerDuty\",\"AWS\",\"Istio\"],\"architecture\":[\"Cloud-Native\",\"Service Mesh\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"Argo CD\",\"GitHub Actions\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nFinancial services platform running on AWS needs a lead SRE to own Kubernetes cluster operations, observability with Prometheus and Grafana, and incident management via PagerDuty. Terraform and Helm for infrastructure management. Istio service mesh experience required. GitOps with Argo CD is the deployment standard. Go or Python for automation tooling. k6 for load testing. The lead will define SLOs and mentor a team of four.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Prometheus, Grafana, and PagerDuty are all directly required and present\",\"Terraform and Helm cover the infrastructure management requirements precisely\",\"Istio service mesh experience is an explicit requirement and is confirmed\",\"Argo CD demonstrates GitOps deployment experience\",\"Lead seniority and k6 usage match the team leadership and load testing expectations\"],\"gaps\":[],\"explanation\":\"This candidate's profile is a precise match for the lead SRE role, covering every named technology including the less common PagerDuty and Istio combination. Their lead-level seniority and experience across the full observability, IaC, and GitOps stack position them well for SLO ownership and team mentoring. There are no meaningful gaps to note.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fullstack_yara\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Next.js\",\"React\",\"FastAPI\",\"Prisma\",\"Docker\",\"AWS\",\"Tailwind CSS\"],\"architecture\":[\"REST\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Vercel\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nHealthcare SaaS startup building patient scheduling tools is hiring a mid-level full stack engineer. Stack is Next.js and React on the frontend, FastAPI on the backend. TypeScript and Python required. PostgreSQL with Prisma for data. Docker and AWS for deployment. GitHub Actions and Vercel for CI/CD. Testing culture is important with Jest and pytest used across the stack. Tailwind CSS for styling.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js, React, FastAPI, TypeScript, and Python match the entire stated stack\",\"Prisma and PostgreSQL are a direct match for the data layer\",\"Docker, AWS, GitHub Actions, and Vercel all align with deployment and CI/CD\",\"Jest, pytest, and Playwright exceed the testing expectations\",\"Tailwind CSS and Redis round out the styling and caching requirements\"],\"gaps\":[],\"explanation\":\"Every technology named in the job description is confirmed in this candidate's profile. The breadth of testing tooling across frontend, backend, and end-to-end layers reflects strong engineering discipline that aligns with the team's stated values. This is an unusually precise match for a mid-level full stack role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"data_eng_rashid\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"Scala\",\"SQL\"],\"tech\":[\"Apache Spark\",\"PySpark\",\"Apache Kafka\",\"Apache Airflow\",\"dbt\",\"Docker\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nRetail analytics company building a lakehouse platform needs a senior data engineer. Deep Apache Spark and Kafka experience required. Python or Scala proficiency expected. Airflow for orchestration and dbt for transformation are standard tools. Snowflake or BigQuery as the warehouse. Great Expectations for data quality. Strong understanding of distributed system design for high-volume workloads.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Apache Spark, PySpark, and Kafka are a direct match for the streaming and processing requirements\",\"Both Python and Scala proficiency exceed the stated language requirement\",\"Airflow and dbt cover the orchestration and transformation stack precisely\",\"Snowflake and BigQuery both present, covering the warehouse requirement\",\"Great Expectations directly addresses the data quality expectation\"],\"gaps\":[],\"explanation\":\"This candidate covers every core technical requirement of the role with precision. The combination of Spark, Kafka, dbt, and Great Expectations demonstrates exactly the lakehouse pipeline maturity the company needs. Their dual Python and Scala proficiency adds flexibility that exceeds the minimum bar.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mobile_tae\",\"seniority\":\"Senior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Retrofit\",\"Hilt\",\"Firebase\"],\"architecture\":[\"Client-Server\",\"Modular Architecture\"],\"databases\":[\"SQLite\",\"Firestore\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Espresso\",\"Mockito\"]}\n\nJob Summary:\nConsumer fintech app with 3 million active Android users is hiring a senior Android engineer. Jetpack Compose and Kotlin are required. Hilt for dependency injection and Retrofit for REST API integration expected. SQLite or Room for local persistence. Fastlane for automated release pipelines. JUnit, Espresso, and Mockito for testing. Firebase for analytics and crash reporting. Modular architecture background preferred.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Jetpack Compose and Kotlin directly match the primary technical requirements\",\"Hilt and Retrofit are explicitly required and both confirmed\",\"SQLite covers the local persistence requirement\",\"Fastlane, JUnit, Espresso, and Mockito match the release and testing stack exactly\",\"Firebase and Modular Architecture address the analytics and architecture preferences\"],\"gaps\":[],\"explanation\":\"This candidate's Android profile maps precisely onto the job description with every named technology confirmed. Their senior seniority is appropriate for a production app with millions of active users, and the modular architecture preference further differentiates this as a strong fit. There are no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"llm_eng_sofia\",\"seniority\":\"Senior\",\"roles\":[\"AI Engineer\",\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"LangChain\",\"FastAPI\",\"Docker\",\"AWS\",\"Pinecone\"],\"architecture\":[\"RAG\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"ChromaDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nEnterprise AI company building knowledge retrieval products needs a senior AI engineer. Production LLM experience required including RAG pipelines and vector databases. Hugging Face Transformers and LangChain are core to the stack. PyTorch proficiency required. FastAPI for model serving on AWS. Docker for containerization. Understanding of LLM evaluation and prompt engineering is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PyTorch, Hugging Face Transformers, and LangChain are all directly required and confirmed\",\"RAG architecture and Pinecone plus ChromaDB vector databases are an exact match\",\"FastAPI and Docker on AWS covers the model serving stack\",\"Senior AI and ML dual roles indicate production AI deployment experience\",\"Microservices architecture supports scalable model API deployment\"],\"gaps\":[\"No explicit LLM evaluation framework tooling visible beyond general pytest\"],\"explanation\":\"This candidate's profile aligns precisely with the role's LLM engineering stack. The presence of LangChain, two vector databases, and a RAG architecture tag demonstrates real production RAG experience, not just familiarity. The only marginal gap is the absence of a dedicated LLM evaluation tool, which may be covered by custom tooling not visible in the GitHub profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devops_emeka\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\",\"Platform Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Docker\",\"Prometheus\",\"Grafana\",\"AWS\",\"Ansible\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\",\"Jenkins\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nGrowth-stage SaaS company needs a senior DevOps engineer to manage AWS infrastructure via Terraform, operate Kubernetes clusters, and own CI/CD pipelines. Helm chart management and Ansible for configuration management expected. Prometheus and Grafana for observability. GitOps with Argo CD preferred. Python or Bash for automation. k6 for performance testing. This is a high-ownership role across the entire delivery pipeline.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Terraform, Helm, and Ansible are all required and confirmed in the profile\",\"Prometheus and Grafana directly match the observability requirements\",\"Argo CD and Jenkins alongside GitHub Actions cover the CI/CD and GitOps needs\",\"Python, Bash, and Go exceed the automation scripting expectations\",\"k6 matches the performance testing expectation\"],\"gaps\":[],\"explanation\":\"This candidate's DevOps and platform engineering profile covers every stated requirement with depth. The combination of Terraform, Helm, Ansible, Argo CD, and Prometheus demonstrates mature infrastructure ownership across the full delivery stack. Their senior background in both DevOps and platform roles supports the high-ownership mandate of this position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rails_dev_priya\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Ruby\",\"JavaScript\"],\"tech\":[\"Ruby on Rails\",\"Sidekiq\",\"Redis\",\"Docker\",\"Heroku\",\"Nginx\"],\"architecture\":[\"Monolith\",\"REST\"],\"databases\":[\"PostgreSQL\",\"MySQL\"],\"ci_cd\":[\"CircleCI\",\"GitHub Actions\"],\"testing\":[\"RSpec\",\"Capybara\"]}\n\nJob Summary:\nEstablished marketplace company extending a Ruby on Rails monolith is hiring a senior backend engineer. Strong Rails experience required. Sidekiq for background jobs and Redis for caching expected. PostgreSQL as primary database. RSpec and Capybara for testing. Docker and Heroku for deployment. CircleCI for CI. Nginx for server configuration in production. REST API design and high-traffic production experience preferred.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Ruby on Rails, Sidekiq, and Redis are a direct match for the background job and caching stack\",\"PostgreSQL is the primary database and is confirmed\",\"RSpec and Capybara match the testing stack exactly\",\"Docker, Heroku, and CircleCI align with the deployment and CI tooling\",\"Nginx experience covers the production server configuration preference\"],\"gaps\":[],\"explanation\":\"Every technology named in the job description is confirmed in this candidate's profile. Their senior Rails experience with Sidekiq, RSpec, and production Nginx configuration makes them immediately productive in a monolith extension context. This is a high-confidence match with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"zk_blockchain\",\"seniority\":\"Mid\",\"roles\":[\"Blockchain Engineer\",\"Smart Contract Developer\"],\"languages\":[\"Solidity\",\"TypeScript\",\"Rust\"],\"tech\":[\"Hardhat\",\"Ethers.js\",\"OpenZeppelin\",\"React\",\"IPFS\"],\"architecture\":[\"Distributed System\"],\"testing\":[\"Chai\",\"Mocha\"]}\n\nJob Summary:\nDeFi protocol building a decentralized derivatives exchange is looking for a mid-level smart contract engineer. Deep Solidity experience required. OpenZeppelin libraries for secure contract patterns and Hardhat as the development environment are core to the stack. TypeScript and Ethers.js for integration scripts. Chai and Mocha for contract testing. Familiarity with common DeFi primitives and gas optimization is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Solidity, OpenZeppelin, and Hardhat are all directly required and present\",\"Ethers.js and TypeScript cover the integration scripting requirements exactly\",\"Chai and Mocha match the contract testing stack\",\"Rust background adds systems-level depth relevant to performance-critical contract work\",\"Distributed systems architecture understanding fits decentralized protocol design\"],\"gaps\":[\"No explicit mention of DeFi-specific primitives like AMMs or derivatives mechanisms\"],\"explanation\":\"The candidate's smart contract toolchain is a precise match for the DeFi protocol's stack. Hardhat, OpenZeppelin, Ethers.js, and the Chai/Mocha testing setup all align directly with the job requirements. The marginal uncertainty is whether their contract experience extends into derivatives-specific DeFi logic, which is domain knowledge not always visible in a GitHub profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fe_lead_mei\",\"seniority\":\"Lead\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Storybook\",\"Radix UI\",\"shadcn/ui\",\"Tailwind CSS\",\"Framer Motion\",\"Vite\"],\"architecture\":[\"Micro Frontend\",\"Monorepo\"],\"ci_cd\":[\"GitHub Actions\",\"Vercel\"],\"testing\":[\"Jest\",\"React Testing Library\",\"Playwright\"]}\n\nJob Summary:\nProduct company building a design-system-driven SaaS platform is looking for a lead frontend engineer. React and Next.js required. Deep TypeScript skills and Storybook for component documentation are essential. Radix UI or shadcn for headless components. Playwright and React Testing Library for testing. Micro-frontend or monorepo architecture experience strongly preferred. The role owns the component library and front-end platform decisions.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React, Next.js, and TypeScript directly match the core stack requirements\",\"Storybook is required and confirmed as a primary tool\",\"Radix UI and shadcn/ui are an exact match for the headless component requirement\",\"Playwright and React Testing Library cover the testing stack precisely\",\"Micro Frontend and Monorepo architecture experience directly addresses the strong preference\"],\"gaps\":[],\"explanation\":\"This candidate's profile is a near-perfect match for a lead frontend role centred on component library ownership. Every technology named in the job description is confirmed, including the less common combination of Radix UI and shadcn. Their lead seniority and micro-frontend architecture experience directly support the platform ownership and architectural decision-making responsibilities.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nest_guru_andrei\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"Prisma\",\"BullMQ\",\"Redis\",\"Docker\",\"AWS\",\"GraphQL\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"GraphQL\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nB2B SaaS platform building a workflow automation product needs a senior backend engineer. NestJS is the primary framework. BullMQ for job queuing and Redis for caching are core to the stack. PostgreSQL as primary database with Prisma as ORM. Docker and AWS deployments. GraphQL API layer alongside REST. Jest and Supertest for testing. TypeScript across the stack is required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS is the exact framework and is confirmed\",\"BullMQ and Redis directly match the job queue and caching requirements\",\"Prisma and PostgreSQL are an exact match for the ORM and database layer\",\"GraphQL architecture tag and tech entry align with the dual API requirement\",\"Jest and Supertest match the testing expectations\"],\"gaps\":[],\"explanation\":\"This candidate's profile aligns with every stated requirement of the role. The combination of NestJS, BullMQ, Redis, and Prisma demonstrates exactly the TypeScript backend engineering depth the SaaS platform needs. Their event-driven and microservices architecture experience reinforces fit for a workflow automation product context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"staff_java_lena\",\"seniority\":\"Staff\",\"roles\":[\"Software Architect\",\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\",\"Go\"],\"tech\":[\"Spring Boot\",\"Kafka\",\"Kubernetes\",\"Istio\",\"Terraform\",\"AWS\"],\"architecture\":[\"Microservices\",\"Domain-Driven Design\",\"CQRS\",\"Event-Driven\",\"Hexagonal Architecture\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"Argo CD\",\"GitHub Actions\",\"Jenkins\"],\"testing\":[\"JUnit\",\"k6\",\"Mockito\"]}\n\nJob Summary:\nPublicly traded enterprise software company hiring a staff engineer to lead architecture across multiple Java teams. Spring Boot and Kafka required. DDD, CQRS, and event-driven architecture must be practical experience not theoretical. Kubernetes and Istio for service mesh deployments on AWS. GitOps via Argo CD. JUnit and Mockito for testing culture. This is a hands-on technical leadership role with cross-team influence.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Java, Spring Boot, and Kafka are all directly required and confirmed\",\"DDD, CQRS, Hexagonal Architecture, and Event-Driven patterns demonstrate deep practical architectural experience\",\"Kubernetes and Istio cover the service mesh deployment standard\",\"Argo CD demonstrates GitOps experience\",\"Staff seniority and Software Architect role align with cross-team technical leadership expectations\"],\"gaps\":[],\"explanation\":\"This candidate is an exceptional match for a staff-level Java architecture role. Their profile demonstrates mastery of every technical domain named in the job description, from Spring Boot and Kafka to DDD, CQRS, Istio, and GitOps. The depth and breadth of architectural patterns combined with staff seniority make them precisely suited for cross-team technical leadership at an enterprise company.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mlops_riku\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"MLflow\",\"Weights & Biases\",\"FastAPI\",\"Docker\",\"Kubernetes\",\"AWS\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"Argo CD\",\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nRetail recommendation engine company looking for a senior MLOps engineer to own the full model lifecycle from training to deployment. MLflow or Weights and Biases for experiment tracking required. Docker and Kubernetes for model serving. FastAPI for model APIs. GitOps CI/CD with Argo CD. AWS as cloud provider. Python primary language. Feature store or data versioning experience is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Both MLflow and Weights and Biases present for experiment tracking, exceeding the requirement\",\"FastAPI, Docker, and Kubernetes directly match the model serving stack\",\"Argo CD demonstrates GitOps CI/CD experience\",\"AWS and Python are confirmed as required\",\"PyTorch adds model development credibility alongside the MLOps tooling\"],\"gaps\":[\"No feature store or data versioning tool visible, which is listed as a plus\"],\"explanation\":\"This candidate's profile aligns closely with the full MLOps lifecycle requirements, covering experiment tracking, containerised serving, API development, and GitOps deployment. The simultaneous presence of both MLflow and Weights and Biases is particularly strong evidence of mature experiment tracking practices. The only gap is the optional feature store experience, which is not a disqualifier.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tss_trpc_pierre\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"Next.js\",\"tRPC\",\"Prisma\",\"Tailwind CSS\",\"Zustand\",\"Docker\"],\"architecture\":[\"Serverless\",\"Monolith\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"Vercel\",\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nEarly-stage legaltech startup building a contract management product needs a mid-level full stack TypeScript engineer. Stack is Next.js with tRPC, Prisma, and PostgreSQL. Tailwind CSS for styling. Zustand or Jotai for state management. Vercel and GitHub Actions for deployment. Vitest and Playwright for testing. High ownership role contributing across the full product surface with minimal oversight.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js, tRPC, Prisma, and PostgreSQL are a precise match for the core stack\",\"Tailwind CSS and Zustand cover the styling and state management requirements\",\"Vercel and GitHub Actions align with the deployment and CI setup exactly\",\"Vitest and Playwright match the testing stack\",\"Supabase adds real-time and auth capability relevant to a product context\"],\"gaps\":[],\"explanation\":\"This candidate's TypeScript-first profile maps onto the startup's stack with precision. Every technology in the job description is confirmed, including the specific tRPC and Vitest combination that is distinctive to this stack. The serverless and monolith architecture tags are appropriate for a Vercel-deployed Next.js product.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vue_mid_felix\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\",\"Vite\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"Vitest\",\"Cypress\"]}\n\nJob Summary:\nTravel tech company looking for a mid-level frontend engineer with React and Next.js experience to build customer-facing booking flows. TypeScript required. Redux Toolkit for state management and React Query for data fetching. GitHub Actions for CI/CD. Accessibility standards and internationalization experience highly valued. Component-driven workflow with Storybook.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript proficiency confirmed and directly required\",\"Mid-level seniority matches the role grade\",\"Strong testing habits with Vitest and Cypress\",\"Tailwind CSS and Vite show modern frontend tooling familiarity\"],\"gaps\":[\"Vue.js and Nuxt.js do not map to the React and Next.js stack required\",\"No Redux Toolkit or React Query experience visible\",\"GitLab CI does not match the GitHub Actions CI/CD standard\",\"No Storybook or accessibility/internationalization work demonstrated\"],\"explanation\":\"The candidate is a capable mid-level frontend engineer but their stack is Vue-based rather than React-based, which is a significant technical mismatch. TypeScript and testing discipline transfer well, but they would need meaningful ramp-up on React, Next.js, and the state management tooling. This is a moderate fit requiring onboarding investment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"go_mid_nikolai\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Gin\",\"gRPC\",\"Docker\",\"AWS\",\"Redis\"],\"architecture\":[\"Microservices\",\"REST\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nStreaming video infrastructure company needs a mid-level backend engineer in Go. gRPC and microservices for internal service communication. Docker and AWS for deployment. Redis for pub/sub or caching. High-concurrency design patterns expected. WebSocket or HLS streaming protocol experience is a strong plus. Go-native testing practices required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go with Gin and gRPC directly matches the language and RPC requirements\",\"Microservices architecture aligns with the distributed infrastructure approach\",\"Docker, AWS, and Redis cover the deployment and caching stack\",\"Mid-level seniority matches the role grade\"],\"gaps\":[\"No WebSocket or streaming protocol experience visible, which is a strong plus for this domain\",\"Testing is only shown in Python via pytest with no Go-native testing evidence\"],\"explanation\":\"The candidate's Go backend experience with gRPC, Gin, and microservices aligns well with the core requirements of a streaming infrastructure role. The absence of WebSocket or HLS streaming experience is a notable gap for a video delivery platform. Go-specific testing discipline is also not clearly demonstrated, which matters for a team that expects idiomatic Go practices.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"data_analyst_mkwon\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"Python\",\"SQL\",\"R\"],\"tech\":[\"Pandas\",\"Tableau\",\"NumPy\"],\"databases\":[\"PostgreSQL\",\"MySQL\"]}\n\nJob Summary:\nGrowth-stage startup hiring a mid-level data analyst to own dashboards, define metrics, and run ad hoc analysis for product and marketing. SQL and Python required. Tableau or Looker for dashboarding. BigQuery or Redshift for data access. dbt for transformation familiarity preferred. Cross-functional communication with non-technical stakeholders expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SQL, Python, and Tableau directly match core analytical requirements\",\"R adds statistical depth useful for ad hoc analysis\",\"Pandas and NumPy indicate solid data manipulation capability\"],\"gaps\":[\"Junior seniority is below the mid-level requirement\",\"No BigQuery or Redshift experience, only PostgreSQL and MySQL\",\"No dbt experience for transformation workflows\",\"No Looker as the alternative BI tool\"],\"explanation\":\"The candidate has the right foundational analytical toolkit in Python, SQL, and Tableau but their junior seniority and lack of cloud data warehouse and dbt experience are meaningful gaps. They could grow into this role but would require ramp-up time on the modern data stack. A moderately qualified profile for a role expecting more independence.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devops_mid_yusuf\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"Terraform\",\"AWS\",\"Nginx\"],\"ci_cd\":[\"GitHub Actions\",\"CircleCI\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nInsurtech company scaling cloud infrastructure needs a mid-level cloud engineer with multi-cloud experience on AWS and Azure or GCP. Terraform for IaC required. Kubernetes for container orchestration required. Datadog for monitoring. Python or Bash for automation. Security and compliance posture management experience strongly preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"AWS and Terraform match part of the cloud and IaC requirements\",\"Docker provides containerisation familiarity\",\"Python and Bash meet the automation scripting expectation\",\"GitHub Actions and CircleCI cover CI/CD pipeline operation\"],\"gaps\":[\"No Azure or GCP experience for multi-cloud requirement\",\"No Kubernetes experience, which is required for container orchestration\",\"No Datadog or monitoring tooling visible\",\"No security or compliance posture management experience\"],\"explanation\":\"The candidate covers the basics of cloud infrastructure with AWS and Terraform but misses several key requirements including multi-cloud support, Kubernetes, and observability tooling. The absence of security and compliance experience is a notable gap for a regulated insurance company. This profile would require meaningful upskilling across multiple dimensions.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ds_yemi_senior\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"Weights & Biases\",\"NumPy\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"]}\n\nJob Summary:\nRetail analytics company hiring a senior data scientist to build and deploy recommendation models. Python and scikit-learn or PyTorch required. MLflow or Weights and Biases for experiment tracking. SQL and BigQuery for data access. Models deployed as REST APIs. A/B testing framework familiarity is a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch, scikit-learn, and Python directly match the modeling requirements\",\"Weights and Biases covers experiment tracking\",\"BigQuery and SQL are confirmed for data access\",\"Senior seniority fits the ownership expectations\"],\"gaps\":[\"No model deployment or REST API serving experience visible\",\"No A/B testing framework experience demonstrated\"],\"explanation\":\"The candidate is strong on the modeling and experimentation side but shows no evidence of deploying models as REST APIs, which is an explicit requirement. A/B testing experience is also absent. These are operationally important for a data scientist expected to ship production recommendation systems in a retail context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cms_dev_tony\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"PHP\"],\"tech\":[\"WordPress\",\"React\",\"Nginx\",\"Docker\"],\"architecture\":[\"Monolith\",\"REST\"],\"databases\":[\"MySQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nDigital publishing company building a headless CMS architecture needs a mid-level developer with strong WordPress and React experience. WordPress REST API or WPGraphQL. React for the frontend. MySQL and Docker expected. ACF, custom post types, and plugin development experience required. GitHub Actions for CI. Nginx for server configuration.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"WordPress and React directly match the headless CMS architecture requirements\",\"MySQL, Docker, Nginx, and GitHub Actions all align with the supporting stack\",\"REST architecture aligns with the WordPress REST API usage pattern\"],\"gaps\":[\"No WPGraphQL experience mentioned\",\"No visible ACF, custom post type, or WordPress plugin development in the profile\"],\"explanation\":\"The candidate has the right foundational combination of WordPress and React for a headless CMS role but the absence of ACF and plugin development experience is a meaningful gap for a publishing company that relies heavily on these customisation patterns. They are a moderate fit with room to validate deeper WordPress CMS expertise before committing.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"security_hana\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\",\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"AWS\",\"Terraform\",\"Docker\",\"Vault\",\"Prometheus\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nCybersecurity SaaS company needs a senior security engineer to own application security, cloud security posture management, and secrets management with HashiCorp Vault. AWS security controls and Terraform for IaC required. Python or Bash scripting expected. Threat modeling, SAST/DAST tooling, and secure SDLC practices are core expectations. Go knowledge a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"HashiCorp Vault directly matches the secrets management requirement\",\"AWS, Terraform, Python, and Bash cover infrastructure and scripting needs\",\"Go knowledge addresses the internal tooling plus\",\"Senior seniority aligns with the ownership expectations\"],\"gaps\":[\"No SAST or DAST tooling experience visible\",\"No threat modeling or secure SDLC methodology demonstrated\",\"No explicit application security engineering work beyond the role label\"],\"explanation\":\"The candidate has a solid cloud infrastructure and secrets management background but the job places significant weight on application security practices like threat modeling and SAST/DAST tooling, which are not visible in the profile. These are core expectations for a cybersecurity SaaS company, not optional extras, and represent a meaningful skills gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sveltekit_dev_jo\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Svelte\",\"SvelteKit\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nBootstrapped developer productivity startup needs a mid-level frontend engineer with React experience. TypeScript required. Next.js for the frontend framework. Tailwind CSS for styling. State management with Zustand or Context API. Node.js backend contributions expected. Vitest or Jest for testing.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript proficiency confirmed and required\",\"Tailwind CSS is used by the team and is present\",\"Vitest and Playwright demonstrate solid testing discipline\",\"Mid-level seniority matches the role grade\"],\"gaps\":[\"SvelteKit background does not map to the React and Next.js stack required\",\"No state management library experience visible\",\"No Node.js backend contribution experience shown\"],\"explanation\":\"The candidate has strong TypeScript and testing fundamentals but their SvelteKit focus is a framework mismatch for a React and Next.js team. TypeScript and Tailwind transfer well, but they would need to ramp up on React, Next.js, state management, and Node.js backend contributions. This represents a moderate fit with notable onboarding requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"flutter_mina\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"JavaScript\"],\"tech\":[\"Flutter\",\"Firebase\",\"Expo\"],\"databases\":[\"Firestore\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nHealthtech startup hiring a mid-level mobile engineer with React Native experience to build a cross-platform patient app. TypeScript required. REST API integration and offline-first data patterns. Expo or bare React Native workflow. Familiarity with HIPAA data handling practices would be strongly valued.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Expo experience is relevant and directly mentioned in the job\",\"Cross-platform mobile development background with Flutter demonstrates relevant mobile domain depth\",\"Firebase and Firestore show mobile backend integration familiarity\"],\"gaps\":[\"Flutter and Dart background does not map to the React Native and TypeScript stack required\",\"No REST API integration patterns visible\",\"No offline-first data experience demonstrated\",\"No HIPAA or healthcare data handling awareness\"],\"explanation\":\"The candidate has solid cross-platform mobile experience but in Flutter rather than React Native, which are distinct ecosystems with different tooling and language requirements. The Expo presence is a partial bridge, but the TypeScript and React Native gap is significant. Combined with the absence of healthcare data sensitivity, this is a moderate rather than strong fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"platform_dmitri\",\"seniority\":\"Senior\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"Google Cloud\",\"Prometheus\",\"Grafana\",\"Docker\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"Argo CD\",\"GitHub Actions\"]}\n\nJob Summary:\nMedia streaming company running on AWS needs a senior platform engineer to manage EKS clusters, write Terraform modules, and maintain CI/CD pipelines. AWS is the primary cloud provider. Helm and Kubernetes required. Prometheus and Grafana for observability. Argo CD for GitOps. Go for internal tooling. Candidate will own the developer platform across dozens of engineering teams.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes, Helm, Terraform, Prometheus, Grafana, and Argo CD are all directly required and present\",\"Go scripting meets the internal tooling expectation\",\"Cloud-native and microservices background is relevant\",\"Senior seniority aligns with the ownership scope\"],\"gaps\":[\"Primary cloud experience is Google Cloud, not AWS, which is the required provider\",\"No EKS-specific experience visible, as AWS Kubernetes operations may differ from GKE\"],\"explanation\":\"This candidate has strong platform engineering fundamentals with all the required tooling except the cloud provider. Their experience is GCP-centric rather than AWS-centric, creating uncertainty around AWS-specific services like EKS and the broader AWS ecosystem. The platform skills transfer well but cloud provider context requires validation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"junior_nest_jules\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Express.js\",\"Prisma\",\"Docker\"],\"architecture\":[\"REST\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nWorkflow automation company hiring a mid-level backend engineer with Node.js and TypeScript experience. NestJS or Express.js for the API layer. Prisma or TypeORM as ORM. PostgreSQL as database. Docker and AWS deployments. BullMQ for background jobs. Redis for caching. REST API design and basic microservices understanding expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript and Express.js are present and relevant to the backend stack\",\"Prisma and PostgreSQL directly match the ORM and database requirements\",\"Docker addresses part of the deployment stack\",\"REST architecture experience aligns with the API design expectations\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement\",\"No AWS experience for cloud deployment\",\"No BullMQ or Redis experience for background jobs and caching\",\"No microservices architecture experience beyond the REST tag\"],\"explanation\":\"The candidate has a solid foundation in the TypeScript, Express, Prisma, and PostgreSQL stack covering a meaningful portion of the role's requirements. However, junior seniority and the absence of AWS, BullMQ, and Redis experience mean they are not ready for independent mid-level ownership. They could be a strong junior-to-mid track hire with targeted mentorship.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vue_nuxt_jade\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\"],\"databases\":[\"Firebase\"],\"testing\":[\"Vitest\"]}\n\nJob Summary:\nDigital product agency looking for a mid-level Vue.js developer. Vue 3 with Composition API and Nuxt.js for SSR. Pinia for state management. TypeScript required. Tailwind CSS. REST API integration expected. At least two years of professional Vue.js experience preferred. Multi-client project delivery experience valued.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Vue.js, Nuxt.js, Pinia, and Tailwind CSS are all directly aligned with the job stack\",\"TypeScript proficiency confirmed\",\"Vitest shows testing familiarity in the Vue ecosystem\"],\"gaps\":[\"Junior seniority falls below the mid-level and two-year professional experience expectation\",\"No REST API integration experience visible\",\"No multi-project or client-facing delivery evidence\"],\"explanation\":\"The candidate's technical stack is a strong match for a Vue-focused agency role but their junior seniority and absence of REST API and client-facing project experience mean they are not yet at the level expected for independent delivery. They could be a strong fit with additional mentorship and real-world project exposure.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_researcher_ana\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"Data Scientist\"],\"languages\":[\"Python\",\"Julia\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"CUDA\",\"Weights & Biases\",\"NumPy\",\"scikit-learn\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nAI research lab hiring a senior ML research engineer to develop novel NLP architectures and run large-scale training experiments. Deep PyTorch required. Hugging Face Transformers for model development and fine-tuning. CUDA for GPU optimisation. Weights and Biases for tracking. Distributed multi-GPU training experience expected. Open-source or publication contributions in NLP strongly valued.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch and Hugging Face Transformers are both directly required and present\",\"CUDA proficiency covers the GPU optimisation requirement\",\"Weights and Biases is the experiment tracking tool in use\",\"Julia adds rare computational research depth valued in research environments\"],\"gaps\":[\"No distributed or multi-GPU training experience explicitly visible\",\"No open-source NLP contribution or publication evidence in the profile\"],\"explanation\":\"The candidate's core ML research toolchain is a strong match with PyTorch, Hugging Face, CUDA, and Weights and Biases all confirmed. The notable gap is the absence of visible multi-GPU distributed training experience, which is an explicit requirement for large-scale experiments at a research lab. The lack of open-source NLP contributions is also a meaningful differentiator at this level.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"spring_mid_victor\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Python\"],\"tech\":[\"Spring Boot\",\"Docker\",\"AWS\",\"Redis\"],\"architecture\":[\"REST\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MySQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nEnterprise HR platform hiring a senior Java backend engineer. Spring Boot required. Kafka for event streaming between microservices. Kubernetes for deployment on AWS. PostgreSQL as primary database. JUnit and Mockito for testing. Domain-driven design principles expected at the senior level. The role involves mentoring junior developers.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Java and Spring Boot are directly required and confirmed\",\"AWS and Docker provide a deployment foundation\",\"PostgreSQL, JUnit, and Mockito match the database and testing requirements\",\"Microservices architecture aligns with the system design approach\"],\"gaps\":[\"Mid-level seniority does not meet the senior-level requirement with mentoring responsibilities\",\"No Kafka experience for event streaming between microservices\",\"No Kubernetes experience, which is the required container orchestration platform\",\"No domain-driven design background demonstrated\"],\"explanation\":\"The candidate covers the Java and Spring Boot foundation well but falls short on seniority and several key technical requirements. The absence of Kafka and Kubernetes is particularly significant for a microservices-heavy enterprise platform where these are core infrastructure tools. The mentoring expectation at senior level further widens the gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"analytics_eng_isa\",\"seniority\":\"Mid\",\"roles\":[\"Analytics Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Looker\",\"Metabase\",\"Pandas\"],\"databases\":[\"BigQuery\",\"Snowflake\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Great Expectations\"]}\n\nJob Summary:\nMarketplace startup looking for a mid-level analytics engineer to own the dbt transformation layer on BigQuery. Build and maintain Looker dashboards. Define and document data models. Collaborate with product and marketing analysts. SQL proficiency required. Data quality testing expected. Airflow or Prefect for pipeline orchestration a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt and BigQuery are a direct match for the core transformation stack\",\"Looker experience aligns with the dashboard tooling\",\"Great Expectations covers data quality testing\",\"SQL proficiency confirmed as the primary analytical language\"],\"gaps\":[\"No Airflow or Prefect experience for pipeline orchestration, which is listed as a plus\",\"No explicit data modeling documentation practices visible in the profile\"],\"explanation\":\"This candidate is a solid match for the core analytics engineering work with dbt, BigQuery, Looker, and Great Expectations all confirmed. The modest gaps are around orchestration tooling and documentation practices, neither of which is a hard requirement. This is a moderate rather than strong match only because the orchestration plus is absent and the role may grow to require it.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cloud_intern_rin\",\"seniority\":\"Intern\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"AWS\",\"GitHub Actions\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nSeries A startup looking for a junior DevOps engineer to assist with AWS infrastructure management, Docker-based deployments, and CI/CD pipelines using GitHub Actions. Terraform familiarity preferred. Python or Bash scripting required. This is a growth role with mentorship from senior engineers. Some Kubernetes exposure is a bonus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Docker, AWS, and GitHub Actions are all directly relevant and present\",\"Python and Bash meet the scripting requirement\",\"Intern background combined with a junior-targeted role description reduces the seniority gap\"],\"gaps\":[\"Intern seniority is below the junior level expectation\",\"No Terraform experience, which is the preferred IaC tool\",\"No Kubernetes exposure at any level\"],\"explanation\":\"The candidate's technical foundation in Docker, AWS, and GitHub Actions maps well to a junior DevOps role, and the gap between intern and junior seniority is narrower than for more senior positions. The absence of Terraform and Kubernetes is notable but not disqualifying for a growth role with mentorship. This is a moderate fit with room to grow quickly.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"react_native_omar\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React Native\",\"Expo\",\"Redux\",\"Firebase\"],\"databases\":[\"Firestore\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Detox\"]}\n\nJob Summary:\nFitness app company looking for a mid-level React Native engineer. TypeScript required. Expo managed workflow. Redux or Zustand for state management. REST API integration and offline-first storage with SQLite or AsyncStorage. Jest and Detox for testing. Fastlane for release automation preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React Native, TypeScript, and Expo are directly required and confirmed\",\"Redux addresses the state management requirement\",\"SQLite and Jest plus Detox match the storage and testing stack\",\"Mid-level seniority is appropriate\"],\"gaps\":[\"No Fastlane experience for release automation, which is preferred\",\"No explicit REST API integration patterns visible beyond Firebase usage\"],\"explanation\":\"The candidate's React Native and TypeScript profile covers the core requirements well, with Expo, Redux, SQLite, and the Detox testing stack all aligned. The main gap is the absence of Fastlane for release automation, which is a preferred skill for a fitness app that likely ships frequent updates. REST API integration depth is also unconfirmed beyond Firebase-based workflows.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elixir_mid_bene\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Elixir\",\"JavaScript\"],\"tech\":[\"Phoenix\",\"Docker\",\"Redis\"],\"architecture\":[\"Event-Driven\",\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nReal-time chat infrastructure company hiring a senior Elixir engineer. Phoenix required. OTP patterns and distributed Elixir for fault tolerance. PostgreSQL and Redis for data and pub/sub. Docker and AWS deployments. Deep understanding of concurrency models expected. Senior-level ownership with mentoring responsibilities.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Elixir and Phoenix are directly required and confirmed\",\"Event-Driven architecture and PostgreSQL plus Redis match the concurrency and data stack\",\"ExUnit shows Elixir-native testing discipline\",\"Docker and GitHub Actions cover deployment and CI basics\"],\"gaps\":[\"Mid-level seniority does not meet the senior-level requirement with mentoring responsibilities\",\"No AWS experience for cloud deployment\",\"No explicit OTP or distributed Elixir pattern work visible beyond implied usage\"],\"explanation\":\"The candidate has the right Elixir and Phoenix foundation for a real-time infrastructure role, but falls short on seniority and AWS experience. The depth of OTP and distributed Elixir knowledge, which is central to fault-tolerant concurrent system design, is also not clearly demonstrated beyond the event-driven architecture tag. Senior mentoring responsibilities are a further stretch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"php_mid_oscar\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"Laravel\",\"Vue.js\",\"Redis\",\"Docker\",\"Nginx\"],\"architecture\":[\"Monolith\",\"REST\"],\"databases\":[\"MySQL\",\"PostgreSQL\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nDigital agency with enterprise clients looking for a senior full stack developer with Laravel and Vue.js experience. PHPUnit tests and Docker required. MySQL and Redis primary data stores. GitLab for CI/CD. Nginx server configuration. This role involves client-facing communication and leading technical decisions on projects.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Laravel and Vue.js are a direct stack match\",\"PHPUnit, Docker, MySQL, Redis, GitLab CI, and Nginx all confirmed and required\",\"REST API and monolith architecture experience aligns with agency project types\"],\"gaps\":[\"Mid-level seniority does not meet the senior-level expectation for technical leadership\",\"No client-facing communication or project leadership experience visible in profile\"],\"explanation\":\"This candidate's technical stack is an excellent match for the agency's tools, with every named technology confirmed. The gap is primarily in seniority and the client-facing, decision-making expectations of a senior role. Strong technical alignment means they could contribute quickly, but the leadership gap may require evaluation through the interview process.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_classical_carlos\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"TensorFlow\",\"scikit-learn\",\"MLflow\",\"Pandas\",\"NumPy\",\"Docker\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"]}\n\nJob Summary:\nAI startup building LLM-powered customer support automation needs a senior ML engineer. Hands-on LLM fine-tuning experience required. Hugging Face Transformers core to the stack. PyTorch required. RAG pipeline and vector database experience strongly preferred. LangChain for LLM orchestration. Model deployment via FastAPI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Strong classical ML engineering background with TensorFlow, scikit-learn, and MLflow\",\"Docker supports model deployment workflows\",\"Senior ML seniority aligns with the experience level expected\"],\"gaps\":[\"No PyTorch experience, which is explicitly required\",\"No Hugging Face Transformers or LLM fine-tuning experience visible\",\"No RAG pipeline or vector database knowledge\",\"No LangChain or LLM orchestration tooling\",\"No FastAPI for model serving\"],\"explanation\":\"The candidate has a strong traditional ML engineering background but lacks the LLM-specific stack this role demands. PyTorch is a hard requirement that is absent, and there is no evidence of experience with Hugging Face, RAG, or LangChain. Their profile is better suited to classical ML roles than LLM product engineering, placing this as a moderate fit at best given their senior experience level.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"intern_sam\",\"seniority\":\"Intern\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"React\",\"Tailwind CSS\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nProduct startup hiring a mid-level frontend engineer. At least two years of professional React experience. TypeScript required. Redux or Zustand for state management. REST API integration and Git-based team workflows. Next.js a bonus. We value clean code and collaborative PR culture.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and Tailwind CSS are relevant to the job stack\"],\"gaps\":[\"Intern seniority does not meet the two-year professional experience requirement\",\"No TypeScript experience, which is required\",\"No state management library visible in the profile\",\"No REST API integration or Next.js experience\"],\"explanation\":\"While the candidate has made a start with React and Jest, their intern-level profile falls well short of the professional experience and technical breadth this role requires. The absence of TypeScript and state management are concrete gaps that would need significant mentorship to bridge. This is not a match for the described expectations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wordpress_paul\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"WordPress\",\"Nginx\",\"Docker\"],\"architecture\":[\"Monolith\",\"REST\"],\"databases\":[\"MySQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nSeries C analytics startup building a real-time data pipeline platform needs a mid-level backend engineer in Python or Go. Event-driven microservices with Apache Kafka. PostgreSQL or ClickHouse for analytics workloads. Kubernetes and Docker for deployment. Strong API design and distributed systems thinking required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker and GitHub Actions provide basic infrastructure familiarity\"],\"gaps\":[\"No Python or Go experience, which are the required languages\",\"WordPress and PHP do not align with analytics platform or distributed systems work\",\"No Kafka or event-driven microservices experience\",\"No PostgreSQL or ClickHouse for analytics workloads\",\"No Kubernetes experience\"],\"explanation\":\"This candidate's background is heavily oriented toward CMS and PHP development, which is a significant domain mismatch for a real-time analytics pipeline role. The required languages, frameworks, and distributed systems experience are all absent. A career transition of this scope would require substantial reskilling before this candidate could contribute meaningfully.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"embedded_haruto\",\"seniority\":\"Mid\",\"roles\":[\"Embedded Engineer\"],\"languages\":[\"C\",\"C++\",\"Python\"],\"tech\":[\"CUDA\",\"CMake\"],\"architecture\":[\"Client-Server\"]}\n\nJob Summary:\nAutonomous vehicle company building sensor data pipelines needs a senior backend engineer in Python and Go. Apache Kafka for event streaming, Docker and Kubernetes for deployment, AWS or GCP for cloud. Distributed system design required. The role is not embedded or firmware engineering.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python proficiency is present and relevant to backend work\"],\"gaps\":[\"Mid-level seniority falls below the senior-level requirement\",\"Embedded engineering domain does not match the distributed backend role\",\"No Go experience, which is a core language\",\"No Kafka, Docker, or Kubernetes experience\",\"No cloud infrastructure experience with AWS or GCP\"],\"explanation\":\"Despite having Python skills, this candidate's background is in embedded systems, which is explicitly not what this role requires. The absence of Go, Kafka, Kubernetes, and cloud infrastructure means they would need to rebuild their skill set substantially. This is a significant mismatch in domain, tooling, and seniority.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_intern_sara\",\"seniority\":\"Intern\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nRobotics company building perception models needs a mid-level ML engineer with PyTorch and CUDA for GPU acceleration. OpenCV for computer vision. ROS or embedded model deployment experience strongly preferred. Two years of production ML experience deploying to real hardware required. C++ for performance-critical modules a plus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"scikit-learn and Python show foundational ML knowledge\"],\"gaps\":[\"Intern seniority is significantly below the mid-level and two-year production requirement\",\"No PyTorch, which is required for deep learning model development\",\"No CUDA or GPU computing experience\",\"No OpenCV or computer vision work visible\",\"No ROS or embedded ML deployment experience\",\"No C++ for performance-critical modules\"],\"explanation\":\"This is a poor match. The candidate's intern-level scikit-learn profile is in a different tier from what a robotics company requires for hardware-deployed perception models. Every specific technical requirement, from PyTorch to CUDA and OpenCV, is absent. This candidate is at the beginning of an ML career and not ready for production robotics engineering.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"junior_django_cleo\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"Flask\",\"Docker\"],\"databases\":[\"PostgreSQL\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nWellness SaaS platform hiring a senior backend engineer. Python and Django required. Celery for async task processing, Redis for caching, PostgreSQL for data. AWS and Kubernetes for cloud deployments. Mentoring junior developers and leading backend technical decisions expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and PostgreSQL are relevant to the tech stack\",\"pytest shows basic testing discipline\"],\"gaps\":[\"Junior seniority is significantly below the senior-level requirement with mentoring responsibilities\",\"Flask does not substitute for the Django framework requirement\",\"No Celery or async task processing experience\",\"No Redis for caching\",\"No AWS or Kubernetes experience\"],\"explanation\":\"While the candidate has Python and PostgreSQL experience, they fall significantly short of the senior backend requirements in both seniority and technical depth. The absence of Django, Celery, Redis, AWS, and Kubernetes are concrete gaps that would prevent independent contribution in this role. The mentoring and leadership expectations are well beyond the candidate's current profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"game_dev_obi\",\"seniority\":\"Junior\",\"roles\":[\"Game Developer\"],\"languages\":[\"C++\",\"C#\"],\"tech\":[\"Unity\",\"WebGL\"],\"architecture\":[\"Client-Server\"]}\n\nJob Summary:\nAdtech platform building programmatic advertising systems needs a mid-level backend engineer. Python or Go required. Real-time bidding, Kafka for event streaming, PostgreSQL or Cassandra for high-volume storage. Docker and Kubernetes for deployment. REST API design and low-latency system optimisation core requirements. Not a game or graphics engineering role.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"C++ background suggests some awareness of performance-critical system design\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement\",\"No Python or Go experience, which are the required languages\",\"Game development background does not transfer to programmatic advertising systems\",\"No Kafka, PostgreSQL, or Cassandra experience\",\"No Docker or Kubernetes experience\"],\"explanation\":\"This candidate's background in Unity and WebGL game development has minimal overlap with a backend adtech engineering role. The required languages, distributed data systems, and cloud infrastructure are all absent. Their junior seniority adds to the mismatch, and the job explicitly notes it is not a game engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"junior_ml_fe\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Next.js\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nAI infrastructure company hiring a senior ML platform engineer. Python required. MLflow and Kubeflow for ML pipeline orchestration. Kubernetes and Docker for containerised model serving. Familiarity with distributed training frameworks like Horovod or DeepSpeed. AWS or GCP cloud platform experience. This is a backend and infrastructure focused role.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Frontend engineering background does not align with an ML infrastructure role\",\"No Python experience, which is the primary language required\",\"No MLflow, Kubeflow, or ML pipeline tooling experience\",\"No Kubernetes or Docker experience for model serving\",\"No distributed training or cloud infrastructure experience\",\"Junior seniority is well below the senior-level requirement\"],\"explanation\":\"This candidate is a frontend engineer with no visible backend, infrastructure, or machine learning experience. Every technical requirement of the ML platform role, from Python and Kubernetes to MLflow and distributed training, is absent. This is a fundamental domain mismatch with no meaningful overlap in skills.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"intern_mobile_mina\",\"seniority\":\"Intern\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\"],\"tech\":[\"Flutter\",\"Firebase\"],\"databases\":[\"Firestore\"]}\n\nJob Summary:\nHealthtech startup looking for a mid-level React Native engineer. TypeScript required. Cross-platform patient app with offline-first data patterns and REST API integration. Expo workflow preferred. HIPAA data handling familiarity strongly valued. At least two years professional mobile experience expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Cross-platform mobile development with Flutter shows relevant mobile domain foundation\"],\"gaps\":[\"Intern seniority does not meet the mid-level and two-year professional experience requirement\",\"Flutter and Dart do not map to the React Native and TypeScript stack required\",\"No REST API integration patterns visible\",\"No offline-first data experience\",\"No HIPAA or healthcare data handling awareness\"],\"explanation\":\"The candidate has mobile development experience but in the wrong framework and at an intern level. Flutter and React Native are distinct ecosystems requiring different tooling and language skills. Combined with the junior seniority and the absence of healthcare data compliance awareness, this profile does not meet the role's expectations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"analyst_junior_tamar\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Tableau\",\"Pandas\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nFAANG-adjacent adtech company hiring a senior data analyst. Petabyte-scale analytics in BigQuery or Redshift required. Looker for dashboarding. Amplitude or Mixpanel for product analytics. A/B testing and statistically rigorous measurement frameworks. Strong stakeholder communication and autonomous analytical ownership. Senior level with at least four years of relevant experience.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"SQL and Python proficiency are present and required\",\"Tableau shows BI dashboard experience\"],\"gaps\":[\"Junior seniority and lack of four-plus years of experience does not meet the senior requirement\",\"No BigQuery or Redshift experience for petabyte-scale analytics\",\"No Looker, Amplitude, or Mixpanel experience\",\"No A/B testing or statistical measurement framework experience\",\"No evidence of senior-level stakeholder management or autonomous ownership\"],\"explanation\":\"The candidate has foundational analytical skills in SQL, Python, and Tableau but is significantly underprepared for the scope and scale of this FAANG-adjacent role. The cloud data warehouse, product analytics tooling, A/B testing, and senior ownership expectations all represent substantial gaps. Seniority level is the most immediate disqualifier, compounded by missing technical tools.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"spark_dev_ethan\",\"seniority\":\"Junior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Pandas\",\"Apache Airflow\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nFinancial institution building a centralised data platform needs a senior data engineer. Deep Apache Spark and Kafka expertise. Scala or Python proficiency. dbt for transformation and Snowflake or Redshift as the warehouse. Great Expectations for data quality. Distributed system design for high-volume financial data required. Senior leadership and cross-team collaboration expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and Airflow demonstrate basic pipeline and orchestration awareness\"],\"gaps\":[\"Junior seniority is well below the senior-level and leadership requirement\",\"No Apache Spark or Kafka experience, which are core requirements\",\"No Scala proficiency\",\"No dbt experience for the transformation workflow\",\"No Snowflake or Redshift data warehouse experience\",\"No Great Expectations for data quality\"],\"explanation\":\"The candidate has early-stage data engineering foundations in Python and Airflow but lacks the depth required for a senior financial data platform role. Apache Spark, Kafka, dbt, and Snowflake are all absent, and the seniority gap is wide. This profile is suitable for a junior data engineering role, not a senior cross-team leadership position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ios_junior_lin\",\"seniority\":\"Junior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"Firebase\"],\"databases\":[\"Firestore\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nConsumer app with 8 million iOS users hiring a senior iOS engineer. SwiftUI and Swift required. Fastlane for automated releases, XCTest and XCUITest for testing. Deep REST API integration with complex token-based auth. Architecture-level ownership and mentoring junior engineers. Performance profiling and memory optimisation at scale expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"SwiftUI and Swift are directly required and confirmed\",\"XCTest shows basic testing awareness\"],\"gaps\":[\"Junior seniority is significantly below the senior-level requirement with mentoring responsibilities\",\"No Fastlane experience for automated release pipelines\",\"No XCUITest experience beyond basic XCTest\",\"No complex REST API or token-based authentication experience visible\",\"No performance profiling or memory optimisation at scale demonstrated\"],\"explanation\":\"The candidate has the right foundational iOS stack with SwiftUI and Swift but falls well short of the senior expectations in both seniority and depth. The absence of Fastlane, XCUITest, complex auth integration, and performance engineering experience are concrete gaps for an app serving 8 million users. The mentoring responsibility further highlights the seniority mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"php_intern_leo\",\"seniority\":\"Intern\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"Laravel\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nGlobal e-commerce platform building event-driven microservices needs a mid-level backend engineer. Python or Go primary languages. Apache Kafka for event streaming. PostgreSQL for transactional data. Kubernetes and Docker for deployment. REST API design and distributed system patterns required. High-traffic production experience expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Some backend web development foundation with Laravel\"],\"gaps\":[\"Intern seniority does not meet the mid-level requirement\",\"PHP and Laravel do not align with the Python or Go language requirements\",\"No Kafka or event-driven microservices experience\",\"No PostgreSQL experience, only MySQL\",\"No Kubernetes or Docker experience for deployment\",\"No distributed systems background\"],\"explanation\":\"This candidate's PHP and Laravel background has minimal overlap with a Python or Go-based event-driven microservices platform. The required languages, infrastructure tooling, and distributed systems experience are all absent, and the intern seniority adds a further significant gap. This profile is not suitable for the described role without extensive reskilling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fe_only_grace\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Pinia\",\"Tailwind CSS\"],\"testing\":[\"Vitest\"]}\n\nJob Summary:\nMid-stage fintech company building high-frequency trading dashboards needs a senior full stack engineer. React and TypeScript on the frontend. Go or Rust on the backend for low-latency services. PostgreSQL and Redis. Docker and Kubernetes on AWS. gRPC for internal services. Deep understanding of financial data models and system performance required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript proficiency is present\"],\"gaps\":[\"Junior seniority is well below the senior-level requirement\",\"Vue.js background does not match the React frontend requirement\",\"No Go or Rust experience for the backend low-latency services\",\"No PostgreSQL, Redis, Docker, Kubernetes, or AWS experience\",\"No gRPC or financial data model experience\"],\"explanation\":\"This candidate has a limited frontend Vue.js profile that mismatches almost every technical requirement of a senior full stack fintech role. The backend requirements in Go or Rust, combined with the infrastructure stack and financial domain expertise, are entirely absent. Seniority and domain depth are both significant disqualifiers.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"notebook_dan\",\"seniority\":\"Intern\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"Matplotlib\"]}\n\nJob Summary:\nEnterprise MLOps platform company hiring a senior MLOps engineer. MLflow and Kubeflow required. Kubernetes and Docker for containerised model serving. Terraform for infrastructure as code. Python for automation. AWS or Azure cloud. CI/CD pipelines for model retraining and deployment. Experience productionising ML models at scale with at least five years of relevant experience.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and scikit-learn provide a machine learning foundation\"],\"gaps\":[\"Intern seniority with no production experience does not meet the five-year senior requirement\",\"No MLflow or Kubeflow experience for ML pipeline orchestration\",\"No Kubernetes or Docker for containerised model serving\",\"No Terraform or infrastructure as code experience\",\"No AWS or Azure cloud experience\",\"No CI/CD pipeline experience for model retraining\"],\"explanation\":\"This candidate is a data science intern with notebook-level ML skills and no production or infrastructure experience. Every technical requirement for a senior MLOps engineer, from Kubernetes and Kubeflow to Terraform and cloud infrastructure, is absent. This profile would need several years of engineering-focused growth before being considered for an MLOps role at this level.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kotlin_mid_ryo\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Spring Boot\",\"Docker\",\"AWS\"],\"architecture\":[\"REST\",\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nEnterprise SaaS platform hiring a senior backend engineer. Kotlin and Spring Boot preferred. Kafka for async messaging between microservices. Kubernetes for deployment on AWS. PostgreSQL required. JUnit and Mockito for testing. Senior-level mentoring and system design contributions expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin, Spring Boot, AWS, PostgreSQL, JUnit, and Mockito are all directly aligned with the job requirements\",\"Microservices architecture background fits the system design context\",\"Docker provides a containerisation foundation\"],\"gaps\":[\"Mid-level seniority does not meet the senior requirement with mentoring responsibilities\",\"No Kafka experience for async microservice messaging\",\"No Kubernetes experience, which is the required container orchestration platform\"],\"explanation\":\"The candidate covers the Kotlin and Spring Boot core competently with solid testing habits, but misses Kafka and Kubernetes which are operationally critical for a senior microservices role. The seniority gap further limits their fit for a position that expects system design leadership and mentoring.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"django_junior_aiko\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Django\",\"Docker\",\"Redis\"],\"architecture\":[\"REST\",\"Monolith\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nB2C food delivery app hiring a mid-level Python backend engineer. Django required. PostgreSQL and Redis for data and caching. Celery for order processing async jobs. AWS for cloud deployment. Docker for containerisation. GitHub Actions for CI. Good test coverage with pytest. Engineers work autonomously on full feature areas.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Django, PostgreSQL, Redis, Docker, GitHub Actions, and pytest all align with the job stack directly\",\"REST and monolith architecture experience is appropriate for a Django-based backend\",\"Junior-to-mid gap is narrower given strong stack alignment\"],\"gaps\":[\"Junior seniority does not meet the mid-level autonomous ownership expectation\",\"No Celery experience for async order processing jobs\",\"No AWS experience for cloud deployment\"],\"explanation\":\"The candidate has a well-aligned Django stack with Redis, PostgreSQL, Docker, and pytest all confirmed, which reduces the onboarding gap considerably. The missing pieces are Celery, which is critical for order processing in a food delivery context, and AWS for cloud deployment. Junior seniority is a concern for a role that expects autonomous feature ownership without oversight.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rustam_payments\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"Go\"],\"tech\":[\"Actix\",\"Tokio\",\"gRPC\",\"Docker\",\"Kubernetes\",\"AWS\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"CockroachDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"pytest\",\"k6\"]}\n\nJob Summary:\nHigh-frequency payment processor building sub-millisecond order settlement infrastructure needs a senior backend engineer. Rust with Tokio and async gRPC required. Microservices on Kubernetes with AWS. CockroachDB or PostgreSQL for distributed ACID transactions. Redis for coordination. GitOps with Argo CD preferred. Load testing with k6. Low-latency systems thinking and ownership of critical payment paths expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Rust with Tokio and gRPC are directly required and all confirmed in the profile\",\"CockroachDB and PostgreSQL both present for the distributed ACID transaction requirement\",\"Kubernetes and AWS cover the deployment platform\",\"Redis aligns with the coordination requirement\",\"Argo CD demonstrates GitOps experience and k6 matches the load testing expectation\"],\"gaps\":[\"Testing is shown only via pytest which is Python-based, not Rust-native testing\"],\"explanation\":\"This candidate's Rust systems engineering profile maps precisely onto a high-frequency payments role. CockroachDB alongside PostgreSQL is a rare combination that directly addresses the distributed ACID requirement. The only marginal gap is the absence of Rust-native testing evidence, which is a minor consideration given the otherwise strong signal.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"appsec_maya\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\",\"AppSec Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Semgrep\",\"Burp Suite\",\"AWS\",\"Terraform\",\"Vault\",\"Docker\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nCloud security company building a developer-first security platform needs a senior application security engineer. Python and Go for tooling required. SAST tooling experience with Semgrep or similar. Dynamic testing with Burp Suite or OWASP ZAP. HashiCorp Vault for secrets management. Terraform and AWS for infrastructure. Threat modeling and secure SDLC integration across CI/CD pipelines. Experience embedding security into developer workflows expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Semgrep for SAST and Burp Suite for dynamic testing are directly required and confirmed\",\"HashiCorp Vault addresses the secrets management requirement exactly\",\"Python and Go meet the tooling language requirements\",\"Terraform and AWS cover the infrastructure context\",\"AppSec Engineer role label confirms the specialised security engineering background\"],\"gaps\":[\"No explicit threat modeling framework or OWASP methodology evidence visible\"],\"explanation\":\"This candidate's profile is a precise match for a developer-first AppSec role. The combination of Semgrep, Burp Suite, and Vault is distinctive and directly named in the job description. Their dual role as Security and AppSec engineer confirms the specialisation depth the company needs. The only minor gap is the absence of a named threat modeling methodology.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cv_engineer_lin\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"C++\"],\"tech\":[\"PyTorch\",\"OpenCV\",\"CUDA\",\"ONNX\",\"Docker\",\"AWS\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nAutonomous drone company building real-time perception systems needs a senior computer vision engineer. PyTorch for model training and CUDA for GPU acceleration required. OpenCV for image processing pipeline. ONNX for model export and edge deployment. C++ for performance-critical inference modules. Python for research and experimentation. Docker and AWS for cloud infrastructure.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PyTorch, CUDA, OpenCV, and ONNX are all directly required and confirmed\",\"C++ proficiency covers the performance-critical inference module requirement\",\"Docker and AWS align with the cloud infrastructure stack\",\"Senior ML engineer role indicates production computer vision deployment experience\"],\"gaps\":[\"No explicit edge inference device or embedded deployment experience visible beyond ONNX\"],\"explanation\":\"This candidate's computer vision stack is a near-exact match for the perception engineering role. The combination of PyTorch, CUDA, OpenCV, ONNX, and C++ is precisely what a real-time drone perception system requires. The marginal gap is the absence of confirmed edge hardware deployment experience, which may be implied by the ONNX usage but is not made explicit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"search_eng_nour\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"Java\"],\"tech\":[\"Elasticsearch\",\"Apache Kafka\",\"FastAPI\",\"Docker\",\"AWS\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Elasticsearch\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nE-commerce search platform serving 50 million queries per day needs a senior search infrastructure engineer. Elasticsearch expertise required for indexing, relevance tuning, and cluster management. Apache Kafka for real-time product catalog updates. Python or Java for backend services. FastAPI for search APIs. Redis for query caching. AWS for cloud. Load testing experience with Locust or k6 expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Elasticsearch is listed in both tech and databases confirming deep usage, directly matching the primary requirement\",\"Apache Kafka aligns with real-time catalog update streaming\",\"FastAPI and Python meet the backend service and API requirements\",\"Redis addresses the query caching expectation\",\"Locust covers the load testing requirement, and AWS aligns with the cloud platform\"],\"gaps\":[],\"explanation\":\"This candidate's profile maps precisely onto a high-scale search infrastructure role. The depth signalled by Elasticsearch appearing in both the tech and databases sections suggests both operational and query-level experience. Combined with Kafka, FastAPI, Redis, and load testing via Locust, this is a strong and comprehensive fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"iot_platform_bjorn\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"C\"],\"tech\":[\"MQTT\",\"Apache Kafka\",\"Docker\",\"Kubernetes\",\"AWS\",\"Terraform\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Event-Driven\",\"Microservices\",\"Distributed System\"],\"databases\":[\"InfluxDB\",\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"pytest\",\"k6\"]}\n\nJob Summary:\nIndustrial IoT company building a device telemetry platform needs a senior backend engineer. Go or Python for cloud services. MQTT for device-to-cloud messaging. Kafka for telemetry event streaming. InfluxDB for time-series sensor data storage. Kubernetes and AWS for deployment. Terraform for infrastructure. Prometheus and Grafana for observability. Experience with distributed event-driven systems at scale required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"MQTT for device messaging and Kafka for telemetry streaming are both directly required and confirmed\",\"InfluxDB is the exact time-series database named and is present\",\"Go and Python meet the cloud services language requirement\",\"Kubernetes, AWS, and Terraform cover the deployment and IaC stack\",\"Prometheus and Grafana directly match the observability requirements\"],\"gaps\":[],\"explanation\":\"This candidate's profile is an exceptional match for an industrial IoT telemetry platform role. Every technology named in the job description is confirmed, including the distinctive IoT-specific combination of MQTT, InfluxDB, and Kafka. Their dual backend and platform engineering background adds infrastructure ownership credibility beyond pure application development.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"game_backend_igor\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"C++\",\"Python\"],\"tech\":[\"gRPC\",\"Redis\",\"Docker\",\"Kubernetes\",\"Google Cloud\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"CockroachDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"k6\"]}\n\nJob Summary:\nMultiplayer gaming studio building cross-platform matchmaking and game state infrastructure needs a senior backend engineer. Go or C++ required. gRPC for low-latency service communication. Redis for session and game state caching. Kafka for player event streaming. Kubernetes on Google Cloud for deployment. CockroachDB or PostgreSQL for persistent player data. Experience with high-concurrency, low-latency distributed systems required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go and C++ both meet the primary language requirement\",\"gRPC is directly required for low-latency communication and is confirmed\",\"Redis, Kafka, CockroachDB, and PostgreSQL all align precisely with the data and streaming requirements\",\"Kubernetes on Google Cloud matches the deployment platform\",\"Distributed system and event-driven architecture tags confirm the concurrency and latency systems experience\"],\"gaps\":[],\"explanation\":\"This candidate's profile maps onto every technical requirement of the game backend role with precision. The combination of Go, gRPC, Redis, Kafka, and CockroachDB demonstrates the exact stack a matchmaking and game state system requires. Their distributed systems background further supports the high-concurrency, low-latency design expectations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"robotics_sw_hana\",\"seniority\":\"Senior\",\"roles\":[\"Embedded Engineer\",\"Backend Engineer\"],\"languages\":[\"C++\",\"Python\",\"Rust\"],\"tech\":[\"ROS2\",\"OpenCV\",\"CUDA\",\"Docker\",\"CMake\"],\"architecture\":[\"Distributed System\",\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nRobotics startup building warehouse automation systems needs a senior robotics software engineer. ROS2 for robot middleware required. C++ for control and perception modules. OpenCV for vision pipeline. CUDA for GPU-accelerated inference. Python for tooling and simulation scripting. CMake for build system. Docker for containerised deployment. Experience with real-time control loops and sensor fusion expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"ROS2 is directly required and confirmed as the primary robot middleware\",\"C++ and Python meet the language requirements for control modules and tooling\",\"OpenCV and CUDA address the vision pipeline and GPU inference requirements\",\"CMake and Docker cover the build and deployment stack\",\"Rust background adds systems-level depth for safety-critical robotic control\"],\"gaps\":[\"No explicit sensor fusion or real-time control loop experience visible beyond ROS2 usage\"],\"explanation\":\"This candidate's robotics software profile is a strong and precise match for a warehouse automation role. Every named technology in the job description is confirmed, including the distinctive ROS2, OpenCV, and CUDA combination. The Rust background adds credibility for safety-critical embedded work. The only minor uncertainty is the depth of sensor fusion experience, which may be embedded in their ROS2 usage.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cli_tooling_sam\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Bash\",\"Python\"],\"tech\":[\"Cobra\",\"Docker\",\"Kubernetes\",\"Terraform\",\"AWS\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Goreleaser\"],\"testing\":[\"pytest\",\"k6\"]}\n\nJob Summary:\nDeveloper tooling company building a Kubernetes-native CLI platform needs a senior Go engineer. Cobra framework for CLI development required. Deep Go expertise for writing performant, well-tested binaries. Kubernetes and Terraform for platform integration. Docker for containerised workflows. AWS for cloud services. Goreleaser for cross-platform binary release automation. GitHub Actions for CI/CD. Experience shipping open-source developer tools preferred.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Cobra for CLI development is directly required and confirmed\",\"Go is the primary language and is confirmed as dominant in the profile\",\"Kubernetes and Terraform align with the platform integration requirements\",\"Goreleaser is specifically named for release automation and is present\",\"Docker and AWS round out the cloud and containerisation stack\"],\"gaps\":[\"No open-source tooling project contributions visible in profile metadata\"],\"explanation\":\"This candidate's Go CLI engineering profile is a precise match for a Kubernetes-native developer tooling role. The presence of both Cobra and Goreleaser, which are niche Go tooling ecosystem tools, is strong evidence of relevant experience. The only marginal gap is the preference for open-source contributions, which is not verifiable from the profile fields alone.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"healthdata_femi\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"TypeScript\"],\"tech\":[\"Django\",\"FastAPI\",\"Docker\",\"AWS\",\"Celery\",\"Redis\"],\"architecture\":[\"Microservices\",\"REST\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nDigital health company building a clinical data platform needs a senior backend engineer. Python required with Django or FastAPI for REST APIs. Celery for async clinical workflow processing. Redis for caching and session management. PostgreSQL for structured patient data. AWS and Docker for deployment. HIPAA-compliant architecture design experience strongly preferred. Locust or k6 for load testing expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Django and FastAPI both present, directly matching the framework options\",\"Celery and Redis address the async processing and caching requirements\",\"PostgreSQL is the required structured data store and is confirmed\",\"Docker and AWS cover the deployment stack\",\"Locust meets the load testing expectation explicitly\"],\"gaps\":[\"No explicit HIPAA compliance or healthcare data governance experience visible\"],\"explanation\":\"This candidate's Python backend profile aligns closely with every technical requirement of the clinical data platform role. The simultaneous presence of both Django and FastAPI alongside Celery and Redis is a particularly strong signal for async healthcare workflow processing. The meaningful gap is the absence of confirmed HIPAA compliance experience, which is strongly preferred for a regulated health data context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"spatial_eng_kai\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\",\"C#\"],\"tech\":[\"Three.js\",\"WebGL\",\"React\",\"Unity\",\"WebXR\"],\"architecture\":[\"Client-Server\",\"REST\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nAR/VR startup building a browser-based spatial collaboration tool needs a mid-level 3D frontend engineer. Three.js and WebGL required for 3D rendering in the browser. WebXR API for headset and AR device integration. TypeScript and React for the application layer. Unity background a strong plus for understanding spatial interaction patterns. REST API integration expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Three.js and WebGL are directly required for browser 3D rendering and both confirmed\",\"WebXR covers the headset and AR device integration requirement precisely\",\"TypeScript and React align with the application layer requirements\",\"Unity background directly addresses the strong plus for spatial interaction understanding\",\"C# from Unity adds depth to the spatial computing context\"],\"gaps\":[\"No visible experience with collaborative real-time features like WebRTC or CRDTs for a collaboration tool\"],\"explanation\":\"This candidate's combination of Three.js, WebGL, WebXR, and Unity background is a rare and precise match for a browser-based spatial collaboration platform. Every major technical requirement is confirmed, and the Unity experience addresses a stated preference that most web engineers would not have. The only gap is the absence of real-time collaboration protocol experience, which may be critical for the collaborative aspect.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"greentech_pita\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\",\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Kafka\",\"Apache Airflow\",\"dbt\",\"FastAPI\",\"Docker\",\"AWS\"],\"architecture\":[\"Event-Driven\",\"Microservices\",\"Distributed System\"],\"databases\":[\"TimescaleDB\",\"PostgreSQL\",\"BigQuery\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nClimate tech company building a carbon footprint monitoring platform needs a senior data and backend engineer. Python and SQL required. Apache Kafka for real-time emissions event streaming. Airflow for pipeline orchestration. dbt for transformation. TimescaleDB for time-series energy and emissions data. BigQuery for analytics. Great Expectations for data quality. FastAPI for internal APIs. AWS for cloud infrastructure.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"TimescaleDB for time-series emissions data is directly required and present, a distinctive match\",\"Kafka, Airflow, dbt, and Great Expectations cover the full pipeline stack\",\"BigQuery aligns with the analytics warehouse requirement\",\"FastAPI and Python address the internal API and language requirements\",\"AWS and Docker cover the deployment infrastructure\"],\"gaps\":[],\"explanation\":\"This candidate's profile is an exceptionally precise match for a climate data platform role. TimescaleDB is an uncommon requirement that is directly confirmed in the profile, alongside every other named tool in the job description. The dual data engineering and backend role background supports the breadth of work described across pipeline and API development.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"supply_chain_dev\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Software Architect\"],\"languages\":[\"Java\",\"Python\"],\"tech\":[\"Spring Boot\",\"Apache Kafka\",\"Docker\",\"Kubernetes\",\"AWS\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Domain-Driven Design\",\"CQRS\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nGlobal logistics company modernising its supply chain platform is hiring a senior backend engineer. Java and Spring Boot required. Kafka for event-driven inventory and shipment updates. Domain-driven design and CQRS for bounded context modelling. PostgreSQL for transactional data. Kubernetes and AWS for deployment. JUnit and Mockito for testing. Prior supply chain or logistics domain experience a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Java, Spring Boot, and Kafka are all directly required and confirmed\",\"Domain-Driven Design and CQRS are explicitly required architectural patterns and are both present\",\"PostgreSQL, Kubernetes, and AWS cover the data and deployment stack\",\"JUnit and Mockito match the testing framework pair\",\"Software Architect role tag suggests prior system design ownership relevant to a modernisation initiative\"],\"gaps\":[\"No explicit supply chain or logistics domain experience confirmed beyond general backend work\"],\"explanation\":\"This candidate's Java and Spring Boot profile combined with DDD, CQRS, and Kafka experience is a strong technical match for a supply chain modernisation role. Every named technology and architectural pattern in the job description is confirmed. The only gap is the absence of confirmed logistics domain experience, which is listed as a strong plus rather than a hard requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"edtech_fullstack\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Next.js\",\"React\",\"FastAPI\",\"Prisma\",\"Tailwind CSS\",\"Docker\",\"AWS\"],\"architecture\":[\"REST\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"Vercel\",\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nEdTech startup building adaptive learning tools for universities needs a mid-level full stack engineer. Next.js and React for the frontend. FastAPI on the backend. TypeScript and Python required. PostgreSQL with Prisma for the data layer. Redis for caching session and quiz state. AWS and Vercel for deployment. Jest, pytest, and Playwright expected for quality coverage.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js, React, FastAPI, TypeScript, and Python match the full stated stack\",\"Prisma and PostgreSQL are a direct match for the data layer\",\"Redis addresses the caching requirement for session and quiz state\",\"Jest, pytest, and Playwright cover the exact testing expectations\",\"AWS and Vercel align with the deployment infrastructure\"],\"gaps\":[],\"explanation\":\"This candidate's profile maps precisely onto every requirement of the EdTech full stack role. The combination of TypeScript, Python, Next.js, and FastAPI is a distinctive match that many generalist engineers would not cover simultaneously. The testing breadth across frontend, backend, and end-to-end layers reflects engineering discipline well-aligned with an academic product context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"media_streaming_lee\",\"seniority\":\"Staff\",\"roles\":[\"Backend Engineer\",\"Software Architect\"],\"languages\":[\"Go\",\"Python\",\"C++\"],\"tech\":[\"Apache Kafka\",\"gRPC\",\"Redis\",\"Docker\",\"Kubernetes\",\"AWS\",\"Nginx\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Distributed System\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"pytest\",\"k6\",\"Locust\"]}\n\nJob Summary:\nMajor streaming platform serving 100 million users needs a staff backend engineer to lead video delivery infrastructure architecture. Go primary language. Kafka for viewing event streaming. gRPC for internal service communication. Cassandra for high-throughput viewer data. Redis for CDN edge caching. Kubernetes and AWS for platform. Prometheus and Grafana for observability. Staff-level cross-team technical leadership expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go is the primary language and is confirmed as the most prominent language in the profile\",\"Kafka, gRPC, Cassandra, and Redis are all directly named and confirmed\",\"Prometheus and Grafana cover the observability requirements\",\"Kubernetes and AWS align with the platform infrastructure\",\"Staff seniority and Software Architect role match the cross-team technical leadership expectations\"],\"gaps\":[],\"explanation\":\"This candidate's staff-level profile is a comprehensive and precise match for a large-scale video delivery infrastructure role. Every technology named in the job description is confirmed with depth, including the distinctive Cassandra and gRPC combination. Their architectural and leadership background at staff level directly supports the cross-team technical direction responsibilities.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"web3_nft_kai\",\"seniority\":\"Mid\",\"roles\":[\"Blockchain Engineer\"],\"languages\":[\"Solidity\",\"TypeScript\",\"JavaScript\"],\"tech\":[\"Hardhat\",\"Ethers.js\",\"React\",\"IPFS\"],\"architecture\":[\"Distributed System\"],\"testing\":[\"Chai\",\"Mocha\"]}\n\nJob Summary:\nWeb3 gaming company building an NFT-based in-game asset marketplace needs a mid-level blockchain engineer. Solidity for ERC-721 and ERC-1155 contracts. Hardhat for development and testing. OpenZeppelin for secure contract patterns. TypeScript and Ethers.js for backend integration. IPFS for decentralised asset storage. Gas optimisation techniques and mainnet deployment experience expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Solidity, Hardhat, Ethers.js, TypeScript, and IPFS are all directly relevant and confirmed\",\"Chai and Mocha demonstrate contract testing discipline\",\"Distributed systems architecture understanding fits decentralised marketplace design\"],\"gaps\":[\"No OpenZeppelin experience visible, which is required for secure ERC contract patterns\",\"No explicit mainnet deployment or gas optimisation experience demonstrated\"],\"explanation\":\"The candidate has the core Solidity and Hardhat toolchain well covered but lacks the OpenZeppelin library experience that is explicitly required for secure ERC-721 and ERC-1155 patterns. Gas optimisation and mainnet deployment experience are also not confirmed, which are meaningful for a production NFT marketplace. A solid foundational match with notable gaps in production depth.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"crm_salesforce_ron\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Python\"],\"tech\":[\"Spring Boot\",\"REST API\",\"Docker\",\"AWS\"],\"architecture\":[\"REST\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MySQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nEnterprise CRM company building Salesforce integrations and custom backend services needs a mid-level Java backend engineer. Spring Boot required. Salesforce REST and SOAP APIs for integration. Apex knowledge a strong plus. PostgreSQL for internal data. Docker and AWS for deployment. JUnit and Mockito for testing. Experience with webhook-driven event flows and OAuth-based auth integration expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Java and Spring Boot are directly required and confirmed\",\"PostgreSQL, Docker, AWS, JUnit, and Mockito all align with the job requirements\",\"REST API and microservices experience is relevant for Salesforce integration patterns\"],\"gaps\":[\"No Salesforce REST or SOAP API integration experience visible\",\"No Apex knowledge, which is listed as a strong plus\",\"No webhook event flow or OAuth integration experience demonstrated\"],\"explanation\":\"The candidate covers the Java and Spring Boot backend foundation well, but lacks the Salesforce-specific integration experience that is central to this role. CRM integration engineering requires understanding of external API patterns, Apex, and OAuth flows that are not evident in the profile. This is a moderate fit where the backend skills transfer but the domain tooling requires development.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"legal_tech_dev_yui\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Next.js\",\"FastAPI\",\"Prisma\",\"Docker\",\"AWS\",\"Tailwind CSS\"],\"architecture\":[\"REST\",\"Serverless\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Vercel\"],\"testing\":[\"Jest\",\"pytest\"]}\n\nJob Summary:\nLegaltech startup building AI-assisted contract review tooling needs a mid-level full stack engineer. Next.js and FastAPI stack. TypeScript and Python required. PostgreSQL with Prisma. Docker and AWS deployments. Vercel for frontend. LangChain or LlamaIndex for LLM integration is highly valued. Experience working with PDF parsing or document processing pipelines a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js, FastAPI, TypeScript, Python, Prisma, and PostgreSQL are all directly required and confirmed\",\"Docker, AWS, Vercel, and GitHub Actions cover the full deployment and CI/CD stack\",\"Jest and pytest meet the testing expectations\"],\"gaps\":[\"No LangChain or LlamaIndex experience for the LLM integration requirement, which is highly valued\",\"No PDF parsing or document processing pipeline experience visible\"],\"explanation\":\"The candidate's full stack profile aligns very well with the core technical stack but is missing the AI-specific tooling that is central to the product value proposition. LangChain or LlamaIndex experience is highly valued and absent. For a legaltech product where LLM contract review is the core feature, this gap is meaningful even if the base engineering skills are a strong match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ecom_rec_eng_pita\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"scikit-learn\",\"PyTorch\",\"MLflow\",\"Pandas\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nE-commerce recommendation engine company hiring a senior ML engineer. PyTorch and scikit-learn for model development. MLflow for experiment tracking. Redis for feature caching and real-time serving. AWS for cloud. Models served via REST APIs using FastAPI. Familiarity with real-time feature stores such as Feast or Tecton expected. A/B testing and online evaluation frameworks required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch, scikit-learn, and MLflow are all confirmed and directly required\",\"Redis aligns with the feature caching and real-time serving requirement\",\"AWS and Docker cover the deployment infrastructure\",\"Senior ML engineering background supports the model ownership expectations\"],\"gaps\":[\"No FastAPI experience for the REST model serving requirement\",\"No Feast, Tecton, or feature store experience, which is expected\",\"No A/B testing or online evaluation framework experience visible\"],\"explanation\":\"The candidate covers the core ML modeling and experiment tracking stack well but lacks FastAPI for model serving and feature store experience, both of which are explicitly expected for a production recommendation system. The absence of A/B testing framework experience is a further gap for a role where online evaluation is central to the product feedback loop.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"embedded_iot_jun\",\"seniority\":\"Mid\",\"roles\":[\"Embedded Engineer\"],\"languages\":[\"C\",\"C++\",\"Python\"],\"tech\":[\"FreeRTOS\",\"CMake\",\"Docker\"],\"architecture\":[\"Client-Server\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nSmart home hardware company building connected thermostat firmware needs a mid-level embedded engineer. C and C++ for firmware development. FreeRTOS for real-time task scheduling. MQTT for cloud connectivity. BLE and Wi-Fi protocol stack integration experience expected. CMake build system. Over-the-air update mechanisms familiarity preferred. Python for test automation scripting.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"C and C++ directly match the firmware development language requirements\",\"FreeRTOS is explicitly required for real-time scheduling and is confirmed\",\"CMake covers the build system requirement\",\"Python meets the test automation scripting expectation\"],\"gaps\":[\"No MQTT experience for cloud connectivity, which is a core protocol for this product\",\"No BLE or Wi-Fi protocol stack integration experience visible\",\"No OTA update mechanism experience demonstrated\"],\"explanation\":\"The candidate has solid embedded fundamentals with C, C++, FreeRTOS, and CMake all aligned. However, the absence of MQTT and wireless protocol experience is a meaningful gap for a connected thermostat product where cloud connectivity and radio stack integration are core responsibilities. OTA update familiarity is also missing from the profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"browser_ext_dev\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Chrome Extension API\",\"Webpack\",\"Tailwind CSS\"],\"databases\":[\"Firebase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nProductivity SaaS company building a browser extension suite needs a mid-level frontend engineer specialising in Chrome and Firefox extension development. TypeScript required. Manifest V3 architecture for Chrome extensions. WebExtensions API for cross-browser compatibility. React for popup and options UI. Background service workers and content script injection experience expected. Webpack or Vite for bundling.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Chrome Extension API experience is directly relevant and rare, matching the core domain\",\"React, TypeScript, and Webpack are all aligned with the stated stack\",\"Tailwind CSS and Jest show frontend development discipline\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement\",\"No explicit Manifest V3 or service worker experience demonstrated\",\"No WebExtensions or cross-browser Firefox extension experience visible\",\"No content script injection patterns shown\"],\"explanation\":\"The candidate has the most important domain signal with Chrome Extension API experience, which is uncommon and directly relevant. However, junior seniority and the absence of Manifest V3, service workers, and cross-browser compatibility experience are notable gaps for a product shipping to both Chrome and Firefox. This is a moderate fit with meaningful ramp-up required.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"db_internals_ola\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C++\",\"Python\",\"Rust\"],\"tech\":[\"PostgreSQL\",\"RocksDB\",\"Docker\",\"CMake\"],\"architecture\":[\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"CockroachDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nDatabase infrastructure company building a cloud-native distributed SQL engine needs a senior database systems engineer. C++ or Rust for storage engine development. Deep PostgreSQL internals knowledge required. RocksDB as the storage backend. Experience with distributed consensus protocols like Raft or Paxos expected. CMake for build system. Docker for testing environments. Familiarity with query optimisation and execution engine design preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"C++ and Rust are both present and cover the language requirement for systems-level storage work\",\"PostgreSQL and RocksDB are directly named and confirmed as both tech and database entries\",\"CockroachDB experience implies familiarity with distributed SQL systems\",\"CMake and Docker align with the build and test environment requirements\"],\"gaps\":[\"No explicit distributed consensus protocol experience such as Raft or Paxos visible\",\"No query optimisation or execution engine design experience demonstrated\"],\"explanation\":\"The candidate has strong systems engineering credentials with C++, Rust, PostgreSQL internals, and RocksDB all aligned with the core technical requirements. The gaps are in the higher-level distributed consensus and query engine design areas that distinguish a storage engineer from a full database systems engineer. These are meaningful gaps for a company building their own distributed SQL engine.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"climate_data_jun\",\"seniority\":\"Junior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Airflow\",\"dbt\",\"Pandas\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nClimate analytics company building an emissions reporting platform needs a mid-level data engineer. Python and SQL required. dbt and Airflow for transformation and orchestration. BigQuery as the cloud warehouse. TimescaleDB for time-series energy data. Great Expectations for data quality. Kafka for real-time sensor event streaming. AWS for cloud infrastructure.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python, SQL, dbt, Airflow, BigQuery, and Docker are all directly relevant and confirmed\",\"Junior-to-mid gap is narrower given strong stack alignment on the core ETL tools\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement\",\"No TimescaleDB experience for time-series emissions data\",\"No Great Expectations for data quality\",\"No Kafka for real-time sensor streaming\",\"No AWS experience, only BigQuery cloud context\"],\"explanation\":\"The candidate has solid foundational data engineering skills with dbt, Airflow, and BigQuery all confirmed, which covers the transformation and orchestration core. However, the time-series, data quality, and streaming tooling are all absent, and junior seniority means they would need meaningful support for the mid-level autonomous role described. A moderate fit with several specific tooling gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"arvr_shader_teo\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\",\"GLSL\"],\"tech\":[\"Three.js\",\"WebGL\",\"React\",\"Vite\"],\"architecture\":[\"Client-Server\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nVirtual production company building browser-based film previsualization tools needs a mid-level 3D web engineer. Three.js and WebGL required. GLSL shader development for custom rendering effects. React for UI layer. WebXR for VR headset preview mode. Experience with real-time 3D scene management and performance optimisation in the browser expected. TypeScript required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Three.js, WebGL, GLSL, TypeScript, and React are all directly required and confirmed\",\"Vite demonstrates modern frontend toolchain familiarity\",\"Mid-level seniority is appropriate\"],\"gaps\":[\"No WebXR experience for the VR headset preview mode requirement\",\"No explicit real-time 3D scene management or browser performance optimisation evidence\"],\"explanation\":\"The candidate covers the core 3D rendering stack with Three.js, WebGL, and GLSL shader development all confirmed. The notable gap is the absence of WebXR experience, which is required for the VR headset preview mode that is a key product feature. Real-time scene management and performance optimisation depth is also not clearly demonstrated, which is important for a film previsualization tool.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"game_be_junior_alex\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Gin\",\"Docker\",\"Redis\",\"AWS\"],\"architecture\":[\"REST\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nMobile gaming studio building a social leaderboard and reward system needs a mid-level backend engineer. Go preferred. Redis for real-time leaderboard scoring. gRPC for internal service communication. Kubernetes for deployment on AWS. PostgreSQL for player profile persistence. Experience with high-concurrency read patterns and distributed caching strategies expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go and Gin demonstrate relevant backend language experience for the primary requirement\",\"Redis aligns with the real-time leaderboard caching requirement\",\"PostgreSQL and AWS are both present and required\",\"Microservices architecture shows relevant system design familiarity\"],\"gaps\":[\"Junior seniority does not meet the mid-level expectation\",\"No gRPC experience, which is required for internal service communication\",\"No Kubernetes experience for deployment\",\"No demonstrated high-concurrency or distributed caching design experience\"],\"explanation\":\"The candidate has the right Go and Redis foundation for a gaming leaderboard backend but falls short on seniority and key infrastructure requirements. gRPC and Kubernetes are both absent and are not minor gaps for a distributed microservices architecture. They are a moderate fit who could grow into the role with targeted upskilling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nlp_researcher_zara\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\",\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"spaCy\",\"NLTK\",\"Weights & Biases\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise search company building an NLP-powered document classification system needs a senior NLP engineer. Python and PyTorch required. Hugging Face Transformers for fine-tuning. spaCy for entity extraction and pipeline construction. Model deployment via FastAPI as REST endpoints. Docker and AWS for serving infrastructure. Experiment tracking with MLflow or Weights and Biases.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch, Hugging Face Transformers, spaCy, and Weights and Biases are all directly required and confirmed\",\"NLTK adds further NLP depth beyond the stated requirements\",\"Senior NLP background supports the fine-tuning and pipeline ownership expectations\"],\"gaps\":[\"No FastAPI experience for model REST endpoint deployment\",\"No Docker or AWS experience for serving infrastructure\"],\"explanation\":\"The candidate is strong on the NLP modeling and research side, covering the Hugging Face and spaCy stack with depth. The gaps are on the deployment and serving side, with FastAPI, Docker, and AWS all absent. For a role that explicitly expects model deployment as REST APIs on AWS infrastructure, these are not optional skills and represent a meaningful operational gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"healthcare_ios_dev\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Firebase\",\"HealthKit\"],\"architecture\":[\"Client-Server\"],\"databases\":[\"SQLite\",\"Firestore\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nDigital therapeutics company building an FDA-regulated patient monitoring app needs a senior iOS engineer. Swift and SwiftUI required. HealthKit integration for biometric data access. CoreBluetooth for wearable device pairing. Fastlane for release automation. XCTest and XCUITest for test coverage. Familiarity with accessibility standards and App Store compliance processes expected. HIPAA data handling experience strongly valued.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Swift, SwiftUI, HealthKit, and Fastlane are all directly required and confirmed\",\"XCTest shows iOS testing discipline\",\"UIKit and Objective-C add depth for hybrid UIKit and SwiftUI codebases\"],\"gaps\":[\"Mid-level seniority does not meet the senior-level requirement\",\"No CoreBluetooth experience for wearable device pairing\",\"No XCUITest beyond XCTest for UI testing coverage\",\"No HIPAA data handling experience confirmed\"],\"explanation\":\"The candidate covers the SwiftUI, HealthKit, and Fastlane stack well, which is directly relevant for patient monitoring. However, the absence of CoreBluetooth for wearable pairing is a meaningful functional gap for a wearable-integrated health app. Mid-level seniority and the absence of HIPAA compliance experience also reduce fit for an FDA-regulated context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"stream_data_mid\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Kafka\",\"Apache Airflow\",\"Pandas\",\"Docker\"],\"architecture\":[\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nMedia analytics startup building a real-time audience engagement platform needs a mid-level data engineer. Kafka for live event streaming required. Apache Flink or Spark Streaming for stream processing. Airflow for batch pipeline orchestration. dbt for transformation. ClickHouse for high-speed analytics queries. AWS for cloud. Python and SQL proficiency expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kafka and Airflow are directly required and confirmed\",\"Python and SQL meet the primary language requirements\",\"Event-driven architecture experience aligns with the streaming platform context\",\"Docker and pytest show deployment and testing awareness\"],\"gaps\":[\"No Apache Flink or Spark Streaming experience for the stream processing requirement\",\"No dbt experience for the transformation layer\",\"No ClickHouse experience for high-speed analytics\",\"No AWS experience visible in the profile\"],\"explanation\":\"The candidate covers the streaming ingestion and batch orchestration side with Kafka and Airflow but lacks the stream processing framework and analytics database experience that are central to a real-time audience platform. The absence of dbt, ClickHouse, and AWS means several critical layers of the described data stack are uncovered.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fintech_android_dev\",\"seniority\":\"Mid\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Retrofit\",\"Firebase\"],\"architecture\":[\"Client-Server\"],\"databases\":[\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Espresso\"]}\n\nJob Summary:\nNeobank hiring a senior Android engineer for their mobile payments app. Kotlin and Jetpack Compose required. Hilt for dependency injection. Retrofit for REST API integration. Room for local database persistence. Fastlane for release automation. JUnit and Espresso for testing. Biometric authentication integration experience expected. Modular architecture background preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin, Jetpack Compose, Retrofit, JUnit, and Espresso are all directly aligned with the job requirements\",\"SQLite familiarity provides a foundation for Room migration\",\"Mid-level experience with financial app context demonstrated via Firebase integration\"],\"gaps\":[\"Mid-level seniority does not meet the senior-level requirement\",\"No Hilt dependency injection experience visible\",\"No Room experience beyond SQLite, which requires specific Jetpack migration\",\"No Fastlane for release automation\",\"No modular architecture or biometric authentication experience\"],\"explanation\":\"The candidate covers the Kotlin and Jetpack Compose core but is missing several explicitly required skills including Hilt, Room, and Fastlane. The seniority gap is also meaningful for a neobank app where senior ownership and security-aware development are expected. These gaps across tooling and seniority place this as a moderate rather than strong fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"soc_analyst_code\",\"seniority\":\"Mid\",\"roles\":[\"Security Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Splunk\",\"AWS\",\"Docker\",\"Terraform\"],\"architecture\":[\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nFinancial institution building a cloud security operations platform needs a senior security engineer. SIEM experience with Splunk or Elastic SIEM required. Python and Bash for detection rule automation. AWS security services including GuardDuty, Security Hub, and Config. Terraform for compliance-as-code. Familiarity with MITRE ATT&CK framework and incident response playbooks expected. SOC experience and alert triage skills preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Splunk directly matches the SIEM requirement\",\"Python, Bash, AWS, and Terraform are all confirmed and required\",\"Cloud-native background is relevant for AWS security operations\"],\"gaps\":[\"Mid-level seniority does not meet the senior-level requirement\",\"No explicit AWS GuardDuty, Security Hub, or Config experience visible\",\"No MITRE ATT&CK framework or incident response playbook experience demonstrated\",\"No SOC operations or alert triage background confirmed\"],\"explanation\":\"The candidate has useful security operations tooling with Splunk, Python, and AWS, but the depth of AWS-native security service experience and the SOC operational background are not confirmed. The MITRE ATT&CK and incident response skills are also absent, which are core to a financial institution's security posture. This is a moderate fit where foundational tools align but specialised depth is missing.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"robotics_junior_path\",\"seniority\":\"Junior\",\"roles\":[\"Embedded Engineer\"],\"languages\":[\"C++\",\"Python\"],\"tech\":[\"ROS2\",\"CMake\",\"Docker\"],\"architecture\":[\"Distributed System\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAutonomous mobile robot company hiring a mid-level robotics software engineer. ROS2 required. C++ for navigation and path planning algorithms. Python for simulation scripting with Gazebo. SLAM or localisation algorithm experience expected. Sensor fusion across LiDAR and camera inputs. CMake for build. Docker for simulation environments.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"ROS2, C++, CMake, and Docker are all directly required and confirmed\",\"Python meets the simulation scripting language requirement\",\"Distributed system architecture understanding is relevant for multi-node ROS2 setups\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement\",\"No Gazebo simulation experience visible\",\"No SLAM or localisation algorithm experience demonstrated\",\"No sensor fusion across LiDAR and camera inputs shown\"],\"explanation\":\"The candidate has the foundational ROS2 and C++ background for a robotics software role but lacks the domain-specific experience in SLAM, sensor fusion, and Gazebo simulation that are core to autonomous mobile robot development. Junior seniority further limits their readiness for the independent mid-level ownership expected in navigation and path planning.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"edtech_mobile_dev\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"TypeScript\"],\"tech\":[\"Flutter\",\"Firebase\",\"Riverpod\"],\"databases\":[\"Firestore\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"Flutter Test\",\"Mockito\"]}\n\nJob Summary:\nEdTech company building gamified learning apps for children needs a mid-level Flutter developer. Dart required. Riverpod or Bloc for state management. Firebase for authentication and real-time sync. Fastlane for deployment automation. Flutter Test and Mockito for testing. Accessibility features for children and parental control integration experience strongly preferred. SQLite for offline learning content.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Dart, Flutter, Riverpod, Firebase, Fastlane, Flutter Test, Mockito, and SQLite are all directly required and confirmed\",\"Firestore aligns with the real-time sync requirement\",\"Mid-level seniority is appropriate\"],\"gaps\":[\"No accessibility feature implementation experience for children-facing apps visible\",\"No parental control integration experience demonstrated\"],\"explanation\":\"The candidate's Flutter and Dart toolchain is an almost exact match for the stated technical requirements, with Riverpod, Fastlane, and testing tooling all confirmed. The gaps are in the product-domain specialisation, specifically children's accessibility and parental control features, which are strongly preferred for an app targeting this audience. These are not easily inferred from standard mobile profiles.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"spark_ml_senior_mo\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"Data Engineer\"],\"languages\":[\"Python\",\"Scala\"],\"tech\":[\"Apache Spark\",\"PySpark\",\"MLflow\",\"Pandas\",\"Docker\",\"AWS\"],\"databases\":[\"Snowflake\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nRetail personalisation company hiring a senior ML engineer to build real-time recommendation models. PyTorch or TensorFlow required for deep learning. Kafka for real-time feature streaming. Redis for low-latency feature serving. FastAPI for model APIs. AWS for cloud. Spark for batch feature engineering. MLflow for experiment tracking.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Apache Spark and PySpark directly match the batch feature engineering requirement\",\"MLflow covers the experiment tracking expectation\",\"AWS and Docker align with the deployment infrastructure\",\"Senior dual ML and data engineering background is relevant\"],\"gaps\":[\"No PyTorch or TensorFlow experience for deep learning model development\",\"No Kafka for real-time feature streaming\",\"No Redis for low-latency feature serving\",\"No FastAPI for model API serving\"],\"explanation\":\"The candidate is strong on the batch feature engineering and experiment tracking side with Spark and MLflow, but lacks the deep learning framework and real-time serving stack that are central to this personalisation role. PyTorch or TensorFlow is a hard requirement and is absent, as are the Kafka and Redis components needed for real-time recommendations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devrel_tooling_nia\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Go\"],\"tech\":[\"Next.js\",\"React\",\"Tailwind CSS\",\"Docker\",\"AWS\"],\"architecture\":[\"REST\",\"Serverless\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Vercel\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nDeveloper experience company building an API documentation and sandbox platform needs a mid-level full stack engineer. Next.js and TypeScript required. Go for backend API services. PostgreSQL for data. Docker and AWS for deployment. OpenAPI or Swagger experience for API schema tooling. GraphQL familiarity preferred. Ability to build interactive code sandboxes and developer-facing UI expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js, TypeScript, and React directly match the frontend requirements\",\"Go meets the backend API services language requirement\",\"PostgreSQL, Docker, AWS, and GitHub Actions align with the infrastructure stack\",\"Jest and Playwright demonstrate frontend testing discipline\"],\"gaps\":[\"No OpenAPI or Swagger schema tooling experience visible\",\"No GraphQL experience, which is preferred\",\"No interactive sandbox or code editor component experience demonstrated\"],\"explanation\":\"The candidate's full stack TypeScript and Go profile is a solid technical match for this developer experience role. The gaps are in the developer tooling specifics, particularly OpenAPI schema tooling and interactive sandbox component experience, which are central to the product being built. GraphQL familiarity is also absent as a preferred skill.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"supply_chain_junior\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"Celery\",\"Docker\",\"AWS\"],\"architecture\":[\"REST\",\"Monolith\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nLogistics SaaS company building a carrier routing and rate management platform needs a mid-level Python backend engineer. Django or FastAPI required. Celery for async routing job processing. PostgreSQL and Redis for data and caching. Docker and AWS for deployment. REST API design experience. Familiarity with EDI or freight carrier API integrations a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Django, Celery, PostgreSQL, Redis, Docker, AWS, and pytest are all directly aligned with the job stack\",\"REST and monolith architecture background fits a Django-centred backend\",\"Stack alignment is strong for a junior-to-mid transition hire\"],\"gaps\":[\"Junior seniority does not meet the mid-level autonomous ownership expectation\",\"No FastAPI experience as the alternative framework option\",\"No EDI or carrier API integration experience, which is a strong plus\"],\"explanation\":\"The candidate's Django and Celery stack alignment is strong and covers most of the core technical requirements. The seniority gap is the primary concern for a role expecting independent ownership. The absence of EDI or freight carrier API experience is also meaningful in a logistics domain context, though it is listed as a plus rather than a hard requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"frontend_intern_li\",\"seniority\":\"Intern\",\"languages\":[\"JavaScript\"],\"tech\":[\"React\",\"CSS\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nCybersecurity startup building a threat detection dashboard needs a senior full stack engineer. React and TypeScript on the frontend. Go or Python for backend security data APIs. PostgreSQL and Elasticsearch for threat log storage. Docker and Kubernetes on AWS. D3.js or Recharts for threat visualisation. Senior-level ownership across the full stack expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React experience is present and relevant to the frontend requirement\"],\"gaps\":[\"Intern seniority is far below the senior-level requirement\",\"No TypeScript experience, which is required for the frontend\",\"No backend language experience in Go or Python\",\"No PostgreSQL, Elasticsearch, Docker, Kubernetes, or AWS experience\",\"No D3.js or data visualisation library experience\"],\"explanation\":\"This candidate has only a basic React and CSS profile at intern level, which falls well short of the senior full stack engineering expectations. The cybersecurity backend stack, infrastructure, and data visualisation requirements are entirely absent. This is a fundamental mismatch in seniority and technical breadth.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"no_sql_junior_dev\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"PHP\"],\"tech\":[\"Express.js\",\"WordPress\"],\"databases\":[\"MySQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nDatabase infrastructure company building a NewSQL distributed database engine needs a mid-level systems engineer. C++ or Rust required for storage engine development. Deep PostgreSQL internals and RocksDB experience needed. Raft consensus protocol implementation experience expected. CMake for build system. Docker for testing. Low-level performance profiling and benchmarking skills required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"No C++ or Rust experience, which are both required for systems-level storage engine work\",\"No PostgreSQL internals or RocksDB experience\",\"No distributed consensus or Raft protocol knowledge\",\"No CMake or low-level build system experience\",\"JavaScript and PHP background does not transfer to systems programming\",\"Junior seniority does not meet the mid-level requirement\"],\"explanation\":\"This candidate has no overlap with the technical requirements of a database systems engineering role. JavaScript, PHP, and WordPress development is entirely orthogonal to low-level C++ storage engine work with Raft consensus protocols. There are no transferable technical skills from this profile to the described position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_notebook_intern\",\"seniority\":\"Intern\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"Matplotlib\"]}\n\nJob Summary:\nAutonomous vehicle startup building LiDAR-based perception systems needs a mid-level computer vision engineer. PyTorch and CUDA for deep learning model training on GPU clusters. OpenCV for point cloud processing. C++ for real-time inference modules. ROS2 for sensor integration. ONNX for model export to edge devices. Two years of production CV experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and scikit-learn show a basic machine learning foundation\"],\"gaps\":[\"Intern seniority with no production experience does not meet the two-year mid-level requirement\",\"No PyTorch or CUDA for GPU deep learning\",\"No OpenCV for point cloud or image processing\",\"No C++ for real-time inference\",\"No ROS2 for sensor integration\",\"No ONNX for edge model export\"],\"explanation\":\"This candidate's intern-level data science profile has virtually no overlap with the computer vision engineering requirements for an autonomous vehicle perception system. Every required technology from PyTorch and CUDA to ROS2 and ONNX is absent. This is a significant domain and skill level mismatch requiring years of focused development.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ux_only_dev\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"CSS\",\"Figma\",\"Tailwind CSS\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nFintech company building real-time options trading infrastructure needs a senior backend engineer. Go or Rust required for low-latency order execution. gRPC for internal service communication. Apache Kafka for market event streaming. Kubernetes and AWS for deployment. Redis for order book caching. CockroachDB or PostgreSQL for trade persistence. Systems-level thinking and sub-millisecond latency experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Frontend engineer background has no overlap with low-latency backend systems engineering\",\"No Go or Rust experience, which are the required languages\",\"No gRPC, Kafka, Kubernetes, Redis, or CockroachDB experience\",\"Junior seniority does not meet the senior-level requirement\",\"No systems-level or latency-sensitive engineering experience\"],\"explanation\":\"This candidate is a junior frontend engineer whose profile has no technical overlap with a senior low-latency trading backend role. Go or Rust systems engineering, distributed infrastructure, and sub-millisecond latency design are entirely absent from the profile. This is a fundamental domain mismatch with no transferable skills for this specific role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"basic_android_intern\",\"seniority\":\"Intern\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Android SDK\",\"Firebase\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nDigital therapeutics company building an FDA-regulated mental health app needs a senior Android engineer. Kotlin and Jetpack Compose required. Hilt for dependency injection. HealthKit alternative Android Health Connect API integration. Fastlane for release automation. Biometric authentication. HIPAA-compliant data handling and end-to-end encryption experience strongly required. Modular architecture and senior mentoring responsibilities.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Kotlin and Android SDK show a basic Android foundation\"],\"gaps\":[\"Intern seniority is well below the senior-level and mentoring requirement\",\"No Jetpack Compose for modern Android UI\",\"No Hilt for dependency injection\",\"No Health Connect or biometric authentication experience\",\"No Fastlane for release automation\",\"No HIPAA compliance or encryption experience\"],\"explanation\":\"This candidate has only entry-level Android development experience and lacks nearly every specific technical and compliance requirement for a senior FDA-regulated health app role. The combination of intern seniority, absent modern Android tooling, and no HIPAA compliance background makes this a very weak match for a high-stakes regulated healthcare context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"data_viz_only_jen\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Tableau\",\"Pandas\",\"Matplotlib\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nIoT data company building a real-time industrial sensor monitoring platform needs a senior data engineer. Apache Kafka and Apache Flink for streaming required. Python and Scala for pipeline development. InfluxDB for time-series sensor data. Kubernetes on AWS for deployment. dbt and Airflow for batch layers. Great Expectations for data quality. Senior cross-team ownership and mentoring expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and SQL proficiency present and relevant as a starting point\"],\"gaps\":[\"Junior seniority with no senior ownership or mentoring experience\",\"No Kafka or Flink for streaming data pipelines\",\"No Scala experience for pipeline development\",\"No InfluxDB for time-series data\",\"No Kubernetes, AWS, dbt, Airflow, or Great Expectations\",\"Data analyst background does not map to data engineering infrastructure ownership\"],\"explanation\":\"This candidate is a junior data analyst whose profile is oriented toward visualisation and reporting, not engineering streaming infrastructure. The required streaming, time-series, and orchestration tooling are entirely absent. Senior-level cross-team ownership and mentoring responsibilities further widen the gap from this candidate's current capability.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wordpress_cms_bob\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\"],\"tech\":[\"WordPress\",\"WooCommerce\"],\"databases\":[\"MySQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nClimate fintech company building carbon credit trading infrastructure needs a mid-level backend engineer. Go or Python required. Apache Kafka for trade event streaming. PostgreSQL for ACID transaction data. Kubernetes and Docker for deployment. gRPC for internal service communication. Understanding of financial settlement workflows and regulatory reporting data pipelines expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Basic backend web development experience demonstrated\"],\"gaps\":[\"No Go or Python experience, which are the required languages\",\"WordPress and WooCommerce domain does not transfer to financial trading infrastructure\",\"No Kafka, gRPC, Kubernetes, or Docker experience\",\"No PostgreSQL experience; only MySQL from a CMS context\",\"No financial settlement or regulatory reporting knowledge\"],\"explanation\":\"This candidate's CMS and e-commerce PHP background has no meaningful overlap with the financial trading and event streaming infrastructure requirements. The language mismatch alone is disqualifying, and the absence of every core infrastructure tool reinforces this. A significant domain and technical reskilling effort would be required.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fresh_grad_ml\",\"seniority\":\"Intern\",\"languages\":[\"Python\"],\"tech\":[\"NumPy\",\"Pandas\",\"Jupyter\"]}\n\nJob Summary:\nDefence contractor building an AI-powered radar signal classification system needs a senior ML engineer. PyTorch and CUDA for deep learning on GPU clusters. Signal processing with NumPy and SciPy. ONNX for edge deployment. C++ for real-time inference integration. Distributed training with Horovod or DeepSpeed. Security clearance eligibility and at least five years of production ML experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"NumPy is present and relevant for signal processing\"],\"gaps\":[\"Intern seniority with no production experience versus five-year senior requirement\",\"No PyTorch or CUDA for GPU-based deep learning\",\"No SciPy for signal processing beyond NumPy basics\",\"No ONNX for edge deployment\",\"No C++ for real-time inference\",\"No distributed training experience with Horovod or DeepSpeed\"],\"explanation\":\"This candidate has only basic Python data manipulation experience at intern level, which is far from the senior production ML engineering depth required for a defence radar classification system. Every specialised requirement, from CUDA and distributed training to C++ inference and edge deployment, is absent. There is no viable path to contribution in this role without years of targeted development.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vba_excel_dev\",\"seniority\":\"Mid\",\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Pandas\",\"Excel\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nB2B SaaS company building a real-time collaborative code review and CI analytics platform needs a mid-level backend engineer. Go or TypeScript for backend services. GraphQL for the API layer. PostgreSQL for analytics data. Docker and Kubernetes for deployment. GitHub Actions integration experience for CI webhook processing. Redis for caching and pub/sub. Strong REST and event-driven API design expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and SQL provide a minimal backend foundation\"],\"gaps\":[\"No Go or TypeScript experience for the backend language requirement\",\"No GraphQL experience for the API layer\",\"No Docker or Kubernetes for deployment\",\"No Redis for caching or pub/sub\",\"No GitHub Actions integration or webhook processing experience\",\"No event-driven API design background\"],\"explanation\":\"This candidate's profile is oriented toward data analysis with Python and Excel rather than backend API and infrastructure engineering. The required languages, API patterns, and infrastructure tooling are all absent. There is no meaningful technical overlap with the responsibilities of a mid-level backend engineer building a CI analytics platform.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"unity_game_dev_pat\",\"seniority\":\"Junior\",\"roles\":[\"Game Developer\"],\"languages\":[\"C#\",\"C++\"],\"tech\":[\"Unity\",\"Unreal Engine\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nHealthtech startup building a remote patient monitoring platform needs a mid-level backend engineer. Python and Django for REST APIs. Celery for async health alert processing. PostgreSQL for structured patient records. AWS and Docker for deployment. HIPAA-compliant data architecture experience. Familiarity with HL7 or FHIR health data standards strongly preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"C++ background provides some systems-level programming awareness\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement\",\"Game development background does not transfer to healthcare backend engineering\",\"No Python or Django for the required REST API framework\",\"No Celery, PostgreSQL, Docker, or AWS experience\",\"No HIPAA, HL7, or FHIR healthcare standards knowledge\"],\"explanation\":\"This candidate's Unity and Unreal Engine game development background has no meaningful overlap with a Python-based healthcare backend role. The required language, framework, infrastructure tooling, and healthcare compliance domain knowledge are all absent. The domain mismatch is as significant as the technical gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"intern_data_viz_cai\",\"seniority\":\"Intern\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"D3.js\",\"React\",\"CSS\"]}\n\nJob Summary:\nQuantitative hedge fund building an internal risk analytics platform needs a senior full stack engineer. Python for quantitative backend services. FastAPI for REST APIs. PostgreSQL and TimescaleDB for financial time-series data. Docker and Kubernetes on AWS. TypeScript and React for frontend. D3.js or Recharts for risk visualisation. At least five years of financial software development experience.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"D3.js and React are present and relevant to the frontend visualisation requirement\"],\"gaps\":[\"Intern seniority with no professional experience versus five-year senior requirement\",\"No TypeScript, which is required for the frontend\",\"No Python or FastAPI for quantitative backend services\",\"No PostgreSQL, TimescaleDB, Docker, Kubernetes, or AWS experience\",\"No financial domain knowledge or quantitative systems background\"],\"explanation\":\"While the candidate has D3.js and React experience that is directly relevant to the risk visualisation frontend, the rest of the profile is an intern-level mismatch for a senior financial software engineering role. The backend, infrastructure, and quantitative finance domain requirements are entirely unaddressed. D3.js alone cannot bridge this gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"php_laravel_mid_dev\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"Laravel\",\"Redis\",\"Docker\"],\"architecture\":[\"Monolith\",\"REST\"],\"databases\":[\"MySQL\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nRobotics-as-a-service company building a cloud robot management platform needs a mid-level backend engineer. Go or Rust required for performance-critical robot telemetry ingestion services. gRPC for robot communication protocol. Apache Kafka for telemetry event streaming. Kubernetes and Docker on AWS for deployment. Time-series database experience with InfluxDB or TimescaleDB required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker experience provides basic containerisation familiarity\"],\"gaps\":[\"No Go or Rust experience, which are required for telemetry ingestion performance\",\"Laravel and PHP do not transfer to low-latency robotics backend engineering\",\"No gRPC experience for robot communication protocols\",\"No Kafka for telemetry streaming\",\"No Kubernetes or AWS experience\",\"No InfluxDB or TimescaleDB for time-series data\"],\"explanation\":\"This candidate's Laravel and PHP background is oriented toward web application development and has minimal overlap with a robotics telemetry ingestion platform. The required languages, communication protocols, and time-series data infrastructure are all absent. Docker is the only transferable tool, which is insufficient for the scope of the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"basic_fe_grad_tomo\",\"seniority\":\"Junior\",\"languages\":[\"JavaScript\",\"HTML\"],\"tech\":[\"Vue.js\",\"CSS\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nMedia tech company building a browser-based live video streaming and clipping tool needs a mid-level frontend engineer. TypeScript and React required. WebRTC for peer-to-peer video streaming. Media Source Extensions API for adaptive bitrate playback. Canvas API or WebGL for video frame manipulation. Webpack or Vite for bundling. Mid-level with at least two years of production video or media web engineering experience expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Junior seniority does not meet the mid-level and two-year production requirement\",\"Vue.js background does not map to the React and TypeScript stack required\",\"No WebRTC experience for peer-to-peer video streaming\",\"No Media Source Extensions or adaptive bitrate playback experience\",\"No Canvas API or WebGL for video frame manipulation\",\"No TypeScript proficiency\"],\"explanation\":\"This candidate's basic junior Vue.js profile has no overlap with the specialised browser media engineering requirements of a live video streaming tool. WebRTC, Media Source Extensions, and video frame manipulation APIs are niche skills that are entirely absent. The framework mismatch and junior seniority compound the technical gaps significantly.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"excel_analyst_sri\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Tableau\",\"Excel\",\"Pandas\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nHigh-frequency trading firm building a real-time market microstructure analytics platform needs a senior data engineer. Apache Kafka and Apache Flink for tick-by-tick market event streaming. ClickHouse for low-latency analytics queries. C++ or Go for performance-critical data consumers. Kubernetes on AWS for deployment. Python for scripting only. At least four years of financial data engineering experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and SQL are present and acknowledged as scripting tools in this context\"],\"gaps\":[\"Junior seniority versus four-year senior financial data engineering requirement\",\"No Kafka or Flink for real-time market event streaming\",\"No ClickHouse for low-latency analytics\",\"No C++ or Go for performance-critical data consumers\",\"No Kubernetes or AWS infrastructure experience\",\"Data analyst background with Excel and Tableau does not transfer to financial data engineering infrastructure\"],\"explanation\":\"This candidate's data analysis background in Tableau and Excel is entirely misaligned with a senior real-time financial data engineering infrastructure role. The required streaming, query engine, and systems programming tools are all absent. Junior seniority and the absence of financial domain engineering experience compound the mismatch significantly.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wasm_mid_dev_kira\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"Rust\"],\"tech\":[\"React\",\"WebAssembly\",\"Vite\",\"Tailwind CSS\"],\"architecture\":[\"Client-Server\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nDeveloper tools company building a browser-based code execution sandbox needs a mid-level frontend engineer. TypeScript and React required. WebAssembly for in-browser sandboxed execution of multiple languages. Rust for compiling WASM modules. Vite for bundling. Tailwind CSS for UI. Vitest and Playwright for testing. Experience with worker threads and SharedArrayBuffer for parallel execution preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript, React, WebAssembly, Rust, Vite, Tailwind, Vitest, and Playwright are all directly required and confirmed\",\"The Rust plus WebAssembly combination is a rare and precise match for WASM module compilation\",\"Mid-level seniority is appropriate\"],\"gaps\":[\"No explicit worker thread or SharedArrayBuffer experience for parallel execution, which is preferred\"],\"explanation\":\"The candidate's profile is technically a near-perfect stack match for a browser-based code execution sandbox. The combination of Rust and WebAssembly is uncommon and highly relevant. The only gap is the absence of confirmed worker thread and SharedArrayBuffer experience, which is preferred for the parallel execution architecture. This sits at the high end of moderate, close to strong.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ar_sdk_mid_dev\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"ARKit\",\"SwiftUI\",\"UIKit\",\"SceneKit\",\"Firebase\"],\"architecture\":[\"Client-Server\"],\"databases\":[\"SQLite\",\"Firestore\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nAR startup building indoor navigation experiences for retail stores needs a mid-level iOS engineer. ARKit required for spatial tracking. SceneKit or RealityKit for 3D rendering. Swift and SwiftUI for the application layer. Fastlane for release automation. XCTest for testing. REST API integration for map data. Experience with LiDAR-based depth sensing on newer iPhone devices strongly preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"ARKit, SceneKit, Swift, SwiftUI, Fastlane, and XCTest are all directly required and confirmed\",\"Objective-C adds backward compatibility depth for legacy SDK integration\",\"Mid-level seniority matches the role grade\"],\"gaps\":[\"No RealityKit experience as the alternative to SceneKit named in the job\",\"No explicit LiDAR-based depth sensing experience, which is strongly preferred\",\"No confirmed REST API integration for map data visible in profile\"],\"explanation\":\"The candidate's ARKit and SceneKit profile is well-aligned with the core indoor navigation requirements, and the SwiftUI, Fastlane, and XCTest toolchain covers the release and testing stack. The notable gap is the absence of LiDAR depth sensing experience, which is strongly preferred for the next-generation spatial tracking features of the product. RealityKit experience is also not confirmed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ravi-krishnamurthy\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\"],\"tech\":[\"FastAPI\",\"Docker\",\"Kubernetes\",\"Redis\",\"Nginx\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"pytest\",\"k6\"]}\n\nJob Summary:\nWe are a Series B fintech startup building a high-throughput payment processing platform. We need a senior backend engineer with strong Python or Go experience to own microservices development and deployment. You will design event-driven pipelines, work with PostgreSQL and Redis, and ship containerized services to Kubernetes. Experience with load testing and CI/CD automation is expected. Our stack is cloud-native and fast-moving.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Senior-level Python and Go match the core language requirements\",\"Microservices and event-driven architecture experience maps directly to the platform design\",\"Kubernetes and Argo CD indicate production-grade deployment experience\",\"PostgreSQL and Redis align with the stated data layer\",\"k6 load testing is a direct match for throughput validation needs\"],\"gaps\":[\"No explicit fintech or payments domain experience visible\"],\"explanation\":\"This candidate's technical profile is a near-exact match for the role's requirements across language, architecture, infrastructure, and testing. The only notable gap is the absence of fintech domain signals, though the technical depth likely compensates. Strong hire for this position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tiffany-wu-dev\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"Firebase\"],\"testing\":[\"Jest\",\"React Testing Library\"]}\n\nJob Summary:\nGrowing e-commerce startup looking for a junior to mid frontend engineer to build and maintain our React and Next.js storefront. You will work on server-side rendering, responsive UI with Tailwind, and integrate with REST APIs. Familiarity with testing practices is a plus. We value clean code and a product mindset. Firebase experience is helpful as we use it for some real-time features.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React and Next.js are a direct stack match for the storefront\",\"Tailwind CSS experience aligns with UI requirements\",\"Jest and React Testing Library show testing awareness valued by the team\",\"Firebase experience matches the real-time feature mention\",\"TypeScript use indicates code quality mindset\"],\"gaps\":[\"No explicit REST API integration signals in the profile\"],\"explanation\":\"This junior candidate's profile covers nearly every technical signal called out in the job summary. The stack alignment is unusually tight for a junior profile, and the testing experience is a bonus. Minimal gaps make this a strong fit despite the seniority level.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"marcus-okonkwo\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Express.js\",\"Docker\",\"Strapi\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Cypress\"]}\n\nJob Summary:\nEnterprise SaaS company seeks a mid-level full stack engineer to maintain and extend a Node.js and React application. Candidates should have experience with relational databases, basic containerization, and an understanding of CMS integrations. We follow agile practices and expect some CI/CD familiarity. TypeScript is required across the stack.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript across the stack satisfies the hard requirement\",\"React and Express.js match the frontend and Node.js backend\",\"PostgreSQL covers the relational database need\",\"GitHub Actions provides CI/CD coverage\"],\"gaps\":[\"No Kubernetes or advanced container orchestration for enterprise-scale deployment\",\"Strapi CMS experience is basic and may not cover complex CMS integration scenarios\",\"No performance monitoring or observability tooling signals\"],\"explanation\":\"The candidate has solid mid-level full stack fundamentals aligned with the core stack. However, the enterprise context implies scale and observability requirements not evidenced in the profile. CMS integration depth and deployment maturity are uncertain, making this a moderate fit pending further validation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priya-menon-ml\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"LangChain\",\"MLflow\",\"Docker\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Pinecone\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAI-first startup building retrieval-augmented generation pipelines for enterprise knowledge management. We need a senior ML engineer experienced with LLM orchestration, vector databases, and model evaluation. PyTorch or equivalent deep learning framework experience is required. You will own the end-to-end ML pipeline from data ingestion to serving. Familiarity with MLflow or similar experiment tracking is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LangChain and Pinecone are a direct match for RAG pipeline development\",\"Hugging Face Transformers covers LLM orchestration requirements\",\"PyTorch satisfies the deep learning framework requirement\",\"MLflow directly matches the experiment tracking callout\",\"Docker and GitHub Actions support end-to-end pipeline ownership\"],\"gaps\":[\"No explicit model serving or inference optimization signals\"],\"explanation\":\"This candidate is purpose-built for the role, with direct experience in every major technical domain called out in the job summary. The RAG stack alignment including vector databases and LLM tooling is particularly strong. Minor gap around serving infrastructure is unlikely to be disqualifying at this seniority.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yusuf-al-rashid\",\"seniority\":\"Lead\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"Ansible\",\"Docker\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitLab CI\",\"Argo CD\"]}\n\nJob Summary:\nLarge financial services firm modernizing its infrastructure. Seeking a lead DevOps or platform engineer with deep Kubernetes and infrastructure-as-code experience. Terraform and Helm are used heavily. Observability tooling including Prometheus and Grafana is part of the core stack. GitLab CI is our primary CI/CD system. Cloud-native architecture knowledge is essential.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes and Helm are a direct match for the core infrastructure stack\",\"Terraform covers the infrastructure-as-code requirement explicitly\",\"Prometheus and Grafana align with the stated observability stack\",\"GitLab CI is a direct match for the CI/CD system\",\"Cloud-native and microservices architecture signal matches the firm's modernization goal\",\"Lead seniority is appropriate for the team leadership implied\"],\"gaps\":[],\"explanation\":\"Every technical signal in the job description is present in this candidate's profile. The combination of IaC, Kubernetes orchestration, and observability tooling at lead seniority makes this an unusually clean match. No meaningful gaps identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"chen-wei-fullstack\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Next.js\",\"Express.js\",\"Tailwind CSS\",\"Docker\"],\"databases\":[\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nHealthtech startup building a patient-facing telemedicine platform. Looking for a mid-level full stack engineer comfortable with React and Node.js. PostgreSQL experience is required for structured health records. GraphQL API experience is preferred. We value test coverage and deploy via GitHub Actions. HIPAA-adjacent data handling experience is a bonus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Next.js cover the frontend requirement well\",\"Express.js provides Node.js backend experience\",\"Docker and GitHub Actions match the deployment setup\",\"Jest indicates some test coverage awareness\"],\"gaps\":[\"MongoDB and Redis but no PostgreSQL, which is explicitly required for structured health records\",\"No GraphQL signals despite it being a preferred skill\",\"No signals related to healthcare data handling or compliance\"],\"explanation\":\"The candidate has solid full stack fundamentals and a compatible deployment workflow, but the missing PostgreSQL experience is a direct gap against a stated requirement. The absence of GraphQL and any healthcare domain signals add further uncertainty. Potentially viable with onboarding but not an immediate fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ana-lima-data\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Spark\",\"Apache Airflow\",\"dbt\",\"Pandas\",\"Docker\"],\"architecture\":[\"Event-Driven\"],\"databases\":[\"Snowflake\",\"PostgreSQL\",\"Redshift\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nMedia company scaling its data platform. We need a senior data engineer to own our Snowflake-based warehouse, build dbt models, and orchestrate pipelines with Airflow. Spark experience is a plus for large-scale batch processing. We use Redshift for legacy workloads. Python and SQL are required. The role involves collaborating with analysts and improving pipeline reliability.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Snowflake and dbt are direct matches for the core warehouse and modeling work\",\"Apache Airflow aligns with the orchestration requirement\",\"Apache Spark covers the large-scale batch processing plus\",\"Redshift experience is directly relevant to the legacy workload context\",\"Python and SQL are confirmed across the profile\"],\"gaps\":[\"No explicit data quality or observability tooling signals\"],\"explanation\":\"This candidate hits every major technical requirement for the role with direct, stack-specific experience. The combination of Snowflake, dbt, and Airflow at senior level is a particularly strong signal for pipeline ownership. The only minor gap is observability tooling, which is not called out explicitly in the job summary.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dmitri-volkov-backend\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"Celery\",\"Redis\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nB2B SaaS platform for HR automation. We are hiring a mid-level backend engineer to work on our Django-based API and background job infrastructure. Celery and Redis are used for async processing. PostgreSQL is our primary database. We are beginning to explore Kubernetes for orchestration. Strong testing habits with pytest are expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Django directly matches the core API framework\",\"Celery and Redis align with the async processing requirement\",\"PostgreSQL is confirmed as the primary database\"],\"gaps\":[\"No Kubernetes exposure despite the role beginning to explore it\",\"MongoDB in the profile may indicate non-relational habits that conflict with PostgreSQL-first design\",\"No signals on API documentation or contract-first development practices\"],\"explanation\":\"The candidate's existing Django stack is well-aligned with current requirements. The Kubernetes gap is noted even though the role describes it as exploratory, as the company will likely expect some readiness. Overall a moderate fit with strong potential for the current stack.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sofia-barreto-mobile\",\"seniority\":\"Senior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Expo\"],\"databases\":[\"Firebase\",\"SQLite\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nConsumer fintech app with 2M active iOS users. Looking for a senior iOS engineer to lead SwiftUI migration from UIKit, improve app performance, and own the release pipeline. Fastlane experience is required for CI/CD. Firebase is used for analytics and crash reporting. Strong Swift fundamentals are non-negotiable.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SwiftUI and UIKit experience is directly relevant for the migration\",\"Fastlane is a direct match for the CI/CD requirement\",\"Firebase aligns with the analytics and crash reporting context\"],\"gaps\":[\"No explicit performance profiling tools for a 2M user production app\",\"Expo signals suggest some cross-platform work which may not align with a native iOS focus\",\"Senior iOS performance optimization at scale is not evidenced beyond the framework signals\"],\"explanation\":\"The candidate has appropriate iOS framework experience for the migration context and a matching CI/CD toolchain. However, the scale of a 2M user fintech app demands demonstrated performance and reliability signals that are not clearly present. A moderate fit that warrants deeper evaluation of production iOS experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"james-oduya\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Docker\",\"Kafka\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MySQL\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nLarge logistics enterprise running a Java-based microservices platform. Seeking a mid to senior backend engineer proficient in Spring Boot and Apache Kafka for event streaming. PostgreSQL is the primary store. Jenkins is the CI/CD system. We follow test-driven development using JUnit. Cloud migration to AWS is a future initiative.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Spring Boot is a direct match for the core framework\",\"Apache Kafka covers the event streaming requirement\",\"PostgreSQL aligns with the primary database\",\"Jenkins matches the stated CI/CD system\",\"JUnit and Mockito align with the TDD expectation\",\"Microservices architecture experience fits the platform design\"],\"gaps\":[\"No AWS or cloud experience ahead of the planned migration\"],\"explanation\":\"The candidate's stack is nearly a mirror of the job description's current technology requirements. Every stated tool is represented with appropriate seniority. The only forward-looking gap is cloud experience for the AWS migration initiative, which is described as future work and not an immediate requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leila-nouri-frontend\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"Firebase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Cypress\"]}\n\nJob Summary:\nEuropean e-learning startup seeking a mid-level frontend engineer to build interactive course interfaces. Our stack is React and Next.js with TypeScript. We use Tailwind for styling and Vitest for unit testing. The ideal candidate has strong component design skills and some experience with state management libraries.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript and Tailwind CSS are direct matches\",\"Vitest is a direct match for the testing framework\",\"Nuxt.js experience shows SSR familiarity transferable to Next.js\",\"Cypress indicates end-to-end testing awareness\"],\"gaps\":[\"Vue.js and Nuxt.js experience does not transfer directly to the React and Next.js stack requirement\",\"No React-specific signals in the profile\",\"No state management library signals despite it being called out\"],\"explanation\":\"The candidate has strong frontend fundamentals and several stack overlaps, but the core framework mismatch between Vue/Nuxt and React/Next.js is a meaningful gap. Framework migration is possible but requires ramp-up time. Styling and testing alignment partially offset this concern.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nathaniel-cross\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"Tableau\",\"MLflow\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"]}\n\nJob Summary:\nRetail analytics company hiring a senior data scientist to build predictive models for inventory optimization. Python and scikit-learn are required. BigQuery is the data warehouse. We present findings via Tableau dashboards. Experiment tracking with MLflow or similar is preferred. Some SQL proficiency is expected for data extraction.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Python and scikit-learn are direct matches for the core modeling requirement\",\"BigQuery aligns with the data warehouse\",\"Tableau matches the dashboard presentation requirement\",\"MLflow is a direct match for the experiment tracking preference\",\"SQL and Pandas support data extraction and manipulation needs\"],\"gaps\":[\"No domain-specific signals for supply chain or inventory modeling\"],\"explanation\":\"The candidate's tooling profile maps precisely onto the job description's technical requirements. The combination of scikit-learn modeling, BigQuery, Tableau, and MLflow at senior level is highly aligned. The only gap is supply chain domain context, which is not uncommon to acquire on the job given strong technical foundations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alicia-moreno-devops\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"Terraform\",\"Ansible\",\"Prometheus\"],\"architecture\":[\"Cloud-Native\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"CircleCI\"]}\n\nJob Summary:\nGrowth-stage startup seeking a mid-level DevOps engineer to own infrastructure automation and cloud deployments on AWS. Kubernetes experience is required. Terraform is used for provisioning. Observability via Prometheus and Grafana is part of the stack. We use GitHub Actions for CI/CD. Python scripting is expected for automation tasks.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform is a direct match for the provisioning requirement\",\"Prometheus aligns with the observability stack\",\"GitHub Actions matches the CI/CD system\",\"Python scripting supports the automation expectation\",\"Cloud-native architecture signal indicates relevant mindset\"],\"gaps\":[\"No Kubernetes experience despite it being a stated requirement\",\"No Grafana signals to complete the observability stack\",\"No explicit AWS experience despite it being the target cloud\"],\"explanation\":\"The candidate covers several key areas but is missing Kubernetes, which is called out as a hard requirement. The AWS and Grafana gaps further reduce confidence. Docker and Terraform provide a reasonable foundation but the role likely needs someone who can operate Kubernetes clusters immediately.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kevin-ng-sre\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Prometheus\",\"Grafana\",\"Terraform\",\"Helm\",\"Datadog\"],\"architecture\":[\"Microservices\",\"Cloud-Native\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nFAANG-adjacent company with high-scale distributed systems. Seeking a senior SRE to own reliability, incident response, and platform observability. Kubernetes is the orchestration layer. Prometheus and Grafana or Datadog for observability. Terraform for IaC. Familiarity with Go or Python for tooling development. Microservices and cloud-native background required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform is a direct match for the provisioning requirement\",\"Prometheus aligns with the observability stack\",\"GitHub Actions matches the CI/CD system\",\"Python scripting supports the automation expectation\"],\"gaps\":[\"No Kubernetes experience despite it being a stated requirement\",\"No Grafana signals to complete the observability stack\",\"No explicit AWS experience despite it being the target cloud\"],\"explanation\":\"The candidate covers several key areas but is missing Kubernetes, which is called out as a hard requirement. The AWS and Grafana gaps further reduce confidence. Docker and Terraform provide a reasonable foundation but the role likely needs someone who can operate Kubernetes clusters immediately.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fatima-hassan-mobile\",\"seniority\":\"Junior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\"],\"databases\":[\"Firebase\",\"SQLite\"],\"testing\":[\"JUnit\"]}\n\nJob Summary:\nMobile-first startup building a consumer social app for Android. Seeking a junior to mid Android engineer with Jetpack Compose experience. Kotlin is required. Firebase will be used for real-time data sync and authentication. We follow test-driven development and expect basic JUnit familiarity. The team is small and collaborative.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Jetpack Compose is a direct match for the UI framework requirement\",\"Kotlin satisfies the hard language requirement\",\"Firebase covers both real-time data and authentication use cases\",\"JUnit aligns with the TDD expectation\",\"Android SDK confirms platform experience\"],\"gaps\":[\"Junior seniority may require mentorship investment in a small team\"],\"explanation\":\"The candidate's technical profile directly satisfies every named requirement in the job description. The Jetpack Compose and Firebase combination is particularly strong for the stated product context. The only consideration is junior seniority in a small team, which the job posting explicitly acknowledges as acceptable.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pierre-dubois-arch\",\"seniority\":\"Staff\",\"roles\":[\"Software Architect\"],\"languages\":[\"Java\",\"Python\",\"TypeScript\"],\"tech\":[\"Spring Boot\",\"Kafka\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Domain-Driven Design\",\"CQRS\",\"Event Sourcing\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"GitLab CI\",\"Argo CD\"]}\n\nJob Summary:\nEnterprise platform company building a multi-tenant SaaS product. Seeking a staff engineer or architect to define system architecture, lead DDD adoption, and guide teams on event-driven patterns including CQRS and event sourcing. Java and Spring Boot are the core stack. Strong distributed systems experience required. Multi-tenant architecture knowledge is essential.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Domain-Driven Design, CQRS, and Event Sourcing are all directly present and match the core architectural mandate\",\"Java and Spring Boot satisfy the core stack requirements\",\"Kafka supports the event-driven platform design\",\"Staff seniority matches the architectural leadership scope\",\"Cassandra and Redis indicate distributed systems database experience\"],\"gaps\":[\"No explicit multi-tenant architecture signals despite it being listed as essential\"],\"explanation\":\"This candidate is exceptionally well-positioned for an architectural leadership role. The precise match on DDD, CQRS, and event sourcing at staff level is rare and directly relevant. The multi-tenant gap is worth probing in an interview but does not significantly undermine the overall fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amir-hosseini-backend\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"Flask\",\"Celery\",\"Redis\",\"Docker\"],\"databases\":[\"MySQL\",\"MongoDB\"]}\n\nJob Summary:\nEarly-stage startup in the legaltech space seeking a mid-level backend engineer. We use FastAPI and PostgreSQL exclusively. TypeScript will be introduced for some tooling. Kubernetes-based deployment is planned for Q3. Strong async programming skills are needed. Testing with pytest is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python is the correct language and Celery indicates async task experience\",\"Redis experience is transferable to the async infrastructure\",\"Docker provides a foundation for the Kubernetes transition\"],\"gaps\":[\"Uses Flask rather than FastAPI, which is the required framework\",\"No PostgreSQL experience; uses MySQL and MongoDB\",\"No pytest signals despite it being expected\",\"No TypeScript experience for the planned tooling work\",\"No Kubernetes signals\"],\"explanation\":\"The candidate has relevant Python backend experience but misses on several specific stack requirements including the framework, primary database, and testing toolchain. The async experience is a positive signal, but the cumulative gaps across framework, database, and testing represent a meaningful ramp-up investment for the startup.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"grace-osei-fullstack\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Next.js\",\"React\",\"FastAPI\",\"Docker\",\"Tailwind CSS\"],\"architecture\":[\"Serverless\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nProduct-led growth startup building developer tools. Seeking a senior full stack engineer comfortable with Next.js frontends and Python backends. Supabase is our BaaS layer. We deploy serverless functions on Vercel. Testing is taken seriously with both unit and end-to-end coverage expected. The ideal candidate can own features end to end.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and React match the frontend requirements directly\",\"FastAPI and Python cover the backend stack\",\"Supabase is a direct match for the BaaS layer\",\"Serverless architecture aligns with the Vercel deployment model\",\"Jest, pytest, and Playwright demonstrate both unit and end-to-end testing maturity\",\"Tailwind CSS and Docker round out the practical toolchain\"],\"gaps\":[\"No explicit Vercel deployment signals though serverless architecture knowledge is present\"],\"explanation\":\"This candidate's profile is an excellent match across frontend, backend, BaaS, and testing requirements. The serverless architecture signal aligns well with Vercel deployments even without an explicit Vercel reference. The testing breadth across unit and end-to-end is a particularly strong fit for a quality-focused team.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rafael-silva-data\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Tableau\",\"Pandas\"],\"databases\":[\"MySQL\",\"PostgreSQL\"]}\n\nJob Summary:\nRetail company seeking a senior data engineer to design and maintain Snowflake pipelines, build dbt transformation models, and orchestrate workflows with Apache Airflow. Python and SQL are baseline requirements. Spark experience for large-scale processing is preferred. The role requires at least 5 years of relevant experience.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and SQL are confirmed, satisfying baseline language requirements\"],\"gaps\":[\"Junior seniority is far below the 5-year experience requirement for a senior role\",\"No Snowflake experience despite it being the core data warehouse\",\"No dbt experience for transformation modeling\",\"No Apache Airflow or any orchestration tooling\",\"No Apache Spark or large-scale processing signals\",\"Data analyst role profile does not map to data engineering responsibilities\"],\"explanation\":\"While the candidate demonstrates foundational data skills, the experience level and technical depth fall significantly short of the senior data engineering requirements. The absence of the entire core stack including Snowflake, dbt, and Airflow makes this a poor match regardless of the seniority gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tom-warren-ios\",\"seniority\":\"Junior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"UIKit\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nEnterprise mobility company building a fleet management app for Android. Seeking a mid-level Android engineer with Kotlin and Jetpack Compose experience. Firebase is used for push notifications and real-time sync. Prior experience with complex list views and offline-first architecture is preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Mobile development experience exists, showing general mobile engineering familiarity\"],\"gaps\":[\"iOS-only profile with no Android, Kotlin, or Jetpack Compose experience\",\"No Firebase signals for the required notification and sync features\",\"SQLite on iOS does not demonstrate Android-specific offline-first architecture\",\"Junior seniority does not meet the mid-level expectation\"],\"explanation\":\"This is a fundamental platform mismatch. The candidate's experience is entirely iOS-based while the role requires Android expertise. Cross-platform mobile experience is not evidenced, and the seniority level is below the expectation. This profile is not suitable for the role as described.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yuki-tanaka-ml\",\"seniority\":\"Junior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\"]}\n\nJob Summary:\nAutonomous vehicle company seeking a senior ML engineer with deep experience in computer vision using PyTorch and OpenCV. CUDA optimization and ONNX model export experience required. MLflow for experiment tracking is used. The role involves training large models on GPU clusters and deploying to edge hardware.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is confirmed as the baseline language\",\"scikit-learn and Pandas show some ML foundations\"],\"gaps\":[\"No PyTorch experience despite it being required for computer vision work\",\"No OpenCV signals for the core computer vision requirement\",\"No CUDA or GPU optimization experience\",\"No ONNX or model export experience\",\"No MLflow or experiment tracking signals\",\"Junior seniority is mismatched against a senior specialized role\",\"No edge deployment or embedded inference experience\"],\"explanation\":\"The candidate has entry-level ML foundations with traditional ML libraries but lacks every specialized skill the role requires. Computer vision, GPU optimization, edge deployment, and senior-level experience are all absent. This is a significant experience and specialization mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"emeka-chukwu\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"SQL\"],\"tech\":[\"Laravel\",\"Docker\"],\"databases\":[\"MySQL\",\"Redis\"]}\n\nJob Summary:\nE-commerce company using a legacy LAMP stack transitioning to a Laravel and MySQL architecture. Seeking a mid-level PHP developer with Laravel experience. Redis is used for session and cache management. Docker for local development environments. The role involves API development and integrating payment gateways.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python is the correct language and Celery indicates async task experience\",\"Redis experience is transferable to the async infrastructure\",\"Docker provides a foundation for the Kubernetes transition\"],\"gaps\":[\"Uses Flask rather than FastAPI, which is the required framework\",\"No PostgreSQL experience; uses MySQL and MongoDB\",\"No pytest signals despite it being expected\",\"No TypeScript experience for the planned tooling work\"],\"explanation\":\"The candidate has relevant Python backend experience but misses on several specific stack requirements including the framework, primary database, and testing toolchain. The async experience is a positive signal, but the cumulative gaps across framework, database, and testing represent a meaningful ramp-up investment for the startup.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"isabelle-martin-frontend\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Redux\",\"Webpack\",\"Jest\",\"styled-components\"],\"ci_cd\":[\"Jenkins\"]}\n\nJob Summary:\nFinancial data platform modernizing from a legacy React and Redux stack to a micro-frontend architecture using Module Federation. TypeScript is required. They are also adopting Vite and moving from styled-components to Tailwind CSS. Strong testing practices with React Testing Library are expected. CI/CD runs on GitHub Actions.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Redux provide directly relevant experience for the legacy system and migration context\",\"TypeScript is confirmed as required\",\"Jest shows testing familiarity that can transfer to React Testing Library\"],\"gaps\":[\"No Module Federation or micro-frontend architecture signals\",\"Uses Webpack rather than Vite which is being adopted\",\"styled-components experience is the old approach being replaced by Tailwind CSS\",\"No React Testing Library signals specifically\",\"CI/CD is Jenkins rather than GitHub Actions\"],\"explanation\":\"The candidate has strong foundational React experience relevant to understanding the existing codebase but lacks signals for the target state of the architecture. Multiple tools in the modernization stack are absent or replaced. This is a moderate fit with meaningful technical transition investment required.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"caleb-osei-devops\",\"seniority\":\"Junior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"GitHub Actions\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nMid-size SaaS company seeking a mid-level DevOps engineer to manage Kubernetes clusters on AWS EKS, automate infrastructure with Terraform, and maintain observability with Prometheus and Grafana. Familiarity with Helm is expected. GitHub Actions is the CI/CD system. Prior experience operating production Kubernetes environments is essential.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"GitHub Actions is a direct match for the CI/CD requirement\",\"Docker knowledge is foundational for Kubernetes work\"],\"gaps\":[\"No Kubernetes experience despite production Kubernetes being listed as essential\",\"No Terraform for infrastructure automation\",\"No AWS or EKS signals\",\"No Prometheus or Grafana for observability\",\"No Helm experience\",\"Junior seniority does not meet the mid-level expectation for a role requiring production Kubernetes ownership\"],\"explanation\":\"The candidate is at an early stage of DevOps experience with foundational tools only. The role requires production Kubernetes ownership and an IaC and observability stack that are entirely absent from the profile. This is a significant experience and skills gap for the position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nadia-petrov-fullstack\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Go\"],\"tech\":[\"Next.js\",\"React\",\"Gin\",\"Docker\",\"Redis\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nClimate tech startup building a carbon tracking SaaS. Seeking a senior full stack engineer comfortable owning both Next.js product features and Go microservices backends. PostgreSQL is the primary store. Docker-based deployments. Strong testing culture with e2e coverage expected. TypeScript is required on the frontend.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Domain-Driven Design, CQRS, and Event Sourcing are present matching architectural areas\",\"Java and Spring Boot satisfy the core stack requirements\",\"Kafka supports event-driven platform design\",\"Staff seniority is appropriate for architectural scope\"],\"gaps\":[\"No multi-tenant architecture signals despite it being listed as essential\",\"No explicit SaaS platform or tenant isolation experience evidenced\",\"Cassandra may not be used in this stack and could indicate different prior context\"],\"explanation\":\"The candidate has strong architectural depth in DDD and event-driven patterns, directly relevant to the design mandate. However, the absence of multi-tenant architecture signals is a meaningful gap given it is listed as essential for a multi-tenant SaaS product. This warrants deeper investigation before a strong recommendation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kwame-asante-backend\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"Celery\",\"Docker\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nHealthcare data startup building clinical decision support tools. Seeking a mid-level backend engineer with FastAPI and PostgreSQL experience. Python is required. Async job processing with Celery is part of the stack. We test rigorously with pytest. Docker for containerization. Some familiarity with FHIR or HL7 is a plus but not required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"FastAPI is a direct match for the core API framework\",\"PostgreSQL satisfies the primary database requirement\",\"Celery aligns with the async job processing stack\",\"pytest matches the testing expectation\",\"Docker covers containerization\",\"GitHub Actions rounds out the CI/CD expectation\"],\"gaps\":[\"No FHIR or HL7 experience, though the job notes this is a plus not a requirement\"],\"explanation\":\"Every required technical element in the job description is directly represented in the candidate's profile. The match is clean across framework, database, async processing, and testing. The FHIR gap is explicitly acceptable per the job description, making this a strong overall fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"luca-ferrari-backend\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"Python\"],\"tech\":[\"Actix\",\"Docker\",\"Kafka\"],\"architecture\":[\"Event-Driven\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"]}\n\nJob Summary:\nHigh-frequency trading infrastructure company seeking a senior Rust engineer to build low-latency data processing services. Actix or Axum for HTTP services. Event-driven architecture with Kafka. PostgreSQL for trade data persistence. Redis for order book caching. Performance-critical systems background is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and FastAPI cover the core frontend and backend requirements\",\"Supabase is a direct match for the BaaS layer\",\"Jest, pytest, and Playwright show strong testing coverage\",\"Serverless architecture signal is relevant to the Vercel deployment context\"],\"gaps\":[\"No explicit Vercel deployment signals in the profile\",\"Tailwind CSS is present but no component library signals for a design-focused product\",\"No analytics or product event tracking signals for a PLG context\"],\"explanation\":\"The candidate covers the core technical stack well with strong testing practices. The serverless architecture background is directionally aligned with Vercel but not confirmed as platform-specific experience. A moderate fit that is likely to strengthen with closer evaluation of the deployment and product analytics experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mei-chen-data\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Airflow\",\"dbt\",\"Pandas\"],\"databases\":[\"Redshift\",\"PostgreSQL\"]}\n\nJob Summary:\nMedia streaming company building its analytics infrastructure on Snowflake and dbt. Airflow is used for orchestration. Python and SQL are required. The role involves migrating legacy Redshift workloads to Snowflake. Some experience with data quality tooling like Great Expectations is preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt experience is a direct match for the core transformation work\",\"Apache Airflow aligns with the orchestration requirement\",\"Redshift experience is directly relevant to the legacy workload migration context\",\"Python and SQL are confirmed\"],\"gaps\":[\"No Snowflake experience despite it being the target warehouse\",\"No Great Expectations or data quality tooling signals\"],\"explanation\":\"The candidate brings strong pipeline and orchestration skills with directly relevant Redshift experience for the migration context. However, the absence of Snowflake is a notable gap given it is the destination platform. The fit is moderate, contingent on ability to ramp on Snowflake quickly given strong dbt and Airflow foundations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"oscar-lindqvist\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\",\"Backend Engineer\"],\"languages\":[\"Go\",\"Java\",\"Python\"],\"tech\":[\"Kubernetes\",\"Kafka\",\"Docker\",\"Istio\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Microservices\",\"Service Mesh\",\"Event-Driven\",\"Cloud-Native\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"Argo CD\",\"GitLab CI\"]}\n\nJob Summary:\nTelecommunications company modernizing a decade-old monolith. Seeking a principal engineer to lead microservices decomposition strategy, implement service mesh with Istio, and define platform engineering practices. Kafka for event streaming. Kubernetes for orchestration. Strong observability background required. The candidate must be comfortable setting technical direction across multiple teams.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Istio is a direct match for the service mesh implementation requirement\",\"Kafka covers the event streaming requirement\",\"Kubernetes and Argo CD indicate production orchestration and GitOps maturity\",\"Prometheus and Grafana align with the observability requirement\",\"Principal seniority matches the multi-team technical direction scope\",\"Microservices and cloud-native architecture signals align with the decomposition mandate\",\"Cassandra and Redis alongside PostgreSQL show distributed systems database breadth\"],\"gaps\":[],\"explanation\":\"This is an exceptional match for a principal-level platform engineering leadership role. Every architectural and tooling requirement is present with depth. The Istio and service mesh experience is particularly rare and directly relevant. No meaningful gaps identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amara-diallo\",\"seniority\":\"Junior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"React\",\"Express.js\",\"Node.js\"],\"databases\":[\"MongoDB\"]}\n\nJob Summary:\nEnterprise software company seeking a senior full stack engineer with TypeScript, Next.js, PostgreSQL, and GraphQL experience. The role requires designing scalable APIs, mentoring junior developers, and owning technical decisions. AWS deployment experience with ECS or EKS is expected. Strong testing practices are non-negotiable.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and Express.js provide some frontend and backend web development foundation\"],\"gaps\":[\"No TypeScript despite it being a requirement across the stack\",\"No Next.js experience\",\"No GraphQL signals\",\"MongoDB only, no PostgreSQL which is required\",\"No AWS or cloud deployment experience\",\"No testing signals at all despite being described as non-negotiable\",\"Junior seniority with no mentoring capability for a role requiring senior leadership\"],\"explanation\":\"The candidate has basic JavaScript web development skills but falls significantly short on every specific technical requirement for this senior role. The absence of TypeScript, testing practices, cloud experience, and the seniority gap make this an unsuitable match for the position as described.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hana-park-security\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\",\"AppSec Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Docker\",\"Kubernetes\",\"Terraform\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nCloud security startup seeking a senior application security engineer. Experience with SAST, DAST, or penetration testing tooling is required. Kubernetes security hardening background is strongly preferred. Python or Go for automation and tooling development. The role involves embedding security practices in CI/CD pipelines and conducting threat modeling.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python and Go match the automation and tooling language requirements\",\"Kubernetes experience is relevant to the security hardening preference\",\"Senior seniority aligns with the role scope\",\"Docker and Terraform indicate infrastructure familiarity useful in a cloud security context\"],\"gaps\":[\"No explicit SAST, DAST, or penetration testing tooling signals\",\"No CI/CD security integration signals\",\"No threat modeling indicators\",\"AppSec role listing is present but no tooling evidence to support the specialization\"],\"explanation\":\"The candidate has the right language and infrastructure background for a cloud security role and the appropriate seniority. However, the core security-specific tooling signals around SAST, DAST, and pen testing are absent, leaving the actual AppSec depth unverified. Moderate fit pending evidence of security-specific work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"carlos-ruiz-ml\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"Data Scientist\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Weights & Biases\",\"Pandas\",\"Hugging Face Transformers\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAd tech company building a real-time bidding system powered by ML models. Seeking a senior ML engineer to build and serve recommendation and ranking models. PyTorch is the primary framework. Experiment tracking with Weights and Biases. BigQuery for feature stores and offline evaluation. Low-latency serving infrastructure experience is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch is a direct match for the primary ML framework\",\"Weights and Biases directly matches the experiment tracking tool\",\"BigQuery aligns with the feature store and evaluation data warehouse\",\"Hugging Face Transformers indicates modern model experience\",\"Senior ML seniority matches the role level\"],\"gaps\":[\"No model serving infrastructure signals for the low-latency serving requirement\",\"No real-time system or streaming experience signals\",\"Recommendation and ranking model experience is not explicitly evidenced\"],\"explanation\":\"The candidate covers the research and experimentation side of the ML stack well with strong PyTorch and W&B alignment. However, the ad tech role's emphasis on real-time, low-latency model serving is not evidenced in the profile. Fit is moderate, contingent on production serving experience that may not be visible in the profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"zoe-mackenzie-frontend\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Framer Motion\",\"Storybook\"],\"testing\":[\"Jest\",\"Playwright\",\"React Testing Library\"]}\n\nJob Summary:\nDesign-led SaaS company building a no-code platform. Seeking a mid-level frontend engineer with strong React and Next.js skills and an eye for animation and interaction design. Tailwind CSS is required. Framer Motion for animation. We document components in Storybook. TypeScript is required. Testing with React Testing Library and Playwright.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Ruby on Rails is directly relevant to the monolith\",\"React provides frontend coverage\",\"RSpec and Cypress show testing familiarity\",\"PostgreSQL and Redis are both present\"],\"gaps\":[\"No TypeScript or modern JavaScript tooling signals for the React layer\",\"No background job processing signals beyond Redis general use\",\"No API design or versioning signals for a collaborative SaaS product\"],\"explanation\":\"The candidate's Rails experience aligns with the existing monolith, and the testing stack matches. However, the absence of TypeScript and modern JavaScript tooling for the React layer is a notable gap for a contemporary SaaS product. Mid-level fit with some uncertainty around frontend depth.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"victor-obi-backend\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Scala\",\"Python\"],\"tech\":[\"Apache Spark\",\"Apache Kafka\",\"Airflow\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"Cassandra\",\"PostgreSQL\",\"Redshift\"]}\n\nJob Summary:\nLarge financial services company building a real-time risk analytics platform. Seeking a senior backend or data platform engineer with experience in Apache Spark, Kafka, and distributed systems. Scala is preferred. Experience with time-series or analytical databases is valued. The role involves designing low-latency data pipelines and owning the reliability of streaming infrastructure.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Apache Kafka and Spark cover the stream processing tools\",\"Snowflake and Airflow are present\"],\"gaps\":[\"No sub-millisecond latency optimization signals critical for live sports betting\",\"No experience with real-time odds calculation or betting-specific data models\",\"Event-driven architecture signal is generic and does not indicate sports betting domain readiness\",\"Senior data engineering at this scale for regulated gambling markets requires domain compliance knowledge not evidenced\"],\"explanation\":\"The candidate has a strong general data engineering profile but the sports betting context requires specialized real-time latency and regulatory compliance knowledge that is entirely absent. Domain-specific gaps in a regulated industry are significant for a senior ownership role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sarah-kovacs\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"Ruby\",\"JavaScript\"],\"tech\":[\"Ruby on Rails\",\"React\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"RSpec\",\"Cypress\"]}\n\nJob Summary:\nSaaS startup in the project management space running a Ruby on Rails monolith with React frontend. Seeking a mid-level full stack engineer to build features across the stack. PostgreSQL is the database. Redis for background jobs. Testing with RSpec for backend and Cypress for frontend. Docker for local development.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"GitHub Actions is shared, showing some CI/CD awareness\"],\"gaps\":[\"No JavaScript or TypeScript experience for a JavaScript-based stack role\",\"No React, Node.js, or any web framework signals\",\"No MongoDB or web-focused database experience\",\"No Tailwind CSS or CSS framework signals\",\"Embedded and low-level systems background does not transfer to web agency client work\"],\"explanation\":\"This is a domain mismatch. The candidate specializes in embedded and systems programming while the role requires web development expertise. There is no overlap in the technical stack beyond CI/CD tooling. This candidate is not suitable for the role as described.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"bogdan-marin\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C#\",\"SQL\"],\"tech\":[\"ASP.NET\",\"Docker\"],\"databases\":[\"MS SQL Server\",\"Redis\"]}\n\nJob Summary:\nEnterprise healthcare company seeking a senior .NET engineer to work on a microservices platform built with ASP.NET Core and Entity Framework. Azure cloud infrastructure including Azure Service Bus for messaging. PostgreSQL is being adopted alongside SQL Server. Senior-level experience with system design and code reviews expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"C# and ASP.NET are relevant to the .NET Core stack\",\"SQL Server experience is applicable in the dual-database transition context\",\"Docker indicates some containerization familiarity\"],\"gaps\":[\"No Entity Framework signals despite it being called out\",\"No Azure or Azure Service Bus experience for the messaging and cloud infrastructure\",\"No PostgreSQL experience despite adoption being underway\",\"Mid seniority does not meet the senior experience requirement for system design and code review leadership\",\"No microservices architecture signals\"],\"explanation\":\"The candidate has foundational .NET backend experience but lacks depth in the specific tooling, cloud infrastructure, and seniority the role requires. The Azure ecosystem gaps and missing Entity Framework signals are notable. This is a moderate fit at best, requiring significant ramp-up for the senior-level responsibilities.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"aisha-williams-de\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"Apache Kafka\",\"dbt\",\"Apache Airflow\"],\"architecture\":[\"Event-Driven\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nStreaming analytics company building a real-time data platform for sports betting. Seeking a senior data engineer with Kafka and Spark for stream processing, Snowflake for warehousing, and Airflow for orchestration. dbt for data modeling. Python and SQL required. Low-latency data pipeline experience is critical given the real-time betting context.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and Express.js provide some frontend and backend web development foundation\"],\"gaps\":[\"No TypeScript despite it being a requirement across the stack\",\"No Next.js experience\",\"No GraphQL signals\",\"MongoDB only, no PostgreSQL which is required\",\"No AWS or cloud deployment experience\",\"No testing signals at all despite being described as non-negotiable\",\"Junior seniority with no mentoring capability for a role requiring senior leadership\"],\"explanation\":\"The candidate has basic JavaScript web development skills but falls significantly short on every specific technical requirement for this senior role. The absence of TypeScript, testing practices, cloud experience, and the seniority gap make this an unsuitable match for the position as described.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"felix-huang-embedded\",\"seniority\":\"Senior\",\"roles\":[\"Embedded Engineer\"],\"languages\":[\"C\",\"C++\",\"Rust\"],\"tech\":[\"CUDA\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nWeb agency seeking a mid-level full stack developer for client project work. Primary stack is React, Node.js, and MongoDB. Familiarity with Tailwind CSS and REST API design is expected. Some experience with Vercel or Netlify for deployment. The role involves building landing pages, dashboards, and CMS integrations.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"GitHub Actions is shared, showing some CI/CD awareness\"],\"gaps\":[\"No JavaScript or TypeScript experience for a JavaScript-based stack role\",\"No React, Node.js, or any web framework signals\",\"No MongoDB or web-focused database experience\",\"No Tailwind CSS or CSS framework signals\",\"No REST API or web API design signals\",\"Embedded and low-level systems background does not transfer to web agency client work\"],\"explanation\":\"This is a domain mismatch. The candidate specializes in embedded and systems programming while the role requires web development expertise. There is no overlap in the technical stack beyond CI/CD tooling. This candidate is not suitable for the role as described.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"patricia-nwosu\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"TypeScript\"],\"tech\":[\"Flutter\",\"React Native\",\"Expo\"],\"databases\":[\"Firebase\",\"SQLite\"]}\n\nJob Summary:\nGlobal NGO building a field data collection app for offline-first use cases in low-connectivity environments. Seeking a mid-level mobile engineer with Flutter or React Native experience. SQLite is used for local offline storage. Firebase is used for data sync when connectivity is restored. Cross-platform support for iOS and Android is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python and PostgreSQL are confirmed and align with baseline requirements\",\"Django provides REST API development background\",\"Docker shows deployment awareness\"],\"gaps\":[\"No Airflow or Prefect experience despite orchestration being a stated requirement\",\"No Pandas or PySpark for the data transformation requirement\",\"Junior seniority does not meet the mid-level expectation\",\"No testing signals despite testing culture being emphasized\"],\"explanation\":\"The candidate has foundational Python and Django backend skills relevant to REST API work but lacks the data engineering tooling the role specifically requires. The orchestration and transformation gaps are direct misses against stated requirements. The seniority gap adds further concern for a consulting context expecting client-facing independence.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"andrei-popescu-backend\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nConsulting firm seeking a mid-level backend Python engineer to work on client data pipelines and ETL workflows. Experience with Airflow or Prefect for orchestration is required. Pandas or PySpark for data transformation. PostgreSQL is commonly used across client projects. REST API development is part of the role. Testing culture is important.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python and PostgreSQL are confirmed and align with the baseline requirements\",\"Django provides REST API development background\",\"Docker shows deployment awareness\"],\"gaps\":[\"No Airflow or Prefect experience despite orchestration being a stated requirement\",\"No Pandas or PySpark for the data transformation requirement\",\"Junior seniority does not meet the mid-level expectation\",\"No testing signals despite testing culture being emphasized\"],\"explanation\":\"The candidate has foundational Python and Django backend skills relevant to REST API work but lacks the data engineering tooling the role specifically requires. The orchestration and transformation gaps are direct misses against stated requirements. The seniority gap adds further concern for a consulting context expecting client-facing independence.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lin-wei-cloud\",\"seniority\":\"Senior\",\"roles\":[\"Cloud Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"Terraform\",\"Kubernetes\",\"Helm\",\"AWS Lambda\",\"Docker\"],\"architecture\":[\"Serverless\",\"Cloud-Native\"],\"databases\":[\"DynamoDB\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nE-commerce platform modernizing to a serverless architecture on AWS. Seeking a senior cloud engineer to design and deploy serverless pipelines using AWS Lambda, API Gateway, and DynamoDB. Terraform is used for IaC. Kubernetes for non-serverless workloads. GitHub Actions for CI/CD. Python preferred for Lambda functions.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"GitHub Actions is a direct match for the CI/CD requirement\",\"Docker knowledge is foundational for Kubernetes work\"],\"gaps\":[\"No Kubernetes experience despite production Kubernetes being listed as essential\",\"No Terraform for infrastructure automation\",\"No AWS or EKS signals\",\"No Prometheus or Grafana for observability\",\"No Helm experience\",\"Junior seniority does not meet the mid-level expectation\"],\"explanation\":\"The candidate is at an early stage of DevOps experience with foundational tools only. The role requires production Kubernetes ownership and an IaC and observability stack that are entirely absent from the profile. This is a significant experience and skills gap for the position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mia-johnson-intern\",\"seniority\":\"Intern\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"React\",\"Flask\"]}\n\nJob Summary:\nEarly-stage startup looking for a software engineering intern to help build internal tooling. Stack is Python and React. No prior professional experience required. We value curiosity and a willingness to learn. Basic familiarity with web development concepts is sufficient. Mentorship will be provided.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Go and Next.js provide relevant language signals\"],\"gaps\":[\"No carbon accounting, sustainability metrics, or climate domain signals\",\"No experience with regulatory or compliance data workflows common in climate tech\",\"TypeScript frontend presence but no specialized data visualization for emissions reporting\",\"Microservices background does not indicate readiness for the complex data integrity requirements in carbon tracking\"],\"explanation\":\"The candidate has general full stack skills but the climate tech domain requires specialized understanding of carbon data standards and regulatory compliance that are entirely absent from the profile. Technical fit is partial at best for a domain-specific product at this stage.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tobias-eriksson\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"gRPC\",\"Docker\",\"Kubernetes\",\"Redis\"],\"architecture\":[\"Microservices\",\"Cloud-Native\"],\"databases\":[\"PostgreSQL\",\"CockroachDB\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nGlobal payments company building distributed payment infrastructure. Seeking a senior Go engineer to develop high-reliability microservices using gRPC for inter-service communication. CockroachDB for globally distributed data. Redis for caching. Kubernetes for orchestration. Strong understanding of distributed systems consistency and fault tolerance required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"FastAPI and PostgreSQL are present as baseline signals\",\"pytest indicates some testing discipline\"],\"gaps\":[\"No FHIR or HL7 experience despite clinical decision support being the core domain\",\"No healthcare compliance or audit logging signals\",\"No experience with clinical data models or medical terminology standards\",\"Celery async job processing does not demonstrate clinical workflow management capability\"],\"explanation\":\"While the candidate has foundational Python backend skills, clinical decision support tools require deep healthcare data standards knowledge that is absent. FHIR and HL7 integration are essential for any clinical application, and the lack of healthcare domain signals makes this a weak fit for a specialized healthtech product.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ibrahim-yilmaz\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Power BI\",\"Tableau\",\"Pandas\"],\"databases\":[\"MySQL\",\"PostgreSQL\"]}\n\nJob Summary:\nLogistics company seeking a mid-level data engineer to build and maintain ETL pipelines, orchestrate workflows with Dagster, and transform data using dbt. BigQuery is the data warehouse. Python and SQL are required. Experience with visualization tools is not a focus of this role. The candidate should be comfortable working with large datasets and optimizing query performance.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python and SQL are confirmed as required languages\",\"Pandas shows data manipulation experience\",\"PostgreSQL and MySQL experience transfers to SQL query optimization\"],\"gaps\":[\"No Dagster or any workflow orchestration experience\",\"No dbt experience for the transformation requirement\",\"No BigQuery experience for the target warehouse\",\"Role profile is data analyst rather than data engineer, indicating a potential scope and skill gap\",\"Power BI and Tableau experience is explicitly not valued in the role\"],\"explanation\":\"The candidate has foundational data skills but the profile skews toward analytics and visualization rather than engineering and pipeline development. The absence of orchestration, dbt, and BigQuery experience represents a meaningful gap against the core technical requirements of the data engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"claire-nguyen-platform\",\"seniority\":\"Staff\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Prometheus\",\"Grafana\",\"Vault\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"Argo CD\",\"GitHub Actions\"]}\n\nJob Summary:\nFintecch scale-up building an internal developer platform. Seeking a staff platform engineer to own the Kubernetes infrastructure, define IaC standards with Terraform, implement secrets management with HashiCorp Vault, and drive internal platform adoption. Observability stack is Prometheus and Grafana. GitOps with Argo CD is the deployment model.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes ownership experience matches the core infrastructure requirement\",\"Terraform is a direct match for the IaC standards requirement\",\"HashiCorp Vault is a direct match for the secrets management requirement\",\"Prometheus and Grafana align with the observability stack\",\"Argo CD matches the GitOps deployment model\",\"Staff seniority matches the platform ownership and standards-setting scope\"],\"gaps\":[],\"explanation\":\"This candidate's profile is an exact match for the internal developer platform role. Every named technology is present including the less common Vault signal. Staff seniority with GitOps and secrets management experience makes this a highly compelling fit with no identifiable gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ben-adeyemi\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Angular\",\"FastAPI\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitLab CI\"]}\n\nJob Summary:\nGov tech company building public services applications. Stack is React and Next.js on the frontend with FastAPI on the backend. PostgreSQL for data. Docker and GitLab CI for deployment. TypeScript is required. The role involves accessibility-compliant UI work and API development.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI is a direct match for the backend requirement\",\"PostgreSQL aligns with the database requirement\",\"Docker and GitLab CI match the deployment stack\",\"TypeScript is confirmed\",\"Python is confirmed supporting the FastAPI work\"],\"gaps\":[\"Angular experience does not transfer directly to the React and Next.js frontend requirement\",\"No accessibility or a11y tooling signals for the compliance requirement\",\"No React or Next.js specific signals\"],\"explanation\":\"The backend profile is a strong match for the FastAPI and PostgreSQL stack, but the frontend is a significant mismatch. Angular and React are meaningfully different frameworks and the role requires Next.js with server-side rendering patterns. The accessibility gap is also worth noting for a gov tech context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nguyen-van-an\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"Flask\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nSoftware consultancy seeking a principal engineer to define architecture for a new microservices platform. Must have experience with distributed systems design, event-driven architecture using Kafka, service mesh, and multi-cloud deployments. The role requires the ability to evaluate build vs buy decisions and mentor engineering managers.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is a useful language for tooling and scripting in a backend context\"],\"gaps\":[\"Junior seniority is far below the principal-level requirement\",\"No distributed systems or microservices architecture experience\",\"No Kafka or event-driven architecture signals\",\"No service mesh or multi-cloud signals\",\"Flask and MySQL represent a simple monolithic profile with no enterprise architecture depth\",\"No leadership or mentoring signals\"],\"explanation\":\"This candidate is at a very early career stage with a foundational backend profile, while the role requires principal-level distributed systems architecture expertise. There is no meaningful overlap in technical depth, scale, or leadership expectations. This is not a viable match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ella-brandt-data\",\"seniority\":\"Mid\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"scikit-learn\",\"PyTorch\",\"Pandas\",\"NumPy\",\"MLflow\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"]}\n\nJob Summary:\nInsurtech company building actuarial models and fraud detection systems. Seeking a mid to senior data scientist with Python and scikit-learn for classical ML and some PyTorch experience for deep learning. SQL and BigQuery for data access. MLflow for experiment tracking. Domain knowledge in insurance or risk modeling is a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI is a direct match for the backend requirement\",\"PostgreSQL aligns with the database requirement\",\"Docker and GitLab CI match the deployment stack\",\"TypeScript is confirmed\"],\"gaps\":[\"Angular experience does not transfer directly to the React and Next.js frontend requirement\",\"No accessibility or a11y tooling signals for the compliance requirement\",\"No React or Next.js specific signals\"],\"explanation\":\"The backend profile is a strong match for the FastAPI and PostgreSQL stack, but the frontend is a significant mismatch. Angular and React are meaningfully different frameworks and the role requires Next.js with server-side rendering patterns. The accessibility gap is also worth noting for a gov tech context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mateus-silva-rn\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React Native\",\"Expo\",\"Redux\"],\"databases\":[\"Firebase\",\"SQLite\"],\"testing\":[\"Jest\",\"Detox\"]}\n\nJob Summary:\nHealth and wellness startup building a cross-platform mobile app. Stack is React Native with Expo. TypeScript required. Redux for state management. Firebase for backend services. Detox for end-to-end testing on device. Some SQLite for offline storage. Mid-level experience expected with attention to performance and polish.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React Native and Expo are a direct match for the core mobile framework\",\"TypeScript is confirmed as required\",\"Redux directly matches the state management requirement\",\"Firebase aligns with the backend services requirement\",\"Detox is a direct match for the end-to-end device testing requirement\",\"SQLite covers the offline storage requirement\",\"Jest provides complementary unit testing coverage\"],\"gaps\":[],\"explanation\":\"This is an exceptional stack match for the mobile health app role. Every single technical requirement is directly represented in the candidate's profile. The Detox signal in particular is rare and directly confirms mobile end-to-end testing experience. No gaps identified.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"anya-kozlov-llm\",\"seniority\":\"Senior\",\"roles\":[\"LLM Engineer\",\"AI Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"LangChain\",\"LangGraph\",\"Ollama\",\"Hugging Face Transformers\",\"FastAPI\",\"Docker\"],\"architecture\":[\"RAG\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"ChromaDB\",\"Qdrant\"]}\n\nJob Summary:\nEnterprise AI company building a multi-agent LLM platform for internal enterprise workflows. Seeking a senior LLM engineer with LangChain and LangGraph for agent orchestration. Vector database experience with Chroma or Qdrant required. RAG pipeline experience essential. Hugging Face for open source model evaluation. FastAPI for serving. Self-hosted model capability with Ollama is a bonus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LangChain and LangGraph are direct matches for the agent orchestration requirements\",\"ChromaDB and Qdrant both satisfy the vector database requirement\",\"RAG architecture experience is directly confirmed\",\"Hugging Face Transformers aligns with the open source model evaluation requirement\",\"FastAPI is a direct match for the serving requirement\",\"Ollama is a direct match for the self-hosted model bonus requirement\",\"Docker supports the deployment infrastructure\"],\"gaps\":[],\"explanation\":\"This candidate is purpose-built for the multi-agent LLM platform role. Every required and bonus technology is explicitly present in the profile. The combination of LangGraph, Qdrant, RAG architecture, and Ollama at senior level represents deep specialization in exactly the right domain.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"derek-callahan-php\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"SQL\"],\"tech\":[\"Symfony\",\"Docker\"],\"databases\":[\"MySQL\",\"Redis\"]}\n\nJob Summary:\nMedia company running a Node.js and TypeScript microservices backend with a React frontend. Seeking a mid-level full stack engineer to build new product features and maintain existing services. PostgreSQL is the primary database. GraphQL API layer. Testing with Jest and Cypress. CI/CD with GitHub Actions.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker experience is transferable across technology stacks\",\"Mid-level seniority matches the role level\"],\"gaps\":[\"PHP and Symfony background does not transfer to Node.js and TypeScript requirements\",\"No React or frontend experience signals\",\"No PostgreSQL experience, uses MySQL\",\"No GraphQL signals\",\"No Jest or Cypress testing signals\",\"No GitHub Actions CI/CD signals\"],\"explanation\":\"The candidate's PHP backend profile has almost no overlap with the Node.js, TypeScript, and React stack required for this role. The language, framework, and database are all mismatched, and testing and CI/CD tooling are absent. This represents a fundamental stack incompatibility rather than a ramp-up challenge.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fatou-diop-platform\",\"seniority\":\"Lead\",\"roles\":[\"Platform Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Prometheus\",\"Grafana\",\"Docker\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\",\"CircleCI\"]}\n\nJob Summary:\nGrowth-stage startup seeking a lead DevOps or platform engineer to own cloud infrastructure on GCP, drive IaC adoption with Terraform, and establish observability practices. Kubernetes is central to the platform. Prometheus and Grafana for monitoring. Argo CD for GitOps deployments. The candidate will mentor junior engineers and set engineering standards.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes experience aligns with the central platform requirement\",\"Terraform is a direct match for the IaC adoption drive\",\"Prometheus and Grafana match the observability stack\",\"Argo CD is a direct match for the GitOps deployment requirement\",\"Lead seniority aligns with the mentoring and standards-setting expectations\",\"Cloud-native and microservices architecture signals are relevant\"],\"gaps\":[\"No explicit GCP signals; cloud provider experience is unspecified in the profile\"],\"explanation\":\"The candidate's platform engineering profile is a strong match for the role across Kubernetes, IaC, observability, and GitOps. Lead seniority with the full tooling stack provides confidence for the mentoring and standards mandate. The GCP-specific gap is worth confirming but is not likely disqualifying given the cloud-native depth otherwise present.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jake-morrison-gamedev\",\"seniority\":\"Mid\",\"roles\":[\"Game Developer\"],\"languages\":[\"C++\",\"C#\"],\"tech\":[\"Three.js\",\"WebGL\"],\"architecture\":[\"Client-Server\"]}\n\nJob Summary:\nEdtech company building browser-based 3D interactive learning simulations. Seeking a mid-level frontend or game developer with WebGL and Three.js experience. JavaScript or TypeScript is required for the web environment. React integration is expected for the surrounding application shell. Performance optimization for browser rendering is important.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Three.js and WebGL are direct matches for the 3D rendering requirements\",\"Mid-level seniority is appropriate\",\"C++ background suggests graphics and performance awareness transferable to browser rendering optimization\"],\"gaps\":[\"No JavaScript or TypeScript signals despite being required for the web environment\",\"No React experience for the application shell integration requirement\",\"Game development background may require adjustment to web application patterns\"],\"explanation\":\"The candidate has the rare and directly relevant Three.js and WebGL expertise the role needs, which is a significant strength. However, the absence of JavaScript or TypeScript and React signals creates uncertainty about the web application integration side of the role. A moderate fit that could become strong with confirmed JS and React proficiency.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sung-jin-oh\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Spring Boot\",\"Kafka\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nRide-sharing platform seeking a senior backend engineer to build real-time location and dispatch services. Core stack is Kotlin and Spring Boot with Kafka for event streaming. PostgreSQL and Redis for persistence and caching. Kubernetes for orchestration. The team follows TDD with JUnit and Mockito. High-throughput and low-latency system design experience required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kotlin and Spring Boot are direct matches for the core stack\",\"Kafka covers the event streaming requirement for real-time dispatch\",\"PostgreSQL and Redis match the persistence and caching requirements\",\"Kubernetes aligns with the orchestration setup\",\"JUnit and Mockito directly satisfy the TDD requirement\",\"Event-driven and microservices architecture signals match the platform design\"],\"gaps\":[\"No explicit geo-spatial or location services tooling signals\"],\"explanation\":\"This candidate's backend profile is an almost perfect match for the ride-sharing platform role. Every named technology including the testing framework is present, and the event-driven architecture background is directly relevant to real-time dispatch use cases. The geo-spatial gap is a minor concern that can be addressed on the job.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lena-hoffmann\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Redux\",\"Webpack\",\"Jest\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise dashboard product company transitioning to a micro-frontend architecture using Module Federation and Vite. Seeking a mid-level frontend engineer with React and TypeScript experience. State management with Zustand. New stack uses Tailwind CSS. Testing with Vitest and React Testing Library. The candidate should be comfortable with performance profiling.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and TypeScript are directly relevant to the frontend requirement\",\"Redux experience shows state management familiarity transferable to Zustand learning\",\"GitHub Actions matches CI/CD expectations\",\"Jest experience provides a testing foundation for Vitest transition\"],\"gaps\":[\"No Module Federation or micro-frontend architecture signals\",\"Webpack rather than Vite, which is being adopted\",\"Redux rather than Zustand, which is the new state management approach\",\"No Tailwind CSS signals\",\"No React Testing Library signals alongside Jest\"],\"explanation\":\"The candidate has solid React and TypeScript foundations but the profile is aligned with the legacy stack rather than the target micro-frontend architecture. Multiple specific tooling choices including Vite, Zustand, and Tailwind are absent. Moderate fit with a non-trivial learning curve across several dimensions.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"arjun-sharma-infra\",\"seniority\":\"Principal\",\"roles\":[\"Infrastructure Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Pulumi\",\"Prometheus\",\"Grafana\",\"Vault\",\"Consul\"],\"architecture\":[\"Cloud-Native\",\"Service Mesh\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Cassandra\"],\"ci_cd\":[\"Argo CD\",\"GitHub Actions\",\"GitLab CI\"]}\n\nJob Summary:\nHigh-growth fintech seeking a principal infrastructure engineer to define multi-cloud strategy, lead platform engineering teams, and build a self-service developer platform. HashiCorp stack including Vault and Consul is used. Terraform and Pulumi for IaC. Kubernetes at scale with service mesh. Strong observability and incident management required. This role sets the technical direction for infrastructure across the engineering organization.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Vault and Consul are direct matches for the HashiCorp stack requirement\",\"Terraform and Pulumi both present, satisfying the dual IaC requirement\",\"Kubernetes with service mesh architecture directly matches the orchestration approach\",\"Prometheus and Grafana align with the observability requirement\",\"Principal seniority matches the organization-wide technical direction scope\",\"Argo CD, GitHub Actions, and GitLab CI show broad GitOps and CI/CD maturity\"],\"gaps\":[\"No explicit multi-cloud or cloud provider diversity signals\"],\"explanation\":\"This principal-level candidate is an exceptional match for the infrastructure leadership role. The rare combination of Vault, Consul, Pulumi, and service mesh experience at principal seniority is directly aligned with the role's technical and leadership requirements. The multi-cloud gap is worth exploring but does not undermine the overall fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"diana-okonkwo-fe\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"TanStack Query\",\"shadcn/ui\",\"Tailwind CSS\"],\"testing\":[\"Vitest\",\"Playwright\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nB2B SaaS startup building an analytics dashboard product. Stack is Next.js and React with TypeScript. TanStack Query for server state management. Component library is shadcn/ui with Tailwind. We test with Vitest and Playwright. GitHub Actions for CI/CD. The role involves building data visualization components and accessible UI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and React are direct stack matches\",\"TypeScript is confirmed\",\"TanStack Query is a direct and specific match for the server state management approach\",\"shadcn/ui is a direct match for the component library\",\"Tailwind CSS aligns with the styling requirement\",\"Vitest and Playwright are exact testing stack matches\",\"GitHub Actions satisfies CI/CD expectations\"],\"gaps\":[\"No explicit data visualization library signals such as D3 or Recharts\"],\"explanation\":\"This candidate's profile is a comprehensive and highly specific match for the role. Every named technology including the less common TanStack Query and shadcn/ui choices is present. The only potential gap is data visualization tooling experience, which is implied by the role but not stated as a specific library requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sam-okafor-generalist\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Django\",\"React\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nFintech startup hiring a senior full stack engineer to lead the migration from a Django monolith to a FastAPI microservices architecture. GraphQL API layer is being introduced. TypeScript is required on the frontend with Next.js replacing React standalone. Kubernetes for deployment. Strong architecture and code review skills expected at senior level.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Django experience is relevant to understanding and migrating from the existing monolith\",\"React provides foundational frontend experience for the Next.js transition\",\"PostgreSQL and Docker are both useful in the target architecture\",\"Python is the right language for FastAPI work\"],\"gaps\":[\"No FastAPI or microservices architecture signals for the target state\",\"No TypeScript despite it being required on the frontend\",\"No Next.js signals despite it replacing the current React setup\",\"No GraphQL signals for the new API layer\",\"No Kubernetes experience for the deployment requirement\",\"Mid seniority does not meet the senior architecture and code review expectation\"],\"explanation\":\"The candidate's Django and React experience is useful context for the migration but aligns with the legacy rather than target architecture. Multiple specific requirements for the target state including FastAPI, TypeScript, Next.js, GraphQL, and Kubernetes are absent. The seniority gap also limits readiness for the architectural leadership expected in this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"olumide-eze-kotlin\",\"seniority\":\"Senior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Kotlin Multiplatform\"],\"databases\":[\"SQLite\",\"Firebase\"],\"testing\":[\"JUnit\",\"Detox\"]}\n\nJob Summary:\nConsumer app company expanding to iOS using Kotlin Multiplatform. Seeking a senior Android engineer with Jetpack Compose and KMP experience to build shared business logic across Android and iOS. SQLite for local persistence. Firebase for backend. Testing culture is important with JUnit for unit tests.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kotlin Multiplatform is a direct and specific match for the KMP expansion requirement\",\"Jetpack Compose aligns with the Android UI requirement\",\"SQLite covers the local persistence requirement\",\"Firebase matches the backend services requirement\",\"JUnit satisfies the unit testing expectation\",\"Senior seniority is appropriate for the cross-platform expansion ownership\"],\"gaps\":[\"No explicit iOS or Swift signals to validate cross-platform integration depth\"],\"explanation\":\"The candidate's KMP experience is the key differentiating signal for this role and is directly confirmed. Combined with Jetpack Compose, SQLite, and Firebase alignment at senior level, this is a strong match. The iOS experience gap is noted but KMP is designed to minimize native iOS expertise requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rkauffman_dev\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\"],\"tech\":[\"Django\",\"FastAPI\",\"Docker\",\"Kubernetes\",\"AWS\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nWe are a Series B fintech startup looking for a Senior Backend Engineer to own our payments microservices platform. You will build high-throughput APIs in Python or Go, deploy on Kubernetes, and integrate with PostgreSQL and Redis. Experience with event-driven architecture and GitOps workflows is essential. We run a fully remote team and ship fast.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Senior-level Python and Go experience matches our dual-language backend stack\",\"Direct Kubernetes and ArgoCD usage aligns with our GitOps deployment model\",\"PostgreSQL and Redis proficiency covers our primary data layer\",\"Event-driven architecture experience is highly relevant to our payments platform\",\"pytest and Locust indicate both correctness and performance testing discipline\"],\"gaps\":[\"No visible fintech or payments domain experience\"],\"explanation\":\"This candidate's stack is an almost exact match for the role's technical requirements across languages, infrastructure, and architecture patterns. The GitOps experience via ArgoCD is a particularly strong signal for our deployment workflow. The only notable gap is domain-specific fintech exposure, which is a nice-to-have rather than a blocker.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tnguyen_ui\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Redux\",\"Vite\"],\"databases\":[\"Firebase\"],\"testing\":[\"Jest\",\"React Testing Library\"]}\n\nJob Summary:\nFast-growing e-commerce company seeks a Mid-level Frontend Engineer to build and maintain our React and Next.js storefront. You will own UI components, integrate REST APIs, and write unit and integration tests. TypeScript required. We are also adopting Storybook for component documentation.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Next.js are the exact frontend frameworks required\",\"TypeScript is a first-class language in the candidate's profile\",\"Tailwind CSS and Redux are both present and relevant\",\"Jest and React Testing Library demonstrate frontend testing discipline\"],\"gaps\":[\"No Storybook experience visible, which the company is actively adopting\",\"No REST API integration signals beyond Firebase\"],\"explanation\":\"The candidate's core frontend stack aligns well with the role, covering React, Next.js, TypeScript, and testing. The absence of Storybook is a meaningful gap as the team is actively adopting it for component documentation. Overall a solid but not exceptional match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dsbrenner\",\"seniority\":\"Junior\",\"roles\":[\"Software Engineer\"],\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"Flask\",\"Docker\"],\"databases\":[\"SQLite\",\"PostgreSQL\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nEnterprise SaaS company hiring a Senior Full Stack Engineer to architect and lead development of a multi-tenant platform. Must have deep experience with microservices, Kubernetes, and cloud infrastructure on AWS or GCP. TypeScript required. Candidates should have a track record of technical leadership and system design at scale.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and Flask show basic full-stack exposure\"],\"gaps\":[\"Junior seniority is far below the Senior level required\",\"No TypeScript experience visible\",\"No Kubernetes or cloud infrastructure signals\",\"No microservices or system design experience\",\"No technical leadership indicators\",\"No AWS or GCP exposure\"],\"explanation\":\"This candidate is at a junior level and their stack is limited to foundational tools that do not reflect the depth required for a senior architect role. The role demands TypeScript, Kubernetes, cloud infrastructure, and technical leadership, none of which are present in the profile. The gap in both seniority and technical breadth makes this a weak fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_pavlenko\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"Scala\"],\"tech\":[\"PyTorch\",\"TensorFlow\",\"Hugging Face Transformers\",\"MLflow\",\"Apache Spark\",\"Ray\",\"CUDA\"],\"architecture\":[\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nAI research lab at a large tech company is hiring a Senior ML Engineer to train and fine-tune large language models. Candidates must have experience with PyTorch, distributed training, CUDA optimization, and Hugging Face. Experience with MLflow or another experiment tracking tool is required. Familiarity with Spark or Ray for data pipelines is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PyTorch and Hugging Face Transformers are directly required and present\",\"CUDA experience signals low-level GPU optimization capability\",\"Ray and Apache Spark cover the distributed training and data pipeline requirements\",\"MLflow satisfies the experiment tracking requirement\",\"Distributed system architecture experience is essential for LLM training\"],\"gaps\":[\"No visible vector database or RAG experience for potential inference pipelines\"],\"explanation\":\"The candidate's profile is exceptionally well-aligned with the LLM training role, hitting every explicitly stated requirement including PyTorch, Hugging Face, CUDA, MLflow, and distributed compute. The combination of Ray and Spark signals strong data engineering capability alongside the ML core. The only minor gap is inference-side tooling, which is not mentioned in the job summary.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"josie_builds\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Node.js\",\"Express.js\",\"Prisma\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nEarly-stage startup building a B2B SaaS product is looking for a Mid-level Full Stack Engineer. Our stack is TypeScript end-to-end with React on the frontend and NestJS on the backend. We use PostgreSQL, containerize with Docker, and deploy via GitHub Actions. You should be comfortable owning features across the entire stack.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript end-to-end matches the startup's language requirement\",\"React covers the frontend requirement\",\"PostgreSQL and Docker align with the data and infrastructure stack\",\"GitHub Actions matches the CI/CD requirement\",\"Playwright demonstrates solid end-to-end testing practice\"],\"gaps\":[\"Uses Express.js rather than NestJS, which is the stated backend framework\",\"No NestJS-specific patterns like decorators, modules, or dependency injection visible\"],\"explanation\":\"The candidate's frontend and infrastructure stack match well, but the backend is built on Express rather than NestJS, which has meaningfully different architecture conventions. The TypeScript foundation makes migration learnable, but for a startup moving fast this represents a real onboarding cost at the backend level.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cRoland99\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Vite\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nGrowth-stage startup seeks a Mid-level Full Stack Engineer comfortable in both React and Node.js. You will build customer-facing dashboards and backend APIs, manage PostgreSQL schemas, and write automated tests. Experience with Docker and a CI/CD tool is expected. The role requires ownership of features from design to deployment.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and TypeScript are relevant to the frontend portion of the role\"],\"gaps\":[\"Junior seniority falls short of the mid-level requirement\",\"No backend or Node.js experience visible\",\"No PostgreSQL or database management signals\",\"No Docker or containerization experience\",\"No CI/CD tooling present\",\"Cannot demonstrate full-stack ownership based on available signals\"],\"explanation\":\"The candidate is a frontend-only junior developer with no visible backend, database, or infrastructure experience. The role requires full-stack ownership from API development to deployment, which the candidate's profile does not support. The seniority gap compounds the technical gaps, making this a weak fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devops_hirsch\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Docker\",\"AWS\",\"Ansible\",\"Prometheus\",\"Grafana\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\",\"ArgoCD\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nLarge enterprise is hiring a Senior DevOps Engineer to manage our cloud infrastructure on AWS. You will own Terraform modules, manage Kubernetes clusters with Helm, set up observability with Prometheus and Grafana, and maintain CI/CD pipelines. Ansible experience is a plus. Strong scripting skills in Python or Bash required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Terraform, Kubernetes, and Helm are all directly required and present\",\"Prometheus and Grafana satisfy the observability requirements exactly\",\"AWS is the specified cloud platform\",\"Ansible is listed as a plus and is present in the profile\",\"Python and Bash scripting match the required scripting skills\",\"ArgoCD and GitHub Actions show mature CI/CD pipeline experience\"],\"gaps\":[],\"explanation\":\"This candidate satisfies every stated technical requirement for the role and also covers the Ansible nice-to-have. The combination of infrastructure-as-code, cluster management, observability, and CI/CD experience reflects a well-rounded senior DevOps engineer. There are no meaningful gaps given the job description.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amelia_data\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Airflow\",\"dbt\",\"Apache Spark\",\"Pandas\"],\"databases\":[\"Snowflake\",\"PostgreSQL\",\"BigQuery\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nMedia company building a modern data platform is looking for a Mid-level Data Engineer. You will design and maintain ELT pipelines using dbt and Airflow, work with Snowflake and BigQuery, and write performant SQL and Python. Experience with Spark is a bonus. We value data quality and expect familiarity with testing practices for data pipelines.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt and Airflow are the exact orchestration and transformation tools required\",\"Snowflake and BigQuery cover the stated data warehouse requirements\",\"Python and SQL are the primary languages mentioned\",\"Apache Spark is a bonus skill that is present\",\"Mid-level seniority matches the role\"],\"gaps\":[\"No data quality or pipeline testing framework visible such as Great Expectations\"],\"explanation\":\"The candidate's profile aligns closely with the data platform role, covering every required tool including dbt, Airflow, Snowflake, and BigQuery. The Spark bonus is also satisfied. The only gap is the absence of an explicit data quality testing framework, which the job description flags as an expectation, though this may be covered by their dbt testing practices.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kwame_ios\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Expo\"],\"ci_cd\":[\"Fastlane\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nConsumer app company is looking for a Mid-level Android Engineer to build features in Jetpack Compose using Kotlin. Experience with the Android SDK and writing unit tests with JUnit or Mockito is required. Familiarity with CI/CD for mobile using Fastlane or a similar tool is a plus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Fastlane experience is relevant to mobile CI/CD\"],\"gaps\":[\"Candidate is an iOS engineer with no visible Android or Kotlin experience\",\"No Jetpack Compose or Android SDK signals\",\"No JUnit or Mockito testing experience for Android\",\"Swift and Objective-C are not applicable to the Android role\"],\"explanation\":\"The candidate is specialized in iOS development with Swift and SwiftUI, which is an entirely different platform from the Android role being hired for. While Fastlane is shared tooling, the core technical requirements of Kotlin, Jetpack Compose, and Android SDK are absent. This is a fundamental platform mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ori_sre\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"AWS\",\"Prometheus\",\"Grafana\",\"PagerDuty\",\"Docker\"],\"architecture\":[\"Distributed System\",\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nHigh-traffic e-commerce platform is hiring a Senior SRE to own reliability. You will manage on-call with PagerDuty, monitor with Datadog, run Kubernetes on AWS, and automate in Python or Go. Chaos engineering experience is required. Incident post-mortem and blameless culture experience expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PagerDuty experience directly covers on-call management\",\"Kubernetes on AWS is the specified cluster environment\",\"Python and Go match the automation scripting requirement\",\"k6 shows load testing familiarity adjacent to reliability engineering\",\"Senior seniority is appropriate\"],\"gaps\":[\"Uses Prometheus and Grafana while the role requires Datadog specifically\",\"No chaos engineering tooling visible, which is listed as required\",\"No explicit incident management or post-mortem process signals\"],\"explanation\":\"The candidate has solid SRE foundations but the observability stack mismatch from Prometheus to Datadog and the absence of chaos engineering experience are notable gaps. Datadog has a different instrumentation model and pricing surface that matters in practice. The chaos engineering requirement being unfilled is a hard gap for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priya_backend\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Python\"],\"tech\":[\"Spring Boot\",\"Docker\",\"AWS\",\"Apache Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nFinancial services firm building event-driven backend systems in Java and Spring Boot. Mid to senior level engineers should have experience with Kafka, microservices, PostgreSQL, and running on AWS. Jenkins or another CI tool is expected. We write thorough unit tests and expect JUnit proficiency.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Java and Spring Boot are the primary required languages and framework\",\"Apache Kafka directly satisfies the event streaming requirement\",\"Microservices and event-driven architecture match the system design\",\"PostgreSQL and Redis cover the data layer\",\"Jenkins satisfies the CI requirement\",\"JUnit and Mockito demonstrate the expected testing rigor\"],\"gaps\":[\"Candidate is mid-level; role may prefer senior candidates based on phrasing\"],\"explanation\":\"This candidate hits every technical requirement for the role with direct experience in Java, Spring Boot, Kafka, and event-driven microservices on AWS. The testing stack with JUnit and Mockito matches the firm's expectations explicitly. The only soft gap is that the candidate is mid-level in a role that skews toward senior, though they may still be competitive.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priya_backend\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Python\"],\"tech\":[\"Spring Boot\",\"Docker\",\"AWS\",\"Apache Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nFinancial services firm building event-driven backend systems in Java and Spring Boot. Senior engineers should have experience with Kafka, microservices, PostgreSQL, and AWS. Strong security and compliance awareness is expected. Experience with secrets management and audit logging is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Java and Spring Boot are the primary required technologies\",\"Apache Kafka and event-driven microservices match the system design\",\"PostgreSQL and Redis cover the data layer\",\"JUnit and Mockito show solid testing practice\"],\"gaps\":[\"Mid-level seniority falls short of the senior expectation\",\"No secrets management tooling such as Vault or AWS Secrets Manager\",\"No audit logging or compliance-related signals\",\"Financial services security awareness cannot be assessed from the profile\"],\"explanation\":\"The candidate's technical stack is well-aligned with the core backend requirements but the role explicitly calls for senior-level experience and compliance-aware engineering practice. The absence of secrets management and audit logging signals is a meaningful gap for a financial services firm with regulatory requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"felix_devops\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"AWS\",\"Terraform\",\"Nginx\"],\"ci_cd\":[\"GitHub Actions\",\"CircleCI\"]}\n\nJob Summary:\nSeries A startup needs a Mid-level DevOps Engineer to manage AWS infrastructure, write Terraform modules, and maintain CI/CD pipelines. Kubernetes experience is strongly preferred. We run containerized workloads and need someone comfortable with observability tooling like Prometheus or Datadog.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"AWS and Terraform directly match infrastructure requirements\",\"Docker experience is relevant to containerized workloads\",\"GitHub Actions and CircleCI cover the CI/CD requirement\",\"Mid-level seniority is appropriate\"],\"gaps\":[\"No Kubernetes experience visible, which is strongly preferred\",\"No observability tooling such as Prometheus, Grafana, or Datadog\"],\"explanation\":\"The candidate covers the core infrastructure requirements with AWS, Terraform, and Docker, but is missing Kubernetes which is called out as a strong preference for managing containerized workloads. The absence of any observability tooling is another notable gap given the job description. The candidate could grow into these areas but would require onboarding investment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lena_ml\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"XGBoost\",\"Pandas\",\"NumPy\",\"MLflow\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nAdtech company building real-time bidding models is looking for a Senior ML Engineer. You will train and deploy deep learning models using PyTorch, work with large-scale data pipelines, and serve models at low latency. Experience with CUDA or GPU training and distributed training frameworks like Ray is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"MLflow for experiment tracking is relevant and present\",\"Strong classical ML background with scikit-learn and XGBoost\"],\"gaps\":[\"No PyTorch or deep learning framework experience\",\"No CUDA or GPU training signals\",\"No Ray or distributed training experience\",\"No data pipeline or streaming infrastructure signals for real-time systems\",\"Classical ML focus does not match the deep learning requirements\"],\"explanation\":\"The candidate has a solid classical machine learning background but lacks the deep learning expertise this role requires. PyTorch, CUDA, and distributed training with Ray are core expectations, none of which appear in the profile. The gap between classical ML and production deep learning at scale is significant and would be difficult to bridge quickly for a senior-level hire.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"theo_k8s\",\"seniority\":\"Lead\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"Istio\",\"Docker\",\"AWS\",\"Prometheus\",\"Grafana\",\"Vault\"],\"architecture\":[\"Cloud-Native\",\"Service Mesh\",\"Microservices\"],\"ci_cd\":[\"ArgoCD\",\"GitHub Actions\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nHigh-growth fintech scaling infrastructure is hiring a Lead Platform Engineer. You will own our Kubernetes platform, manage service mesh with Istio, implement GitOps with ArgoCD, and secure secrets with Vault. Deep AWS and Terraform expertise required. Observability with Prometheus and Grafana expected. Go scripting preferred.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Istio, and Helm directly cover the platform ownership requirements\",\"ArgoCD satisfies the GitOps requirement explicitly\",\"Vault is present for secrets management\",\"Prometheus and Grafana cover observability expectations\",\"Terraform and AWS match the infrastructure requirements\",\"Go is listed as preferred and is the candidate's primary language\",\"Lead seniority is appropriate for the role\"],\"gaps\":[],\"explanation\":\"This candidate is an exceptionally strong match, satisfying every named technology in the job description including the more specialized ones like Istio, Vault, and ArgoCD. The combination of Go proficiency, cloud-native architecture experience, and lead-level seniority makes this a near-ideal fit for the platform engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kwame_ios\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Expo\",\"React Native\"],\"ci_cd\":[\"Fastlane\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nConsumer app company seeks a Mid-level iOS Engineer to build SwiftUI features for their social app. You will write unit and UI tests, integrate REST APIs, and collaborate with designers on custom animations. Fastlane for mobile CI is standard. Objective-C legacy code maintenance is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SwiftUI is the required UI framework and is present\",\"Fastlane satisfies the mobile CI requirement\",\"XCTest covers the unit and UI testing requirement\",\"Objective-C is a plus and is present\",\"Mid-level seniority matches the role\"],\"gaps\":[\"No custom animation or Core Animation experience visible\",\"No REST API integration signals for iOS specifically\",\"React Native and Expo in a native iOS profile may indicate cross-platform focus over deep native expertise\"],\"explanation\":\"The candidate has a solid SwiftUI foundation with the required CI and testing tooling in place. However, the emphasis on custom animations and deep REST integration is not evidenced in the profile, and the presence of React Native and Expo raises questions about the depth of native iOS focus. This is a moderate fit worth exploring further in an interview.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ori_sre\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"AWS\",\"Prometheus\",\"Grafana\",\"PagerDuty\",\"Docker\"],\"architecture\":[\"Distributed System\",\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nE-commerce platform with high traffic is hiring a Senior SRE to own reliability and uptime. You will manage on-call rotations with PagerDuty, monitor with Prometheus and Grafana, run Kubernetes clusters on AWS, and write automation in Python or Go. Experience with chaos engineering or load testing tools is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PagerDuty experience directly covers on-call management requirement\",\"Prometheus and Grafana satisfy monitoring and observability requirements\",\"Kubernetes on AWS is the stated cluster management environment\",\"Python and Go match the automation scripting languages required\",\"k6 satisfies the load testing strong-plus requirement\",\"Senior seniority is appropriate\"],\"gaps\":[\"No chaos engineering tooling visible such as Chaos Monkey or Litmus\"],\"explanation\":\"The candidate covers the full SRE stack including on-call tooling, observability, cluster management, and automation languages. The presence of k6 for load testing addresses one of the bonus requirements. Chaos engineering tooling is absent, but load testing is closely related and demonstrates reliability engineering mindset.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"peter_php\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"Laravel\",\"Vue.js\",\"MySQL\",\"Docker\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"GitLab CI\"]}\n\nJob Summary:\nDigital agency building Node.js and React applications for enterprise clients. You will build REST APIs in Node.js with Express, work with PostgreSQL, and deploy using Docker and Kubernetes. TypeScript is required across the stack. CI/CD is managed via GitHub Actions.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker experience is transferable\",\"Backend API development experience with Laravel shows relevant patterns\"],\"gaps\":[\"No Node.js or JavaScript backend experience in a server context\",\"No TypeScript experience\",\"No React experience on the frontend\",\"PostgreSQL not in profile; uses MySQL\",\"No Kubernetes experience\",\"Uses GitLab CI vs required GitHub Actions\"],\"explanation\":\"The candidate works in a PHP and Laravel ecosystem which is fundamentally different from the Node.js and React TypeScript stack this agency uses. While backend API patterns are transferable, the specific technology mismatches across language, framework, database, and infrastructure make this a weak fit for the role as described.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fiona_sec\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"AWS\",\"Terraform\",\"Docker\",\"Kubernetes\",\"Vault\",\"OpenTelemetry\",\"Sentry\"],\"architecture\":[\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nFinancial institution hiring a Senior Application Security Engineer with deep AppSec background. You will perform SAST and DAST scans, integrate security into CI/CD pipelines, conduct threat modeling, and advise engineering teams on secure coding. OWASP expertise required. Experience with Burp Suite or similar tooling preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Cloud infrastructure security experience via AWS, Kubernetes, and Vault is relevant\",\"CI/CD security integration experience with GitHub Actions is applicable\",\"Python and Go scripting support automation tasks\",\"Senior seniority is appropriate\"],\"gaps\":[\"No SAST or DAST tooling visible\",\"No Burp Suite or application security scanning experience\",\"No OWASP or threat modeling signals\",\"Profile skews toward cloud/infrastructure security rather than application security\"],\"explanation\":\"The candidate has strong cloud and infrastructure security experience but the role specifically needs application security expertise including SAST, DAST, OWASP, and Burp Suite. These are distinct security disciplines and the profile does not demonstrate the AppSec depth required. The candidate may be a stronger fit for a cloud security engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nadia_vue\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\",\"Vite\"],\"testing\":[\"Vitest\",\"Cypress\"]}\n\nJob Summary:\nEuropean SaaS company hiring a Mid-level Frontend Engineer for a Vue.js and Nuxt.js product. You will build complex UI features, manage state with Pinia, write tests, and also contribute to a React-based internal dashboard. TypeScript preferred. Tailwind CSS is our utility-first approach.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Vue.js and Nuxt.js are the primary framework requirements and are present\",\"Pinia satisfies the state management requirement\",\"Tailwind CSS matches the styling approach\",\"Vitest and Cypress cover the testing requirements\",\"TypeScript is preferred and present\"],\"gaps\":[\"No React experience visible, which is required for the internal dashboard contribution\",\"Dual-framework expectation may stretch the candidate\"],\"explanation\":\"The candidate is an excellent fit for the Vue and Nuxt work but has no React experience for the internal dashboard contribution. In a role where both codebases are active responsibilities, this creates a meaningful onboarding gap on the React side. The Vue side of the role is covered well.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"intern_sam\",\"seniority\":\"Intern\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"React\",\"Flask\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nStartup offering a software engineering internship for students. You will contribute to our React frontend and Flask backend. Python and JavaScript basics expected. You will learn from senior engineers and work on real features. No prior professional experience required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Flask match the internship tech stack directly\",\"Python and JavaScript cover the stated language expectations\",\"Intern seniority is appropriate for the role\"],\"gaps\":[\"SQLite is the only database signal; production databases like PostgreSQL are not present\",\"No testing frameworks visible\",\"Profile is sparse overall, limiting confidence in depth of experience\"],\"explanation\":\"The candidate's stack matches the internship requirements in terms of framework and language, and no prior professional experience is explicitly required. However, the profile is very sparse with no testing, limited database exposure, and no other signals of breadth. This is a reasonable but not exceptional fit for the internship.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"grace_fullstack\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"Django\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\"],\"testing\":[\"Jest\",\"pytest\"]}\n\nJob Summary:\nLegaltech startup seeking a Mid-level Full Stack Engineer with React and Django. We use PostgreSQL and deploy on AWS with Docker. TypeScript adoption is underway. The role also requires integrating with third-party legal data APIs and managing async task queues with Celery.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Django match the frontend and backend requirements\",\"PostgreSQL and AWS with Docker cover the infrastructure and data layer\",\"Jest and pytest show testing discipline across both layers\",\"Mid-level seniority is appropriate\"],\"gaps\":[\"No TypeScript experience, which the company is actively adopting\",\"No Celery or task queue experience, which is explicitly required\",\"No third-party API integration signals\"],\"explanation\":\"The candidate covers the core stack well with React, Django, PostgreSQL, and AWS all present. However, Celery for async task queues is an explicit requirement that is missing, and TypeScript adoption means the candidate would be learning it on the job. These are practical gaps that would require meaningful onboarding time.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"grace_fullstack\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"Django\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\"],\"testing\":[\"Jest\",\"pytest\"]}\n\nJob Summary:\nLegaltech startup is looking for a Mid-level Full Stack Engineer comfortable working in React and a Python backend. We use Django, PostgreSQL, and deploy on AWS with Docker. TypeScript adoption is underway so prior TypeScript experience is a plus. We write unit tests and expect good coverage.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Django match the frontend and backend requirements\",\"PostgreSQL and AWS with Docker cover the data and infrastructure layers\",\"Jest and pytest demonstrate testing discipline across both stack layers\",\"Mid-level seniority is appropriate\"],\"gaps\":[\"No TypeScript experience, which is listed as a plus and actively being adopted\",\"Profile is relatively sparse with limited visibility into depth\"],\"explanation\":\"The candidate covers the core technical stack well with React, Django, PostgreSQL, and AWS all present. The absence of TypeScript is a mild gap as the company is actively adopting it, meaning the candidate would need to learn it on the job. Overall this is a solid but not exceptional fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"arch_mccallum\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\"],\"languages\":[\"Java\",\"Go\",\"Python\"],\"tech\":[\"Spring Boot\",\"Kubernetes\",\"Kafka\",\"AWS\",\"Terraform\",\"Docker\",\"Istio\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Domain-Driven Design\",\"CQRS\",\"Event Sourcing\",\"Clean Architecture\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"ArgoCD\",\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise software company hiring a Principal Architect to define technical strategy. You will lead architecture across distributed systems, drive DDD and event sourcing, and oversee Kubernetes infrastructure on AWS. Stakeholder communication and roadmap planning experience is required. Experience with cost optimization and cloud FinOps is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Principal seniority matches the leadership level\",\"DDD, CQRS, and event sourcing are all present and explicitly required\",\"Kafka, Kubernetes, and AWS cover distributed infrastructure\",\"Terraform and ArgoCD signal mature infrastructure ownership\"],\"gaps\":[\"No stakeholder communication or roadmap planning signals visible in the profile\",\"No cloud FinOps or cost optimization experience visible\",\"GitHub profile signals skew technical; leadership and communication skills cannot be assessed\"],\"explanation\":\"The candidate is technically exceptional for this role, but the principal architect position also requires demonstrated stakeholder management and roadmap planning experience, which cannot be assessed from a GitHub profile alone. The FinOps gap is a softer concern. This would be a moderate fit pending evidence of leadership and communication skills in the interview process.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rafael_mobile\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"JavaScript\"],\"tech\":[\"Flutter\",\"React Native\",\"Firebase\",\"Expo\"],\"databases\":[\"Firebase\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"]}\n\nJob Summary:\nHealthcare startup building a cross-platform patient app is seeking a Mid-level Flutter Developer. You will build features in Dart and Flutter, integrate healthcare REST APIs, implement HIPAA-aware data handling, and manage local state. Firebase is the primary backend. Fastlane for CI. Accessibility compliance is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Flutter and Dart are the primary requirements and are the candidate's main tools\",\"Firebase satisfies the backend integration requirement\",\"Fastlane covers the mobile CI requirement\",\"Cross-platform delivery experience is evident\"],\"gaps\":[\"No HIPAA-aware data handling or healthcare compliance signals\",\"No accessibility compliance experience visible\",\"No explicit REST API integration signals beyond Firebase\"],\"explanation\":\"The candidate has strong Flutter fundamentals and the right CI and backend tooling, but the healthcare context introduces specific compliance requirements around HIPAA and accessibility that are absent from the profile. For a patient-facing healthcare app these are meaningful gaps rather than nice-to-haves.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hiro_data\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Pandas\",\"Tableau\",\"Metabase\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"]}\n\nJob Summary:\nE-commerce company is looking for a Mid-level Analytics Engineer to model data with dbt, write advanced SQL, and build dashboards in Looker. Experience with BigQuery or Snowflake is expected. Familiarity with Python for data manipulation is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SQL and Python are both present and relevant\",\"BigQuery is the exact data warehouse listed in the job description\",\"Analytics and dashboard experience via Tableau and Metabase shows BI familiarity\"],\"gaps\":[\"No dbt experience, which is a core requirement for the analytics engineer role\",\"No Looker experience; uses Tableau and Metabase instead\",\"Data Analyst background may not fully align with the analytics engineering scope\"],\"explanation\":\"The candidate has a solid analytics foundation with SQL, Python, and BigQuery, but the role specifically requires dbt for data modeling and Looker for dashboards, neither of which are present. The distinction between a data analyst and analytics engineer is meaningful here, and the missing dbt experience is a notable gap for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kim_cloud\",\"seniority\":\"Senior\",\"roles\":[\"Cloud Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"AWS\",\"Terraform\",\"Docker\",\"Ansible\",\"Cloudflare\"],\"architecture\":[\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\",\"Jenkins\"]}\n\nJob Summary:\nManaged services provider looking for a Senior Cloud Engineer focused on Google Cloud Platform. You will manage GCP infrastructure with Terraform, automate deployments, and support multi-cloud environments. Experience with GCP services like BigQuery, GKE, and Cloud Run is required. Kubernetes knowledge is essential.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Terraform and infrastructure-as-code experience is transferable to GCP\",\"Cloud-native architecture knowledge is relevant\",\"Automation experience with Ansible and GitHub Actions\"],\"gaps\":[\"No Google Cloud or GCP experience; focused on AWS\",\"No Kubernetes or GKE experience\",\"No BigQuery or Cloud Run signals\",\"Missing the core GCP-specific platform knowledge required\"],\"explanation\":\"While the candidate has strong AWS and Terraform skills, the role specifically requires Google Cloud expertise including GKE, BigQuery, and Cloud Run, none of which appear in the profile. Terraform experience is transferable but is not sufficient to close the platform-specific knowledge gap. This is a significant mismatch for a GCP-focused role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hiro_data\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Pandas\",\"Tableau\",\"Metabase\",\"dbt\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"]}\n\nJob Summary:\nE-commerce company is looking for a Mid-level Analytics Engineer to model data with dbt and write advanced SQL. BigQuery is the warehouse. You will build dashboards in Looker and collaborate with data engineers. Familiarity with Python for data manipulation is a plus. Experience with data quality testing in dbt is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt is present and directly required\",\"BigQuery is the stated warehouse and is present\",\"SQL and Python cover the language expectations\",\"Analytics background with Tableau and Metabase shows BI competence\"],\"gaps\":[\"No Looker experience; uses Tableau and Metabase for dashboarding\",\"No explicit dbt testing or data quality signals\",\"Data Analyst title may not fully reflect analytics engineering scope\"],\"explanation\":\"The candidate has the right technical foundation with dbt and BigQuery but lacks Looker experience, which is the specific dashboarding tool used. The absence of dbt testing signals is also a gap given the explicit expectation around data quality. This is a moderate fit that would require Looker ramp-up.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"marta_fe\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"React\",\"Bootstrap\"]}\n\nJob Summary:\nProduct studio hiring a Mid-level Frontend Engineer to own a Next.js and TypeScript codebase. You will work independently on complex UI features, integrate APIs, and be responsible for performance optimization. Tailwind CSS is our design system foundation. Testing with Jest and Playwright required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React experience is partially relevant as foundational knowledge for Next.js\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement\",\"No TypeScript experience\",\"No Next.js or SSR framework experience\",\"No Tailwind CSS; uses Bootstrap instead\",\"No testing experience with Jest or Playwright\",\"Cannot demonstrate independent ownership expected of a mid-level hire\"],\"explanation\":\"The candidate is a junior developer with a very limited profile that lacks TypeScript, Next.js, Tailwind CSS, and any testing tooling, all of which are explicit requirements. The seniority gap compounds the technical shortfalls, making this a weak match for a mid-level role requiring independent ownership.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ev_rust\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"C++\",\"Go\"],\"tech\":[\"Axum\",\"Docker\",\"AWS\",\"gRPC\",\"ONNX\"],\"architecture\":[\"Microservices\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"testing\":[\"Rust unit tests\"]}\n\nJob Summary:\nGame engine company hiring a Senior Rust Engineer for a high-performance 2D rendering pipeline. You will write memory-safe rendering code, integrate with the GPU via WebGL or Vulkan, and optimize for real-time frame rates. Experience with game engine internals or graphics programming is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Rust is the required language and is the candidate's primary language\",\"C++ experience is relevant to systems and game engine contexts\"],\"gaps\":[\"No WebGL, Vulkan, or graphics API experience visible\",\"No game engine or rendering pipeline experience\",\"ONNX suggests ML inference background rather than graphics\",\"Backend and microservices focus does not map to real-time rendering work\",\"No game development domain signals\"],\"explanation\":\"While the candidate is a skilled Rust engineer, their experience is in backend microservices and distributed systems rather than graphics programming or game engine development. The role requires WebGL or Vulkan integration and rendering pipeline expertise, which are entirely absent from the profile. Domain mismatch in systems programming makes this a weak fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ben_swe\",\"seniority\":\"Mid\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Flask\",\"React\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nGovernment contractor building internal tooling is hiring a Mid-level Software Engineer. The stack is Python and Django for the backend and React on the frontend. PostgreSQL is the database. Docker is used for local development. Must be comfortable in both backend and frontend. Security clearance is a process the company will support.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python and React cover the core language and frontend requirements\",\"PostgreSQL and Docker are both present and required\",\"Mid-level seniority is appropriate\",\"Full-stack profile with Python backend and React frontend\"],\"gaps\":[\"Uses Flask rather than Django, which is the required backend framework\",\"No CI/CD tooling visible\",\"No testing frameworks visible\"],\"explanation\":\"The candidate has the right language and frontend skills but uses Flask instead of Django for the backend, which is a gap since Django has its own ORM, admin panel, and conventions that differ meaningfully from Flask. The absence of testing and CI/CD tooling is also a mild concern for a government contracting context. Overall a moderate fit that would require some Django ramp-up.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"liz_ruby\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Ruby\",\"Python\"],\"tech\":[\"Ruby on Rails\",\"Sidekiq\",\"Docker\",\"AWS\",\"Nginx\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"CircleCI\"],\"testing\":[\"RSpec\"]}\n\nJob Summary:\nLate-stage startup is migrating their Ruby on Rails monolith to a Go-based microservices architecture. They are hiring a Senior Backend Engineer to lead the migration. Deep Go experience is required. Knowledge of Rails is useful for understanding the legacy system. Kubernetes and Terraform for new infrastructure.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Rails experience is useful for understanding the legacy monolith being migrated from\",\"Senior seniority is appropriate\",\"PostgreSQL knowledge transfers to the new system\"],\"gaps\":[\"No Go experience; the new architecture is entirely Go-based\",\"No Kubernetes or Terraform experience for the new infrastructure\",\"Rails expertise is being phased out, limiting the candidate's long-term role value\",\"No microservices migration signals\"],\"explanation\":\"The candidate has deep Rails expertise which is helpful for understanding the system being migrated away from, but the target architecture is Go-based microservices on Kubernetes, none of which are present in the profile. This is a fundamental mismatch for a migration lead role where Go and Kubernetes are the core requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sol_gql\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"NestJS\",\"GraphQL\",\"Apollo GraphQL\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nProductivity SaaS company building a GraphQL-first API platform is seeking a Mid-level Full Stack Engineer with both GraphQL and REST API experience. The REST layer is equally important for third-party integrations. You will work in NestJS, React, and TypeScript. PostgreSQL for storage. Observability via Datadog.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"GraphQL and Apollo GraphQL are directly required and present\",\"NestJS is the exact backend framework specified\",\"React, TypeScript, and PostgreSQL cover the remaining core requirements\",\"Jest and Supertest show solid testing discipline\"],\"gaps\":[\"No explicit REST API integration signals beyond general backend experience\",\"No Datadog or observability tooling visible\"],\"explanation\":\"The candidate is well-aligned on the GraphQL and NestJS stack but the role explicitly requires equal REST API experience for third-party integrations, which is not directly evidenced. The absence of Datadog for observability is a secondary gap. This is a moderate fit that would benefit from clarification on REST and monitoring experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tom_junior\",\"seniority\":\"Junior\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Django\",\"React\",\"Docker\"],\"databases\":[\"PostgreSQL\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nConsulting firm hiring Mid-level Full Stack Engineers for client-facing projects. Typical stack includes React, Django, and PostgreSQL deployed with Docker. TypeScript experience is preferred. You should be able to work independently on features and interface with clients. Prior consulting experience is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React, Django, PostgreSQL, and Docker directly match the typical client stack\",\"pytest shows testing awareness appropriate for consulting delivery\",\"Profile stack matches the consulting firm's standard toolchain\"],\"gaps\":[\"Junior seniority falls short of the mid-level requirement\",\"No TypeScript experience, which is preferred\",\"No signals of client-facing or consulting experience\",\"Independent feature ownership may be challenging at the junior level\"],\"explanation\":\"The candidate's technical stack is well-aligned with the consulting firm's tools, but the junior seniority and absence of TypeScript and consulting experience are notable gaps for a mid-level role requiring client interaction and independent delivery. The candidate would likely need mentorship, which may not fit the consulting model.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nina_ts\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"tRPC\",\"Prisma\",\"Tailwind CSS\",\"Docker\",\"Vercel\"],\"databases\":[\"PostgreSQL\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nSoftware studio building SaaS products in the Next.js ecosystem is hiring a Senior Full Stack Engineer. We use Next.js, tRPC, Prisma, and PostgreSQL. TypeScript only. Tailwind CSS for styling. We deploy on Vercel. You will also be expected to mentor junior engineers and participate in architectural decisions.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js, tRPC, Prisma, and PostgreSQL are all required and present\",\"TypeScript-only profile matches the studio's requirement\",\"Tailwind CSS and Vercel deployment match exactly\",\"Vitest and Playwright provide solid testing coverage\"],\"gaps\":[\"No mentorship or team leadership signals visible in the profile\",\"No architectural decision-making indicators beyond technical tool usage\"],\"explanation\":\"The candidate's technical stack is an exact match, but the role adds a mentorship and architectural leadership dimension that cannot be assessed from a GitHub profile alone. For a senior role with explicit mentoring expectations, these are meaningful gaps. The technical fit is excellent but the leadership dimension introduces uncertainty.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"carlo_data\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"PyTorch\",\"Pandas\",\"NumPy\",\"Weights & Biases\",\"dbt\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nInsurance company is hiring a Senior Data Scientist to build actuarial models and pricing algorithms. Experience with classical ML, time-series modeling, and Python is required. You will work closely with data engineers and should understand SQL and data warehouse tooling. Experiment tracking with MLflow or Weights and Biases is preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Strong classical ML background with scikit-learn directly matches actuarial modeling needs\",\"Python and R are both present for statistical computing\",\"Weights and Biases satisfies the experiment tracking preference\",\"Snowflake and PostgreSQL show data warehouse familiarity\",\"dbt signals collaboration ability with the data engineering team\"],\"gaps\":[\"No time-series or statistical modeling libraries visible such as statsmodels or Prophet\",\"No actuarial or insurance domain signals\",\"PyTorch may be underutilized in a classical ML actuarial context\"],\"explanation\":\"The candidate has a solid data science foundation with relevant tools for this role, but there is no explicit time-series modeling experience which is a stated requirement for actuarial work. The domain gap in insurance is also a soft concern. This is a moderate fit that would require some domain ramp-up.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"paco_devrel\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Next.js\",\"Node.js\",\"Astro\",\"Storybook\",\"Contentful\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nSaaS company is hiring a Senior Full Stack Engineer with strong backend ownership. You will build REST APIs in Node.js, design PostgreSQL schemas, implement authentication with JWT and OAuth, and work on a React frontend. TypeScript required. Docker and Kubernetes for deployment.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and TypeScript are present and relevant to the frontend requirement\",\"Node.js and PostgreSQL cover the backend language and database\"],\"gaps\":[\"No Docker or Kubernetes experience\",\"No JWT or OAuth authentication implementation signals\",\"Profile skews toward frontend and CMS tooling rather than backend API ownership\",\"No CI/CD tooling visible\",\"Storybook, Contentful, and Astro suggest content and marketing site focus rather than SaaS product backend work\"],\"explanation\":\"The candidate's profile is oriented toward frontend development, JAMstack, and content sites rather than the backend API ownership this role requires. The absence of Docker, Kubernetes, and authentication implementation signals is significant, and the technology choices suggest a mismatch in engineering focus. This is a weak fit for a backend-heavy senior SaaS role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"xavier_java\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Docker\",\"AWS\",\"RabbitMQ\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nStreaming platform is hiring a Mid-level Backend Engineer to build real-time event pipelines using Apache Kafka. Our backend services are in Java and Spring Boot. PostgreSQL is the primary database. AWS deployment using ECS. JUnit and Mockito for testing. Experience with event-driven architecture preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Java and Spring Boot are the required backend stack\",\"JUnit and Mockito satisfy the testing requirements\",\"AWS experience is relevant to the ECS deployment environment\",\"Event-driven experience with RabbitMQ shows message queue familiarity\"],\"gaps\":[\"Uses RabbitMQ rather than Apache Kafka, which is the required event streaming platform\",\"PostgreSQL not present; uses MySQL instead\",\"No ECS-specific deployment experience\",\"Jenkins vs preferred AWS-native or GitHub Actions CI\"],\"explanation\":\"The candidate is experienced in Java and Spring Boot which are the core backend requirements, but the specific event streaming and database technologies are mismatched. RabbitMQ experience is relevant but Kafka has different semantics and scale characteristics. MySQL to PostgreSQL is a minor gap, while the Kafka gap is more significant for a streaming platform role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"anya_infra\",\"seniority\":\"Mid\",\"roles\":[\"Infrastructure Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Terraform\",\"AWS\",\"Docker\",\"Ansible\",\"Prometheus\",\"Grafana\"],\"ci_cd\":[\"GitLab CI\"]}\n\nJob Summary:\nSaaS company running entirely on Azure is hiring a Mid-level Cloud Infrastructure Engineer. You will manage Azure infrastructure with Pulumi, maintain observability with Datadog, and automate provisioning. Kubernetes on AKS is a core part of the role. CI/CD runs on Azure Pipelines.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Infrastructure-as-code experience with Terraform is conceptually transferable\",\"Observability experience with Prometheus and Grafana shows relevant mindset\"],\"gaps\":[\"No Azure experience; focused on AWS\",\"Uses Terraform while role requires Pulumi\",\"No Kubernetes or AKS experience\",\"No Datadog experience; uses Prometheus and Grafana\",\"GitLab CI vs required Azure Pipelines\"],\"explanation\":\"The candidate has infrastructure engineering experience but their stack is AWS and Terraform-focused while the role operates entirely on Azure with Pulumi, AKS, and Azure Pipelines. These are not just configuration differences but represent distinct ecosystems that would require significant reskilling. The platform mismatch across cloud, IaC, Kubernetes, and observability tooling makes this a weak fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nina_ts\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"tRPC\",\"Prisma\",\"Tailwind CSS\",\"Docker\",\"Vercel\"],\"databases\":[\"PostgreSQL\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nIndependent software studio building SaaS products in the Next.js ecosystem is hiring a Senior Full Stack Engineer. We use Next.js, tRPC, Prisma, and PostgreSQL end-to-end. TypeScript only. Tailwind CSS for styling. We deploy on Vercel. Testing with Vitest for unit and Playwright for E2E.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js, tRPC, Prisma, and PostgreSQL are all required and present\",\"TypeScript-only profile matches the studio's language requirement\",\"Tailwind CSS is the stated styling approach\",\"Vercel deployment matches exactly\",\"Vitest and Playwright cover the full testing stack as specified\"],\"gaps\":[],\"explanation\":\"This is an unusually precise stack match with every named technology in the job description represented in the candidate's profile. The combination of tRPC and Prisma in a Next.js context is distinctive and signals genuine experience in this specific ecosystem rather than surface-level exposure. There are no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"theo_k8s\",\"seniority\":\"Lead\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"Istio\",\"Docker\",\"AWS\",\"Prometheus\",\"Grafana\",\"Vault\"],\"architecture\":[\"Cloud-Native\",\"Service Mesh\",\"Microservices\"],\"ci_cd\":[\"ArgoCD\",\"GitHub Actions\",\"Jenkins\"]}\n\nJob Summary:\nGlobal fintech seeking a Lead Platform Engineer to drive platform engineering for a GCP-native stack. You will own GKE cluster management, define Terraform modules for GCP resources, implement GitOps with Flux, and monitor with Google Cloud Monitoring and Datadog. Helm and Python scripting required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Kubernetes cluster management experience is directly relevant, even across cloud providers\",\"Terraform and Helm experience transfers to GCP contexts\",\"Lead seniority matches the role\",\"Python scripting is required and present\"],\"gaps\":[\"No GCP experience; specialized in AWS\",\"Uses ArgoCD for GitOps while the role requires Flux\",\"No Google Cloud Monitoring or Datadog experience; uses Prometheus and Grafana\",\"GKE-specific networking and IAM knowledge not evidenced\",\"No Flux-based GitOps signals\"],\"explanation\":\"While the candidate has strong platform engineering skills, the role is GCP-native and requires GKE, Flux, Google Cloud Monitoring, and Datadog, none of which are in the profile. The AWS-specific expertise and ArgoCD GitOps approach represent meaningful reskilling requirements beyond just tooling differences, particularly at the lead level where platform ownership is immediate.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leon_csharp\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C#\",\"TypeScript\"],\"tech\":[\"ASP.NET\",\".NET Core\",\"Entity Framework\",\"Docker\",\"Azure\"],\"databases\":[\"MS SQL Server\",\"Redis\"],\"ci_cd\":[\"Azure DevOps\"],\"testing\":[\"xUnit\"]}\n\nJob Summary:\nEnterprise company with a Microsoft-first stack is hiring a Mid-level Backend Developer. You will build REST APIs in C# and ASP.NET Core, use Entity Framework for ORM, deploy on Azure, and run CI/CD with Azure DevOps. SQL Server is the primary database. Testing with xUnit or NUnit is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"C# and ASP.NET Core are the exact required technologies\",\"Entity Framework satisfies the ORM requirement directly\",\"Azure is the deployment target and is present\",\"Azure DevOps covers the CI/CD requirement\",\"MS SQL Server is the primary database and is present\",\"xUnit satisfies the testing requirement\"],\"gaps\":[],\"explanation\":\"The candidate's Microsoft stack is a precise match for this enterprise role, with every named technology present from the language and framework to the ORM, database, cloud platform, and testing library. This is a strong fit with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"paco_devrel\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Next.js\",\"Node.js\",\"Astro\",\"Storybook\",\"Contentful\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nA media company migrating from a legacy CMS to headless is hiring a Senior Frontend Engineer. You will build JAMstack sites with Next.js or Astro, integrate with headless CMS platforms, and build a component library in Storybook. TypeScript required. React is the primary UI library.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and Astro directly cover the stated JAMstack frameworks\",\"Contentful is a leading headless CMS and satisfies that integration requirement\",\"Storybook is explicitly required for the component library\",\"React is the primary UI library and is present\",\"TypeScript is required and present\",\"Senior seniority matches the role\"],\"gaps\":[\"No explicit CI/CD or testing signals visible\"],\"explanation\":\"The candidate's stack is an excellent match for this headless CMS migration role, hitting Next.js, Astro, Contentful, Storybook, React, and TypeScript. The combination of JAMstack frameworks and CMS integration experience is particularly strong. The absence of visible testing tooling is a minor concern but does not significantly detract from an otherwise strong profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vera_platform\",\"seniority\":\"Staff\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"AWS\",\"Docker\",\"ArgoCD\",\"Vault\",\"Prometheus\",\"Grafana\",\"Datadog\"],\"architecture\":[\"Cloud-Native\",\"Microservices\",\"Service Mesh\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\",\"Jenkins\"]}\n\nJob Summary:\nScaleup company with 200 engineers is hiring a Staff Platform Engineer to own the internal developer platform. You will design self-service infrastructure, lead Kubernetes platform strategy, implement GitOps with ArgoCD, and define observability standards. Terraform and Vault for IaC and secrets. Go or Python scripting expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Staff seniority matches the strategic ownership level required\",\"Kubernetes platform strategy experience is core to the role\",\"ArgoCD directly satisfies the GitOps requirement\",\"Vault satisfies the secrets management requirement\",\"Terraform covers IaC requirements\",\"Prometheus, Grafana, and Datadog show mature observability capability\",\"Go and Python cover scripting expectations\"],\"gaps\":[\"No explicit developer experience or internal tooling signals beyond infrastructure\"],\"explanation\":\"This candidate is well-positioned for a staff platform engineering role, covering every named technology and demonstrating the breadth expected at the staff level. The combination of ArgoCD, Vault, and multi-layered observability tooling is particularly strong for an internal developer platform mandate. The developer experience gap is minor and likely covered by the breadth of platform work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"riku_ml\",\"seniority\":\"Junior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"TensorFlow\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nAI startup building production LLM applications is hiring a Mid-level ML Engineer. You will fine-tune large language models with PyTorch, build RAG pipelines with LangChain, manage vector databases, and deploy models on AWS. Experience with Hugging Face and distributed training is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python proficiency is the foundational requirement and is present\",\"scikit-learn and TensorFlow show ML exposure\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement\",\"No PyTorch experience; uses TensorFlow\",\"No LangChain or RAG pipeline experience\",\"No vector database experience\",\"No AWS deployment or cloud ML infrastructure signals\",\"No Hugging Face or distributed training experience\",\"Classical ML focus does not reflect LLM production experience\"],\"explanation\":\"The candidate is a junior ML engineer with classical ML experience that does not extend to the LLM ecosystem. The role requires PyTorch, LangChain, vector databases, and Hugging Face fine-tuning, none of which are present. The seniority gap compounds the technical mismatch, making this a weak fit for a production LLM engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sophie_angular\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Angular\",\"NgRx\",\"RxJS\",\"Tailwind CSS\",\"Webpack\"],\"testing\":[\"Karma\",\"Jasmine\",\"Cypress\"]}\n\nJob Summary:\nInsurance enterprise is hiring a Senior Frontend Engineer to maintain and extend a large Angular application. TypeScript is required. State management with NgRx is our standard. We use Karma and Jasmine for unit testing and Cypress for E2E. RxJS proficiency is expected throughout the codebase.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Angular is the exact required framework\",\"NgRx is the stated state management solution and is present\",\"RxJS is explicitly expected and is present\",\"Karma and Jasmine for unit testing match directly\",\"Cypress is the specified E2E testing tool and is present\",\"TypeScript is required and is the candidate's primary language\",\"Senior seniority matches the role\"],\"gaps\":[],\"explanation\":\"This candidate satisfies every stated technical requirement for the Angular enterprise role with zero gaps. Angular, NgRx, RxJS, and the complete testing stack of Karma, Jasmine, and Cypress are all directly present. This level of stack alignment is rare and represents an exceptional fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"matt_node\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Express.js\",\"Node.js\",\"Docker\",\"AWS\"],\"databases\":[\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Mocha\"]}\n\nJob Summary:\nB2C startup using a GraphQL API gateway is hiring a Mid-level Backend Engineer. You will build resolvers in NestJS, manage PostgreSQL with TypeORM, and handle authentication with JWT. Apollo Server experience preferred. TypeScript required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript and Node.js provide foundational compatibility with the NestJS stack\",\"Docker and AWS align with deployment infrastructure\",\"Jest testing experience is relevant\",\"Mid-level seniority is appropriate\"],\"gaps\":[\"Uses Express.js rather than NestJS, which is the required framework\",\"Uses MongoDB rather than PostgreSQL as the primary database\",\"No TypeORM experience\",\"No GraphQL or Apollo Server signals\",\"No JWT or authentication implementation visible\"],\"explanation\":\"The candidate has a Node.js TypeScript background which is compatible with NestJS at the language level, but the specific framework, database, ORM, and API protocol are all mismatched. Migrating from Express to NestJS is learnable but represents real onboarding overhead, and the GraphQL and PostgreSQL gaps compound the transition cost for a mid-level hire.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ines_devops\",\"seniority\":\"Junior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"GitHub Actions\",\"AWS\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nStartup looking for a Junior DevOps Engineer to help maintain Docker-based deployments, write automation scripts in Python or Bash, and manage CI/CD pipelines with GitHub Actions on AWS. No Kubernetes required at this stage. Willingness to learn is valued over years of experience.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Docker, GitHub Actions, and AWS match the three core requirements\",\"Python and Bash cover the automation scripting requirement\",\"Junior seniority aligns with the role's explicit junior positioning\"],\"gaps\":[\"Profile is sparse with limited visibility into depth of experience\",\"No monitoring or observability tooling\",\"No infrastructure-as-code signals such as Terraform\"],\"explanation\":\"The candidate covers the essential technology requirements for this junior-friendly DevOps role with Docker, GitHub Actions, and AWS all present. The profile is quite sparse, making it hard to assess depth, but the stated role values willingness to learn over experience. A moderate fit that warrants a closer look at the candidate's actual project experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"serena_be\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Elixir\",\"Python\"],\"tech\":[\"Phoenix\",\"Docker\",\"AWS\",\"RabbitMQ\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nReal-time collaboration startup is hiring a Senior Elixir Engineer to build and scale their Phoenix-based backend. You will implement real-time features using Phoenix Channels, design distributed systems, and work with PostgreSQL. RabbitMQ for async messaging. AWS for deployment.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Elixir and Phoenix are the required primary technologies and the candidate's core stack\",\"Distributed system architecture is essential for the real-time collaboration context and is present\",\"RabbitMQ satisfies the async messaging requirement\",\"PostgreSQL and Redis cover the data layer\",\"AWS deployment experience is present\",\"ExUnit demonstrates testing practice appropriate for the role\"],\"gaps\":[\"No explicit Phoenix Channels experience signaled, though Phoenix is listed\"],\"explanation\":\"The candidate is a strong fit for this Elixir backend role with Phoenix, distributed systems, RabbitMQ, and PostgreSQL all present. Elixir and Phoenix engineers are relatively rare, and this candidate demonstrates the core stack depth required. The only minor uncertainty is explicit Phoenix Channels experience, which is likely part of their Phoenix work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mo_android\",\"seniority\":\"Mid\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Firebase\"],\"databases\":[\"SQLite\",\"Firebase\"],\"testing\":[\"JUnit\",\"Espresso\"]}\n\nJob Summary:\nMedia company building a podcast app is hiring a Mid-level Android Engineer. Kotlin and Jetpack Compose are required. You will integrate audio streaming APIs, manage complex local state, and write unit and UI tests. Experience with ExoPlayer or media playback frameworks is strongly preferred. CI/CD experience is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin and Jetpack Compose are exact matches for the required stack\",\"JUnit and Espresso cover unit and UI testing requirements\",\"Android SDK experience is directly relevant\",\"Mid-level seniority is appropriate\"],\"gaps\":[\"No ExoPlayer or media playback framework experience, which is strongly preferred\",\"No CI/CD tooling visible\",\"Audio streaming integration is a specialized domain with no visible signals\"],\"explanation\":\"The candidate has the correct Android development foundation with Kotlin, Jetpack Compose, and relevant testing tools. However, the media playback and audio streaming requirements are a meaningful gap for a podcast app, and ExoPlayer is a strong preference that is absent. The missing CI/CD signals are also a mild concern. This is a moderate fit that hinges on media experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cj_blockchain\",\"seniority\":\"Mid\",\"roles\":[\"Blockchain Engineer\"],\"languages\":[\"Solidity\",\"TypeScript\",\"Python\"],\"tech\":[\"Hardhat\",\"Ethers.js\",\"IPFS\",\"Docker\"],\"architecture\":[\"Distributed System\"]}\n\nJob Summary:\nWeb3 startup building a DeFi protocol is hiring a Mid-level Smart Contract Developer. You will write and audit Solidity contracts, deploy on Ethereum and L2s, and integrate with frontends using Ethers.js or Wagmi. Hardhat or Foundry experience required. Security-first mindset essential.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Solidity is the required smart contract language and is present\",\"Hardhat satisfies the required tooling\",\"Ethers.js covers the frontend integration requirement\",\"TypeScript experience is relevant for integration work\"],\"gaps\":[\"No Foundry experience, which is increasingly preferred for smart contract testing\",\"No L2 deployment experience visible\",\"No audit or formal security tooling signals\",\"No Wagmi experience\"],\"explanation\":\"The candidate has solid Solidity and Hardhat experience relevant to DeFi smart contract development, but gaps in L2 deployment, formal security auditing tools, and Foundry are notable for a security-first Web3 role. Foundry is increasingly the standard for contract testing and its absence alongside no explicit security audit experience leaves meaningful questions open.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex_mlops\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"MLflow\",\"Kubeflow\",\"Docker\",\"Kubernetes\",\"AWS\",\"Weights & Biases\",\"ONNX\",\"FastAPI\"],\"architecture\":[\"Microservices\",\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nRetail company scaling its ML platform is hiring a Senior MLOps Engineer. You will manage model lifecycle with MLflow, orchestrate training pipelines with Kubeflow, deploy models as FastAPI services on Kubernetes, and export to ONNX for inference optimization. AWS is our cloud. Python scripting required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"MLflow satisfies the model lifecycle management requirement\",\"Kubeflow directly covers the training pipeline orchestration requirement\",\"FastAPI and Kubernetes match the model serving deployment requirements\",\"ONNX for inference optimization is explicitly required and present\",\"AWS is the specified cloud platform\",\"Python scripting is present\"],\"gaps\":[],\"explanation\":\"The candidate's profile is an exact match for this MLOps role, covering MLflow, Kubeflow, FastAPI on Kubernetes, and ONNX, all of which are explicitly named in the job description. This level of specificity in the candidate's toolchain strongly suggests hands-on experience with production ML infrastructure rather than surface-level familiarity.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"luis_fullstack\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"Python\",\"TypeScript\"],\"tech\":[\"FastAPI\",\"React\",\"Next.js\",\"Docker\",\"GCP\",\"Redis\"],\"architecture\":[\"Microservices\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"Firestore\"],\"ci_cd\":[\"GitHub Actions\",\"Cloud Build\"]}\n\nJob Summary:\nClimate tech startup deploying on Google Cloud is hiring a Senior Full Stack Engineer. You will build Python FastAPI services, develop React dashboards, and deploy serverless workloads on GCP. Firestore and PostgreSQL are our databases. We use Cloud Build for CI. TypeScript is required on the frontend.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"FastAPI is the exact backend framework required\",\"React and Next.js cover the dashboard frontend requirements\",\"GCP is the deployment cloud and is present\",\"Serverless architecture experience matches the deployment model\",\"Firestore and PostgreSQL are both present and required\",\"Cloud Build satisfies the CI requirement\",\"TypeScript is required on the frontend and is present\"],\"gaps\":[],\"explanation\":\"The candidate matches every stated requirement including the backend framework, frontend library, cloud platform, serverless architecture, both databases, and CI tooling. GCP-experienced full-stack engineers with FastAPI and serverless background are relatively specialized, making this a particularly competitive fit for the climate tech role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"w_backend\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"Flask\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nEdtech platform is hiring a Mid-level Backend Engineer to build REST APIs in Node.js with NestJS, manage MongoDB, and implement WebSocket-based real-time features. TypeScript is required. Experience with Redis for caching and Bull for job queues is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Basic backend REST API development experience with Flask\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement\",\"Python and Flask are not transferable to the Node.js and NestJS stack\",\"No TypeScript experience\",\"No MongoDB experience; uses PostgreSQL\",\"No WebSocket or real-time implementation signals\",\"No Redis or Bull job queue experience\"],\"explanation\":\"The candidate is a junior Python developer working in Flask, while the role requires a mid-level Node.js engineer working in NestJS with TypeScript, MongoDB, and real-time features. This is a fundamental mismatch across language, framework, seniority, database, and feature domain. There are no meaningful technical overlaps beyond general REST API concepts.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"anders_k8s\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"AWS\",\"Docker\",\"Prometheus\",\"Grafana\",\"ArgoCD\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nCloud-native startup hiring a Senior DevOps Engineer to own Kubernetes infrastructure on AWS. You will manage Helm releases, implement GitOps with ArgoCD, write Terraform modules, and build observability with Prometheus and Grafana. Go or Python scripting required. GitHub Actions for CI. We move fast and expect infrastructure ownership from day one.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Helm, and ArgoCD directly satisfy the GitOps and cluster management requirements\",\"Terraform and AWS cover the infrastructure-as-code and cloud requirements\",\"Prometheus and Grafana satisfy the observability stack exactly\",\"Go and Python scripting cover the stated language expectations\",\"GitHub Actions and k6 round out CI and load testing practice\"],\"gaps\":[],\"explanation\":\"This candidate hits every named technology in the job description including the less common combination of ArgoCD GitOps, Prometheus observability, and Terraform on AWS. The Go scripting capability is an additional signal of depth beyond typical DevOps profiles. There are no meaningful gaps relative to the stated requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dana_fullstack\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"NestJS\",\"Express.js\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nB2B SaaS startup is hiring a Mid-level Full Stack Engineer. We use React on the frontend, NestJS on the backend, and PostgreSQL as our primary database. TypeScript required across the stack. Docker and GitHub Actions for deployment and CI. We expect solid API testing with Jest or Supertest.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS is the exact required backend framework and is present\",\"React and TypeScript cover the frontend requirements\",\"PostgreSQL satisfies the primary database requirement\",\"Docker and GitHub Actions match deployment and CI\",\"Jest and Supertest directly satisfy the API testing requirements\"],\"gaps\":[\"MongoDB in the profile may indicate prior NoSQL usage but does not affect fit\"],\"explanation\":\"The candidate's profile now includes NestJS directly, satisfying the primary backend requirement. With React, TypeScript, PostgreSQL, and the testing stack all present, this is a strong fit with no material gaps for this B2B SaaS role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yemi_junior\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"React\",\"Bootstrap\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nEnterprise software company is hiring a Senior Frontend Architect to lead the migration of a large Angular codebase to React. You will define component architecture, mentor a team of eight engineers, establish testing standards, and own the frontend CI/CD pipeline. TypeScript required. Minimum five years of professional frontend experience expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React experience is directly relevant to the migration target\"],\"gaps\":[\"Junior seniority is far below the senior architect requirement\",\"No TypeScript experience\",\"No Angular experience relevant to understanding the legacy codebase\",\"No mentorship or team leadership signals\",\"No CI/CD tooling visible\",\"No testing framework experience\",\"Profile is too sparse to support a lead architect assessment\"],\"explanation\":\"This candidate is a junior developer with a minimal profile that lacks TypeScript, testing, CI/CD, and any leadership signals. The role requires senior architect-level experience including team mentorship and frontend pipeline ownership. The gap in seniority and technical breadth is too large to bridge for this position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tara_dataeng\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"PySpark\",\"Apache Kafka\",\"dbt\",\"Airflow\",\"Databricks\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nStreaming analytics company hiring a Senior Data Engineer to build real-time and batch pipelines. You will use Kafka for streaming, Spark for batch processing, and orchestrate with Airflow. Snowflake is our data warehouse. dbt for transformations. Great Expectations for data quality. Python and SQL required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kafka and Spark directly cover streaming and batch pipeline requirements\",\"Airflow satisfies the orchestration requirement\",\"Snowflake is the stated warehouse and is present\",\"dbt covers the transformation requirement\",\"Great Expectations directly satisfies the data quality requirement\",\"Python and SQL are both present\"],\"gaps\":[],\"explanation\":\"This candidate matches every technical requirement in the job description including the more specialized Great Expectations data quality tool. The combination of Kafka, Spark, Airflow, and dbt reflects a mature senior data engineering profile. Databricks and Scala signal additional depth beyond the stated requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"bo_springdev\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Apache Kafka\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nRetail tech company hiring a Mid-level Backend Engineer. Backend is Java and Spring Boot. Messaging via Apache Kafka. PostgreSQL primary database. Deployment on AWS. GitHub Actions for CI. JUnit and Mockito for testing. Event-driven architecture is how we build everything.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Java and Spring Boot are the required backend technologies\",\"Apache Kafka directly satisfies the messaging requirement\",\"PostgreSQL and Redis cover the data layer\",\"JUnit and Mockito match the testing requirements exactly\",\"AWS and GitHub Actions cover cloud and CI requirements\",\"Event-driven architecture is consistent with Kafka usage\"],\"gaps\":[],\"explanation\":\"The candidate's Java and Spring Boot stack combined with Kafka experience is a precise match for this event-driven retail backend role. Every named technology is present and the testing stack is exactly as specified. There are no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nora_mlops\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"PyTorch\",\"Kubeflow\",\"MLflow\",\"FastAPI\",\"Docker\",\"Kubernetes\",\"AWS\",\"ONNX\",\"Ray\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAd-tech company scaling ML infrastructure is hiring a Senior MLOps Engineer. You will manage training pipelines with Kubeflow, track experiments with MLflow, serve models via FastAPI on Kubernetes, and export to ONNX for optimized inference. AWS deployment. Python scripting throughout. Experience with distributed training using Ray is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubeflow directly satisfies the training pipeline management requirement\",\"MLflow covers experiment tracking\",\"FastAPI on Kubernetes matches the model serving requirement exactly\",\"ONNX covers inference optimization\",\"Ray is a strong plus that the candidate satisfies\",\"AWS and Python are both present\"],\"gaps\":[],\"explanation\":\"The candidate's profile is an exact match for this MLOps role, satisfying every named technology including the Ray distributed training bonus. The depth across the full model lifecycle from training orchestration to inference optimization reflects a mature MLOps engineering background.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"joel_php\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"Laravel\",\"Vue.js\",\"Docker\",\"MySQL\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nE-learning startup is hiring a Mid-level Backend Engineer. Our stack is Python and Django, with PostgreSQL as the primary database. Celery for background tasks. Docker for containerization. GitHub Actions for CI. We expect pytest-based testing and clean REST API design.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker experience is transferable across stacks\",\"Backend REST API experience with Laravel demonstrates relevant patterns\"],\"gaps\":[\"PHP and Laravel are fundamentally different from the required Python and Django stack\",\"No Python experience visible\",\"MySQL is used while the role requires PostgreSQL\",\"No Celery or task queue experience\",\"No pytest or Python testing framework experience\",\"Uses GitLab CI while the role uses GitHub Actions\"],\"explanation\":\"The candidate is a PHP and Laravel developer and this role is entirely Python and Django. These are not adjacent technologies that can be bridged quickly, and every layer of the stack from language to framework to database to testing is mismatched. This is a fundamental technology incompatibility rather than a surface gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sasha_react\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Redux\",\"Tailwind CSS\",\"Storybook\",\"Webpack\",\"Vite\"],\"testing\":[\"Jest\",\"React Testing Library\",\"Cypress\"]}\n\nJob Summary:\nFintech company building a complex trading dashboard is hiring a Senior Frontend Engineer. Our stack is React and TypeScript with Zustand for state management. We use Storybook for component documentation and Jest with React Testing Library for unit tests. Cypress for E2E. Tailwind CSS for styling. Micro-frontend architecture is being adopted.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and TypeScript are the required stack and present\",\"Storybook is required for component documentation and is present\",\"Jest and React Testing Library match unit testing expectations\",\"Cypress covers the E2E requirement\",\"Tailwind CSS is the stated styling approach\"],\"gaps\":[\"Uses Redux for state management while the role uses Zustand, which has a fundamentally different API\",\"No micro-frontend architecture experience visible, which is being actively adopted\"],\"explanation\":\"The candidate's testing and styling stack is a precise match, but the state management mismatch from Redux to Zustand is a practical gap since Zustand has a simpler, hooks-based API that differs significantly from Redux. The micro-frontend adoption is an additional area the candidate would need to ramp on quickly in this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lin_platform\",\"seniority\":\"Staff\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"AWS\",\"Vault\",\"Prometheus\",\"Grafana\",\"Datadog\",\"Docker\",\"Pulumi\"],\"architecture\":[\"Cloud-Native\",\"Service Mesh\",\"Microservices\"],\"ci_cd\":[\"ArgoCD\",\"GitHub Actions\"]}\n\nJob Summary:\nHigh-scale tech company is hiring a Staff Platform Engineer to define internal developer platform strategy. You will lead Kubernetes platform architecture, implement GitOps, manage secrets with Vault, and set observability standards. Terraform or Pulumi for IaC. AWS cloud. Go scripting preferred. This is a highly autonomous role shaping infrastructure for 300 engineers.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Staff seniority is appropriate for the strategic platform role\",\"Kubernetes and ArgoCD cover cluster management and GitOps requirements\",\"Vault satisfies the secrets management requirement\",\"Both Terraform and Pulumi are present, covering either IaC option\",\"Prometheus, Grafana, and Datadog show mature multi-layer observability\",\"Go scripting is preferred and present\",\"AWS is the specified cloud platform\"],\"gaps\":[],\"explanation\":\"This candidate is exceptionally well-positioned for a staff platform engineering role, covering every named requirement including the rare combination of both Terraform and Pulumi. The multi-layer observability stack with Datadog alongside Prometheus and Grafana signals enterprise-grade maturity appropriate for a 300-engineer organization.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"matt_analyst\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Pandas\",\"Tableau\",\"Power BI\"],\"databases\":[\"MySQL\",\"BigQuery\"]}\n\nJob Summary:\nRetail company is hiring a Mid-level Analytics Engineer. You will build dbt models, write advanced SQL, and develop dashboards in Looker. BigQuery is the data warehouse. Collaboration with data engineers is expected. Python is a plus. Data quality testing within dbt pipelines is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"BigQuery is the stated warehouse and is present\",\"Python and SQL provide the foundational language skills\",\"Analytics background with Tableau and Power BI demonstrates BI experience\"],\"gaps\":[\"No dbt experience, which is the core transformation tool for the role\",\"No Looker experience; uses Tableau and Power BI instead\",\"No data quality or dbt testing signals\",\"Data Analyst background may not reflect the engineering depth analytics engineering requires\"],\"explanation\":\"The candidate has a solid analytics foundation with BigQuery and SQL, but the role centers on dbt modeling and Looker dashboarding, neither of which are present. The distinction between business analytics and analytics engineering is meaningful here, and the missing dbt experience is the most significant gap for this position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hana_ios\",\"seniority\":\"Senior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Combine\",\"CoreData\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"XCTest\",\"Quick\",\"Nimble\"]}\n\nJob Summary:\nConsumer finance app company is hiring a Senior iOS Engineer. You will build SwiftUI features, manage local persistence with CoreData, use Combine for reactive data flows, and write unit and snapshot tests. Fastlane for mobile CI. Objective-C knowledge needed to maintain legacy code. The app also integrates Stripe SDK for payments.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SwiftUI is the required UI framework and is present\",\"CoreData satisfies the local persistence requirement directly\",\"Combine is explicitly required for reactive flows and is present\",\"Fastlane satisfies the mobile CI requirement\",\"Objective-C for legacy maintenance is present\"],\"gaps\":[\"No Stripe SDK or payment integration experience visible\",\"No snapshot testing framework beyond XCTest visible\"],\"explanation\":\"The candidate covers the core iOS requirements well including the SwiftUI, Combine, and CoreData combination. However, Stripe SDK payment integration is a domain-specific requirement that is absent from the profile, and for a consumer finance app this is a meaningful gap. The candidate would need to ramp on payments integration from the start.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"raf_node\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Express.js\",\"Node.js\",\"Docker\",\"AWS\",\"Socket.io\"],\"databases\":[\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Mocha\"]}\n\nJob Summary:\nGaming startup building a real-time multiplayer backend is hiring a Mid-level Backend Engineer. You will implement WebSocket game logic with Socket.io, manage player sessions with Redis, and serve APIs via Node.js. MongoDB for game state persistence. AWS deployment. TypeScript preferred.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Socket.io directly satisfies the WebSocket real-time requirement\",\"Redis covers the player session management requirement\",\"MongoDB is the specified persistence layer for game state\",\"Node.js and AWS match the API server and cloud requirements\",\"TypeScript is preferred and is present alongside JavaScript\",\"Jest and Mocha show solid testing coverage\"],\"gaps\":[\"No explicit game state or matchmaking architecture experience signaled\"],\"explanation\":\"The candidate's stack is a precise match for this real-time gaming backend, with Socket.io, Redis, MongoDB, and Node.js all covering the core requirements. The combination of real-time WebSocket tooling and in-memory session management via Redis is particularly strong for a multiplayer game context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"preet_sre\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"AWS\",\"Prometheus\",\"Grafana\",\"Docker\",\"PagerDuty\"],\"architecture\":[\"Distributed System\",\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nE-commerce company hiring a Senior SRE to own reliability engineering. You will run Kubernetes on GCP, instrument services with Datadog, manage on-call rotations in PagerDuty, write SLOs, and automate runbooks in Python. Terraform for infrastructure. Chaos engineering experience strongly preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PagerDuty for on-call management is directly present\",\"Kubernetes and Terraform cover cluster management and IaC\",\"Python scripting matches automation requirements\",\"Senior seniority is appropriate\"],\"gaps\":[\"AWS-focused profile while the role runs on GCP\",\"Uses Prometheus and Grafana while the role requires Datadog\",\"No chaos engineering experience, which is strongly preferred\",\"No GCP-specific networking or IAM experience visible\"],\"explanation\":\"The candidate has a strong SRE foundation but two meaningful platform gaps: the cloud provider is GCP not AWS, and the observability stack is Prometheus rather than Datadog. These are practical reskilling needs, not just tooling swaps. The missing chaos engineering experience is an additional gap for a reliability-first role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dex_rust\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"Go\"],\"tech\":[\"Axum\",\"Tokio\",\"Docker\",\"AWS\",\"gRPC\",\"Redis\"],\"architecture\":[\"Microservices\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Rust unit tests\"]}\n\nJob Summary:\nInfrastructure company building a high-performance data plane is hiring a Senior Rust Engineer. You will write async Rust services using Tokio and Axum, expose gRPC APIs, and manage data in PostgreSQL. Low-latency design experience required. AWS deployment. Docker containerization.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Rust is the required language and is the candidate's primary language\",\"Tokio and Axum are the exact async runtime and framework named in the job description\",\"gRPC is explicitly required and present\",\"PostgreSQL satisfies the data management requirement\",\"AWS and Docker cover the deployment requirements\",\"Distributed system and low-latency context is reflected in the architecture signals\"],\"gaps\":[],\"explanation\":\"This candidate is a precise fit for the Rust data plane role with the specific Tokio and Axum combination named in the job description both present. The gRPC and distributed systems experience further reinforces suitability for a high-performance infrastructure context. There are no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lis_flutter\",\"seniority\":\"Junior\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"JavaScript\"],\"tech\":[\"Flutter\",\"Firebase\",\"Expo\"],\"databases\":[\"Firebase\"]}\n\nJob Summary:\nHealthtech startup building a Flutter patient app is hiring a Mid-level Flutter Developer. You will build complex stateful UI, integrate FHIR-compliant REST APIs, implement secure local storage, and write unit and widget tests. Fastlane for mobile CI. HIPAA-compliant data handling is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Flutter and Dart are the required framework and language\",\"Firebase provides basic mobile backend integration experience\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement\",\"No unit or widget testing experience visible\",\"No Fastlane or mobile CI experience\",\"No HIPAA-aware data handling or healthcare compliance signals\",\"No secure local storage implementation experience\",\"No REST API integration signals beyond Firebase\"],\"explanation\":\"The candidate has basic Flutter experience but lacks the testing, CI, and compliance requirements that are critical for a healthcare application. HIPAA compliance and FHIR API integration are specialized expectations this profile cannot support. The seniority gap compounds the technical shortfalls.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lis_flutter\",\"seniority\":\"Junior\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"JavaScript\"],\"tech\":[\"Flutter\",\"Firebase\",\"Expo\"],\"databases\":[\"Firebase\"]}\n\nJob Summary:\nConsumer lifestyle startup is hiring a Junior Flutter Developer. You will build features in Flutter with Dart, integrate Firebase for authentication and storage, and ship to iOS and Android. No prior professional experience necessary but Dart familiarity is required. Willingness to learn and iterate quickly is valued above all.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Flutter and Dart are the required technologies and are present\",\"Firebase satisfies the authentication and storage requirement\",\"Junior seniority aligns with the role\",\"Cross-platform delivery experience is evidenced by the profile\"],\"gaps\":[\"Profile is quite sparse with limited visibility into code quality or depth\",\"No testing frameworks visible\",\"Expo and React Native exposure may indicate cross-platform breadth over Flutter depth\"],\"explanation\":\"The candidate has the required Flutter and Firebase stack and the right seniority level for the role. However, the profile is very sparse and the presence of Expo alongside Flutter raises questions about the depth of native Flutter experience. The role values willingness to learn, making this a reasonable but not confident fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tomm_go\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Echo\",\"Docker\",\"GCP\",\"Redis\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Go testing\"]}\n\nJob Summary:\nLogistics tech company is hiring a Mid-level Go Backend Engineer. You will build REST APIs in Go using Gin or Echo, manage PostgreSQL databases, and deploy containerized services on GCP. GitHub Actions for CI. Redis for caching. Experience with gRPC is a bonus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go is the required language and the candidate's primary language\",\"Echo is one of the two stated framework options and is present\",\"PostgreSQL satisfies the database requirement\",\"GCP is the stated cloud platform and is present\",\"Docker and GitHub Actions cover containerization and CI\",\"Redis satisfies the caching requirement\"],\"gaps\":[\"No gRPC experience, which is listed as a bonus\"],\"explanation\":\"The candidate's Go stack maps precisely to this logistics backend role, covering the framework, database, cloud, caching, and CI requirements. The absence of gRPC is a minor gap on a stated bonus skill. This is a strong fit with no material missing requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jake_ml\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"Tableau\",\"MLflow\"],\"databases\":[\"PostgreSQL\",\"MySQL\"]}\n\nJob Summary:\nAI-first startup is hiring a Senior ML Engineer to train and serve deep learning models at scale. You will fine-tune LLMs using PyTorch and Hugging Face, build RAG pipelines with LangChain, serve models via FastAPI, and manage vector databases. CUDA or GPU training experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"MLflow for experiment tracking is relevant\",\"Python proficiency is the foundational language requirement\"],\"gaps\":[\"No PyTorch or deep learning experience; uses scikit-learn for classical ML\",\"No Hugging Face or LLM fine-tuning experience\",\"No LangChain or RAG pipeline experience\",\"No FastAPI or model serving experience\",\"No vector database experience\",\"No CUDA or GPU training signals\",\"Classical ML and data science focus is misaligned with production LLM engineering\"],\"explanation\":\"The candidate is a classical ML and data science practitioner with no visible deep learning or LLM ecosystem experience. Every core requirement from PyTorch to Hugging Face to LangChain and vector databases is absent. This is a fundamental domain mismatch rather than a skill gap that can be quickly addressed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rae_cyber\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"AWS\",\"Kubernetes\",\"Vault\",\"Terraform\",\"GitHub Actions\",\"Sentry\"],\"architecture\":[\"Cloud-Native\",\"Zero Trust\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nSaaS company is hiring a Senior Application Security Engineer with deep AppSec expertise. You will integrate SAST and DAST tooling into CI pipelines, perform threat modeling sessions with engineering teams, conduct penetration testing, and remediate OWASP Top 10 vulnerabilities. Burp Suite or similar tooling preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"CI/CD security integration via GitHub Actions is applicable\",\"Cloud infrastructure security background is adjacent to AppSec\"],\"gaps\":[\"No SAST or DAST tooling experience visible\",\"No Burp Suite or penetration testing tool signals\",\"No OWASP or threat modeling process signals\",\"No application security or code review experience visible\",\"Profile is infrastructure security focused, not application security\"],\"explanation\":\"The candidate has cloud and infrastructure security experience but this role requires application security expertise including SAST, DAST, penetration testing, and OWASP remediation. These are distinct security disciplines and none of the AppSec capabilities are evidenced in the profile. This is a domain mismatch rather than a tool gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tomm_go\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Echo\",\"Docker\",\"GCP\",\"Redis\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Go testing\"]}\n\nJob Summary:\nLogistics tech company is hiring a Mid-level Go Backend Engineer. You will build REST APIs in Go using Gin or Echo, manage PostgreSQL databases, and deploy containerized services on AWS. GitHub Actions for CI. Redis for caching. You will also be responsible for writing comprehensive API documentation with Swagger.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go is the required language and the candidate's primary language\",\"Echo is one of the two stated framework options and is present\",\"PostgreSQL satisfies the database requirement\",\"Redis satisfies the caching requirement\",\"GitHub Actions covers the CI requirement\"],\"gaps\":[\"Uses GCP for deployment while the role deploys on AWS\",\"No Swagger or OpenAPI documentation experience visible, which is a stated responsibility\"],\"explanation\":\"The candidate's Go and Echo stack is well-aligned with the API development requirements, but two gaps are notable: the cloud provider is GCP while the role uses AWS, and Swagger documentation is a stated responsibility with no evidence in the profile. Neither is a hard blocker but both represent onboarding needs in this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"emma_devops\",\"seniority\":\"Junior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"AWS\",\"GitHub Actions\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nSaaS startup looking for a Junior DevOps Engineer to assist with Docker-based deployments, write Python automation scripts, and maintain GitHub Actions pipelines on AWS. No Kubernetes required at this stage. We value eagerness to learn over years of experience. Monitoring with CloudWatch expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Docker, AWS, and GitHub Actions match the three core requirements\",\"Python and Bash cover the scripting expectations\",\"Junior seniority aligns with the role\"],\"gaps\":[\"No AWS CloudWatch or monitoring experience visible\",\"Profile is sparse with limited visibility into practical depth\",\"No infrastructure-as-code signals such as Terraform or CloudFormation\"],\"explanation\":\"The candidate covers the core tooling requirements for this junior DevOps role but the CloudWatch monitoring expectation is notably absent. The profile is also quite sparse, making depth of experience difficult to assess. This is a reasonable fit that would benefit from clarification on monitoring and automation project experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"caro_fe\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Angular\",\"NgRx\",\"RxJS\",\"Tailwind CSS\",\"Storybook\"],\"testing\":[\"Karma\",\"Jasmine\",\"Playwright\"]}\n\nJob Summary:\nInsurance enterprise is hiring a Mid-level Frontend Engineer to maintain a large Angular codebase. TypeScript required. NgRx for state management. Karma and Jasmine for unit tests, Playwright for E2E. RxJS proficiency expected. You will also contribute to a new React-based internal admin dashboard that is under development.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Angular, NgRx, and RxJS are the exact core requirements for the main codebase\",\"Karma and Jasmine match unit testing expectations directly\",\"Playwright satisfies the E2E testing requirement\",\"TypeScript is required and present\"],\"gaps\":[\"No React experience visible for the internal admin dashboard contribution\",\"The dual-framework expectation is a real split responsibility this candidate cannot fully cover\"],\"explanation\":\"The candidate is an excellent match for the Angular codebase work, but the role also requires contributing to a new React admin dashboard, for which no React experience is evidenced. In a role where both responsibilities are active, this creates a meaningful gap that would require React ramp-up alongside ongoing Angular work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"raf_node\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Express.js\",\"Node.js\",\"Docker\",\"AWS\",\"Socket.io\"],\"databases\":[\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Mocha\"]}\n\nJob Summary:\nGaming startup building a real-time multiplayer backend is hiring a Mid-level Backend Engineer. You will implement WebSocket game logic with Socket.io, manage player sessions with Redis, and serve APIs via Node.js. MongoDB for game state. AWS deployment. TypeScript preferred. Engineers are expected to design and document system architecture.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Socket.io directly satisfies the WebSocket real-time requirement\",\"Redis covers player session management\",\"MongoDB is the specified game state persistence layer\",\"Node.js and AWS match the API server and cloud requirements\",\"TypeScript is preferred and present\"],\"gaps\":[\"No system architecture documentation or design signals visible\",\"No game state or matchmaking domain experience evidenced\"],\"explanation\":\"The candidate's core tooling stack is a strong technical match for this real-time gaming backend with Socket.io, Redis, and MongoDB all present. However, the role expects system architecture design and documentation, which is not evidenced in the profile. For a startup building complex multiplayer infrastructure this is a meaningful expectation beyond just tooling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kim_wordpress\",\"seniority\":\"Mid\",\"roles\":[\"Software Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"WordPress\",\"WooCommerce\",\"MySQL\",\"jQuery\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nGrowth-stage startup building a React and Node.js SaaS product is hiring a Mid-level Full Stack Engineer. TypeScript required across the stack. PostgreSQL for storage. Docker and Kubernetes for deployment. GitHub Actions for CI. Engineers are expected to write tests and own features end-to-end from database to UI.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"JavaScript experience provides a basic foundation\"],\"gaps\":[\"WordPress and WooCommerce are CMS platforms, not a transferable SaaS engineering background\",\"No React or modern frontend framework experience\",\"No Node.js or TypeScript experience\",\"PostgreSQL not present; uses MySQL with a CMS-specific schema model\",\"No Docker or Kubernetes experience\",\"No CI/CD tooling visible\",\"No automated testing frameworks\"],\"explanation\":\"The candidate's background is centered on WordPress and WooCommerce development, which is a different engineering discipline from building a TypeScript React and Node.js SaaS product. The stack mismatch is comprehensive across language, framework, infrastructure, and testing. This is a weak fit that would require near-total reskilling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"olga_llm\",\"seniority\":\"Senior\",\"roles\":[\"AI Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"LangChain\",\"LangGraph\",\"OpenAI API\",\"Ollama\",\"Pinecone\",\"Weaviate\",\"FastAPI\",\"Docker\"],\"architecture\":[\"RAG\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Pinecone\",\"Weaviate\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise AI company hiring a Senior AI Engineer to build production RAG pipelines using LangChain, integrate with OpenAI and self-hosted LLMs, and manage vector stores. FastAPI for serving. The role also requires fine-tuning LLMs with PyTorch and Hugging Face. AWS infrastructure experience is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"LangChain satisfies the RAG pipeline orchestration requirement\",\"OpenAI API integration is required and present\",\"Ollama shows self-hosted LLM experience\",\"Pinecone and Weaviate cover vector store management\",\"FastAPI satisfies the serving requirement\"],\"gaps\":[\"No PyTorch or Hugging Face experience for LLM fine-tuning, which is required\",\"No AWS infrastructure signals\"],\"explanation\":\"The candidate is an excellent fit for the RAG and vector store aspects of the role, but the LLM fine-tuning requirement introduces a meaningful gap. PyTorch and Hugging Face fine-tuning is a distinct skill from RAG pipeline engineering, and the absence of AWS experience is an additional concern for a production AI deployment role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex_vue\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Vuex\",\"Tailwind CSS\"],\"testing\":[\"Vitest\"]}\n\nJob Summary:\nEuropean SaaS company hiring a Mid-level Frontend Engineer. Their stack is React and Next.js, not Vue. You will own complex UI features, write tests with Vitest and Cypress, use Tailwind CSS for styling, and manage state with Zustand. TypeScript required. The team ships rapidly and expects React expertise.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript, Tailwind CSS, and Vitest are transferable skills\",\"Component-based UI development experience is relevant at the concept level\"],\"gaps\":[\"Vue.js and Nuxt.js experience does not transfer to the React and Next.js stack required\",\"No React or Next.js experience visible\",\"No Zustand or React state management experience\",\"No Cypress E2E testing experience\",\"React expertise is explicitly required and is absent\"],\"explanation\":\"The candidate is a Vue.js developer and the role requires React and Next.js expertise. While component-based UI concepts are shared, Vue and React are distinct ecosystems with different mental models, state management patterns, and toolchains. The role explicitly expects React expertise, making this a weak fit despite the transferable TypeScript and Tailwind skills.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vera_csharp\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C#\",\"TypeScript\"],\"tech\":[\"ASP.NET\",\".NET Core\",\"Entity Framework\",\"Docker\",\"Azure\",\"SignalR\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"MS SQL Server\",\"Redis\"],\"ci_cd\":[\"Azure DevOps\",\"GitHub Actions\"],\"testing\":[\"xUnit\",\"Moq\"]}\n\nJob Summary:\nEnterprise collaboration software company is hiring a Senior C# Backend Engineer. You will build real-time features with SignalR, write microservices in ASP.NET Core, manage SQL Server, deploy to Azure with Docker, and run CI/CD on Azure DevOps. xUnit and Moq for testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SignalR directly satisfies the real-time feature requirement\",\"ASP.NET Core and .NET Core cover the microservices framework requirement\",\"SQL Server is the stated database and is present\",\"Azure and Docker match the deployment requirements\",\"Azure DevOps satisfies the CI/CD requirement\",\"xUnit and Moq match the testing stack exactly\"],\"gaps\":[],\"explanation\":\"This candidate satisfies every named technology in the job description including SignalR, which is a specialized real-time signaling requirement. The combination of Azure DevOps, xUnit, and Moq alongside the full .NET stack reflects a mature C# engineering background. There are no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"osei_data\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"dbt\",\"Airflow\",\"Pandas\",\"Dagster\",\"Great Expectations\"],\"databases\":[\"Snowflake\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nMedia analytics company hiring a Mid-level Data Engineer. You will build ELT pipelines with dbt and orchestrate with Airflow, work with Snowflake, and write Python and SQL. Data quality testing in dbt pipelines is expected. Experience with Dagster is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt and Airflow directly cover the ELT and orchestration requirements\",\"Snowflake is the stated data warehouse and is present\",\"Python and SQL meet the language requirements\",\"Great Expectations satisfies the data quality expectation\",\"Dagster is a listed plus and is present\",\"GitHub Actions shows CI discipline\"],\"gaps\":[],\"explanation\":\"The candidate covers every core requirement for this data engineering role including the specific data quality expectation via Great Expectations. The Dagster plus is also satisfied. With Snowflake, dbt, Airflow, and data quality tooling all present, this is a strong fit with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pia_rails\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Ruby\",\"Python\"],\"tech\":[\"Ruby on Rails\",\"Sidekiq\",\"Docker\",\"AWS\",\"Redis\",\"Nginx\"],\"architecture\":[\"Monolith\",\"Modular Architecture\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"CircleCI\"],\"testing\":[\"RSpec\"]}\n\nJob Summary:\nLate-stage SaaS company is actively migrating their Ruby on Rails monolith to Go-based microservices. They are hiring a Senior Backend Engineer who must have both deep Go experience and Rails knowledge to bridge the migration. Go is the primary hiring requirement. Kubernetes for new services. Terraform for infrastructure.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Rails expertise is useful context for the monolith being migrated from\",\"PostgreSQL knowledge transfers to the new system\",\"Senior seniority is appropriate for a migration role\"],\"gaps\":[\"No Go experience; the primary hiring requirement is Go\",\"No Kubernetes experience for the new microservices layer\",\"No Terraform experience for infrastructure\",\"Rails expertise becomes less relevant over time as migration progresses\",\"Cannot bridge the migration if unable to write Go from day one\"],\"explanation\":\"The candidate has deep Rails experience which provides useful context for the source system, but Go is explicitly stated as the primary hiring requirement and is entirely absent from the profile. Kubernetes and Terraform for the new infrastructure layer are also missing. A migration lead role that requires Go proficiency from day one is a poor fit for a Rails-only engineer.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"olga_llm\",\"seniority\":\"Senior\",\"roles\":[\"AI Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"LangChain\",\"LangGraph\",\"OpenAI API\",\"Ollama\",\"Pinecone\",\"Weaviate\",\"FastAPI\",\"Docker\"],\"architecture\":[\"RAG\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Pinecone\",\"Weaviate\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise AI company hiring a Senior AI Engineer to build production RAG pipelines using LangChain, integrate with OpenAI and self-hosted LLMs, and manage vector stores. FastAPI for serving. Docker for containerization. Multi-agent workflow experience is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LangChain satisfies the RAG pipeline orchestration requirement directly\",\"OpenAI API integration is explicitly required and present\",\"Ollama demonstrates self-hosted LLM deployment experience\",\"Pinecone and Weaviate cover vector store management requirements\",\"LangGraph signals multi-agent workflow experience, satisfying the strong plus\",\"FastAPI and Docker cover serving and containerization requirements\"],\"gaps\":[],\"explanation\":\"This candidate is an exceptional match for the enterprise RAG role, hitting every stated requirement including the multi-agent workflow plus via LangGraph. The dual vector database experience with both Pinecone and Weaviate suggests genuine breadth in vector store evaluation and deployment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex_vue\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Vuex\",\"Tailwind CSS\"],\"testing\":[\"Vitest\"]}\n\nJob Summary:\nEuropean SaaS company hiring a Mid-level Frontend Engineer for their Vue.js product. You will own UI features, manage state with Pinia, write tests with Vitest and Cypress, and use Tailwind CSS. TypeScript preferred. The team is migrating from Vuex to Pinia and expects the new hire to lead that effort.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Vue.js and Nuxt.js are the required frameworks and are present\",\"Vuex experience provides context for the migration effort being led\",\"Tailwind CSS matches the styling approach\",\"Vitest satisfies the unit testing requirement\",\"TypeScript is preferred and present\"],\"gaps\":[\"Uses Vuex rather than Pinia; the role expects the new hire to lead the Vuex-to-Pinia migration\",\"No Cypress experience for E2E testing\",\"Migration leadership requires Pinia proficiency the candidate has not demonstrated\"],\"explanation\":\"The candidate's Vue stack is broadly compatible with the role, and existing Vuex experience is actually useful context for a migration effort. However, the role specifically expects the new hire to lead the Pinia migration, which requires demonstrated Pinia proficiency that is absent. The missing Cypress experience is a secondary gap in the E2E testing stack.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ian_android\",\"seniority\":\"Mid\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Retrofit\",\"Room\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Mockito\",\"Espresso\"]}\n\nJob Summary:\nStreaming app company hiring a Mid-level Android Engineer. You will build UI in Jetpack Compose with Kotlin, persist data with Room, integrate streaming REST APIs via Retrofit, and write tests. Firebase for analytics. Fastlane for mobile CI. The role also requires integrating ExoPlayer for video playback, which is central to the product.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Jetpack Compose, Room, and Retrofit are all required and present\",\"Firebase satisfies the analytics requirement\",\"Fastlane matches the mobile CI requirement\",\"JUnit, Mockito, and Espresso show a thorough testing background\",\"Kotlin is the required language\"],\"gaps\":[\"No ExoPlayer or video playback framework experience visible, which is central to the product\",\"Media streaming integration is a specialized domain with no visible signals\"],\"explanation\":\"The candidate covers the standard Android development requirements well, but ExoPlayer integration is described as central to the product and is entirely absent from the profile. For a streaming app where video playback is the core feature, this is a meaningful domain gap that goes beyond a simple tooling difference.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wren_devops\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"Kubernetes\",\"Terraform\",\"GCP\",\"Prometheus\",\"Grafana\"],\"ci_cd\":[\"GitLab CI\",\"GitHub Actions\"]}\n\nJob Summary:\nEdtech company running on Azure is hiring a Mid-level DevOps Engineer to manage Azure Kubernetes Service, write Terraform for Azure resources, set up observability with Azure Monitor and Datadog, and maintain CI/CD with Azure Pipelines.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Kubernetes experience transfers to AKS conceptually\",\"Terraform IaC experience is applicable to Azure resource management\",\"Prometheus and Grafana show observability mindset\"],\"gaps\":[\"No Azure experience; focused on GCP\",\"No AKS-specific networking or RBAC experience\",\"No Datadog or Azure Monitor experience\",\"No Azure Pipelines experience; uses GitLab CI and GitHub Actions\",\"Azure-specific Terraform provider configuration differs meaningfully from GCP\"],\"explanation\":\"The candidate has solid Kubernetes and Terraform fundamentals but their cloud platform experience is GCP-centric while the role operates entirely on Azure. Azure-specific tooling including AKS networking, Azure Monitor, Datadog, and Azure Pipelines are all absent. The platform mismatch across cloud, observability, and CI tooling makes this a weak fit despite transferable infrastructure patterns.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leon_scala\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Scala\",\"Java\"],\"tech\":[\"Apache Spark\",\"Apache Kafka\",\"Akka\",\"Docker\",\"AWS\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"Cassandra\",\"PostgreSQL\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"ScalaTest\"]}\n\nJob Summary:\nStreaming data platform at a large media company is hiring a Senior Backend Engineer. You will build distributed Scala services with Akka, process events with Kafka, and manage Cassandra clusters. AWS deployment. Experience with Spark for batch jobs is a strong plus. ScalaTest for unit tests. GitOps with ArgoCD is being adopted.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Scala and Akka are the exact required stack\",\"Kafka satisfies the event processing requirement\",\"Cassandra covers the database management requirement\",\"ScalaTest matches the unit testing requirement\",\"Apache Spark covers the strong-plus bonus\",\"AWS deployment is present\"],\"gaps\":[\"Uses Jenkins while the team is adopting ArgoCD GitOps, which is a meaningful shift in deployment philosophy\",\"No Kubernetes or container orchestration signals for GitOps context\"],\"explanation\":\"The candidate's Scala and Akka stack is a strong technical match, but the GitOps adoption via ArgoCD represents a meaningful tooling shift that Jenkins does not bridge. ArgoCD is Kubernetes-native and the candidate shows no Kubernetes signals, meaning the new deployment workflow would require ramp-up at the same time as taking on senior engineering responsibilities.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ines_react\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Node.js\",\"NestJS\",\"Tailwind CSS\",\"Docker\",\"AWS\"],\"architecture\":[\"Microservices\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nProptech startup building a property management SaaS is hiring a Senior Full Stack Engineer. You will own features in a Next.js and NestJS codebase, manage PostgreSQL, deploy on AWS with Docker, and maintain GitHub Actions pipelines. TypeScript throughout. Jest and Playwright for testing. Stripe payment integration is a core responsibility.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and NestJS are the exact frontend and backend frameworks\",\"TypeScript is required and present throughout\",\"PostgreSQL, AWS, and Docker cover the infrastructure layer\",\"GitHub Actions satisfies the CI/CD requirement\",\"Jest and Playwright cover the testing stack\"],\"gaps\":[\"No Stripe or payment gateway integration experience visible, which is a core responsibility\",\"Payment integration in proptech involves compliance and reconciliation complexity not evidenced in the profile\"],\"explanation\":\"The candidate's stack is technically aligned with the role at every layer, but Stripe payment integration is described as a core responsibility and is entirely absent from the profile. Property management SaaS payments involve recurring billing, reconciliation, and compliance that are non-trivial to implement correctly, representing a meaningful domain gap alongside the technical gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sean_backend\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"TypeScript\"],\"tech\":[\"FastAPI\",\"Celery\",\"Docker\",\"AWS\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nHR tech company hiring a Senior Backend Engineer. You will build Python FastAPI services, manage async tasks with Celery and Redis, and deploy microservices on AWS with Docker. PostgreSQL is the primary database. GitHub Actions for CI. The team is introducing GraphQL and expects the new hire to lead its adoption alongside existing REST APIs.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI directly satisfies the backend framework requirement\",\"Celery and Redis cover the async task management requirements exactly\",\"AWS and Docker match the deployment stack\",\"PostgreSQL is the primary database and is present\",\"pytest and Locust reflect strong testing and performance awareness\"],\"gaps\":[\"No GraphQL experience, which is a stated adoption the new hire is expected to lead\",\"No vector database or emerging AI tooling for a modern HR tech context\"],\"explanation\":\"The candidate's core Python microservices stack is a solid match, but the role expects the new hire to lead GraphQL adoption, which requires demonstrated GraphQL design and schema experience that is absent. Being hired to lead a technology adoption without prior experience in that technology is a meaningful expectation gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"max_principal\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\"],\"languages\":[\"Java\",\"Go\",\"Python\"],\"tech\":[\"Spring Boot\",\"Kubernetes\",\"Kafka\",\"AWS\",\"Terraform\",\"Istio\",\"Docker\"],\"architecture\":[\"Domain-Driven Design\",\"CQRS\",\"Event Sourcing\",\"Microservices\",\"Event-Driven\",\"Clean Architecture\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"ArgoCD\",\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise fintech is hiring a Principal Architect to own system design across six product teams. You will drive DDD and event sourcing adoption, lead Kubernetes infrastructure strategy on AWS, and define engineering standards. Kafka and Istio experience required. Deep polyglot engineering background expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Principal seniority matches the strategic ownership level\",\"DDD, CQRS, and event sourcing are explicitly required and all present\",\"Kafka and Istio are named requirements and both present\",\"Kubernetes on AWS with Terraform and ArgoCD reflects mature infrastructure ownership\",\"Polyglot background in Java, Go, and Python matches the stated expectation\",\"Clean architecture signals provide breadth across design philosophy\"],\"gaps\":[],\"explanation\":\"This candidate is exceptionally well-qualified for the principal architect role, covering every named requirement including the more specialized Istio service mesh and event sourcing combination. The polyglot language background and breadth of architectural patterns make this a strong leadership candidate with no material gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"chloe_nestjs\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"Express.js\",\"Docker\",\"AWS\",\"BullMQ\",\"GraphQL\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nB2B SaaS company hiring a Mid-level Backend Engineer. Backend is TypeScript and NestJS. PostgreSQL for storage and Redis for job queues with BullMQ. Docker and GitHub Actions for deployment and CI. API testing with Jest and Supertest. GraphQL layer for internal tooling.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS is the exact required framework\",\"BullMQ with Redis directly satisfies the job queue requirement\",\"GraphQL experience covers the internal tooling API layer\",\"PostgreSQL covers the storage requirement\",\"Jest and Supertest match the API testing expectations\",\"TypeScript is required and present throughout\",\"Docker, AWS, and GitHub Actions cover deployment and CI\"],\"gaps\":[],\"explanation\":\"The candidate's profile satisfies every stated requirement including GraphQL for the internal tooling layer. The BullMQ and Redis combination is a particularly strong signal for the job queue requirement. There are no meaningful gaps for this NestJS SaaS backend role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"viv_data\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"NumPy\",\"Weights & Biases\",\"Polars\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nBiotech company hiring a Senior Data Scientist for genomics model development. You will use PyTorch for deep learning, manage experiments with Weights and Biases, analyze genomics data in Python and R, and collaborate with wet lab scientists. Biopython or similar bioinformatics libraries required. Experience with cloud HPC or GPU cluster scheduling is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"PyTorch is the required deep learning framework and is present\",\"Weights and Biases satisfies the experiment tracking requirement\",\"Python and R are both required for genomics data work\"],\"gaps\":[\"No bioinformatics library experience such as Biopython, which is required\",\"No cloud HPC or GPU cluster scheduling experience\",\"No genomics or life sciences domain experience\",\"No bioinformatics data formats or pipeline experience visible\",\"Domain gap in genomics is significant for wet lab scientist collaboration\"],\"explanation\":\"The candidate has the right deep learning tools but lacks the bioinformatics domain knowledge that is a hard requirement for this role. Biopython and genomics-specific data formats are not interchangeable with general data science tooling. The additional HPC scheduling gap means the candidate is missing both domain expertise and infrastructure experience required for production genomics model development.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"omar_elixir\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Elixir\",\"Python\"],\"tech\":[\"Phoenix\",\"Docker\",\"AWS\",\"RabbitMQ\",\"Oban\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nCollaboration tools startup building a Phoenix-based backend is hiring a Senior Elixir Engineer. You will implement real-time Phoenix Channel features, manage job queues with Oban, design distributed data flows, and work with PostgreSQL. AWS deployment. GitHub Actions for CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Elixir and Phoenix are the required stack and the candidate's primary technologies\",\"Oban is the exact job queue library named in the job description\",\"PostgreSQL satisfies the database requirement\",\"Distributed system and event-driven architecture match the role's design context\",\"AWS and GitHub Actions cover deployment and CI requirements\",\"ExUnit shows appropriate testing discipline\"],\"gaps\":[\"No explicit Phoenix Channels experience signaled separately from Phoenix\"],\"explanation\":\"The candidate is an excellent fit for this Elixir backend role, with the specific Oban job queue experience being a particularly strong signal since it is listed by name. Elixir engineers with Oban and Phoenix experience are specialized, and the distributed systems background adds relevant depth.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"viv_data\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"NumPy\",\"Weights & Biases\",\"Polars\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nBiotech company is hiring a Senior Data Scientist to build predictive models for drug discovery. You will use PyTorch for deep learning, manage experiments with MLflow or Weights and Biases, work with genomics datasets in Python and R, and collaborate with domain scientists. Experience with bioinformatics libraries is a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch is the required deep learning framework and is present\",\"Weights and Biases satisfies the experiment tracking requirement\",\"Python and R are both required for genomics data work and are present\",\"scikit-learn and Pandas show broad ML and data manipulation coverage\"],\"gaps\":[\"No bioinformatics library experience such as Biopython or RDKit, which is a strong plus\",\"No domain experience in genomics or life sciences visible\",\"Snowflake and PostgreSQL are general data stores; no genomics-specific data format experience\"],\"explanation\":\"The candidate has strong ML and deep learning foundations with the required PyTorch and Weights and Biases tools in place. However, the biotech domain requires bioinformatics library experience that is absent, and genomics data has specialized formats and pipelines that differ from general data science. This is a moderate fit pending domain onboarding.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"chloe_nestjs\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"Express.js\",\"Docker\",\"AWS\",\"BullMQ\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nB2B SaaS company hiring a Mid-level Backend Engineer. Backend is TypeScript and NestJS. PostgreSQL is our database and Redis for job queues with BullMQ. Docker and GitHub Actions for deployment and CI. We write thorough API tests with Jest and Supertest. AWS for cloud infrastructure.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS is the exact required framework and is the candidate's primary backend tool\",\"TypeScript is required and present\",\"BullMQ with Redis directly satisfies the job queue requirement\",\"PostgreSQL covers the database requirement\",\"Jest and Supertest match the API testing expectations\",\"Docker, AWS, and GitHub Actions cover deployment and CI\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a precise match for this NestJS SaaS backend role, with the specific BullMQ and Redis job queue combination being a particularly strong signal. Every stated requirement is satisfied including the CI, testing, and infrastructure stack. There are no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"zach_wordpress\",\"seniority\":\"Senior\",\"roles\":[\"Software Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"WordPress\",\"Symfony\",\"Laravel\",\"MySQL\",\"Docker\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nDigital publisher seeking a Senior Full Stack Engineer to build and extend a Python and Django-based content management platform. PostgreSQL required. React on the frontend. Docker for local dev. TypeScript preferred. You should be comfortable owning complex backend features and integrating third-party APIs.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Web backend development experience with PHP frameworks shows relevant architectural patterns\",\"Docker experience is transferable\"],\"gaps\":[\"No Python or Django experience; uses PHP exclusively for backend work\",\"No React experience on the frontend\",\"No TypeScript experience\",\"PostgreSQL not present; uses MySQL\",\"No CI/CD tooling visible\",\"No third-party API integration signals beyond CMS context\"],\"explanation\":\"The candidate's backend experience is entirely PHP-based while the role requires Python and Django. These are different language ecosystems with distinct conventions, and the mismatch extends across the frontend to React and the database to PostgreSQL. Despite senior seniority, the technology gap is too broad for a role requiring immediate backend ownership.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"max_principal\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\"],\"languages\":[\"Java\",\"Go\",\"Python\"],\"tech\":[\"Spring Boot\",\"Kubernetes\",\"Kafka\",\"AWS\",\"Terraform\",\"Istio\",\"Docker\"],\"architecture\":[\"Domain-Driven Design\",\"CQRS\",\"Event Sourcing\",\"Microservices\",\"Event-Driven\",\"Clean Architecture\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"ArgoCD\",\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise fintech is hiring a Principal Architect to own system design across six product teams. You will drive DDD and event sourcing adoption, lead Kubernetes infrastructure strategy on AWS, define API standards, and oversee vendor management. Kafka and Istio experience required. Experience presenting to C-suite stakeholders is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Principal seniority is appropriate for the strategic ownership level\",\"DDD, CQRS, and event sourcing are all explicitly required and present\",\"Kafka and Istio are named requirements and both present\",\"Kubernetes on AWS with Terraform and ArgoCD reflects infrastructure ownership\",\"Polyglot Java, Go, and Python background suits the breadth expected at principal level\"],\"gaps\":[\"No vendor management experience visible\",\"No C-suite presentation or executive stakeholder signals from a GitHub profile\",\"Leadership and business-facing skills cannot be assessed from technical signals alone\"],\"explanation\":\"The candidate's technical credentials are exceptional for this principal architect role, but the position also requires vendor management and C-suite presentations, which are leadership responsibilities that GitHub signals cannot demonstrate. For a principal-level hire at a fintech, assessing these dimensions in the interview process is essential before drawing a confident conclusion.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tia_react\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nSaaS startup is hiring a Senior Frontend Engineer to lead the design system, architect the React component library, mentor junior engineers, and drive TypeScript adoption. Storybook required. Testing with Vitest and Playwright. Performance optimization and accessibility expertise expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React, Next.js, and Tailwind CSS are relevant to the frontend stack\",\"TypeScript is present, which is a focus of the role\"],\"gaps\":[\"Junior seniority is far below the senior leadership requirement\",\"No Storybook experience, which is a hard requirement for the design system\",\"No Vitest or Playwright experience; uses Jest only\",\"No mentorship or team leadership signals\",\"No accessibility or performance optimization signals\",\"Cannot demonstrate design system or component library architecture experience\"],\"explanation\":\"The candidate is a junior developer with a basic React profile that lacks the design system tooling, testing breadth, and leadership experience this senior role demands. Storybook is a hard requirement for a design system lead, and the absence of Playwright, Vitest, and mentorship signals makes this a weak fit regardless of the seniority gap alone.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pat_lead\",\"seniority\":\"Lead\",\"roles\":[\"Full Stack Engineer\",\"Software Architect\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"FastAPI\",\"Docker\",\"AWS\",\"Kubernetes\",\"Redis\",\"Storybook\"],\"architecture\":[\"Microservices\",\"Clean Architecture\",\"Domain-Driven Design\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"pytest\",\"Jest\",\"Playwright\"]}\n\nJob Summary:\nScaleup hiring a Lead Full Stack Engineer to own the architecture of a Next.js and FastAPI product, lead a team of six engineers, define coding standards, drive DDD adoption, and oversee GitOps deployments with ArgoCD on Kubernetes. TypeScript and Python required. The company is also in the process of SOC 2 certification and expects the new hire to contribute to that effort.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and FastAPI are the exact required frameworks\",\"DDD and clean architecture are explicitly required and present\",\"ArgoCD GitOps on Kubernetes and AWS covers deployment requirements\",\"Lead seniority matches the team leadership expectation\",\"TypeScript and Python are both required and present\",\"pytest, Jest, and Playwright show strong testing culture alignment\"],\"gaps\":[\"No SOC 2 compliance or security audit experience visible\",\"SOC 2 certification involves access controls, logging, and audit trail requirements not evidenced in the profile\"],\"explanation\":\"The candidate is a strong technical match for the architecture and engineering leadership aspects, but the SOC 2 certification effort introduces a compliance engineering dimension that is absent from the profile. Contributing meaningfully to a SOC 2 audit requires understanding of specific control frameworks and security posture, which is not evidenced by GitHub signals alone.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rob_data\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Airflow\",\"dbt\",\"Pandas\",\"Dagster\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nMedia company building a data platform on Snowflake is hiring a Mid-level Data Engineer. You will design ELT pipelines with dbt, orchestrate with Airflow, and work in Snowflake. Python and SQL required. Data quality testing within dbt pipelines is expected. Experience with Dagster is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt and Airflow are the core ELT and orchestration requirements and are present\",\"Python and SQL meet the language requirements\",\"Dagster is a listed plus and is present\",\"GitHub Actions shows CI discipline\"],\"gaps\":[\"Uses BigQuery as the primary warehouse while the role centers on Snowflake\",\"No explicit dbt testing or data quality signals\",\"Snowflake and BigQuery have different SQL dialects and optimization strategies\"],\"explanation\":\"The candidate covers the dbt and Airflow requirements and also satisfies the Dagster bonus, but the warehouse mismatch from BigQuery to Snowflake is a notable gap. Snowflake has distinct features, clustering, and cost optimization patterns that differ from BigQuery. The absent data quality testing signals are also a concern given the explicit expectation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mia_k8s\",\"seniority\":\"Mid\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"AWS\",\"Docker\",\"Prometheus\",\"ArgoCD\",\"Vault\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"]}\n\nJob Summary:\nGrowth-stage company hiring a Mid-level Platform Engineer to maintain Kubernetes clusters on AWS, manage Helm releases, write Terraform, and build observability with Prometheus. ArgoCD for GitOps. Vault for secrets management is a priority. Go or Python scripting preferred.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Helm, and Terraform on AWS cover the cluster and IaC requirements\",\"Prometheus satisfies the observability requirement\",\"ArgoCD covers the GitOps requirement\",\"Vault satisfies the secrets management priority\",\"Go and Python scripting meet the preferred language requirements\",\"GitHub Actions rounds out the CI requirements\"],\"gaps\":[],\"explanation\":\"The candidate's platform engineering stack is a precise match for this role, including ArgoCD and Vault which were previously noted as gaps. Every stated requirement is satisfied from cluster management and IaC to GitOps, secrets management, and observability. There are no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mia_k8s\",\"seniority\":\"Mid\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"AWS\",\"Docker\",\"Prometheus\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nGrowth-stage company hiring a Mid-level Platform Engineer to maintain Kubernetes clusters on AWS, manage Helm releases, write Terraform, and build observability. ArgoCD for GitOps is being introduced. Vault for secrets management is a priority. Prometheus already in use. Go or Python scripting preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes, Helm, and Terraform on AWS cover the cluster and IaC requirements\",\"Prometheus is already in use and present in the profile\",\"Go and Python scripting meet the preferred language requirements\",\"GitHub Actions covers CI requirements\"],\"gaps\":[\"No ArgoCD experience, which is being actively introduced\",\"No Vault experience, which is a stated priority\",\"The role is actively adding two new tools the candidate lacks\"],\"explanation\":\"The candidate covers the current state of the platform engineering stack well, but the role is actively introducing ArgoCD and Vault, both of which are absent from the profile. These are meaningful onboarding items rather than long-term nice-to-haves. The candidate would need to ramp on both tools relatively quickly in the role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nina_devops\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"AWS\",\"Terraform\",\"Docker\",\"Kubernetes\",\"Ansible\",\"Prometheus\",\"Grafana\"],\"ci_cd\":[\"GitHub Actions\",\"Jenkins\"]}\n\nJob Summary:\nEnterprise company hiring a Senior DevOps Engineer to manage AWS infrastructure with Terraform, operate Kubernetes clusters, implement observability with Prometheus and Grafana, automate provisioning with Ansible, and manage CI/CD on GitHub Actions. The role also requires defining and owning disaster recovery procedures across all environments.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"AWS and Terraform satisfy the infrastructure management requirements\",\"Kubernetes covers the cluster operations requirement\",\"Prometheus and Grafana satisfy the observability requirements\",\"Ansible satisfies provisioning automation\",\"Python and Bash scripting meet the language expectations\",\"GitHub Actions covers the CI/CD requirement\"],\"gaps\":[\"No disaster recovery architecture or runbook experience visible\",\"No backup, RTO/RPO, or multi-region failover signals in the profile\"],\"explanation\":\"The candidate covers the operational engineering requirements well, but disaster recovery ownership is a stated responsibility that is not evidenced in the profile. DR in AWS involves multi-region architectures, backup strategies, and recovery testing that are distinct from day-to-day infrastructure management. This is a meaningful responsibility gap despite the otherwise strong technical match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rob_data\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Airflow\",\"dbt\",\"Pandas\",\"Dagster\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nMedia company building a Snowflake-based data platform is hiring a Mid-level Data Engineer. You will design ELT pipelines with dbt, orchestrate with Airflow, ingest real-time data from Kafka, and manage data in Snowflake. Python and SQL required. Data quality testing in dbt is expected. Dagster is a plus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"dbt and Airflow are core requirements and are present\",\"Python and SQL cover the language requirements\",\"Dagster is a listed plus and is present\",\"GitHub Actions reflects CI discipline\"],\"gaps\":[\"No Snowflake experience; uses BigQuery as the primary warehouse\",\"No Kafka or real-time data ingestion experience, which is a stated requirement\",\"No dbt testing or data quality signals\",\"Snowflake and Kafka are both hard requirements that are absent from the profile\"],\"explanation\":\"While the candidate has dbt and Airflow experience, two hard requirements are missing: Snowflake as the warehouse and Kafka for real-time ingestion. BigQuery and Snowflake have different SQL dialects and optimization patterns, and Kafka streaming ingestion is an entirely separate skill. The combination of two missing core requirements makes this a weak fit despite the orchestration experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sam_junior_be\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Flask\",\"Node.js\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"SQLite\"]}\n\nJob Summary:\nSaaS company hiring a Mid-level Backend Engineer to build and own REST APIs in Python and Django, manage PostgreSQL schemas, write Celery tasks for async jobs, and deploy containerized services on AWS. TypeScript experience on the frontend is a plus. We write tests and expect pytest coverage.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and PostgreSQL are present and relevant to the core stack\",\"Docker experience is transferable to the containerized deployment model\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement for API ownership\",\"Uses Flask rather than Django, which is the required framework\",\"No Celery or async task queue experience\",\"No AWS deployment experience\",\"No pytest or automated testing visible\",\"Cannot demonstrate schema management or production backend ownership at mid-level\"],\"explanation\":\"The candidate has Python and PostgreSQL foundations but is a junior developer using Flask while the role requires a mid-level engineer with Django ownership, Celery, AWS, and test coverage. The seniority and framework gaps together make this a weak fit for a role requiring independent production backend ownership.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"gao_senior\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\"],\"tech\":[\"Django\",\"FastAPI\",\"Docker\",\"Kubernetes\",\"AWS\",\"Celery\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nEdtech platform hiring a Senior Backend Engineer to build Python microservices with FastAPI, manage async tasks with Celery and Redis, deploy on Kubernetes with GitOps via ArgoCD, and work with PostgreSQL. AWS cloud. GitHub Actions for CI. The company is building a real-time collaboration feature and requires WebSocket experience.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI, Celery, Redis, and Kubernetes with ArgoCD all cover stated requirements directly\",\"PostgreSQL, AWS, and GitHub Actions cover the data and infrastructure layer\",\"Locust shows performance testing experience relevant to a collaboration feature\",\"Event-driven architecture signals are relevant to real-time system design\"],\"gaps\":[\"No WebSocket or real-time collaboration implementation experience visible\",\"No Socket.io or similar real-time protocol tooling\"],\"explanation\":\"The candidate's async microservices stack is a strong match for the core backend requirements, but the real-time collaboration feature requires WebSocket implementation experience that is absent from the profile. Building WebSocket-based collaborative features involves connection management, state synchronization, and conflict resolution that are distinct from REST-based microservice work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rita_be\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"TypeScript\"],\"tech\":[\"FastAPI\",\"Node.js\",\"Docker\",\"AWS\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Jest\"]}\n\nJob Summary:\nInsurance tech company hiring a Mid-level Backend Engineer. Backend is Python FastAPI with PostgreSQL. Celery and Redis for async tasks. Docker and Kubernetes for deployment. AWS cloud. GitHub Actions for CI. Stripe or payment gateway integration experience is a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI and PostgreSQL are the exact required backend stack\",\"Redis is present for the async task infrastructure\",\"Docker and AWS cover the deployment requirements\",\"GitHub Actions satisfies the CI requirement\",\"pytest aligns with the testing expectations\"],\"gaps\":[\"No Celery experience, which is required for async task management alongside Redis\",\"No Kubernetes experience for the deployment layer\",\"No Stripe or payment gateway integration signals for the strong-plus requirement\"],\"explanation\":\"The candidate's FastAPI and PostgreSQL stack aligns with the core backend requirements, but the missing Celery experience is a real gap for an async task-driven application since Celery has specific worker and retry patterns. Kubernetes and payment integration experience are also absent. This is a moderate fit that would require onboarding on multiple fronts.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nat_fullstack\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"Django\",\"FastAPI\",\"Docker\",\"AWS\",\"Redis\"],\"architecture\":[\"Microservices\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Jest\",\"Playwright\"]}\n\nJob Summary:\nClimate tech company hiring a Senior Full Stack Engineer to build a Next.js dashboard and Python FastAPI backend. PostgreSQL for data. AWS and Docker for deployment. GitHub Actions for CI. TypeScript across the frontend. You will also integrate hardware sensor APIs and manage time-series data pipelines for energy monitoring.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and FastAPI are the exact frontend and backend frameworks required\",\"PostgreSQL, AWS, Docker, and GitHub Actions cover infrastructure requirements\",\"TypeScript is required on the frontend and is present\",\"pytest, Jest, and Playwright reflect strong testing coverage\"],\"gaps\":[\"No hardware sensor API integration or IoT protocol experience\",\"No time-series database experience such as TimescaleDB or InfluxDB for energy monitoring pipelines\",\"Energy monitoring data pipelines are a specialized domain not evidenced in the profile\"],\"explanation\":\"The candidate's web stack matches the standard requirements, but the hardware sensor integration and time-series pipeline requirements introduce specialized IoT and energy domain needs. Time-series data for energy monitoring typically requires dedicated databases like TimescaleDB or InfluxDB and sensor protocol knowledge, neither of which are present. These are meaningful domain gaps for a climate tech hardware-adjacent role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sven_embedded\",\"seniority\":\"Senior\",\"roles\":[\"Embedded Engineer\"],\"languages\":[\"C\",\"C++\",\"Python\"],\"tech\":[\"FreeRTOS\",\"CMake\",\"Docker\"],\"architecture\":[\"Distributed System\"]}\n\nJob Summary:\nMedical device company hiring a Senior Firmware Engineer for embedded Linux systems. You will write C and C++ for ARM processors, work with FreeRTOS, manage build systems with CMake, and ensure IEC 62304 compliance for medical software. Python scripting for test automation. Experience with CAN bus or serial protocols is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"C and C++ are the required primary languages and are present\",\"FreeRTOS directly satisfies the RTOS requirement\",\"CMake satisfies the build system requirement\",\"Python scripting for test automation is present\"],\"gaps\":[\"No IEC 62304 medical software compliance experience visible\",\"No CAN bus or serial protocol experience, which is required\",\"No ARM-specific or hardware-level development signals beyond RTOS\",\"Medical device regulatory context requires compliance experience not evidenced in the profile\"],\"explanation\":\"The candidate has solid embedded fundamentals with C, C++, FreeRTOS, and CMake, but the medical device context introduces two hard requirements that are missing: CAN bus or serial protocol experience and IEC 62304 compliance. Medical software standards are domain-specific and cannot be assumed from a general embedded background. This is a moderate fit pending evidence of protocol and compliance experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ux_dev_kay\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Framer Motion\",\"Radix UI\",\"Storybook\",\"Vite\"],\"testing\":[\"Vitest\",\"Playwright\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nProduct design studio hiring a Mid-level Frontend Engineer to build polished, animated React interfaces. You will implement complex animations with Framer Motion, build accessible components with Radix UI, document in Storybook, and style with Tailwind CSS. TypeScript required. Vitest and Playwright for testing. The role also involves Three.js for 3D product visualization.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Framer Motion directly satisfies the animation requirement\",\"Radix UI covers the accessible component requirement\",\"Storybook is required for documentation and is present\",\"Tailwind CSS, TypeScript, Vitest, and Playwright all match stated requirements\",\"React and Vite round out the framework and build tooling\"],\"gaps\":[\"No Three.js or 3D visualization experience, which is a stated role responsibility\",\"3D rendering in the browser is a specialized discipline distinct from 2D animation\"],\"explanation\":\"The candidate satisfies all of the 2D animation and component library requirements well, but Three.js for 3D product visualization introduces a specialized gap. Three.js involves 3D scene management, camera controls, and shader concepts that are not related to Framer Motion animation work. This is a meaningful technical gap for a role where 3D visualization is a stated responsibility.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kwesi_svelte\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Svelte\",\"SvelteKit\",\"Tailwind CSS\",\"Vite\",\"Storybook\"],\"testing\":[\"Vitest\",\"Playwright\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nDeveloper tools company hiring a Mid-level Frontend Engineer to maintain and grow a SvelteKit-based product portal. TypeScript required. We use Tailwind CSS for styling, Storybook for component documentation, and Vitest with Playwright for testing. GitHub Actions for CI. Performance and accessibility are core priorities.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Svelte and SvelteKit are the exact required frameworks\",\"TypeScript is required and present as the primary language\",\"Tailwind CSS matches the stated styling approach\",\"Storybook is explicitly required for component documentation and is present\",\"Vitest and Playwright satisfy both unit and E2E testing requirements\",\"GitHub Actions covers the CI requirement\"],\"gaps\":[\"No explicit accessibility tooling or audit signals visible\"],\"explanation\":\"The candidate's profile is a precise match for this SvelteKit developer tools role, covering every named technology from the framework and styling to the full testing stack. SvelteKit engineers with TypeScript, Storybook, and the Vitest and Playwright combination are specialized and this candidate hits all of them. The minor accessibility tooling gap is unlikely to be a blocker.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rico_node\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"Express.js\",\"Docker\",\"AWS\",\"BullMQ\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nFintech startup hiring a Mid-level Backend Engineer. Stack is NestJS and TypeScript on the backend, PostgreSQL for primary storage, and Redis for job queues via BullMQ. Docker and AWS for deployment. GitHub Actions for CI. Jest and Supertest for API testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS is the exact required backend framework and is the candidate's primary tool\",\"TypeScript is required and present throughout\",\"BullMQ with Redis directly satisfies the job queue requirement\",\"PostgreSQL covers the storage requirement\",\"Jest and Supertest satisfy the API testing requirements exactly\",\"Docker, AWS, and GitHub Actions cover deployment and CI\"],\"gaps\":[],\"explanation\":\"The candidate's profile satisfies every stated requirement for this fintech backend role with the specific BullMQ and Redis job queue combination being a particularly strong signal. Every named technology is present with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"asha_vue\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\",\"Vite\",\"Storybook\"],\"testing\":[\"Vitest\",\"Cypress\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nEuropean B2B SaaS company hiring a Senior Frontend Engineer to own their Vue.js and Nuxt.js product. State management with Pinia or Vuex. Tailwind CSS for styling. Vitest and Playwright for testing. TypeScript required. GitHub Actions for CI. The team is building a new React-based admin dashboard alongside the Vue app.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Vue.js and Nuxt.js are the primary required frameworks and are present\",\"Pinia satisfies the state management requirement\",\"Tailwind CSS matches the stated styling approach\",\"TypeScript is required and present\",\"GitHub Actions satisfies the CI requirement\"],\"gaps\":[\"Uses Cypress for E2E while the role requires Playwright\",\"No React experience for the new admin dashboard responsibility\",\"Contributing to a parallel React codebase is a requirement this candidate cannot initially cover\"],\"explanation\":\"The candidate is a strong match for the Vue.js work but the role also requires contributing to a new React admin dashboard, which has no representation in the profile. The Playwright vs Cypress difference is also a minor gap. The dual-codebase expectation is a meaningful split responsibility that limits this to a moderate fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex_junior_fe\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"React\",\"Bootstrap\"]}\n\nJob Summary:\nProduct company hiring a Senior React Engineer to lead component architecture, mentor junior engineers, establish testing standards with Vitest and Playwright, and drive TypeScript adoption. Tailwind CSS and Storybook required. Prior experience owning a design system is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React experience is directly relevant to the framework requirement\"],\"gaps\":[\"Junior seniority is far below the senior leadership requirement\",\"No TypeScript experience visible\",\"No Vitest or Playwright testing experience\",\"No Storybook or design system experience\",\"No Tailwind CSS experience; uses Bootstrap\",\"No mentorship or team leadership signals\",\"Profile is too sparse to support a senior architect assessment\"],\"explanation\":\"The candidate is a junior developer with a minimal React and Bootstrap profile that lacks TypeScript, testing, design system tooling, and any leadership signals. The role requires a senior engineer to own architecture and mentor others, representing a gap across both seniority and every named technical requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dan_angular\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Angular\",\"NgRx\",\"RxJS\",\"Angular Material\",\"Webpack\"],\"testing\":[\"Karma\",\"Jasmine\",\"Cypress\"],\"ci_cd\":[\"Azure DevOps\"]}\n\nJob Summary:\nEnterprise consulting firm building Angular-based client applications is hiring a Senior Frontend Engineer. TypeScript required. State management with NgRx and reactive programming with RxJS are essential. We use Karma and Jasmine for unit tests and Cypress for E2E. Azure DevOps for CI/CD pipelines.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Angular is the exact required framework\",\"NgRx satisfies the state management requirement directly\",\"RxJS is explicitly required for reactive programming and is present\",\"Karma and Jasmine match the unit testing stack exactly\",\"Cypress covers the E2E testing requirement\",\"TypeScript is required and present\",\"Azure DevOps satisfies the CI/CD requirement\"],\"gaps\":[],\"explanation\":\"The candidate satisfies every named requirement for this enterprise Angular consulting role, including the less common combination of NgRx, RxJS, and Azure DevOps that distinguishes genuine Angular expertise. Angular engineers with the complete NgRx and reactive programming stack are in demand and this candidate demonstrates all of it.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mira_react_mid\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"NestJS\",\"Node.js\",\"Tailwind CSS\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nHealthtech startup seeking a Mid-level Full Stack Engineer. Stack is Next.js on the frontend and NestJS on the backend, both TypeScript. PostgreSQL for storage, Docker for containerization, GitHub Actions for CI. We test with Jest and Playwright. Engineers own features end-to-end.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js is the required frontend framework and is present\",\"NestJS is the required backend framework and is present\",\"TypeScript is required throughout and is the candidate's primary language\",\"PostgreSQL satisfies the storage requirement\",\"Docker and GitHub Actions cover containerization and CI\",\"Jest and Playwright satisfy the testing requirements\"],\"gaps\":[\"No healthcare API or domain signals\"],\"explanation\":\"The candidate's profile now includes NestJS directly, making this a precise match for the full-stack role across every named technology. The only minor gap is healthcare domain experience, which is not listed as a hard requirement. This is a strong fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"gabriel_go\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Gin\",\"Docker\",\"Kubernetes\",\"AWS\",\"gRPC\",\"Prometheus\",\"Redis\"],\"architecture\":[\"Microservices\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"Go testing\",\"k6\"]}\n\nJob Summary:\nInfrastructure startup hiring a Senior Go Backend Engineer to build high-performance microservices and expose gRPC APIs. You will instrument with Prometheus, deploy on Kubernetes via GitOps with ArgoCD, and work with AWS and PostgreSQL. Istio service mesh integration is a hard requirement for inter-service communication security.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go is the required language and the candidate's primary language\",\"gRPC is explicitly required and present\",\"Prometheus satisfies the instrumentation requirement\",\"Kubernetes with ArgoCD covers the GitOps deployment requirement\",\"AWS and PostgreSQL match the cloud and storage requirements\"],\"gaps\":[\"No Istio service mesh experience, which is a hard requirement\",\"Service mesh security involves mTLS, traffic policies, and sidecar configuration not evidenced in the profile\"],\"explanation\":\"The candidate's Go and Kubernetes stack aligns well with the core infrastructure requirements, but Istio is stated as a hard requirement and is entirely absent. Istio service mesh management involves mTLS configuration, traffic management policies, and observability integration that are distinct from general Kubernetes operation and represent a real onboarding gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"joel_java_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Docker\",\"AWS\",\"Hibernate\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nE-commerce company hiring a Mid-level Java Backend Engineer with Kafka experience. Apache Kafka for event streaming is a hard requirement. Stack is Java and Spring Boot with PostgreSQL via Hibernate. GitHub Actions for CI. JUnit and Mockito for testing. You will also implement DDD patterns across the bounded context boundaries.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Java and Spring Boot are the required backend technologies\",\"Hibernate satisfies the ORM requirement\",\"JUnit and Mockito directly cover the testing requirements\"],\"gaps\":[\"No Apache Kafka experience, which is listed as a hard requirement\",\"Uses MySQL while the role requires PostgreSQL\",\"Uses Jenkins for CI while the role uses GitHub Actions\",\"No DDD or bounded context design experience visible\",\"Three gaps across a core hard requirement, database, and CI all compound\"],\"explanation\":\"While the candidate has a solid Spring Boot and Hibernate background, Kafka is stated as a hard requirement and is entirely absent. Combined with the PostgreSQL and GitHub Actions mismatches and the absence of DDD signals, this candidate faces too many concurrent gaps to be considered even a moderate fit for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"luz_python\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"TypeScript\"],\"tech\":[\"FastAPI\",\"Celery\",\"Docker\",\"AWS\",\"Redis\",\"Nginx\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nLogistics SaaS company hiring a Senior Backend Engineer to build Python FastAPI microservices, manage async workflows with Celery and Redis, and work with PostgreSQL on AWS. GitHub Actions for CI. Load testing experience valued. The role also requires integrating with third-party carrier APIs and managing webhook delivery at scale.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI is the exact required backend framework\",\"Celery and Redis directly cover the async workflow requirements\",\"PostgreSQL and AWS cover the data and cloud layers\",\"GitHub Actions satisfies the CI requirement\",\"Locust satisfies the valued load testing requirement\"],\"gaps\":[\"No third-party API integration or webhook delivery experience visible\",\"High-volume webhook delivery at scale involves retry logic, idempotency, and queue management not evidenced beyond general Celery use\"],\"explanation\":\"The candidate's core Python microservices stack is a strong match, but the role explicitly requires third-party carrier API integration and webhook delivery at scale. These involve domain-specific patterns around idempotency, retry backoff, and delivery guarantees that are not directly evidenced in the profile despite relevant Celery experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nate_elixir\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Elixir\",\"Python\"],\"tech\":[\"Phoenix\",\"Oban\",\"Docker\",\"AWS\",\"RabbitMQ\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nReal-time collaboration startup hiring a Senior Elixir Engineer. You will build Phoenix Channel features, manage background jobs with Oban, work with PostgreSQL, and deploy on GCP. Pub/Sub messaging via Google Cloud Pub/Sub. GitHub Actions for CI.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Elixir and Phoenix are the exact required stack\",\"Oban is named explicitly for background jobs and is directly present\",\"PostgreSQL satisfies the database requirement\",\"GitHub Actions covers the CI requirement\",\"Distributed system and event-driven architecture are relevant to the real-time collaboration context\"],\"gaps\":[\"Uses AWS for deployment while the role runs on GCP\",\"Uses RabbitMQ for messaging while the role requires Google Cloud Pub/Sub\",\"No GCP-specific experience visible\"],\"explanation\":\"The candidate's Elixir and Oban experience is an excellent match for the core backend requirements, but the role runs on GCP with Google Cloud Pub/Sub while the candidate is AWS and RabbitMQ focused. These are platform-specific differences that go beyond generic messaging or cloud patterns, representing real onboarding cost for the messaging and deployment layers.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priya_ruby\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Ruby\",\"JavaScript\"],\"tech\":[\"Ruby on Rails\",\"Sidekiq\",\"Docker\",\"Heroku\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"CircleCI\"],\"testing\":[\"RSpec\",\"Capybara\"]}\n\nJob Summary:\nContent platform startup hiring a Mid-level Ruby on Rails Engineer. You will build REST APIs, manage background jobs with Sidekiq, work with PostgreSQL and Redis, and ship via Heroku. RSpec and Capybara for testing. CircleCI for CI. The team values clean Rails code and fast iteration.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Ruby on Rails is the exact required framework\",\"Sidekiq satisfies the background job requirement directly\",\"PostgreSQL and Redis cover the data and caching layers\",\"Heroku matches the deployment platform\",\"RSpec and Capybara cover the testing requirements exactly\",\"CircleCI satisfies the CI requirement\",\"Mid-level seniority is appropriate\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a complete match for this Rails content platform role, satisfying every named technology including Sidekiq, Heroku, RSpec, Capybara, and CircleCI. This level of stack alignment is uncommon and represents a strong fit with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tom_php_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"Laravel\",\"Vue.js\",\"Docker\",\"MySQL\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nAgency building Node.js and React applications for enterprise clients is hiring a Mid-level Backend Engineer. TypeScript required across the stack. PostgreSQL for storage. NestJS for backend API development. Docker and GitHub Actions for containerization and CI. Engineers own features from API to UI.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker experience is transferable\",\"Backend API development experience with Laravel demonstrates relevant patterns\"],\"gaps\":[\"PHP and Laravel are fundamentally different from the required Node.js and NestJS stack\",\"No TypeScript experience visible\",\"No React experience for UI responsibilities\",\"MySQL not transferable to the required PostgreSQL relational model in all respects\",\"No GitHub Actions experience; uses GitLab CI\",\"Full-stack TypeScript ownership requires skills entirely absent from the profile\"],\"explanation\":\"The candidate works in a PHP and Laravel ecosystem while the agency requires TypeScript across a Node.js and NestJS backend and React frontend. These are distinct ecosystems that require near-total reskilling at every layer of the stack. The framework, language, and database mismatches make this a weak fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fatima_rust\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"Go\"],\"tech\":[\"Axum\",\"Tokio\",\"Docker\",\"AWS\",\"gRPC\",\"Redis\"],\"architecture\":[\"Microservices\",\"Distributed System\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Rust unit tests\"]}\n\nJob Summary:\nGame engine company hiring a Senior Rust Engineer for a high-performance 2D rendering pipeline. You will write memory-safe rendering code, integrate with the GPU via WebGL or Vulkan, optimize for real-time frame rates, and work with the graphics team. Game engine or graphics programming experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Rust is the required language and the candidate's primary language\",\"C-adjacent systems programming background via Rust is relevant at the language level\"],\"gaps\":[\"No WebGL or Vulkan graphics API experience\",\"No game engine or rendering pipeline experience\",\"gRPC and microservices focus is backend web infrastructure, not graphics\",\"No real-time frame rate optimization or shader programming signals\",\"No game development domain experience\"],\"explanation\":\"While the candidate is a skilled Rust engineer, their experience is in backend microservices and distributed systems rather than graphics programming. The role requires WebGL or Vulkan integration and rendering pipeline expertise, both of which are entirely absent. Rust proficiency alone is not sufficient to bridge the domain gap between web backend services and real-time rendering systems.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cam_csharp\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C#\",\"TypeScript\"],\"tech\":[\"ASP.NET\",\".NET Core\",\"Entity Framework\",\"Docker\",\"Azure\",\"SignalR\"],\"architecture\":[\"Microservices\"],\"databases\":[\"MS SQL Server\",\"Redis\"],\"ci_cd\":[\"Azure DevOps\"],\"testing\":[\"xUnit\",\"Moq\"]}\n\nJob Summary:\nInsurance company hiring a Mid-level C# Backend Engineer. You will build REST APIs in ASP.NET Core, use Entity Framework for SQL Server, deploy to Azure, and run CI/CD with Azure DevOps. xUnit and Moq for testing. The team is adopting event sourcing with EventStoreDB and expects the new hire to ramp up on it.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"ASP.NET Core and Entity Framework with SQL Server match the backend requirements\",\"Azure and Docker cover the deployment requirements\",\"Azure DevOps satisfies the CI/CD requirement\",\"xUnit and Moq match the testing stack exactly\",\"SignalR is an additional strength not required but demonstrates .NET depth\"],\"gaps\":[\"No EventStoreDB or event sourcing experience, which the team is actively adopting\",\"Event sourcing involves append-only logs and projection patterns that are architecturally distinct from CRUD systems\"],\"explanation\":\"The candidate's .NET stack is a solid match for the standard backend requirements, but the team is adopting EventStoreDB and event sourcing, which requires learning a fundamentally different data persistence model. Being hired to ramp up on an active architectural adoption adds meaningful onboarding complexity beyond day-to-day feature work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hiro_swift\",\"seniority\":\"Senior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Combine\",\"CoreData\",\"CoreLocation\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"XCTest\",\"Quick\",\"Nimble\"]}\n\nJob Summary:\nFintech app company hiring a Senior iOS Engineer. You will build SwiftUI features, implement Plaid and Stripe SDKs for banking and payment integrations, manage local data with CoreData, and write tests. Fastlane for mobile CI. Performance optimization for financial data rendering expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SwiftUI is the required UI framework and is present\",\"CoreData satisfies the local data management requirement\",\"Fastlane satisfies the mobile CI requirement\",\"XCTest, Quick, and Nimble show comprehensive testing experience\",\"Senior seniority matches the role\"],\"gaps\":[\"No Plaid SDK or banking API integration experience visible\",\"No Stripe SDK or payment integration experience\",\"Fintech SDK integration involves OAuth flows, security requirements, and compliance that are domain-specific\"],\"explanation\":\"The candidate has strong SwiftUI foundations with appropriate testing and CI tooling, but the Plaid and Stripe SDK integration requirements are domain-specific fintech skills that are entirely absent from the profile. Banking and payment SDKs involve OAuth, PSD2 compliance, and secure credential handling that go beyond general iOS development experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ada_kotlin\",\"seniority\":\"Mid\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Retrofit\",\"Room\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Mockito\",\"Espresso\"]}\n\nJob Summary:\nFitness app company seeking a Mid-level Android Engineer. You will build Jetpack Compose UI, integrate health data APIs via Retrofit, persist data with Room, write tests, and ship with Fastlane. Firebase for analytics. The app deeply integrates with Android Health Connect and Wear OS for wearable device data.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Jetpack Compose and Kotlin are the required UI framework and language\",\"Retrofit satisfies the REST API integration requirement\",\"Room covers the local persistence requirement\",\"Firebase satisfies analytics requirements\",\"Fastlane and GitHub Actions cover mobile CI\",\"JUnit, Mockito, and Espresso reflect solid Android testing coverage\"],\"gaps\":[\"No Android Health Connect integration experience visible\",\"No Wear OS or wearable device SDK experience\",\"Health Connect and Wear OS are specialized Android platform APIs requiring specific domain knowledge\"],\"explanation\":\"The candidate covers the standard Android engineering requirements well, but Android Health Connect and Wear OS are platform-specific API integrations that require specialized knowledge not evidenced in the profile. For a fitness app where wearable device integration is a core product requirement, these are meaningful technical gaps beyond general Android development.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kai_flutter_jr\",\"seniority\":\"Junior\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\"],\"tech\":[\"Flutter\",\"Firebase\"],\"databases\":[\"Firebase\"]}\n\nJob Summary:\nHealthcare startup hiring a Mid-level Flutter Engineer to build a HIPAA-compliant patient app. You will implement complex stateful UI, integrate FHIR-based REST APIs, write widget and unit tests, manage secure local storage, and ship via Fastlane. Accessibility compliance is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Flutter and Dart are the required framework and language\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement\",\"No widget or unit testing experience visible\",\"No Fastlane or mobile CI experience\",\"No secure local storage implementation signals\",\"No HIPAA-aware data handling or healthcare compliance experience\",\"No FHIR or healthcare API integration signals\",\"Profile is sparse and cannot support mid-level production expectations\"],\"explanation\":\"The candidate has basic Flutter experience but lacks every specialized requirement for a healthcare application: compliance, testing, CI, secure storage, and healthcare API integration. HIPAA compliance and FHIR APIs require domain-specific knowledge that this junior profile cannot support. The seniority gap compounds the technical shortfalls significantly.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leila_rn\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React Native\",\"Expo\",\"Redux\",\"Firebase\"],\"databases\":[\"Firebase\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"]}\n\nJob Summary:\nConsumer lifestyle startup hiring a Mid-level React Native Developer. You will build cross-platform features in TypeScript, manage state with Redux or Zustand, integrate Firebase, persist data locally with SQLite, and ship via Fastlane. GitHub Actions for CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React Native and Expo are the exact required framework and tooling\",\"TypeScript is required and present\",\"Redux satisfies the state management requirement\",\"Firebase covers the backend integration requirement\",\"SQLite satisfies local persistence requirements\",\"Fastlane and GitHub Actions match the mobile CI setup\"],\"gaps\":[\"No Zustand experience, though Redux satisfies the state management requirement\"],\"explanation\":\"The candidate's React Native stack is a precise match for this lifestyle app role, covering every named requirement from the framework and tooling to CI and local storage. The Redux to Zustand difference is not material since Redux is listed as a valid option. This is a strong fit with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ben_ios_mid\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Firebase\"],\"ci_cd\":[\"Fastlane\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nStreaming music app company is hiring a Mid-level iOS Engineer. You will build SwiftUI features, integrate audio playback with AVFoundation, manage reactive data flows with Combine, write unit and UI tests, and use Fastlane for CI. CoreData for local caching. Objective-C knowledge is a plus for maintaining legacy modules.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SwiftUI is the required UI framework and is present\",\"Fastlane satisfies the mobile CI requirement\",\"XCTest covers the unit and UI testing requirement\",\"Mid-level seniority is appropriate\"],\"gaps\":[\"No AVFoundation or audio playback integration experience visible\",\"No Combine experience for reactive data flows, which is required\",\"No CoreData experience for local caching\",\"No Objective-C signals for legacy module maintenance\"],\"explanation\":\"The candidate has a SwiftUI foundation with Fastlane and XCTest, but three significant gaps are present: AVFoundation for audio playback is central to a music app, Combine is required for reactive data flows, and CoreData is needed for local caching. These are not peripheral skills but core technical requirements for this specific application domain.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"preet_mlops\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"PyTorch\",\"MLflow\",\"Kubeflow\",\"FastAPI\",\"Docker\",\"Kubernetes\",\"AWS\",\"ONNX\",\"Weights & Biases\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nRetail AI company scaling model deployment is hiring a Senior MLOps Engineer. You will manage Kubeflow training pipelines, track experiments with MLflow, serve models via FastAPI on Kubernetes, and export to ONNX. AWS cloud. The role also requires building a real-time feature store and integrating with Kafka for streaming feature computation.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubeflow directly satisfies the training pipeline requirement\",\"MLflow covers experiment tracking\",\"FastAPI on Kubernetes matches model serving requirements\",\"ONNX satisfies the inference optimization requirement\",\"AWS and Python are both present\"],\"gaps\":[\"No Kafka or streaming feature computation experience\",\"No feature store experience such as Feast or Tecton\",\"Real-time feature serving for retail requires low-latency infrastructure beyond standard model serving\"],\"explanation\":\"The candidate covers the standard MLOps requirements well, but the role adds a real-time feature store and Kafka-based streaming feature computation which are absent from the profile. Building a feature store from scratch is a substantial engineering effort distinct from training pipeline management, representing a meaningful scope gap for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tara_ml_mid\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Hugging Face Transformers\",\"MLflow\",\"FastAPI\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nAdtech company building CTR prediction models is hiring a Mid-level ML Engineer. You will train classical and deep learning models with PyTorch and scikit-learn, track experiments with MLflow, serve models via FastAPI, deploy on AWS, and write pytest-based tests.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PyTorch and scikit-learn cover both deep learning and classical ML requirements\",\"MLflow satisfies the experiment tracking requirement\",\"FastAPI covers the model serving requirement\",\"AWS deployment is present and required\",\"pytest aligns with the testing expectations\",\"Docker and GitHub Actions reflect deployment and CI discipline\"],\"gaps\":[],\"explanation\":\"The candidate's ML engineering stack now matches every stated requirement including AWS deployment. PyTorch, scikit-learn, MLflow, FastAPI, and pytest are all present with no meaningful gaps for this adtech CTR prediction role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"omar_llm\",\"seniority\":\"Senior\",\"roles\":[\"AI Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"LangChain\",\"LangGraph\",\"OpenAI API\",\"Ollama\",\"ChromaDB\",\"Pinecone\",\"FastAPI\",\"Docker\"],\"architecture\":[\"RAG\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"ChromaDB\",\"Pinecone\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise SaaS company building AI-powered document search is hiring a Senior AI Engineer. You will design RAG pipelines with LangChain, integrate OpenAI and self-hosted LLMs, manage vector stores, serve via FastAPI, and fine-tune models using PyTorch and Hugging Face. AWS infrastructure experience expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"LangChain is the required RAG orchestration framework and is present\",\"OpenAI API and Ollama satisfy both cloud and self-hosted LLM requirements\",\"ChromaDB and Pinecone cover vector store management\",\"FastAPI satisfies the pipeline serving requirement\",\"LangGraph signals multi-agent orchestration depth\"],\"gaps\":[\"No PyTorch or Hugging Face experience for the model fine-tuning requirement\",\"No AWS infrastructure signals\",\"LLM fine-tuning is a distinct discipline from RAG engineering and requires GPU training experience\"],\"explanation\":\"The candidate is an excellent match for the RAG and vector store components of the role, but the fine-tuning requirement introduces a meaningful gap. PyTorch and Hugging Face fine-tuning is a distinct skill from RAG pipeline engineering involving GPU training workflows, and the absence of AWS experience is an additional concern for a production AI deployment context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vera_ds\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"XGBoost\",\"MLflow\",\"Tableau\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nLarge tech company hiring a Senior ML Engineer to fine-tune and serve large language models at scale. You will train with PyTorch and Hugging Face, run distributed training with Ray on GPU clusters, export with ONNX, and serve high-throughput inference with vLLM. CUDA GPU optimization required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python proficiency is the foundational language requirement\",\"MLflow for experiment tracking is a present and relevant tool\"],\"gaps\":[\"No PyTorch experience; works exclusively with classical ML frameworks\",\"No Hugging Face or LLM fine-tuning experience\",\"No Ray or distributed training experience\",\"No CUDA or GPU optimization signals\",\"No ONNX model export experience\",\"No vLLM or high-throughput inference serving experience\",\"Classical ML and data science background does not bridge to LLM infrastructure\"],\"explanation\":\"The candidate is a classical ML data scientist with gradient boosting and tabular data expertise. Every core LLM engineering requirement is absent: PyTorch, Hugging Face, Ray, CUDA, ONNX, and vLLM. MLflow is the only overlap. This is a fundamental domain mismatch between classical data science and distributed LLM training infrastructure.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sol_pytorch\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"CUDA\",\"Ray\",\"MLflow\",\"Docker\",\"AWS\",\"ONNX\"],\"architecture\":[\"Distributed System\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAI research lab hiring a Senior ML Engineer to fine-tune large language models. You will train with PyTorch on GPU clusters, use Hugging Face for fine-tuning, run distributed training with Ray, track with MLflow, and export to ONNX. CUDA optimization required. The role also requires serving fine-tuned models via vLLM for high-throughput inference.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch, Hugging Face Transformers, Ray, MLflow, and ONNX all cover the stated training requirements directly\",\"CUDA satisfies the GPU optimization requirement explicitly\",\"AWS and distributed system experience support the GPU cluster context\"],\"gaps\":[\"No vLLM experience for the high-throughput inference serving requirement\",\"vLLM is a specialized inference engine with distinct quantization and batching configuration not covered by general FastAPI serving\"],\"explanation\":\"The candidate satisfies every training-side requirement including CUDA and Ray, but the vLLM inference serving requirement is absent. vLLM is a specialized high-throughput inference engine with different deployment patterns from standard FastAPI model serving, and for a research lab that fine-tunes and serves LLMs at scale this is a meaningful gap in the serving layer.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ines_dataeng\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"PySpark\",\"Apache Kafka\",\"dbt\",\"Airflow\",\"Databricks\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nStreaming media company hiring a Senior Data Engineer to build real-time and batch pipelines. You will use Kafka for streaming, Spark for batch, orchestrate with Airflow, transform with dbt in Snowflake, and validate data quality with Great Expectations. Python and SQL required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kafka and Spark cover the streaming and batch pipeline requirements directly\",\"Airflow satisfies the orchestration requirement\",\"dbt with Snowflake matches the transformation and warehouse requirements\",\"Great Expectations directly satisfies the data quality validation requirement\",\"Python and SQL cover the language requirements\",\"Databricks and Scala signal additional depth beyond the stated requirements\"],\"gaps\":[],\"explanation\":\"The candidate satisfies every technical requirement for the streaming media data engineering role, including the more specialized Great Expectations data quality requirement. The Databricks and Scala experience adds depth beyond what is required and signals a mature senior data engineer background.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wren_dbt\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"dbt\",\"Airflow\",\"Pandas\",\"Prefect\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nE-commerce company building a Snowflake-based analytics platform is hiring a Mid-level Data Engineer. You will model data with dbt, orchestrate with Airflow, work in Snowflake, write Python and SQL, and implement data quality tests within dbt pipelines. Kafka for real-time ingestion is also required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"dbt and Airflow are core requirements and are present\",\"Python and SQL cover the language requirements\",\"GitHub Actions shows CI discipline\"],\"gaps\":[\"No Snowflake experience; uses BigQuery as the primary warehouse\",\"No Kafka or real-time data ingestion experience, which is a hard requirement\",\"No data quality testing signals despite it being explicitly expected\",\"Snowflake and BigQuery have different SQL dialects and optimization strategies\"],\"explanation\":\"While the candidate has dbt and Airflow experience, two hard requirements are absent: Snowflake as the target warehouse and Kafka for real-time ingestion. The Snowflake gap requires learning a new platform, and Kafka is an entirely different skill involving consumer groups and stream processing. Combined with the missing data quality testing signals, this is a weak fit with multiple critical gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"max_devops\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"AWS\",\"Docker\",\"Prometheus\",\"Grafana\",\"Ansible\",\"ArgoCD\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nScale-up company hiring a Senior DevOps Engineer to manage Kubernetes infrastructure on AWS, implement GitOps with ArgoCD, write Terraform, build observability with Datadog, automate provisioning with Ansible, and manage CI/CD on GitHub Actions. Go or Python scripting required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes and ArgoCD cover the cluster management and GitOps requirements\",\"Terraform covers the IaC requirement\",\"Ansible satisfies provisioning automation\",\"Go and Python scripting meet language requirements\",\"AWS and GitHub Actions are present\"],\"gaps\":[\"Uses Prometheus and Grafana while the role requires Datadog specifically\",\"Datadog has a distinct instrumentation model, APM tagging system, and alerting DSL that differs from Prometheus\"],\"explanation\":\"The candidate's infrastructure and GitOps stack is well-aligned, but the observability platform mismatch is meaningful: the role requires Datadog while the candidate works with Prometheus and Grafana. Datadog's agent-based instrumentation, APM, and log management differ significantly from the open-source Prometheus stack, representing a real onboarding need for a senior engineer expected to own observability.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wren_dbt\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"dbt\",\"Airflow\",\"Pandas\",\"Prefect\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nStreaming music company building a Snowflake and Kafka-based data platform is hiring a Mid-level Data Engineer. Kafka for real-time streaming ingestion is a hard requirement. dbt and Airflow for ELT and orchestration. Snowflake as the warehouse. Great Expectations for data quality testing within pipelines.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"dbt and Airflow are core pipeline and orchestration tools and are present\",\"Python and SQL meet the language requirements\"],\"gaps\":[\"No Kafka or real-time streaming experience, which is stated as a hard requirement\",\"No Snowflake experience; uses BigQuery as primary warehouse\",\"No Great Expectations or data quality testing framework experience\",\"Three concurrent hard requirements are absent\"],\"explanation\":\"The candidate has dbt and Airflow experience but three explicit requirements are missing: Kafka streaming ingestion, Snowflake as the warehouse, and Great Expectations for data quality. When core hard requirements across streaming, the warehouse platform, and data quality are all absent, the profile does not meet the minimum bar for this role regardless of orchestration experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sienna_sre\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"AWS\",\"Prometheus\",\"Grafana\",\"PagerDuty\",\"Docker\",\"Vault\"],\"architecture\":[\"Distributed System\",\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nHigh-traffic fintech platform hiring a Senior SRE to own reliability engineering. You will manage on-call with PagerDuty, monitor with Prometheus and Grafana, run Kubernetes on AWS, write automation in Go and Python, and manage secrets with Vault. Terraform for IaC. Chaos engineering or load testing experience is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PagerDuty satisfies the on-call management requirement directly\",\"Prometheus and Grafana cover the monitoring requirements exactly\",\"Kubernetes on AWS matches the cluster management environment\",\"Vault satisfies the secrets management requirement\",\"Go and Python cover the automation scripting requirements\",\"Terraform covers the IaC requirement\",\"k6 satisfies the load testing strong-plus requirement\"],\"gaps\":[],\"explanation\":\"The candidate is an exceptional match for this fintech SRE role, covering every named requirement including Vault for secrets management and k6 for the load testing bonus. The breadth across on-call, observability, cluster management, IaC, and automation reflects a well-rounded senior SRE profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leo_infra\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"AWS\",\"Terraform\",\"Kubernetes\",\"Prometheus\",\"Grafana\",\"ArgoCD\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nGrowth-stage startup hiring a Mid-level DevOps Engineer to manage AWS infrastructure with Terraform, operate Kubernetes clusters, build observability with Prometheus and Grafana, and maintain CI/CD pipelines on GitHub Actions. ArgoCD for GitOps. Python and Bash scripting expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"AWS and Terraform cover the infrastructure management requirements\",\"Kubernetes satisfies the cluster operations requirement\",\"Prometheus and Grafana together cover the observability requirements exactly\",\"ArgoCD satisfies the GitOps requirement\",\"GitHub Actions covers the CI/CD requirement\",\"Python and Bash meet the scripting expectations\"],\"gaps\":[],\"explanation\":\"The candidate now satisfies every stated requirement including Kubernetes, Grafana, and ArgoCD. The full coverage from infrastructure-as-code to observability to GitOps reflects the breadth expected for this mid-level DevOps role. There are no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"osei_k8s\",\"seniority\":\"Lead\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"AWS\",\"Istio\",\"Vault\",\"Prometheus\",\"Grafana\",\"Datadog\",\"Docker\",\"ArgoCD\"],\"architecture\":[\"Cloud-Native\",\"Service Mesh\",\"Microservices\"],\"ci_cd\":[\"ArgoCD\",\"GitHub Actions\",\"Jenkins\"]}\n\nJob Summary:\nHigh-growth company hiring a Lead Platform Engineer to own internal developer platform strategy. You will lead Kubernetes platform architecture, implement GitOps with ArgoCD, manage service mesh with Istio, secure secrets with Vault, and define observability standards. Terraform for IaC. Go or Python scripting preferred. AWS cloud.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Lead seniority is appropriate for platform strategy ownership\",\"Kubernetes and Istio service mesh cover the platform architecture requirements\",\"ArgoCD satisfies the GitOps requirement\",\"Vault satisfies the secrets management requirement\",\"Both Prometheus, Grafana, and Datadog demonstrate mature multi-layer observability\",\"Terraform and AWS cover IaC and cloud requirements\",\"Go and Python scripting meet the preferred language requirements\"],\"gaps\":[],\"explanation\":\"This candidate is an exceptional fit for the lead platform engineering role, covering every named requirement including the specialized combination of Istio, Vault, and ArgoCD. The multi-layer observability stack with both Prometheus and Datadog signals enterprise-grade experience appropriate for a platform serving many engineering teams.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elle_platform\",\"seniority\":\"Mid\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"Kubernetes\",\"Terraform\",\"GCP\",\"Prometheus\"],\"ci_cd\":[\"GitLab CI\"]}\n\nJob Summary:\nEnterprise company running entirely on Azure is hiring a Mid-level Cloud Infrastructure Engineer. You will manage Azure Kubernetes Service, write Terraform for Azure resources, set up observability with Azure Monitor and Datadog, and maintain CI/CD with Azure Pipelines. Helm for release management.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Kubernetes experience transfers conceptually to AKS\",\"Terraform IaC experience is applicable to Azure resource management\"],\"gaps\":[\"No Azure experience; focused on GCP\",\"No AKS-specific networking, RBAC, or node pool configuration experience\",\"No Datadog or Azure Monitor experience; uses Prometheus\",\"No Azure Pipelines experience; uses GitLab CI\",\"No Helm experience for release management\",\"Azure-specific Terraform provider knowledge differs significantly from GCP\"],\"explanation\":\"The candidate has cloud and Kubernetes fundamentals but their stack is GCP-centric while the role operates entirely on Azure. Every named tool from the observability stack to the CI system to the Kubernetes distribution is platform-specific and absent from the profile. This is a comprehensive platform mismatch that would require substantial reskilling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"riku_nest\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"Express.js\",\"Docker\",\"AWS\",\"BullMQ\",\"GraphQL\",\"Apollo GraphQL\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nB2C marketplace company building a GraphQL-first backend is hiring a Senior Backend Engineer. You will build NestJS resolvers, manage PostgreSQL and Redis, handle async jobs with BullMQ, and deploy on AWS. TypeScript required. The team is also adopting event sourcing with EventStoreDB and expects senior engineers to lead that effort.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"NestJS and Apollo GraphQL are the exact required backend technologies\",\"BullMQ covers async job management\",\"PostgreSQL and Redis match the data and caching layers\",\"AWS and Docker cover deployment\",\"Jest and Supertest satisfy API testing expectations\"],\"gaps\":[\"No EventStoreDB or event sourcing experience, which the team is actively adopting and senior engineers must lead\",\"Event sourcing requires append-only log architecture and projection patterns distinct from standard CRUD systems\"],\"explanation\":\"The candidate's NestJS and GraphQL stack is a strong match for the current backend requirements, but being expected to lead EventStoreDB adoption as a senior engineer is a meaningful additional responsibility without any event sourcing signals in the profile. Leading an architectural shift you have not previously implemented is a significant expectation gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ana_spring\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Apache Kafka\",\"Docker\",\"AWS\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"CQRS\"],\"databases\":[\"PostgreSQL\",\"Cassandra\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nGovernment contractor building mission-critical Java backend systems is hiring a Senior Java Engineer. You will build Spring Boot microservices, process events with Kafka, use PostgreSQL, and deploy on AWS. JUnit and Mockito for testing. The role requires an active security clearance or eligibility for one, and experience with FedRAMP-compliant cloud architecture is strongly preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Java and Spring Boot are the required backend technologies\",\"Kafka satisfies the event processing requirement\",\"PostgreSQL covers the database requirement\",\"AWS and Docker match the deployment stack\",\"JUnit and Mockito satisfy the testing requirements\",\"Senior seniority is appropriate\"],\"gaps\":[\"No FedRAMP-compliant cloud architecture experience visible\",\"Security clearance eligibility cannot be assessed from a GitHub profile\",\"Government contracting context introduces compliance requirements not evidenced in the technical stack\"],\"explanation\":\"The candidate's Java and Kafka backend stack is a solid technical match, but the government contracting context introduces clearance and FedRAMP compliance requirements that cannot be assessed from technical signals. FedRAMP cloud architecture involves specific AWS GovCloud, access control, and audit logging requirements that differ from commercial cloud deployments, representing meaningful gaps for this specific context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ivan_sol_jr\",\"seniority\":\"Junior\",\"roles\":[\"Blockchain Engineer\"],\"languages\":[\"JavaScript\",\"Solidity\"],\"tech\":[\"Hardhat\",\"Ethers.js\"]}\n\nJob Summary:\nBlockchain security firm is hiring a Senior Smart Contract Auditor. You will perform manual and automated security audits of Solidity contracts, write exploit proof-of-concepts in Foundry, run static analysis with Slither and Mythril, and deliver comprehensive audit reports. Minimum three years of smart contract auditing experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Solidity and Hardhat provide foundational smart contract knowledge\"],\"gaps\":[\"Junior seniority is far below the senior auditor requirement\",\"No Foundry experience for exploit proof-of-concept writing\",\"No Slither or Mythril static analysis experience\",\"No security audit experience or methodology signals\",\"No formal exploit development or vulnerability research background\",\"Three years of auditing experience cannot be inferred from this sparse profile\"],\"explanation\":\"The candidate has basic Solidity and Hardhat exposure but lacks every specialized skill required for a senior smart contract auditor role. Security auditing is a distinct discipline from contract development, requiring formal audit methodology, static analysis tooling, and exploit writing experience that are entirely absent from this junior profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sienna_sre\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"AWS\",\"Prometheus\",\"Grafana\",\"PagerDuty\",\"Docker\",\"Vault\"],\"architecture\":[\"Distributed System\",\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nHigh-traffic fintech platform hiring a Senior SRE to own reliability engineering. You will manage on-call with PagerDuty, monitor with Datadog, run Kubernetes on AWS, write automation in Go and Python, and manage secrets with Vault. Terraform for IaC. Chaos engineering experience required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PagerDuty satisfies the on-call management requirement\",\"Kubernetes on AWS and Terraform cover cluster management and IaC\",\"Vault satisfies the secrets management requirement\",\"Go and Python cover the automation scripting requirements\",\"k6 signals load testing discipline relevant to reliability engineering\"],\"gaps\":[\"Uses Prometheus and Grafana while the role requires Datadog\",\"No chaos engineering experience, which is a hard requirement\",\"Datadog's APM, log management, and alerting differ significantly from Prometheus\"],\"explanation\":\"The candidate covers most SRE requirements but two gaps are notable: the observability stack is Prometheus rather than the required Datadog, and chaos engineering is a hard requirement that is entirely absent. Chaos engineering tools and methodology involve deliberate fault injection at a system level that is distinct from general SRE monitoring and automation work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dex_junior_ops\",\"seniority\":\"Junior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"GitHub Actions\",\"AWS\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nFast-moving startup hiring a Senior DevOps Engineer to own cloud infrastructure on AWS with Terraform, operate Kubernetes clusters, implement observability with Prometheus and Grafana, and build GitOps pipelines with ArgoCD. Strong scripting in Python and Go expected. Minimum three years of DevOps experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker, GitHub Actions, and AWS provide a basic cloud operations foundation\",\"Python and Bash scripting are present\"],\"gaps\":[\"Junior seniority is far below the senior requirement with three years experience minimum\",\"No Kubernetes experience, which is central to the role\",\"No Terraform or infrastructure-as-code experience\",\"No Prometheus or Grafana experience for observability\",\"No ArgoCD or GitOps experience\",\"No Go scripting experience\",\"Profile is too sparse for a senior-level infrastructure ownership role\"],\"explanation\":\"The candidate is a junior DevOps engineer with Docker and GitHub Actions experience, while the role requires a senior engineer with Kubernetes, Terraform, Prometheus, and ArgoCD. Every core technical requirement is absent and the seniority gap is significant. This is a weak fit with fundamental mismatches in both experience level and technical depth.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"zara_fe_intern\",\"seniority\":\"Intern\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"Bootstrap\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nStartup offering a frontend engineering internship. Interns will contribute to a React codebase, fix bugs, write small UI features, and work alongside senior engineers. JavaScript basics required. No prior professional experience necessary. The ability to learn quickly and take feedback is the primary hiring criterion.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React is the required framework and is present\",\"JavaScript is the stated language requirement and is present\",\"Intern seniority aligns with the role\"],\"gaps\":[\"Profile is very sparse with minimal visibility into code depth or quality\",\"No testing frameworks visible\",\"Bootstrap-only styling experience with no modern CSS tooling\"],\"explanation\":\"The candidate has the required React and JavaScript foundation and the appropriate intern-level seniority. However, the profile is extremely sparse, making it difficult to assess whether the candidate has meaningful hands-on experience beyond tutorials. The role explicitly values learning ability, so the fit hinges on interview evidence rather than profile signals.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"osei_k8s\",\"seniority\":\"Lead\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"AWS\",\"Istio\",\"Vault\",\"Prometheus\",\"Grafana\",\"Datadog\",\"Docker\",\"ArgoCD\"],\"architecture\":[\"Cloud-Native\",\"Service Mesh\",\"Microservices\"],\"ci_cd\":[\"ArgoCD\",\"GitHub Actions\",\"Jenkins\"]}\n\nJob Summary:\nHigh-growth company hiring a Lead Platform Engineer to own internal developer platform. You will lead Kubernetes architecture, implement GitOps with ArgoCD, manage service mesh with Istio, secure secrets with Vault, and define observability standards. Terraform for IaC. GCP cloud platform. Go or Python scripting preferred.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Lead seniority matches the platform strategy ownership level\",\"Kubernetes and Istio service mesh cover the architecture requirements\",\"ArgoCD satisfies the GitOps requirement\",\"Vault satisfies the secrets management requirement\",\"Prometheus, Grafana, and Datadog show mature observability depth\",\"Go and Python scripting meet the preferred language requirements\"],\"gaps\":[\"No GCP experience; focused on AWS\",\"GCP-specific Kubernetes networking, IAM, and workload identity differ from AWS equivalents\",\"Cloud platform mismatch requires reskilling on GCP-specific tooling beyond generic Kubernetes knowledge\"],\"explanation\":\"The candidate's platform engineering stack is technically impressive, but the role runs on GCP while the candidate's infrastructure expertise is AWS-centric. GCP introduces specific networking models, IAM, and GKE-specific configuration that differ meaningfully from AWS, and a lead-level hire is expected to own the platform from day one without significant ramp-up on the cloud provider.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ray_node_lead\",\"seniority\":\"Lead\",\"roles\":[\"Full Stack Engineer\",\"Software Architect\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Next.js\",\"NestJS\",\"React\",\"FastAPI\",\"Docker\",\"AWS\",\"Kubernetes\",\"Redis\",\"Storybook\"],\"architecture\":[\"Microservices\",\"Clean Architecture\",\"Domain-Driven Design\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nGrowth-stage startup hiring a Lead Full Stack Engineer to own architecture of a Next.js and NestJS product, lead a team of five engineers, define coding standards, drive DDD adoption, and oversee GitOps deployments with ArgoCD on Kubernetes. TypeScript and Python required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and NestJS are the exact frontend and backend frameworks required\",\"DDD and clean architecture are explicitly required and present\",\"ArgoCD GitOps on Kubernetes covers the deployment requirements\",\"Lead seniority matches the team leadership expectation\",\"TypeScript and Python are both required and present\",\"Jest, pytest, and Playwright reflect comprehensive testing discipline\",\"Storybook signals component documentation maturity appropriate for a team lead\"],\"gaps\":[],\"explanation\":\"The candidate is a strong fit for the lead full-stack architect role, satisfying every technical and leadership requirement. The specific combination of Next.js, NestJS, DDD, and ArgoCD at lead seniority is exactly the profile the startup needs, and the multi-layer testing stack signals quality culture appropriate for a team setting standards.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nina_principal\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\"],\"languages\":[\"Java\",\"Go\",\"Python\"],\"tech\":[\"Spring Boot\",\"Kubernetes\",\"Kafka\",\"AWS\",\"Terraform\",\"Istio\",\"Docker\",\"ArgoCD\"],\"architecture\":[\"Domain-Driven Design\",\"CQRS\",\"Event Sourcing\",\"Microservices\",\"Clean Architecture\",\"Service Mesh\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"ArgoCD\",\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise fintech is hiring a Principal Architect to define system design across multiple product lines. You will drive DDD and event sourcing adoption, lead Kubernetes strategy on AWS, define service mesh standards with Istio, and oversee Kafka streaming. Deep polyglot engineering background required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Principal seniority matches the cross-product strategy responsibility\",\"DDD, CQRS, and event sourcing are all explicitly required and present\",\"Istio service mesh is explicitly named and present\",\"Kafka satisfies the event streaming requirement\",\"Kubernetes on AWS with ArgoCD reflects mature infrastructure ownership\",\"Java, Go, and Python satisfy the polyglot expectation\",\"Clean architecture and service mesh signals reflect principal-level architectural breadth\"],\"gaps\":[],\"explanation\":\"This candidate is an exceptional fit for the principal architect role, with the specific Istio and event sourcing combination being a strong differentiator. The polyglot background across Java, Go, and Python and the breadth of architectural patterns at principal level make this a comprehensive match with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ola_ember\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Ember.js\",\"Backbone.js\",\"jQuery\",\"Bootstrap\"],\"testing\":[\"QUnit\"]}\n\nJob Summary:\nModern SaaS startup hiring a Senior Frontend Engineer to build new features in React and Next.js. TypeScript required throughout. State management with Zustand. Tailwind CSS for styling. Vitest and Playwright for testing. The team ships rapidly and expects React expertise from day one.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript is present as a secondary language\",\"Senior seniority matches the role\"],\"gaps\":[\"No React or Next.js experience; uses Ember.js and Backbone.js which are different paradigms\",\"No Zustand or modern state management experience\",\"No Tailwind CSS; uses Bootstrap\",\"No Vitest or Playwright testing experience\",\"React expertise is required from day one and is absent\",\"Ember.js and Backbone.js reflect a legacy SPA ecosystem that does not transfer to modern React\"],\"explanation\":\"The candidate has senior-level JavaScript experience but in Ember.js and Backbone.js, which are legacy frameworks with different component models, routing paradigms, and state management patterns from React. The role requires React expertise from day one, and the testing, styling, and state management tools are all mismatched. This is a fundamental framework mismatch despite the seniority level.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ngo_ml_junior\",\"seniority\":\"Junior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"TensorFlow\"]}\n\nJob Summary:\nAI startup building production LLM applications is hiring a Mid-level ML Engineer. You will fine-tune LLMs with PyTorch and Hugging Face, build RAG pipelines with LangChain, serve models via FastAPI, and manage vector databases. CUDA and GPU training experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python proficiency is the foundational language requirement\",\"scikit-learn and TensorFlow show ML exposure\"],\"gaps\":[\"Junior seniority does not meet the mid-level requirement\",\"No PyTorch experience; uses TensorFlow only\",\"No Hugging Face or LLM fine-tuning experience\",\"No LangChain or RAG pipeline experience\",\"No FastAPI or model serving experience\",\"No vector database experience\",\"No CUDA or GPU training signals\",\"Classical ML focus does not reflect production LLM engineering depth\"],\"explanation\":\"The candidate is a junior ML engineer with classical ML tools that do not extend to the LLM ecosystem. Every named requirement from PyTorch to Hugging Face to LangChain and CUDA is absent. The seniority gap compounds the fundamental domain mismatch, making this a weak fit for a production LLM engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ray_node_lead\",\"seniority\":\"Lead\",\"roles\":[\"Full Stack Engineer\",\"Software Architect\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"Next.js\",\"NestJS\",\"React\",\"FastAPI\",\"Docker\",\"AWS\",\"Kubernetes\",\"Redis\",\"Storybook\"],\"architecture\":[\"Microservices\",\"Clean Architecture\",\"Domain-Driven Design\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nGrowth-stage startup hiring a Lead Full Stack Engineer to own architecture of a Next.js and NestJS product, lead a team of five engineers, define coding standards, drive DDD adoption, and oversee GitOps deployments with ArgoCD on Kubernetes. TypeScript and Python required. The company is beginning SOC 2 certification and expects engineering leadership to contribute to the effort.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and NestJS are the exact required frameworks\",\"DDD and clean architecture are explicitly required and present\",\"ArgoCD GitOps on Kubernetes covers deployment requirements\",\"Lead seniority matches the team leadership expectation\",\"TypeScript and Python are both required and present\",\"Strong testing stack across Jest, pytest, and Playwright\"],\"gaps\":[\"No SOC 2 compliance or security control framework experience visible\",\"SOC 2 requires access controls, audit logging, and control documentation that are specific compliance responsibilities\"],\"explanation\":\"The candidate is a strong technical match for the architecture and engineering leadership aspects, but SOC 2 certification requires compliance engineering expertise around access controls, audit trails, and control evidence that is not visible in the profile. Engineering leadership involvement in a SOC 2 effort adds a significant compliance responsibility beyond technical feature delivery.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"bo_react_mid\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"Zustand\",\"Vite\",\"Storybook\"],\"testing\":[\"Vitest\",\"Playwright\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nE-commerce company hiring a Mid-level Frontend Engineer to build and maintain a Next.js storefront. TypeScript required. Zustand for state management. Tailwind CSS for styling. Vitest for units, Playwright for E2E. GitHub Actions for CI. Storybook for component documentation.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and React are the exact required frameworks\",\"TypeScript is required and present\",\"Zustand is the stated state management solution and is present\",\"Tailwind CSS matches the styling approach\",\"Vitest and Playwright satisfy both testing requirements\",\"GitHub Actions satisfies the CI requirement\",\"Storybook is required for component documentation and is present\"],\"gaps\":[],\"explanation\":\"The candidate satisfies every named requirement for this e-commerce frontend role including the less common Zustand state management tool and Storybook. The complete match across all stated technologies with no gaps makes this a strong fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yuna_fullstack\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"FastAPI\",\"Docker\",\"AWS\",\"Redis\",\"Tailwind CSS\"],\"architecture\":[\"Microservices\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Jest\",\"Playwright\"]}\n\nJob Summary:\nLegaltech startup hiring a Senior Full Stack Engineer to build a Next.js dashboard and FastAPI backend, work with PostgreSQL, deploy on AWS with Docker, and maintain GitHub Actions pipelines. TypeScript required on the frontend. We write tests and value reliability. Stripe payment integration is a core responsibility.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and FastAPI are the exact required frameworks\",\"PostgreSQL, AWS, and Docker cover the infrastructure and data requirements\",\"GitHub Actions satisfies the CI/CD requirement\",\"TypeScript is required and present\",\"pytest, Jest, and Playwright reflect comprehensive testing coverage\"],\"gaps\":[\"No Stripe or payment gateway integration experience visible, which is a core responsibility\",\"Legal payment workflows involve compliance and billing complexity not evidenced in the profile\"],\"explanation\":\"The candidate's technical stack is a precise match at every layer of the application, but Stripe payment integration is described as a core responsibility and is entirely absent from the profile. Payment integration in a legal context involves invoicing, reconciliation, and trust account compliance that are non-trivial domain requirements beyond the API implementation itself.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elle_platform\",\"seniority\":\"Mid\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"Kubernetes\",\"Terraform\",\"GCP\",\"Prometheus\"],\"ci_cd\":[\"GitLab CI\"]}\n\nJob Summary:\nSaaS company hiring a Mid-level DevOps Engineer. Their infrastructure runs on GCP with Kubernetes. You will write Terraform for GCP resources, set up observability with Prometheus and Grafana, manage Helm releases, and maintain CI/CD with GitLab CI. Python and Bash scripting expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"GCP is the stated cloud platform and is present\",\"Kubernetes covers the cluster management requirement\",\"Terraform is required for GCP resources and is present\",\"Prometheus is present and relevant to the observability requirement\",\"GitLab CI matches the CI/CD requirement\",\"Python and Bash scripting meet the language expectations\"],\"gaps\":[\"No Grafana experience alongside Prometheus for the observability stack\",\"No Helm experience for release management\"],\"explanation\":\"The candidate's GCP, Kubernetes, Terraform, and GitLab CI stack aligns well with the core requirements. The gaps in Grafana and Helm are meaningful since Grafana is typically used alongside Prometheus and Helm is the standard Kubernetes release management tool, but neither represents a deep skill that is difficult to acquire. This is a moderate fit with learnable gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jade_fullstack_mid\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"Django\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\"],\"testing\":[\"pytest\",\"Jest\"]}\n\nJob Summary:\nEdtech company seeking a Mid-level Full Stack Engineer comfortable in React and Django. PostgreSQL for storage, AWS with Docker for deployment. TypeScript is being adopted and prior experience is a plus. Engineers own features from database schema to UI. Celery for async task processing is a requirement.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Django directly match the frontend and backend requirements\",\"PostgreSQL and AWS with Docker cover the data and deployment stack\",\"pytest and Jest satisfy the testing requirements across both layers\",\"Mid-level seniority is appropriate\"],\"gaps\":[\"No TypeScript experience, which is being actively adopted\",\"No Celery or async task processing experience, which is a stated requirement\",\"No CI/CD tooling visible\"],\"explanation\":\"The candidate covers the core stack well, but Celery is listed as a requirement rather than a nice-to-have, and its absence is a meaningful gap for an edtech platform where async task processing is a core workflow. The TypeScript adoption also means the candidate would be learning it on the job alongside owning features end-to-end.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"finn_sol\",\"seniority\":\"Mid\",\"roles\":[\"Blockchain Engineer\"],\"languages\":[\"Rust\",\"TypeScript\",\"JavaScript\"],\"tech\":[\"Anchor\",\"Solana\",\"Ethers.js\",\"Docker\"],\"testing\":[\"Mocha\"]}\n\nJob Summary:\nWeb3 infrastructure company hiring a Mid-level Solana Program Developer to write Rust programs with Anchor, deploy to devnet and mainnet, write integration tests, build TypeScript SDK clients, and optimize for compute unit efficiency. Strong Rust required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Rust is the required language and the candidate's primary language\",\"Anchor is the exact Solana program framework required\",\"TypeScript is required for SDK client development and is present\",\"Solana ecosystem experience is directly relevant\",\"Mocha covers integration testing requirements\"],\"gaps\":[\"No explicit compute unit optimization or profiling signals\",\"No mainnet deployment or production-grade Solana program experience signaled\",\"Ethers.js is Ethereum-focused and suggests cross-chain exposure rather than deep Solana specialization\"],\"explanation\":\"The candidate has the right Rust and Anchor foundation for Solana program development, but compute unit optimization is a stated requirement and is not evidenced. The presence of Ethers.js raises a question about the depth of Solana-specific experience versus broader Web3 exposure. This is a moderate fit that warrants deeper Solana specialization signals.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cj_web3\",\"seniority\":\"Mid\",\"roles\":[\"Blockchain Engineer\"],\"languages\":[\"Solidity\",\"TypeScript\",\"JavaScript\"],\"tech\":[\"Hardhat\",\"Foundry\",\"Ethers.js\",\"Wagmi\",\"The Graph\",\"OpenZeppelin\"],\"testing\":[\"Mocha\",\"Chai\"]}\n\nJob Summary:\nDeFi protocol hiring a Mid-level Smart Contract Developer. You will write and test Solidity contracts with Foundry and OpenZeppelin, deploy on Ethereum and L2 networks, integrate with frontends via Wagmi, and index events with The Graph. Security reviews and audit prep are part of the role.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Solidity is the required smart contract language\",\"Foundry directly satisfies the required testing framework\",\"OpenZeppelin is explicitly named for contract security libraries\",\"Wagmi satisfies the frontend integration requirement\",\"The Graph covers the event indexing requirement\",\"Both Hardhat and Foundry signal tooling depth in the smart contract development lifecycle\"],\"gaps\":[\"No explicit L2 deployment experience visible\",\"No formal security audit preparation experience beyond OpenZeppelin usage\"],\"explanation\":\"The candidate's smart contract stack is a strong match for this DeFi role, with Foundry, OpenZeppelin, Wagmi, and The Graph all present. The combination of both Hardhat and Foundry signals genuine tooling breadth. The L2 deployment and formal audit prep gaps are minor and unlikely to be disqualifying for a mid-level position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nia_python_sr\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\",\"TypeScript\"],\"tech\":[\"Django\",\"FastAPI\",\"Celery\",\"Docker\",\"AWS\",\"Redis\",\"Nginx\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nEdtech SaaS company hiring a Senior Backend Engineer to build Python microservices with FastAPI, manage async task queues with Celery and Redis, work with PostgreSQL, deploy on AWS, and maintain GitHub Actions pipelines. Load testing experience valued. TypeScript knowledge is a plus for occasional frontend tasks.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"FastAPI is the exact required backend framework\",\"Celery and Redis directly cover the async task queue requirements\",\"PostgreSQL is the stated database and is present\",\"AWS and Docker match the deployment stack\",\"GitHub Actions satisfies the CI requirement\",\"Locust satisfies the valued load testing requirement\",\"TypeScript satisfies the plus requirement for frontend tasks\"],\"gaps\":[],\"explanation\":\"The candidate satisfies every core requirement for this edtech SaaS role including the load testing bonus via Locust and the TypeScript plus. The FastAPI and Celery combination with PostgreSQL reflects proven async Python engineering experience. There are no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pete_devops_sr\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"AWS\",\"Terraform\",\"Docker\",\"Kubernetes\",\"Ansible\",\"Jenkins\",\"Prometheus\",\"Grafana\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"]}\n\nJob Summary:\nEnterprise company hiring a Senior DevOps Engineer to manage GCP infrastructure with Terraform, operate GKE clusters, implement observability with Datadog and Google Cloud Monitoring, and run CI/CD pipelines on Google Cloud Build. Kubernetes experience required. Python and Bash scripting expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Kubernetes experience transfers conceptually to GKE\",\"Terraform IaC experience is applicable to GCP resource management\",\"Python and Bash scripting meet the language expectations\"],\"gaps\":[\"AWS-focused infrastructure experience while the role is entirely GCP-native\",\"No Datadog or Google Cloud Monitoring experience; uses Prometheus and Grafana\",\"No Google Cloud Build or GCP-native CI experience\",\"No GKE-specific networking, node pool, or workload identity experience\",\"No GCP IAM or GCP-specific Terraform provider experience\"],\"explanation\":\"The candidate has strong Kubernetes and Terraform experience but their cloud platform expertise is AWS-centric while the role is entirely GCP-native. GCP-specific tooling including GKE, Cloud Build, Cloud Monitoring, and IAM represent a substantial reskilling need beyond just provider familiarity. The observability stack mismatch from Prometheus to Datadog adds a further gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"paz_sre_mid\",\"seniority\":\"Mid\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"AWS\",\"Prometheus\",\"Grafana\",\"Docker\",\"PagerDuty\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nMedia streaming company hiring a Mid-level SRE to run Kubernetes on AWS, monitor with Prometheus and Grafana, write automation in Python and Go, manage infrastructure with Terraform, and handle on-call with PagerDuty. GitHub Actions for CI. SLO definition and incident post-mortem experience expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes on AWS matches the cluster management requirement\",\"Prometheus and Grafana satisfy the monitoring requirements directly\",\"PagerDuty satisfies the on-call management requirement\",\"Python and Go cover automation scripting requirements\",\"Terraform covers the IaC requirement\",\"GitHub Actions satisfies CI\"],\"gaps\":[\"No SLO definition or SLI measurement tooling signals\",\"No incident post-mortem process or runbook experience signals\"],\"explanation\":\"The candidate covers the technical SRE tooling requirements well including PagerDuty. However, SLO definition and incident post-mortem experience are explicitly expected and are not evidenced in the profile. These are practice and process skills beyond tooling that require hands-on SRE experience in on-call rotations and reliability improvement cycles.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jade_fullstack_mid\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"Django\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\"],\"testing\":[\"pytest\",\"Jest\"]}\n\nJob Summary:\nDigital agency hiring a Mid-level Full Stack Engineer for client projects. Typical stack is React and Django with PostgreSQL. Docker and AWS for deployment. TypeScript is preferred. Engineers must work independently, interface directly with clients, and manage multiple concurrent projects.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Django match the standard client project stack\",\"PostgreSQL, Docker, and AWS cover the data and deployment layers\",\"pytest and Jest show testing discipline across both layers\",\"Mid-level seniority is appropriate\"],\"gaps\":[\"No TypeScript experience, which is preferred\",\"No CI/CD tooling visible\",\"No signals of client-facing or multi-project management experience\",\"Independent client delivery in an agency context requires communication and project management skills not assessable from the profile\"],\"explanation\":\"The candidate's technical stack matches the agency's tools well, but the role requires independent client-facing delivery and multi-project management that are not evidenced in the profile. The TypeScript preference and absent CI/CD tooling are secondary gaps. The client-facing independence requirement is a meaningful responsibility scope beyond pure engineering.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cam_ml_classical\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"XGBoost\",\"LightGBM\",\"Pandas\",\"NumPy\",\"MLflow\",\"Weights & Biases\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nAdtech startup hiring a Senior ML Engineer to build and serve real-time bidding models. Stack is PyTorch for deep learning, Hugging Face for transformer-based user embeddings, Ray for distributed training, MLflow for experiment tracking, and FastAPI for model serving. CUDA and GPU cluster experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"MLflow for experiment tracking is a relevant and present tool\",\"Python proficiency is the foundational language requirement\",\"Strong gradient boosting background with XGBoost and LightGBM\"],\"gaps\":[\"No PyTorch or deep learning experience; works exclusively with classical ML\",\"No Hugging Face or transformer-based embedding experience\",\"No Ray or distributed GPU training experience\",\"No CUDA or GPU cluster optimization experience\",\"No FastAPI or model serving infrastructure experience\"],\"explanation\":\"The candidate is a classical ML specialist with gradient boosting expertise, while this role requires a deep learning infrastructure engineer with PyTorch, Hugging Face, Ray, and CUDA. MLflow is the only overlap. The gap between classical gradient boosting for tabular data and distributed transformer-based embedding models on GPU clusters is fundamental and not bridgeable through tooling familiarity alone.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hux_react_sr\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Zustand\",\"Tailwind CSS\",\"Radix UI\",\"Framer Motion\",\"Storybook\",\"Vite\"],\"testing\":[\"Vitest\",\"Playwright\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nProduct studio hiring a Senior Frontend Engineer to build polished, animated React interfaces. You will implement complex animations with Framer Motion, build accessible components with Radix UI, document in Storybook, and style with Tailwind CSS. TypeScript required. Vitest and Playwright for testing. The role also requires Three.js for interactive 3D product visualizations.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Framer Motion satisfies the animation requirement directly\",\"Radix UI covers the accessible component requirement\",\"Storybook is required for documentation and is present\",\"Tailwind CSS, TypeScript, Vitest, and Playwright all match stated requirements\",\"React and Next.js cover the framework requirements\"],\"gaps\":[\"No Three.js or 3D visualization experience, which is a stated role responsibility\",\"3D scene management and rendering is a specialized discipline distinct from 2D animation work\"],\"explanation\":\"The candidate satisfies all 2D animation and component library requirements well, but Three.js for 3D product visualization is a stated responsibility that is entirely absent. Three.js involves 3D scene management, camera controls, and shader concepts that are a separate domain from Framer Motion animation, representing a meaningful technical gap for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jun_kotlin_sr\",\"seniority\":\"Senior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Hilt\",\"Retrofit\",\"Room\",\"ExoPlayer\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Mockito\",\"Espresso\"]}\n\nJob Summary:\nStreaming media company hiring a Senior Android Engineer to build Jetpack Compose UI, integrate ExoPlayer for video playback, manage local data with Room, handle dependency injection with Hilt, and write tests. Firebase for analytics. Fastlane for mobile CI. Clean architecture or MVVM pattern expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Jetpack Compose is the required UI framework and is present\",\"ExoPlayer directly satisfies the video playback integration requirement\",\"Room satisfies the local data management requirement\",\"Hilt is explicitly required for dependency injection and is present\",\"Firebase covers analytics requirements\",\"Fastlane satisfies the mobile CI requirement\",\"JUnit, Mockito, and Espresso provide comprehensive Android testing coverage\"],\"gaps\":[\"No explicit MVVM or clean architecture pattern signals in the profile\"],\"explanation\":\"The candidate is an excellent fit for this streaming Android role, with ExoPlayer and Hilt being specialized requirements that are both directly satisfied. ExoPlayer integration for video playback is a domain-specific skill that distinguishes this candidate for a streaming media context. The architecture pattern gap is a soft concern assessable in interview.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cam_ml_classical\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"XGBoost\",\"LightGBM\",\"Pandas\",\"NumPy\",\"MLflow\",\"Weights & Biases\"],\"databases\":[\"PostgreSQL\",\"Snowflake\"]}\n\nJob Summary:\nLarge tech company hiring a Senior ML Engineer to train and serve LLMs at scale. You will fine-tune models with PyTorch and Hugging Face, run distributed training on GPU clusters with Ray, manage experiment tracking with MLflow, and export models with ONNX. CUDA optimization required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"MLflow for experiment tracking is a relevant and present tool\",\"Strong classical ML and gradient boosting background\"],\"gaps\":[\"No PyTorch experience; works with classical ML frameworks only\",\"No Hugging Face or LLM fine-tuning experience\",\"No Ray or distributed training experience\",\"No CUDA or GPU optimization signals\",\"No ONNX model export experience\",\"Classical ML and gradient boosting expertise does not transfer to LLM fine-tuning workflows\"],\"explanation\":\"The candidate has a strong classical ML background but every core requirement for LLM engineering is absent: PyTorch, Hugging Face, Ray, CUDA, and ONNX. MLflow is the only overlap, and it alone does not bridge the gap between gradient boosting for tabular data and distributed LLM fine-tuning on GPU clusters. This is a fundamental domain mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"paz_sre_mid\",\"seniority\":\"Mid\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"AWS\",\"Prometheus\",\"Grafana\",\"Docker\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nMedia streaming company hiring a Mid-level SRE to run Kubernetes on AWS, monitor with Prometheus and Grafana, write automation in Python and Go, manage infrastructure with Terraform, and handle on-call with PagerDuty. GitHub Actions for CI. SLO definition and incident post-mortem experience expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes on AWS matches the cluster management requirement\",\"Prometheus and Grafana satisfy the monitoring requirements\",\"Python and Go cover the automation scripting requirements\",\"Terraform covers the infrastructure management requirement\",\"GitHub Actions satisfies the CI requirement\"],\"gaps\":[\"No PagerDuty experience for the on-call management requirement\",\"No SLO definition or incident post-mortem process signals\"],\"explanation\":\"The candidate covers the technical SRE tooling requirements well, but PagerDuty is a stated requirement for on-call management and is absent. SLO definition and incident post-mortem experience are also explicitly expected and are not evidenced. These are practice and process gaps beyond tooling that are important for a mid-level SRE role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ryanmoss_dev\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\"],\"tech\":[\"Django\",\"FastAPI\",\"Docker\",\"Kubernetes\",\"AWS\",\"Redis\",\"Nginx\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nWe are a fintech startup building payment infrastructure and need a senior backend engineer with strong Python experience and cloud-native skills. The ideal candidate is comfortable with microservices, has hands-on Kubernetes and AWS experience, writes thorough tests, and can design event-driven systems. PostgreSQL experience is required. We move fast and expect engineers to own features end-to-end.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Senior-level Python engineer with both Django and FastAPI covering framework breadth\",\"Kubernetes and AWS experience directly matches cloud-native requirements\",\"Event-Driven and Microservices architecture align with payment infrastructure design\",\"PostgreSQL listed as primary database satisfying hard requirement\",\"pytest and Locust show both correctness and load-testing awareness\"],\"gaps\":[\"No explicit message queue experience (Kafka, RabbitMQ) which is common in payment event pipelines\"],\"explanation\":\"This candidate maps closely to every stated requirement: Python, Kubernetes, AWS, microservices, event-driven architecture, and PostgreSQL. Load testing with Locust is a strong signal for fintech reliability expectations. The only minor gap is the absence of a dedicated message broker, which is commonly needed in payment event pipelines.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jadelin_codes\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"Firebase\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nGrowing e-commerce company seeks a mid-level frontend engineer to own our React component library and design system. Candidate must be proficient in TypeScript and have experience with state management libraries such as Redux or Zustand. Familiarity with accessibility standards and end-to-end testing with Playwright or Cypress is expected. We use a monorepo managed by Nx and deploy via Vercel.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and TypeScript are present and match the core stack\"],\"gaps\":[\"Junior seniority does not meet mid-level requirement\",\"No state management library (Redux, Zustand, or similar) visible\",\"No end-to-end testing experience with Playwright or Cypress\",\"No Nx monorepo or Vercel experience\",\"No evidence of design system or component library work\"],\"explanation\":\"While the candidate knows React and TypeScript, they fall short on seniority and lack nearly every tooling requirement: state management, E2E testing, and monorepo tooling. The profile is too sparse and too junior to meet the expectations of a mid-level hire owning a component library.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_amara\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"NumPy\",\"MLflow\",\"Docker\",\"FastAPI\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nMid-size analytics company building real-time recommendation systems is hiring an ML engineer. We expect strong Python and PyTorch skills, experience deploying models via REST APIs, and familiarity with experiment tracking. BigQuery is our primary data warehouse. Candidates should be comfortable writing SQL and working in a cloud environment.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch and scikit-learn cover modeling requirements\",\"FastAPI demonstrates REST API model serving\",\"MLflow satisfies experiment tracking requirement\",\"BigQuery matches the data warehouse requirement\",\"SQL and Python are both strong primary tools\"],\"gaps\":[\"No real-time streaming infrastructure (Kafka, Flink, Spark Streaming) despite the role being a real-time recommendation system\",\"No feature store or online feature serving experience for low-latency recommendations\",\"No model serving infrastructure experience (Triton, TorchServe) for high-throughput inference\"],\"explanation\":\"The candidate is well-suited for batch ML workflows but the profile lacks every tool associated with real-time recommendation systems: streaming data pipelines, online feature serving, and high-throughput model inference. These are not minor gaps for a role explicitly focused on real-time recommendations, and the candidate would need significant ramp-up time to contribute to the production system.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devops_felix\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\",\"Go\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"Ansible\",\"AWS\",\"Docker\",\"Prometheus\",\"Grafana\",\"Vault\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitLab CI\",\"Argo CD\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nEnterprise SaaS company seeks a senior DevOps engineer to lead infrastructure-as-code initiatives on AWS using Terraform and Helm. Must have strong Kubernetes administration skills, experience with secrets management, and observability stack experience. GitLab CI is our primary CI/CD platform. Scripting in Bash or Python is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform and Helm satisfy IaC requirements\",\"Kubernetes administration is clearly present\",\"Vault covers secrets management requirement\",\"Prometheus and Grafana form the observability stack\",\"GitLab CI is the primary CI/CD platform\"],\"gaps\":[\"No AWS-specific managed service experience (EKS, RDS, IAM roles) beyond general AWS label \\u2014 a meaningful gap for an enterprise AWS-focused role\",\"Consul is present but may not substitute for AWS-native service discovery in all contexts\",\"Vagrant in the profile suggests some legacy infrastructure context\"],\"explanation\":\"The candidate has strong foundational DevOps skills and matches most stated requirements, but the absence of AWS-specific service depth is a practical concern for an enterprise that relies on managed AWS services like EKS and RDS. General AWS familiarity without explicit managed service experience creates risk for a senior infrastructure hire expected to lead IaC initiatives.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sara_fullstack\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"Node.js\",\"Tailwind CSS\",\"Prisma\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nEarly-stage B2B SaaS startup looking for a full stack engineer who can build and ship features independently. We use Next.js for our frontend and backend API routes, PostgreSQL as our primary database, and Tailwind CSS for styling. You should be comfortable with TypeScript, writing tests, and deploying containerized applications.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js is the candidate's primary framework matching the core stack exactly\",\"PostgreSQL and Prisma together show strong data layer competence\",\"Tailwind CSS matches the styling requirement\",\"TypeScript is the primary language\",\"Jest and Playwright demonstrate both unit and E2E testing ability\",\"Docker satisfies containerized deployment requirement\"],\"gaps\":[],\"explanation\":\"The candidate's profile is a near-perfect match for this role. Every technology mentioned in the job summary is present and prominent in the candidate's stack. Mid-level seniority is appropriate for an early-stage startup expecting independent feature ownership without requiring principal-level experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tomasz_backend\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Maven\",\"Docker\",\"AWS\"],\"databases\":[\"MySQL\",\"PostgreSQL\"],\"ci_cd\":[\"Jenkins\"]}\n\nJob Summary:\nFinancial services firm hiring a backend engineer to maintain and extend a Node.js microservices platform. Must have TypeScript experience and be familiar with event-driven messaging via RabbitMQ or Kafka. Kubernetes experience preferred. We use GitHub Actions for CI/CD and MongoDB for several services.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"General backend engineering experience and SQL proficiency are transferable\",\"Docker experience is relevant to containerized microservices\"],\"gaps\":[\"No Node.js or TypeScript experience \u2014 the job's primary language and runtime\",\"No message queue experience (RabbitMQ or Kafka)\",\"No Kubernetes experience despite it being preferred\",\"No GitHub Actions experience; uses Jenkins instead\",\"No MongoDB experience; only relational databases listed\"],\"explanation\":\"The candidate is a Java/Spring Boot engineer with no visible Node.js or TypeScript background, which is the core technology this role requires. The gaps extend to messaging, orchestration, and CI/CD tooling, making this a poor fit without a significant retraining investment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priya_data\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"Apache Kafka\",\"Airflow\",\"dbt\",\"Docker\",\"AWS\"],\"databases\":[\"Snowflake\",\"PostgreSQL\",\"Redshift\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nRapid-growth marketplace company hiring a senior data engineer to build and maintain our data platform on AWS. Core stack includes Spark for batch processing, Kafka for streaming ingestion, dbt for transformations, and Snowflake as the data warehouse. Airflow is used for orchestration. Strong SQL and Python skills required. Data quality tooling experience is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Apache Spark, Kafka, dbt, Airflow, and Snowflake are all present \u2014 a direct stack match\",\"AWS is the cloud platform in use and is listed in the candidate's profile\",\"Great Expectations satisfies the data quality tooling plus mentioned in the job\",\"Senior seniority matches the role level\",\"Python and SQL are both strong\",\"Scala is a bonus for Spark performance work\"],\"gaps\":[],\"explanation\":\"This is an exceptionally precise match. Every named technology in the job description appears prominently in the candidate's profile, including the bonus data quality requirement. The candidate's seniority and multi-language background make them a compelling pick for building and owning a data platform.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"oliver_mobile\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"TypeScript\"],\"tech\":[\"Flutter\",\"Expo\",\"React Native\",\"Firebase\"],\"databases\":[\"Firebase\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"]}\n\nJob Summary:\nConsumer app startup building a cross-platform fitness app is looking for a mobile engineer comfortable with Flutter. Candidates should have experience integrating Firebase services, shipping to both iOS and Android, and automating mobile builds. Dart is the primary language.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Flutter is the candidate's primary mobile framework matching the requirement\",\"Firebase integration covers backend services\",\"Fastlane demonstrates mobile build automation capability\"],\"gaps\":[\"No explicit iOS or Android native SDK experience (SwiftUI, Jetpack Compose) which matters for edge platform cases\",\"React Native and Expo alongside Flutter suggests breadth without clear specialization depth\"],\"explanation\":\"The candidate has the right primary tools \\u2014 Flutter, Firebase, and Fastlane \\u2014 but the profile shows a spread across multiple mobile frameworks without clear evidence of deep Flutter specialization. A consumer fitness app often requires native integration for health sensors and platform APIs that are not evidenced here.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"new_coder_99\",\"seniority\":\"Intern\",\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"React\",\"Flask\"],\"databases\":[\"SQLite\"]}\n\nJob Summary:\nLarge enterprise bank hiring a staff-level software architect to design distributed systems and lead technical direction across multiple engineering teams. Candidates must have deep experience with cloud infrastructure, event-driven architecture, and service mesh technologies. Strong leadership track record expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Intern seniority is far below the staff-level requirement\",\"No distributed systems or cloud infrastructure experience\",\"No event-driven architecture or service mesh knowledge\",\"No leadership or cross-team technical experience\",\"Tech stack is entry-level and does not overlap with enterprise architecture needs\"],\"explanation\":\"This candidate is at the very beginning of their career and lacks every dimension the role requires: seniority, architectural expertise, cloud infrastructure knowledge, and leadership experience. There is no meaningful overlap with the job's requirements beyond basic programming ability.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lucas_sre\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Prometheus\",\"Grafana\",\"Terraform\",\"AWS\",\"Docker\",\"Datadog\"],\"architecture\":[\"Microservices\",\"Cloud-Native\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nFAANG-adjacent tech company hiring a senior SRE to improve reliability and observability across a large Kubernetes-based infrastructure. Must have strong experience with Prometheus and Grafana, proficiency in Go or Python for tooling, and expertise in Terraform for infrastructure management. Load testing experience is valued.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Prometheus and Grafana match observability requirements directly\",\"Go satisfies the tooling language requirement\",\"Terraform satisfies infrastructure management requirement\",\"Kubernetes is central to the role and clearly present\",\"k6 satisfies load testing requirement\"],\"gaps\":[\"No SLO/error budget tooling or on-call management experience (PagerDuty) visible \\u2014 expected at FAANG-adjacent scale\",\"No distributed tracing experience (Jaeger, Zipkin, OpenTelemetry) which large Kubernetes infrastructures require\",\"No incident management or runbook automation experience evidenced\"],\"explanation\":\"The candidate has strong technical credentials across observability, Go tooling, and Kubernetes, but a FAANG-adjacent SRE role at scale typically requires explicit SLO framework experience, distributed tracing, and on-call engineering practices. These are absent from the profile and represent real gaps at the maturity level the company likely operates.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elena_vue\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\",\"Vite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Cypress\"]}\n\nJob Summary:\nDigital agency building marketing sites and web apps for enterprise clients is looking for a mid-level frontend engineer. Our stack is Vue 3 and Nuxt.js with Pinia for state management. We need someone who writes tests and is comfortable with modern CSS. TypeScript is used across all projects.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Vue.js and Nuxt.js are present and match the agency stack\"],\"gaps\":[\"No accessibility (WCAG) experience \\u2014 a standard requirement for enterprise client work in most markets\",\"No TypeScript depth evidenced despite it being required across all projects\",\"No cross-browser or device compatibility testing experience visible\",\"Profile lacks any enterprise-facing project signals or client delivery experience\"],\"explanation\":\"Despite the Vue and Nuxt stack alignment, the candidate's profile is too thin on enterprise engineering practices for an agency delivering production software to large clients. Accessibility compliance and TypeScript depth are both stated or implied requirements that are not evidenced here.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"bob_embedded\",\"seniority\":\"Senior\",\"roles\":[\"Embedded Engineer\"],\"languages\":[\"C\",\"C++\",\"Python\"],\"tech\":[\"CMake\",\"Docker\"],\"ci_cd\":[\"Jenkins\",\"GitLab CI\"]}\n\nJob Summary:\nIoT startup hiring a senior embedded software engineer to develop firmware for ARM-based edge devices. Candidates should have strong C and C++ skills, experience with RTOS environments, and familiarity with low-level hardware interfaces. Python scripting for tooling is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"C and C++ are primary languages matching firmware development requirements\",\"Senior seniority aligns with role expectations\",\"Python listed as a language satisfying the tooling scripting plus\",\"GitLab CI demonstrates CI/CD pipeline experience in embedded context\"],\"gaps\":[\"No explicit RTOS experience (FreeRTOS, Zephyr, or similar)\",\"No mention of hardware interface protocols (SPI, I2C, UART, CAN)\",\"No ARM-specific toolchain or SDK experience visible\"],\"explanation\":\"The candidate has the right language foundation in C and C++, but the profile lacks the firmware-specific context the role requires: RTOS, hardware protocols, and ARM toolchain experience. These are fundamental for IoT edge firmware development and represent meaningful gaps despite the strong language match.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"aisha_fullstack\",\"seniority\":\"Junior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"Express.js\",\"Flask\",\"Docker\"],\"databases\":[\"MongoDB\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nHealthcare tech company hiring a junior full stack engineer to work on patient-facing web applications. React is used on the frontend and Node.js with Express on the backend. PostgreSQL is the primary database. Candidates should know Git and be comfortable working in a Docker-based development environment.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React matches the frontend requirement\",\"Express.js satisfies the Node.js backend requirement\",\"PostgreSQL is present as a primary database\",\"Docker experience aligns with dev environment expectations\",\"Junior seniority matches the role level\"],\"gaps\":[\"Python and Flask suggest split focus between two backend paradigms which may slow ramp-up on a Node.js-only team\",\"No TypeScript experience, which is common in production React and Node.js applications\",\"No healthcare compliance or security awareness signals\"],\"explanation\":\"The candidate covers the main technologies \u2014 React, Express, and PostgreSQL \u2014 and is appropriately junior. However, the mixed Flask and Express background suggests no deep Node.js specialization yet, and the absence of TypeScript is a practical gap for production codebases. Overall a viable candidate who would need onboarding investment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kai_platform\",\"seniority\":\"Staff\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Istio\",\"AWS\",\"Vault\",\"Consul\",\"Docker\",\"Pulumi\"],\"architecture\":[\"Microservices\",\"Service Mesh\",\"Cloud-Native\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\",\"Flux\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nHigh-scale platform team at a fintech unicorn seeks a staff platform engineer to own the internal developer platform built on Kubernetes. Must have deep knowledge of service mesh technologies, infrastructure-as-code with Terraform, and GitOps practices. Experience with secrets management and multi-tenant cluster design is required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Istio directly satisfies the service mesh requirement\",\"Terraform and Pulumi together show deep IaC expertise\",\"Argo CD and Flux both present demonstrate strong GitOps depth\",\"Vault and Consul satisfy secrets management requirements\",\"Multi-Tenant architecture is listed\",\"Staff seniority appropriate for platform ownership\"],\"gaps\":[\"No observability stack (Prometheus, Grafana, Datadog, OpenTelemetry) visible \\u2014 a significant omission for a platform engineer owning an internal developer platform\",\"No SLO or reliability engineering practices evidenced at the platform level\",\"No developer experience tooling (backstage, port) for internal developer platform context\"],\"explanation\":\"The candidate is technically strong across GitOps, service mesh, and infrastructure-as-code, but the complete absence of an observability stack is a meaningful gap for a staff platform engineer expected to own an internal developer platform. At fintech unicorn scale, observability and reliability engineering are foundational platform responsibilities that cannot be filled quickly.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mei_datascience\",\"seniority\":\"Mid\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"Tableau\",\"Jupyter\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"]}\n\nJob Summary:\nRetail analytics company seeking a data scientist with strong machine learning fundamentals and experience communicating insights to non-technical stakeholders. Python and SQL proficiency required. Experience with BI tools like Tableau or Looker is valued. BigQuery experience is a plus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Tableau and BigQuery present and match stated requirements\",\"Python and SQL are both primary tools\"],\"gaps\":[\"No model deployment or serving experience \\u2014 critical if data scientist is expected to push models to production recommendations\",\"No experiment tracking tooling (MLflow, W&B) suggesting limited production ML experience\",\"scikit-learn only \\u2014 no deep learning or advanced recommendation system modeling experience\",\"R presence suggests academic or statistical background rather than production ML engineering focus\"],\"explanation\":\"The candidate's profile is better suited to a business intelligence or exploratory analytics role than a production recommendation system. The absence of model deployment, experiment tracking, and any advanced recommendation system experience represents fundamental gaps for building real-time product recommendations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nate_react\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"React\",\"Bootstrap\",\"Webpack\"]}\n\nJob Summary:\nProduct startup seeking a mid to senior frontend engineer with strong TypeScript skills to lead the migration of a large React codebase from JavaScript to TypeScript. Experience with modern build tooling (Vite, esbuild), state management (Zustand or Redux), and a testing framework is required. Must be comfortable making architectural decisions independently.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React experience is present and relevant\"],\"gaps\":[\"No TypeScript experience \u2014 the explicit primary requirement for this role\",\"Junior seniority does not match mid-to-senior expectation or architectural decision-making needs\",\"No state management library experience (Zustand or Redux)\",\"No testing framework visible\",\"Webpack is outdated relative to required Vite or esbuild\",\"Bootstrap is not relevant to this role's needs\"],\"explanation\":\"The candidate lacks TypeScript, which is the central skill for a codebase migration role. Combined with junior seniority and the absence of state management and testing experience, this candidate is not positioned to lead the effort described. React familiarity alone is insufficient for this scope.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dev_andreia\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Ruby\",\"SQL\"],\"tech\":[\"Ruby on Rails\",\"Sidekiq\",\"Redis\",\"Docker\",\"AWS\"],\"architecture\":[\"Monolith\",\"Modular Architecture\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"CircleCI\"],\"testing\":[\"RSpec\"]}\n\nJob Summary:\nEstablished SaaS company with a large Rails monolith is hiring a backend engineer to help scale and modularize the codebase. Strong Ruby on Rails experience is required. Familiarity with background job processing, Redis, and PostgreSQL is expected. Must write thorough tests.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Ruby on Rails is the primary framework \\u2014 exact match\",\"Sidekiq for background jobs satisfies that requirement\",\"Redis and PostgreSQL are both listed\",\"RSpec demonstrates testing discipline\"],\"gaps\":[\"No Kubernetes or containerized production orchestration experience if the company plans infrastructure modernization alongside modularization\",\"No performance profiling or database query optimization signals at scale\",\"Modular Architecture is listed but no evidence of module boundary design patterns or bounded contexts\"],\"explanation\":\"The candidate has a solid Rails foundation that directly matches the stated role, but a company scaling and modularizing a Rails monolith typically also needs infrastructure modernization skills. The absence of any cloud-native experience and limited evidence of modularization depth beyond the label are worth noting for a mid-level hire on a platform evolution initiative.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cloud_marcus\",\"seniority\":\"Senior\",\"roles\":[\"Cloud Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"AWS\",\"Terraform\",\"Docker\",\"Lambda\",\"AWS S3\",\"AWS EC2\",\"Cloudwatch\"],\"architecture\":[\"Serverless\",\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nMedia company migrating workloads to GCP is hiring a senior cloud engineer. Must have hands-on GCP experience including BigQuery, Cloud Run, and GCS. Terraform is required for infrastructure-as-code. Python scripting is needed for automation tasks.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Terraform experience is directly applicable regardless of cloud provider\",\"Python scripting satisfies the automation requirement\",\"Strong serverless and cloud-native background is transferable conceptually\"],\"gaps\":[\"No GCP experience \u2014 the job is entirely GCP-specific (BigQuery, Cloud Run, GCS)\",\"All cloud experience is AWS-specific and does not transfer directly\",\"No evidence of GCP IAM, networking, or managed service familiarity\"],\"explanation\":\"Despite strong cloud engineering credentials, the candidate's experience is entirely AWS-focused and the role is explicitly a GCP migration. Terraform and Python are transferable, but the lack of any GCP-specific knowledge \u2014 especially BigQuery and Cloud Run \u2014 creates a significant ramp-up risk for a senior hire leading a migration.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jess_nlp\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"AI Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"LangChain\",\"OpenAI API\",\"FastAPI\",\"Docker\",\"AWS\",\"FAISS\"],\"architecture\":[\"Microservices\",\"RAG\"],\"databases\":[\"PostgreSQL\",\"ChromaDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nAI startup building enterprise search products is hiring a senior ML engineer focused on LLM applications. Must have hands-on LangChain and RAG pipeline experience, familiarity with vector databases, and the ability to deploy models via REST APIs. OpenAI API integration experience required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"LangChain is explicitly present matching requirement directly\",\"RAG listed in architecture confirms pipeline experience\",\"FAISS and ChromaDB provide vector database experience\",\"OpenAI API satisfies integration requirement\",\"FastAPI enables REST API model serving\"],\"gaps\":[\"No LLM evaluation framework experience (RAGAS, LangSmith, TruLens) \\u2014 critical for maintaining enterprise search quality\",\"No production monitoring for AI systems (hallucination detection, latency tracking) visible\",\"No fine-tuning or model customization experience beyond API usage\"],\"explanation\":\"The candidate has the right LLM application building blocks but the profile lacks evidence of production-grade AI quality practices. Enterprise search products require rigorous evaluation pipelines and monitoring to prevent hallucinations and quality degradation, which are not evidenced here. The tooling depth is strong but the production maturity signals are missing.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dario_ios\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Xcode\",\"Fastlane\",\"Firebase\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nConsumer fintech app with 2M+ iOS users seeking a mid-level iOS engineer. Must be proficient in Swift and SwiftUI, experienced with UIKit for legacy view compatibility, and comfortable integrating third-party SDKs. App Store release automation via Fastlane is expected. We use Firebase for analytics and crash reporting.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Swift is the primary language and SwiftUI is the main framework\",\"UIKit is also present for legacy compatibility as required\",\"Fastlane experience directly satisfies release automation expectation\",\"Firebase covers analytics and crash reporting integration\",\"XCTest demonstrates testing discipline\",\"Objective-C is a bonus for older codebase interoperability\"],\"gaps\":[\"No explicit payment SDK integration experience (Stripe, Braintree) which matters for fintech specifically\"],\"explanation\":\"This candidate has a direct technology match for every stated requirement: Swift, SwiftUI, UIKit, Fastlane, and Firebase. The Objective-C background adds value for legacy code. The only fintech-specific gap is payment SDK experience, but this is not a stated requirement and can be acquired quickly.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"greg_php\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"SQL\"],\"tech\":[\"Laravel\",\"Composer\",\"Docker\",\"Nginx\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"GitLab CI\"]}\n\nJob Summary:\nAgency building custom web solutions for SMBs is hiring a backend PHP developer. Laravel is the primary framework. MySQL and Redis are used for persistence and caching. Candidate should be comfortable with Nginx configuration and deploying Docker-based applications.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Laravel is the candidate's primary framework matching the requirement exactly\",\"MySQL and Redis are both listed for persistence and caching\",\"Nginx experience matches web server configuration requirement\",\"Docker covers deployment environment expectations\"],\"gaps\":[\"No testing framework (PHPUnit, Pest) visible \\u2014 a significant omission for an agency delivering client-facing software\",\"No API versioning or REST design experience explicitly evidenced\"],\"explanation\":\"The candidate covers the core Laravel stack well, but the absence of any visible PHP testing experience is a meaningful gap for an agency context where code quality directly impacts client satisfaction and maintenance costs. MySQL, Redis, Nginx, and Docker are all present, making this a partial match held back by the testing gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ximena_android\",\"seniority\":\"Junior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Retrofit\",\"Firebase\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\"]}\n\nJob Summary:\nStartup building a Kotlin-first Android app is hiring a junior Android developer. Jetpack Compose is used for UI. Firebase is integrated for push notifications and remote config. Candidates should be comfortable with REST API integration and writing unit tests. Java knowledge is a plus for legacy module compatibility.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Kotlin and Jetpack Compose match the stated stack\",\"Firebase covers push notifications requirement\"],\"gaps\":[\"Junior seniority means the candidate cannot work independently on production features \\u2014 a significant constraint for a startup with no dedicated Android team\",\"No background service, WorkManager, or complex lifecycle management experience\",\"No performance profiling or memory leak debugging experience for production apps\",\"No App Store release or versioning process experience visible\"],\"explanation\":\"While the technology alignment is solid, junior seniority at a startup building a consumer app with 2M+ users (implied by fitness app scale) creates a meaningful delivery risk. The profile lacks production depth in lifecycle management, performance engineering, and release processes that would be needed for independent contribution.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"patrice_ml\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"TensorFlow\",\"Keras\",\"scikit-learn\",\"Pandas\",\"MLflow\",\"Docker\",\"GCP\"],\"architecture\":[\"Microservices\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nAutomotive company building computer vision systems for ADAS is hiring a senior ML engineer. Must have deep experience with PyTorch and OpenCV, familiarity with model optimization for edge deployment (ONNX, TensorRT), and experience with large-scale dataset management. CUDA programming experience is preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Strong ML engineering background with TensorFlow, Keras, and scikit-learn shows modeling competence\",\"MLflow for experiment tracking is a transferable good practice\"],\"gaps\":[\"No PyTorch experience \u2014 the primary framework for computer vision research\",\"No OpenCV experience \u2014 central to ADAS perception pipelines\",\"No edge deployment tooling (ONNX, TensorRT) which is a core requirement\",\"No CUDA experience despite it being preferred\",\"No computer vision-specific background visible\",\"GCP and BigQuery focus suggests data science rather than edge ML deployment orientation\"],\"explanation\":\"Despite senior ML credentials, this candidate's background is oriented toward data science and general ML rather than the computer vision and edge deployment specialization the role demands. The absence of PyTorch, OpenCV, and any edge optimization tooling represents fundamental gaps for an ADAS computer vision engineer role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tunde_backend\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Gin\",\"FastAPI\",\"Docker\",\"Kubernetes\",\"Redis\",\"AWS\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Supertest\"]}\n\nJob Summary:\nLogistics platform company hiring a backend engineer to work on high-throughput Go microservices. Must be comfortable with Kafka for event streaming, Kubernetes for orchestration, and PostgreSQL. AWS deployment experience required. Event-driven architecture familiarity expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go with Gin is the candidate's primary backend stack \u2014 direct match\",\"Kafka satisfies the event streaming requirement\",\"Kubernetes is present for orchestration\",\"PostgreSQL is listed\",\"AWS experience matches deployment requirement\",\"Event-Driven architecture is explicitly in the profile\"],\"gaps\":[\"No Helm or ArgoCD experience for Kubernetes deployment management\"],\"explanation\":\"The candidate is a strong match across all core requirements: Go microservices with Gin, Kafka for event streaming, Kubernetes, PostgreSQL, and AWS. Event-Driven architecture in the profile directly signals familiarity with the design patterns used. This candidate should be able to contribute immediately.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"laura_qa\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"NestJS\",\"Express.js\",\"Docker\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\",\"Playwright\"]}\n\nJob Summary:\nB2B SaaS startup hiring a backend-focused engineer for their NestJS platform. TypeScript required. Must write integration tests and be comfortable with REST API design. PostgreSQL is the primary database. Redis used for caching and job queues.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"NestJS is the primary backend framework \\u2014 direct match\",\"TypeScript is the primary language\",\"Jest and Supertest demonstrate integration testing capability\",\"PostgreSQL satisfies primary database requirement\"],\"gaps\":[\"No explicit job queue library (BullMQ, Bull) despite Redis being used for queues in this role\",\"No OpenAPI or Swagger documentation experience visible for REST API design\",\"Redis listed but no evidence of advanced Redis usage patterns beyond basic caching\"],\"explanation\":\"The candidate has a good NestJS and TypeScript foundation and satisfies the testing and database requirements. However, the absence of explicit job queue library experience is a real gap given that Redis queues are a stated part of the role. This would require ramp-up time and carries some delivery risk for a startup context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"simone_data\",\"seniority\":\"Senior\",\"roles\":[\"Analytics Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Airflow\",\"Tableau\",\"Looker\",\"Snowflake\",\"dbt\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nInsurance company building a modern analytics stack is hiring a senior analytics engineer. dbt and Snowflake are the core tools. Looker is used for dashboarding. SQL mastery is required. Python scripting for pipeline automation is helpful. Must have experience maintaining production dbt projects.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt is the candidate's primary tool \\u2014 direct match\",\"Snowflake is the primary database\",\"Looker satisfies the dashboarding requirement\",\"SQL is listed as primary language\",\"Python present for pipeline automation\"],\"gaps\":[\"No dbt testing or data quality tooling (Great Expectations, dbt tests) visible \\u2014 a meaningful gap at senior level in production analytics engineering\",\"No CI/CD for dbt deployments or dbt Cloud experience evidenced\",\"Airflow is present but no evidence of complex DAG design or backfill strategies\"],\"explanation\":\"The candidate has strong tooling alignment across dbt, Snowflake, and Looker, but the absence of any visible data quality or testing practice is a notable gap for a senior analytics engineer maintaining production dbt projects. Production analytics engineering at this level is expected to include robust testing and deployment practices.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vlad_rust\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"C++\",\"Python\"],\"tech\":[\"Axum\",\"Tokio\",\"Docker\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Rust unit tests\"]}\n\nJob Summary:\nSystems infrastructure company building a high-performance API gateway in Rust is hiring a mid-level Rust engineer. Must have experience with async Rust and web frameworks. PostgreSQL integration experience is needed. C++ background is a plus for team members contributing to performance-critical shared libraries.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Rust with Axum and Tokio shows async Rust capability\",\"PostgreSQL integration is evidenced\"],\"gaps\":[\"No API gateway design experience (routing, rate limiting, auth middleware, circuit breaking) \\u2014 the core domain knowledge for this role\",\"No distributed tracing or observability tooling (OpenTelemetry, Jaeger) which API gateways require by definition\",\"No load balancing or traffic management experience\",\"No performance benchmarking or profiling experience for high-throughput systems\"],\"explanation\":\"The candidate knows Rust and async web development but lacks the systems engineering knowledge specific to API gateway design. Building a high-performance API gateway requires deep understanding of traffic management, observability, and reliability patterns that go well beyond framework proficiency and are entirely absent from this profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hannah_wordpress\",\"seniority\":\"Mid\",\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"WordPress\",\"Bootstrap\",\"jQuery\"]}\n\nJob Summary:\nFintechstartup hiring a mid-level backend engineer to build scalable payment APIs in Go. Must have experience with gRPC, PostgreSQL, and Kubernetes. Event-driven architecture experience required. Strong understanding of financial transaction systems preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"No Go experience \u2014 the job's primary language\",\"No gRPC or API design experience beyond WordPress\",\"No Kubernetes or cloud infrastructure knowledge\",\"No event-driven architecture experience\",\"No relational database engineering experience at the required level\",\"WordPress/jQuery stack is not transferable to fintech backend API development\"],\"explanation\":\"The candidate's background is entirely in WordPress-based web development and has no overlap with the Go, gRPC, Kubernetes, and event-driven infrastructure the role requires. This is a fundamental skills mismatch across every technical dimension.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"carlos_devops\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"Terraform\",\"AWS\",\"Ansible\",\"GitHub Actions\"],\"ci_cd\":[\"GitHub Actions\",\"CircleCI\"]}\n\nJob Summary:\nMid-size SaaS company hiring a mid-level DevOps engineer to manage CI/CD pipelines and cloud infrastructure on AWS. Terraform is required for infrastructure-as-code. Docker knowledge needed. Ansible for configuration management is a plus. Python or Bash scripting required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform directly satisfies the IaC requirement\",\"AWS is the target cloud platform and is listed\",\"Docker is present for containerization\",\"GitHub Actions matches the CI/CD tooling\",\"Ansible satisfies the configuration management plus requirement\"],\"gaps\":[\"No Kubernetes experience, which is increasingly standard at growing SaaS companies and likely to become required\",\"No observability tooling (Prometheus, Grafana, Datadog) for production monitoring\",\"No secrets management tooling (Vault, AWS Secrets Manager) visible\"],\"explanation\":\"The candidate satisfies every explicitly stated requirement but the profile has meaningful gaps in areas that typically accompany this kind of role: Kubernetes orchestration and production observability. As the company scales, these gaps will likely become blocking, and the absence of both from a mid-level DevOps hire is worth flagging.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ines_frontend\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Angular\",\"NgRx\",\"RxJS\",\"Jest\",\"Tailwind CSS\",\"Storybook\"],\"ci_cd\":[\"Azure Pipelines\"],\"testing\":[\"Jest\",\"Cypress\"]}\n\nJob Summary:\nEnterprise software company building a large-scale Angular application seeks a senior frontend engineer. TypeScript and NgRx for state management are required. Must have experience with component testing and a component library. Azure Pipelines is the CI/CD platform. RxJS proficiency expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Angular is the candidate's primary framework \u2014 exact match\",\"NgRx satisfies the state management requirement\",\"RxJS is explicitly listed\",\"TypeScript is the primary language\",\"Storybook satisfies the component library requirement\",\"Jest and Cypress cover component and E2E testing\",\"Azure Pipelines matches the CI/CD platform\"],\"gaps\":[],\"explanation\":\"This is a near-perfect technology match. Every named requirement \u2014 Angular, NgRx, RxJS, TypeScript, component testing, Storybook, and Azure Pipelines \u2014 is present in the candidate's profile. Senior seniority is appropriate for a large-scale enterprise Angular application.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jerome_backend\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"Celery\",\"Redis\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nEdtech company building a learning management platform seeks a backend engineer with Django experience. Must be comfortable with background tasks via Celery and Redis. PostgreSQL is the primary database. AWS deployment experience needed. Pytest for testing is standard.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Django is the primary framework matching the requirement\",\"Celery and Redis together satisfy the background task requirement\",\"PostgreSQL is listed as primary database\",\"pytest is present for testing\"],\"gaps\":[\"No Django REST Framework (DRF) experience visible \\u2014 critical for building LMS API endpoints\",\"No caching strategy experience beyond Redis presence (cache invalidation, query optimization)\",\"AWS is listed but no specific service experience (S3 for media, SES for email) relevant to edtech platform needs\"],\"explanation\":\"The candidate has a solid Django foundation with Celery and Redis, but the absence of DRF is a meaningful practical gap for an LMS platform that almost certainly exposes a REST API. The AWS gap around media storage and email delivery is also relevant for an edtech context. The match is good but not complete.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"felix_gamedev\",\"seniority\":\"Mid\",\"roles\":[\"Game Developer\"],\"languages\":[\"C++\",\"C#\",\"Lua\"],\"tech\":[\"Unity\",\"Unreal Engine\",\"CMake\"]}\n\nJob Summary:\nMobile gaming studio building casual games seeks a mid-level Unity developer. C# is the primary language. Experience with mobile performance optimization and Unity's asset pipeline required. Familiarity with Lua for scripting is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Unity is the candidate's primary engine matching the requirement\",\"C# is listed as the primary language\",\"Lua satisfies the scripting bonus requirement\"],\"gaps\":[\"No mobile-specific Unity experience (addressables, profiler, texture compression) explicitly evidenced\",\"No performance optimization experience for mobile constraints (60fps on low-end devices)\",\"Unreal Engine experience suggests PC/console focus rather than mobile casual game development\"],\"explanation\":\"The candidate has the right foundational tools \\u2014 Unity, C#, and Lua \\u2014 but the Unreal Engine background and lack of mobile-specific optimization signals suggest a more PC or console-oriented game development focus. Casual mobile gaming has unique performance constraints that are not evidenced in this profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ada_fullstack\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\",\"Solutions Architect\"],\"languages\":[\"TypeScript\",\"Python\",\"Go\"],\"tech\":[\"React\",\"Next.js\",\"FastAPI\",\"Docker\",\"Kubernetes\",\"AWS\",\"Terraform\"],\"architecture\":[\"Microservices\",\"Serverless\",\"Cloud-Native\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nEarly-stage startup building a B2B enterprise product is looking for a founding engineer who can span frontend, backend, and infrastructure. Must be comfortable with React, a Python or Go backend, and AWS deployment. Kubernetes experience preferred. Looking for someone who can make architectural decisions independently.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Full Stack Engineer and Solutions Architect roles show the breadth a founding engineer needs\",\"React and Next.js cover frontend requirements\",\"Both Python (FastAPI) and Go satisfy the backend language requirement\",\"AWS, Kubernetes, and Terraform demonstrate infrastructure ownership capability\",\"Multi-architecture background (Microservices, Serverless, Cloud-Native) supports independent architectural decision-making\",\"Testing coverage across Jest, pytest, and Playwright shows disciplined engineering practice\"],\"gaps\":[\"No CMS or content management experience which early-stage B2B products sometimes need for marketing site ownership\"],\"explanation\":\"This candidate is exceptionally well-suited for a founding engineering role. The breadth of frontend, backend, and infrastructure skills combined with solutions architect experience directly supports the independent decision-making requirement. AWS and Kubernetes are both evidenced. This is a rare profile that matches the role's full scope.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"marco_security\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"AWS\",\"Vault\",\"Terraform\",\"Docker\",\"Kubernetes\",\"Sentry\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nCloud security team at a healthcare company seeking a senior security engineer. Must have experience with secrets management, infrastructure security on AWS, and container security. Familiarity with compliance frameworks (SOC 2, HIPAA) is required. Python or Go scripting for automation is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Vault directly satisfies secrets management requirement\",\"AWS and Terraform together demonstrate cloud infrastructure security competence\",\"Kubernetes experience is relevant to container security\",\"Python and Go both present for security automation scripting\",\"Senior seniority matches the role level\"],\"gaps\":[\"No explicit compliance framework experience (SOC 2, HIPAA) \u2014 a stated requirement for healthcare\",\"No AppSec tooling visible (SAST, DAST, vulnerability scanning)\",\"No identity and access management tooling (IAM, OIDC, SAML) explicitly listed\"],\"explanation\":\"The candidate has strong infrastructure security credentials with Vault, Terraform, and AWS, which cover a significant portion of the role. However, the absence of any visible compliance framework experience is a meaningful gap for healthcare, where HIPAA adherence is non-negotiable. The profile suggests platform security depth but may lack regulatory and application security breadth.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yumi_kotlin\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Spring Boot\",\"Docker\",\"Kubernetes\",\"AWS\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nEuropean fintech company expanding its Spring Boot microservices platform is hiring a mid-level backend engineer. Kotlin is preferred over Java. Must have Kubernetes and AWS experience. JUnit and Mockito for testing are standard. PostgreSQL is the primary database.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin is the preferred language satisfying the preference over Java\",\"Spring Boot is the primary framework \\u2014 direct match\",\"Kubernetes and AWS are both present\",\"JUnit and Mockito satisfy testing requirements\",\"PostgreSQL matches the primary database\"],\"gaps\":[\"No event streaming experience (Kafka, RabbitMQ) \\u2014 commonly required in fintech microservices for transaction events and audit logs\",\"No API security or OAuth2 experience visible despite fintech context requiring authentication compliance\",\"Jenkins is listed alongside GitHub Actions suggesting mixed CI/CD environments that may need consolidation\"],\"explanation\":\"The candidate matches the stated technical requirements well, but for a fintech microservices platform, the absence of event streaming experience is a meaningful practical gap. Financial transaction systems typically rely on Kafka for audit trails and event replay, and this candidate would need onboarding time to contribute to those parts of the platform.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dev_sparse_01\",\"seniority\":\"Junior\",\"languages\":[\"Python\"]}\n\nJob Summary:\nHealthtech startup hiring a mid-level full stack engineer comfortable with React, Node.js, and PostgreSQL. Must have TypeScript experience, write tests, and be comfortable with Docker. Previous experience in regulated industries is a plus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python experience shows programming fundamentals\"],\"gaps\":[\"Junior seniority does not meet mid-level requirement\",\"No React or any frontend experience\",\"No Node.js or backend JavaScript experience\",\"No TypeScript experience\",\"No PostgreSQL or database engineering experience\",\"No testing framework visible\",\"No Docker experience\"],\"explanation\":\"This is a sparse profile with a single language that does not overlap with the job's core stack. The seniority gap compounded by the complete absence of frontend, database, and DevOps experience makes this candidate a poor fit for the role as described.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nina_graphql\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Apollo GraphQL\",\"Next.js\",\"NestJS\",\"Prisma\",\"Docker\",\"AWS\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\",\"Vitest\"]}\n\nJob Summary:\nProduct company building a developer tools platform is hiring a senior full stack engineer. GraphQL with Apollo is the API layer. React and Next.js on the frontend. NestJS on the backend. TypeScript across the stack. PostgreSQL is primary database. Must write comprehensive tests.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Apollo GraphQL directly satisfies the GraphQL API layer requirement\",\"React and Next.js are the frontend stack \u2014 exact match\",\"NestJS on the backend is explicitly present\",\"TypeScript is the primary language across the stack\",\"Prisma with PostgreSQL covers the data layer requirement\",\"Jest, Playwright, and Vitest demonstrate comprehensive testing coverage\"],\"gaps\":[\"No observability or monitoring tooling visible for a developer tools platform\"],\"explanation\":\"The candidate's profile is a precise match for every stated technology: Apollo GraphQL, React, Next.js, NestJS, TypeScript, and PostgreSQL. Three testing frameworks demonstrate exactly the comprehensive testing discipline the job expects. This is an exceptionally strong match for a TypeScript full stack role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"liam_dataeng\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Airflow\",\"Docker\",\"AWS\",\"Pandas\",\"dbt\"],\"databases\":[\"Redshift\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nMedia analytics company hiring a mid-level data engineer. We use Snowflake as our data warehouse and have recently migrated away from Redshift. dbt is used for transformations and Airflow for orchestration. Must be comfortable with Python and SQL. AWS knowledge is helpful for S3 and Glue integrations.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"dbt and Airflow are both present covering transformation and orchestration\",\"Python and SQL are primary languages\"],\"gaps\":[\"No Snowflake experience \\u2014 the company has migrated entirely to Snowflake, making this the primary daily tool\",\"All warehouse experience is in Redshift which is now deprecated in this environment\",\"No streaming pipeline experience visible despite real-time media analytics requirements\",\"No cost optimization or warehouse performance tuning experience in Snowflake context\"],\"explanation\":\"The candidate's data warehouse experience is entirely Redshift-based, which is the platform the company has already moved away from. For a role where Snowflake is the daily tool, the lack of any Snowflake experience represents a significant and immediate productivity gap. dbt and Airflow experience is transferable but insufficient to compensate.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"petra_spring\",\"seniority\":\"Lead\",\"roles\":[\"Backend Engineer\",\"Software Architect\"],\"languages\":[\"Java\",\"Kotlin\",\"Python\"],\"tech\":[\"Spring Boot\",\"Kafka\",\"Docker\",\"Kubernetes\",\"AWS\",\"Terraform\",\"Istio\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Domain-Driven Design\",\"CQRS\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\",\"k6\"]}\n\nJob Summary:\nLarge enterprise logistics company seeking a lead backend engineer and architect to drive the design of their Java microservices platform. Must have Spring Boot expertise, strong Kafka knowledge, and experience with DDD and CQRS patterns. AWS and Kubernetes required. Cassandra experience is a plus for high-write workloads.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Spring Boot is the primary framework \u2014 direct match\",\"Kafka satisfies the event streaming requirement\",\"DDD and CQRS are both listed in architecture \u2014 precise match for design patterns\",\"AWS and Kubernetes are both present\",\"Cassandra satisfies the plus requirement for high-write workloads\",\"Lead seniority and Software Architect role align with driving platform design\",\"Istio adds service mesh depth beyond stated requirements\"],\"gaps\":[\"Python presence may suggest attention split, though Java and Kotlin are clearly primary\"],\"explanation\":\"This candidate is an exceptional fit. Every requirement \u2014 Spring Boot, Kafka, DDD, CQRS, AWS, Kubernetes \u2014 and the bonus requirement of Cassandra are all explicitly evidenced. Lead seniority and a Software Architect role designation directly match the expectation of driving platform design. This is a compelling profile for this position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"remy_nextjs\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"tRPC\",\"Prisma\",\"Tailwind CSS\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nProduct agency building T3-stack applications for startup clients. Stack is Next.js, TypeScript, tRPC, Prisma, Tailwind, and PostgreSQL. Must be able to ship features independently and write integration tests. Mid-level experience expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js is the primary framework\",\"tRPC is explicitly present \u2014 an uncommon and specific match\",\"Prisma with PostgreSQL satisfies the data layer requirement precisely\",\"Tailwind CSS matches the styling requirement\",\"TypeScript is the primary language\",\"Vitest and Playwright demonstrate integration testing capability\"],\"gaps\":[],\"explanation\":\"The candidate is a textbook T3-stack engineer. Next.js, TypeScript, tRPC, Prisma, Tailwind, and PostgreSQL are all present and prominent. The tRPC match is particularly notable as it is a specific and uncommon requirement. This is an exceptional stack alignment for the described role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex_infra\",\"seniority\":\"Senior\",\"roles\":[\"Infrastructure Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Ansible\",\"Docker\",\"Vagrant\",\"Nginx\",\"Apache\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nCloud-native SaaS company hiring a senior infrastructure engineer to manage Kubernetes clusters on AWS using Terraform. Must have strong experience with Helm, GitOps practices, and container orchestration. Observability with Prometheus and Grafana required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Infrastructure engineering background and Docker experience are partially relevant\",\"Ansible shows configuration management familiarity\"],\"gaps\":[\"No Kubernetes experience \u2014 the central requirement for this role\",\"No Terraform experience for infrastructure-as-code\",\"No Helm or GitOps tooling (ArgoCD, Flux) experience\",\"No cloud platform experience (AWS or otherwise) beyond on-premise tools\",\"No Prometheus or Grafana observability experience\",\"Vagrant and Apache suggest an older on-premise or VM-based infrastructure background\"],\"explanation\":\"The candidate's infrastructure background appears to be oriented toward traditional on-premise or VM-based environments rather than cloud-native Kubernetes infrastructure. The absence of Kubernetes, Terraform, Helm, and observability tooling represents fundamental gaps for this role. The tooling mismatch is too significant for a senior hire expected to lead cloud-native operations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fatou_swe\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"Python\",\"TypeScript\"],\"tech\":[\"FastAPI\",\"React\",\"Docker\",\"AWS\",\"Celery\",\"Redis\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Jest\"]}\n\nJob Summary:\nHealthtech company building a telemedicine platform is hiring a full stack engineer. Backend is FastAPI with Python, frontend is React. PostgreSQL is the primary database. Background task processing with Celery is used. AWS for deployment. Must write tests for both frontend and backend.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"FastAPI and Python match the backend requirement precisely\",\"React satisfies the frontend requirement\",\"PostgreSQL is listed as primary database\",\"Celery satisfies the background task processing requirement directly\",\"AWS covers deployment requirement\",\"pytest and Jest demonstrate testing on both backend and frontend\"],\"gaps\":[\"No HIPAA or healthcare compliance signals in the profile\",\"No TypeScript usage in React work explicitly shown\"],\"explanation\":\"The candidate matches every stated technical requirement: FastAPI, React, PostgreSQL, Celery, and AWS, with testing coverage for both layers. Celery is a particularly specific and direct match. The only concerns are implicit: healthcare compliance awareness and whether the React work leverages TypeScript in practice.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"theo_scala\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Scala\",\"Java\",\"Python\"],\"tech\":[\"Apache Spark\",\"Kafka\",\"Akka\",\"Docker\",\"AWS\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"Cassandra\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ScalaTest\"]}\n\nJob Summary:\nStreaming analytics company hiring a senior data platform engineer with Scala and Spark expertise. Kafka for real-time ingestion and Cassandra for time-series storage. AWS deployment. Must have distributed systems experience.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Scala and Apache Spark are the candidate's primary technical foundation \u2014 direct match\",\"Kafka satisfies real-time ingestion requirement\",\"Cassandra satisfies time-series storage requirement\",\"Distributed System architecture confirms relevant design experience\",\"AWS covers deployment requirement\",\"Event-Driven architecture aligns with streaming analytics patterns\"],\"gaps\":[\"No explicit stream processing framework beyond Spark (Flink, Kafka Streams) which is not a gap but a note\"],\"explanation\":\"The candidate is purpose-built for this role. Scala, Spark, Kafka, and Cassandra are all explicitly listed and match every core requirement. Distributed systems architecture experience and event-driven background directly apply to a streaming analytics platform. This is a strong hire with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"will_junior_fe\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Vite\",\"shadcn/ui\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\"]}\n\nJob Summary:\nProductivity SaaS company seeking a junior frontend engineer to build UI components in React with TypeScript. We use Tailwind and shadcn/ui for our component library. Vite is our build tool. Write unit tests with Vitest.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React and TypeScript are the core requirements \u2014 both present\",\"Tailwind CSS matches the styling requirement\",\"shadcn/ui is an uncommon and specific match\",\"Vite is listed as the build tool\",\"Vitest satisfies the testing requirement\",\"Junior seniority matches the role level\"],\"gaps\":[],\"explanation\":\"The candidate is a precise match for every technology named in the job description. The shadcn/ui match is particularly notable given its specificity. Junior seniority is exactly what the company is targeting. This profile is a strong fit with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dan_elixir\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Elixir\",\"JavaScript\",\"SQL\"],\"tech\":[\"Phoenix\",\"Docker\",\"AWS\",\"Oban\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nReal-time collaboration startup hiring a backend engineer with Elixir and Phoenix experience. PostgreSQL as primary database. Background job processing with Oban. Must write tests with ExUnit. AWS deployment.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Elixir is the primary language \\u2014 direct match\",\"Phoenix framework is present\",\"PostgreSQL is the primary database\",\"Oban for background jobs is an exact and specific match\",\"ExUnit satisfies testing requirement\"],\"gaps\":[\"No Phoenix Channels or LiveView experience despite the role being a real-time collaboration startup \\u2014 a significant domain gap\",\"No WebSocket or pub/sub integration experience visible\",\"No distributed Erlang/OTP patterns evidenced for scaling real-time systems\"],\"explanation\":\"While the candidate matches the core Elixir and Phoenix stack, the absence of Phoenix Channels or LiveView experience is a meaningful gap for a real-time collaboration product where these are the primary technical mechanism. Oban is a strong specific match, but the real-time collaboration domain requires more than basic Phoenix knowledge.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sofia_mlops\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"MLflow\",\"Weights & Biases\",\"Docker\",\"Kubernetes\",\"AWS\",\"FastAPI\",\"Ray\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"S3\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nML infrastructure team at a large tech company hiring a senior MLOps engineer. Must have experience with experiment tracking (MLflow or W&B), model serving via REST APIs, and distributed training infrastructure. Kubernetes and AWS are the deployment targets.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"MLflow and Weights and Biases together exceed the experiment tracking requirement\",\"FastAPI enables REST API model serving\",\"Ray satisfies distributed training requirement\",\"Kubernetes and AWS cover deployment targets\"],\"gaps\":[\"No model monitoring or drift detection tooling (Evidently, Arize, Fiddler) \\u2014 critical for production ML at scale\",\"No feature store experience (Feast, Tecton, Hopsworks) which is standard at large tech MLOps teams\",\"No data versioning tooling (DVC, lakeFS) visible\"],\"explanation\":\"The candidate has strong experiment tracking and training infrastructure credentials, but a large tech MLOps team operates at a maturity level where model monitoring, feature stores, and data versioning are standard expectations. The absence of all three is a meaningful gap for a senior MLOps role at that scale, even with strong core tooling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"joel_csharp\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C#\",\"SQL\"],\"tech\":[\"ASP.NET\",\"Entity Framework\",\"Docker\",\"Azure\"],\"databases\":[\"MS SQL Server\",\"PostgreSQL\"],\"ci_cd\":[\"Azure DevOps\"],\"testing\":[\"xUnit\"]}\n\nJob Summary:\nMicrosoft-stack company building enterprise internal tooling is hiring a .NET backend engineer. ASP.NET Core with Entity Framework is the stack. Azure for cloud deployment. Azure DevOps for CI/CD. SQL Server as primary database. Must write unit tests.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"ASP.NET and Entity Framework are the exact stack required\",\"C# is the primary language\",\"MS SQL Server matches the primary database\",\"Azure satisfies cloud deployment requirement\",\"Azure DevOps is the CI/CD platform \u2014 exact match\",\"xUnit satisfies unit testing requirement\"],\"gaps\":[\"No gRPC or SignalR experience for real-time or inter-service communication\"],\"explanation\":\"The candidate matches every named technology: ASP.NET, Entity Framework, C#, SQL Server, Azure, and Azure DevOps. xUnit covers the testing requirement. This is a direct technology alignment for a Microsoft-stack enterprise role with no meaningful gaps relative to stated requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sam_blockchain\",\"seniority\":\"Mid\",\"roles\":[\"Blockchain Engineer\",\"Smart Contract Developer\"],\"languages\":[\"Solidity\",\"TypeScript\",\"Python\"],\"tech\":[\"Hardhat\",\"Ethers.js\",\"OpenZeppelin\",\"Docker\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Hardhat tests\",\"Foundry\"]}\n\nJob Summary:\nDeFi protocol startup hiring a mid-level smart contract developer. Must have Solidity proficiency, experience with Hardhat or Foundry for testing, and knowledge of OpenZeppelin standards. TypeScript for frontend integration scripts.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Solidity is the primary language \\u2014 direct match\",\"Hardhat and Foundry both present covering the testing requirement\",\"OpenZeppelin knowledge satisfies standards requirement\",\"Ethers.js shows on-chain interaction library familiarity\"],\"gaps\":[\"No visible DeFi protocol experience (AMMs, lending, yield farming) which is central to a DeFi startup context\",\"No formal audit or security review experience which DeFi protocols require before deployment\",\"No Layer 2 or cross-chain experience (Optimism, Arbitrum, bridges)\"],\"explanation\":\"The candidate has solid smart contract development fundamentals \\u2014 Solidity, testing frameworks, and OpenZeppelin \\u2014 but lacks evidence of DeFi-specific protocol design experience. A DeFi protocol startup needs engineers who understand financial primitive design and security auditing, which are not visible in this profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kofi_generic\",\"seniority\":\"Mid\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Flask\",\"React\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nHigh-frequency trading firm seeking a mid-level C++ systems engineer. Must have strong understanding of low-latency networking, memory management, and lock-free concurrency patterns. CUDA experience is a plus. Linux systems programming background expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"General software engineering fundamentals are present\"],\"gaps\":[\"No C++ experience \u2014 the primary language for this role\",\"No low-latency or systems programming background\",\"No networking or concurrency experience at the required level\",\"No Linux systems programming signals\",\"No CUDA or GPU computing experience\",\"Web development stack (Flask, React) is entirely irrelevant to HFT systems engineering\"],\"explanation\":\"The candidate has a generalist web development background with no overlap with the specialized systems engineering requirements of a high-frequency trading firm. C++, low-latency networking, memory management, and lock-free concurrency are all absent. This is a fundamental mismatch across the technical domain.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"brigitte_lead\",\"seniority\":\"Lead\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"FastAPI\",\"Docker\",\"AWS\",\"Redis\"],\"architecture\":[\"Microservices\",\"Modular Architecture\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nScaleup SaaS company looking for a tech lead to drive technical decisions across a team of 5 engineers. Stack is React and Next.js on the frontend, FastAPI on the backend, and PostgreSQL on the database. TypeScript and Python are used across the codebase. Must be experienced with microservices and code review practices.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Lead seniority matches the tech lead requirement\",\"React and Next.js cover the frontend stack precisely\",\"FastAPI matches the backend framework\",\"TypeScript and Python are both present as primary languages\",\"PostgreSQL is the primary database\",\"Microservices architecture aligns with the system design context\",\"Comprehensive testing with Jest, pytest, and Playwright demonstrates engineering discipline expected of a lead\"],\"gaps\":[\"No explicit mentorship or team leadership experience signals in the profile\"],\"explanation\":\"The candidate's profile is a precise technology match for every stated requirement. Lead seniority, combined with a diverse testing practice and microservices experience, supports the expectation of driving technical decisions across a team. The lack of explicit leadership signals in the profile is a minor uncertainty but does not undermine the strong overall fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex_devrel\",\"seniority\":\"Senior\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Next.js\",\"FastAPI\",\"Docker\",\"Stripe\",\"Vercel\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\"]}\n\nJob Summary:\nPayment infrastructure company building developer-facing tools is hiring a senior software engineer to own integrations and example apps. Must be comfortable with React and a Python backend. Stripe integration experience is valued. Deployment on Vercel or similar platforms expected. PostgreSQL or Supabase for data.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Stripe is explicitly present \u2014 a specific and direct match for payment infrastructure context\",\"React and Next.js cover the frontend requirement\",\"FastAPI satisfies the Python backend requirement\",\"Vercel is listed as deployment platform\",\"Both PostgreSQL and Supabase are present satisfying either database option\",\"Diverse testing with Jest and pytest shows full-stack testing discipline\"],\"gaps\":[\"No gRPC or webhook handling experience explicitly visible for a developer tools integration context\"],\"explanation\":\"The candidate is an exceptionally well-suited fit. Stripe, React, FastAPI, Vercel, and Supabase/PostgreSQL are all explicitly evidenced and match the role's stated and implied requirements. The Stripe experience is particularly valuable for a payment infrastructure company building developer tools. No meaningful gaps relative to stated requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hiro_tanaka_dev\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"Python\",\"Bash\"],\"tech\":[\"Axum\",\"Tokio\",\"Docker\",\"Kubernetes\",\"AWS\",\"Kafka\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"CQRS\"],\"databases\":[\"PostgreSQL\",\"CockroachDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"Rust unit tests\",\"k6\"]}\n\nJob Summary:\nDistributed systems company building a high-throughput financial ledger is hiring a senior backend engineer. We write everything in Rust and need deep async expertise with Tokio. Kafka for event streaming, CockroachDB for distributed SQL, and Kubernetes for orchestration. CQRS architecture knowledge required. AWS deployment. Must have load testing experience.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Rust with Axum and Tokio is the candidate's primary stack \u2014 precise match for async requirements\",\"Kafka satisfies event streaming requirement directly\",\"CockroachDB is explicitly present \u2014 an uncommon and specific match\",\"CQRS architecture is listed satisfying the design pattern requirement\",\"Kubernetes and AWS cover orchestration and deployment\",\"k6 demonstrates load testing experience for high-throughput validation\"],\"gaps\":[\"No distributed tracing (OpenTelemetry, Jaeger) visible despite financial ledger observability needs\"],\"explanation\":\"This candidate maps precisely to every stated requirement: Rust async with Tokio, Kafka, CockroachDB, CQRS, Kubernetes, and AWS. The CockroachDB match is particularly notable given its specificity. k6 for load testing directly addresses the high-throughput ledger validation need. A compelling fit with no meaningful gaps relative to stated requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sophie_ml_nyc\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"ONNX\",\"FastAPI\",\"Docker\",\"CUDA\",\"OpenCV\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nAutonomous vehicle startup hiring a mid-level ML engineer to build and optimize perception models. PyTorch required. CUDA programming for GPU acceleration expected. OpenCV for image processing pipelines. ONNX for edge deployment optimization. Experience serving models via REST APIs is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch is the primary framework satisfying the modeling requirement\",\"CUDA satisfies GPU acceleration requirement\",\"OpenCV is present for image processing pipelines\",\"ONNX satisfies edge deployment optimization requirement\"],\"gaps\":[\"No ROS or any robotics or autonomous vehicle framework experience \\u2014 a significant domain gap for ADAS perception\",\"No TensorRT or hardware-specific inference optimization for real edge devices\",\"No sensor fusion or point cloud processing experience for LiDAR pipelines\"],\"explanation\":\"The candidate has strong computer vision tool coverage \\u2014 PyTorch, CUDA, OpenCV, and ONNX \\u2014 but the profile lacks any autonomous vehicle domain context. ROS integration, sensor fusion, and hardware-specific inference optimization are practical requirements for ADAS perception work that are entirely absent.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kelvin_odeya\",\"seniority\":\"Junior\",\"languages\":[\"JavaScript\",\"Python\"],\"tech\":[\"React\",\"Flask\",\"Bootstrap\"]}\n\nJob Summary:\nGrowth-stage startup building a developer productivity tool is hiring a senior platform engineer. Must own Kubernetes cluster administration on GCP, write Terraform modules, and design GitOps pipelines with Argo CD. Go is the primary language for internal tooling. Experience with Prometheus, Grafana, and OpenTelemetry required for observability.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Junior seniority is far below the senior platform engineer requirement\",\"No Kubernetes or any container orchestration experience\",\"No Go experience \u2014 the primary tooling language\",\"No GCP or cloud platform experience of any kind\",\"No Terraform or infrastructure-as-code experience\",\"No observability tooling (Prometheus, Grafana, OpenTelemetry) visible\",\"React, Flask, and Bootstrap are entirely irrelevant to a platform engineering role\"],\"explanation\":\"This candidate has no meaningful overlap with the platform engineering role. The profile is junior web development with no cloud, infrastructure, or systems engineering experience. Every core requirement \u2014 Kubernetes, Go, GCP, Terraform, and observability \u2014 is absent.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nadine_frontend\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Zustand\",\"React Query\",\"Tailwind CSS\",\"Radix UI\",\"Storybook\",\"Webpack\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"React Testing Library\",\"Playwright\"]}\n\nJob Summary:\nSaaS company building a complex data visualization dashboard is hiring a senior frontend engineer. React with TypeScript is the stack. State management via Zustand. Data fetching with React Query. Tailwind CSS for styling. Comprehensive component testing with Testing Library and E2E with Playwright. Radix UI for accessible components.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and TypeScript are the core stack and both present\",\"Zustand satisfies state management requirement\",\"React Query satisfies data fetching requirement\",\"Radix UI is explicitly present \\u2014 a specific match\",\"React Testing Library and Playwright together cover testing requirements\"],\"gaps\":[\"No D3.js or data visualization charting library (Recharts, Nivo, Victory) despite this being a data visualization dashboard \\u2014 a central product requirement\",\"Webpack in the profile may indicate unfamiliarity with Vite-based build tooling\",\"No WebSocket or real-time data update experience for live dashboard data feeds\"],\"explanation\":\"The candidate matches the component and state management requirements well but the absence of any charting or data visualization library is a significant gap for a data visualization dashboard product. Radix UI is for layout and accessibility, not charting, and the core differentiating skill for this product type is not evidenced.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dmytro_backend\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"Celery\",\"Redis\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Supertest\"]}\n\nJob Summary:\nLegal tech startup seeking a mid-level backend engineer for their document processing platform. We use NestJS and TypeScript for the backend. PostgreSQL is the primary database. Redis for caching. Background jobs via BullMQ. Must write Jest tests. Familiar with AWS deployment.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"PostgreSQL, Redis, and AWS are present and map to the stack\",\"Background task processing experience with Celery is conceptually transferable\"],\"gaps\":[\"No NestJS or Node.js experience \u2014 the job's primary runtime and framework\",\"No TypeScript experience \u2014 required across the stack\",\"No BullMQ or Bull experience despite Celery being transferable at the concept level\",\"No Jest testing experience; uses pytest which is Python-specific\",\"Python/FastAPI background does not overlap with a TypeScript-first team\"],\"explanation\":\"Despite partial infrastructure overlap (PostgreSQL, Redis, AWS), the candidate's backend experience is entirely Python-based and has no exposure to the Node.js and TypeScript ecosystem the role requires. NestJS, TypeScript, BullMQ, and Jest are all absent, making this a weak match that would require a full stack transition.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amara_swe_berlin\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Express.js\",\"Pinia\",\"Tailwind CSS\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"Vitest\",\"Cypress\"]}\n\nJob Summary:\nEuropean e-commerce company seeking a mid-level full stack engineer. Frontend is Vue 3 and Nuxt.js. Backend API in Express.js with TypeScript. Pinia for state management. PostgreSQL for data. Redis for sessions and caching. GitLab CI is the CI/CD platform. Cypress for E2E tests.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Vue.js and Nuxt.js are the candidate's primary frontend stack \u2014 exact match\",\"Express.js satisfies the backend API requirement\",\"Pinia is explicitly listed for state management\",\"PostgreSQL and Redis both present for data and session caching\",\"GitLab CI is the CI/CD platform \u2014 exact match\",\"Cypress satisfies the E2E testing requirement\",\"TypeScript is the primary language across the stack\"],\"gaps\":[\"No explicit REST API versioning or OpenAPI documentation experience visible\"],\"explanation\":\"The candidate's profile is a precise match for every stated technology in the job description. Vue 3, Nuxt.js, Express.js, Pinia, PostgreSQL, Redis, GitLab CI, and Cypress are all explicitly evidenced. This is a high-confidence hire for this e-commerce stack with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"raj_dataplatform\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"PySpark\",\"dbt\",\"Airflow\",\"Kafka\",\"Docker\",\"GCP\",\"Polars\"],\"databases\":[\"BigQuery\",\"PostgreSQL\",\"Firestore\"],\"ci_cd\":[\"Cloud Build\",\"GitHub Actions\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nMedia streaming company building a real-time and batch data platform on GCP is hiring a senior data engineer. Core stack is PySpark and Kafka for streaming, dbt for transformations, BigQuery as the warehouse, and Airflow for orchestration. Python and SQL required. Great Expectations for data quality.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PySpark satisfies Spark requirement\",\"Kafka is listed for real-time ingestion\",\"dbt and Airflow are both present\",\"BigQuery is the primary warehouse\",\"Great Expectations satisfies data quality requirement\"],\"gaps\":[\"No Google Dataflow experience for GCP-native streaming processing alongside Kafka\",\"No GCP-native orchestration tooling (Cloud Composer) experience beyond Airflow\",\"Firestore in the databases profile suggests application development context not relevant to data engineering\"],\"explanation\":\"The candidate has strong core tooling alignment but lacks GCP-native streaming and orchestration depth. A media streaming company on GCP is likely to use Cloud Composer or Dataflow, and the absence of these native services is a meaningful gap for production GCP data platform work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"li_wei_mobile\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"CoreData\",\"Combine\",\"Fastlane\",\"Firebase\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"Bitrise\",\"Fastlane\"],\"testing\":[\"XCTest\",\"XCUITest\"]}\n\nJob Summary:\nDigital health company with a large iOS user base is hiring a mid-level iOS engineer. Swift and SwiftUI required. UIKit familiarity needed for legacy screens. CoreData for local persistence. Combine for reactive data flows. Must have E2E UI testing experience. Firebase for analytics.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Swift and SwiftUI are the candidate's primary stack\",\"UIKit present for legacy screen compatibility\",\"CoreData satisfies local persistence\",\"Combine is listed for reactive data flows\"],\"gaps\":[\"No HealthKit or health data API integration experience despite the digital health domain\",\"No privacy or HIPAA compliance signals for a health data application\",\"XCUITest present but no performance or accessibility testing for health-critical user flows\"],\"explanation\":\"The candidate covers the iOS technical stack well but lacks any visible experience with health data APIs, which are central to a digital health application. HealthKit integration and healthcare data privacy practices are domain requirements that are not evidenced in this profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ana_clara_br\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Vite\",\"Axios\"]}\n\nJob Summary:\nSeries A startup building a B2B analytics product is hiring a mid-level frontend engineer. React with TypeScript required. Must have experience with D3.js or Recharts for data visualization. State management via Redux or Zustand. Must write tests with Jest and Testing Library. Comfortable with RESTful API integration.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and TypeScript are present matching the core framework requirement\"],\"gaps\":[\"Junior seniority does not meet mid-level requirement\",\"No D3.js or Recharts experience \u2014 central to a data visualization product\",\"No state management library (Redux or Zustand) listed\",\"No testing experience (Jest, Testing Library) visible\",\"Profile is sparse and does not evidence the depth expected at mid level\"],\"explanation\":\"The candidate has React and TypeScript basics but lacks every specialized requirement for a data visualization product: charting libraries, state management, and testing. The seniority gap compounds the technical gaps, making this a poor fit for a mid-level analytics product role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ben_devops_au\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\",\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"AWS\",\"Prometheus\",\"Grafana\",\"OpenTelemetry\",\"PagerDuty\",\"Datadog\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nFAANG-scale company hiring a senior SRE to own reliability for a microservices platform on AWS. Must define SLOs and error budgets, build observability with Prometheus, Grafana, and OpenTelemetry, manage incident response with PagerDuty, and conduct load testing. Kubernetes and Terraform expertise required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Prometheus, Grafana, and OpenTelemetry together satisfy the full observability stack\",\"PagerDuty is explicitly listed for incident response\",\"Kubernetes and Terraform cover orchestration and IaC\",\"k6 satisfies load testing requirement\"],\"gaps\":[\"No explicit SLO framework or error budget tooling (Sloth, OpenSLO, Nobl9) \\u2014 a stated expectation for FAANG-adjacent reliability engineering\",\"No chaos engineering experience expected at this scale for proactive reliability testing\",\"No capacity planning or cost optimization tooling visible for large infrastructure management\"],\"explanation\":\"The candidate has strong observability and incident response tooling, but a FAANG-adjacent SRE role at scale typically requires explicit SLO framework implementation experience, chaos engineering practices, and capacity planning \\u2014 none of which are evidenced. The technical foundation is solid but the SRE practice depth is uncertain.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fatima_backend_fr\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Kafka\",\"Docker\",\"AWS\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nLogistics platform scaling its Go-based microservices backend is hiring a mid-level engineer. Go is the primary language and Gin is the main HTTP framework. PostgreSQL and Redis required. Kubernetes and Helm for deployment. GitHub Actions for CI/CD. Event-driven patterns using NATS.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Microservices and Event-Driven architecture experience is transferable\",\"PostgreSQL and Redis are both present\"],\"gaps\":[\"No Go experience \u2014 the job's primary language\",\"No Gin or any Go web framework experience\",\"No Kubernetes or Helm experience for deployment\",\"No NATS experience; Kafka messaging is not directly transferable to NATS\",\"No GitHub Actions experience; uses Jenkins instead\"],\"explanation\":\"The candidate has strong Java microservices experience but no exposure to Go, which is the primary language for this role. The infrastructure gaps in Kubernetes and NATS compound the language mismatch. Despite architecture and database overlap, this candidate would require a full language transition to contribute effectively.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"oskar_fullstack\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"Django\",\"Docker\",\"AWS\",\"GraphQL\",\"Prisma\"],\"architecture\":[\"Serverless\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nE-learning startup hiring a senior full stack engineer. Frontend is React and Next.js. Backend is Django with Python. GraphQL API layer. PostgreSQL as primary database. AWS deployment with some serverless Lambda functions. Comprehensive testing required across the stack.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Next.js match the frontend requirement\",\"Django satisfies the Python backend requirement\",\"PostgreSQL is the primary database\",\"AWS and Serverless satisfy deployment requirements\",\"Comprehensive testing across Jest, pytest, and Playwright\"],\"gaps\":[\"No Apollo Client or Graphene for Django \\u2014 specific GraphQL implementation libraries matter at scale\",\"No explicit Django REST Framework or graphene-django experience for the GraphQL server layer\",\"DynamoDB in profile is inconsistent with the PostgreSQL-first job requirement\"],\"explanation\":\"The candidate has broad stack alignment but the GraphQL match is generic. The specific server (Graphene for Django) and client (Apollo) libraries are not evidenced, and the DynamoDB presence alongside PostgreSQL suggests mixed data modeling experience that may not map cleanly to this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"chan_ml_sg\",\"seniority\":\"Senior\",\"roles\":[\"AI Engineer\",\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"LangChain\",\"LangGraph\",\"OpenAI API\",\"Ollama\",\"FastAPI\",\"Docker\",\"Weaviate\",\"ChromaDB\",\"MLflow\"],\"architecture\":[\"RAG\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Weaviate\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nEnterprise AI company building agentic workflows for business automation is hiring a senior AI engineer. Must have LangChain and LangGraph experience for orchestrating multi-step agents. RAG pipeline expertise required. Vector database experience (Weaviate or Pinecone). FastAPI for service deployment. OpenAI API integration experience.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LangChain and LangGraph are both explicitly present \u2014 direct match for agentic workflow orchestration\",\"RAG architecture is listed confirming pipeline experience\",\"Weaviate satisfies the vector database requirement precisely\",\"OpenAI API integration is listed\",\"FastAPI covers the service deployment requirement\",\"MLflow adds experiment tracking maturity\",\"Ollama shows local model deployment capability beyond cloud APIs\"],\"gaps\":[\"No evaluation framework for agentic systems (LangSmith, RAGAS) visible\"],\"explanation\":\"The candidate is purpose-built for this role. LangChain, LangGraph, RAG, Weaviate, OpenAI API, and FastAPI are all explicitly evidenced. The LangGraph match is particularly specific and uncommon. Ollama adds flexibility for self-hosted model scenarios. This is a compelling hire for an enterprise agentic AI platform.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nia_android\",\"seniority\":\"Mid\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Hilt\",\"Retrofit\",\"Room\",\"Coroutines\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Espresso\",\"Mockito\"]}\n\nJob Summary:\nFintech app with 5M Android users hiring a mid-level Android engineer. Kotlin required. Jetpack Compose for modern UI. Hilt for dependency injection. Retrofit for API calls. Room for local database. Coroutines for async. Must write UI tests with Espresso.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin and Jetpack Compose match the core stack\",\"Hilt listed for dependency injection \\u2014 a specific match\",\"Retrofit satisfies API integration requirement\",\"Room covers local database requirement\",\"Coroutines present for async\"],\"gaps\":[\"No payment SDK experience for a fintech application\",\"No certificate pinning or security hardening experience visible for a financial app with 5M users\",\"No performance testing for high-load fintech transaction flows\"],\"explanation\":\"The candidate covers the standard Android technology stack well, but a fintech app with 5M users requires payment SDK integration and security hardening that are not evidenced. These are domain-critical requirements that represent practical delivery risk for the fintech context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mikkel_fe\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Redux\",\"Material-UI\",\"Webpack\",\"Axios\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"Jest\",\"Enzyme\"]}\n\nJob Summary:\nGrowing startup building a project management tool is hiring a mid-level frontend engineer. React with TypeScript. State management with Zustand. Tailwind CSS for styling. Vite for building. Tanstack Query for data fetching. Must test with Vitest and React Testing Library.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React is the primary framework and TypeScript is present\",\"State management experience with Redux is transferable to Zustand\",\"Jest testing background is partially transferable to Vitest\"],\"gaps\":[\"No Zustand experience; Redux patterns differ meaningfully in API and philosophy\",\"No Tailwind CSS experience \u2014 uses Material-UI instead\",\"No Vite experience; uses Webpack which has a different configuration model\",\"No Tanstack Query experience for data fetching\",\"Enzyme is deprecated and React Testing Library represents a different testing paradigm\",\"No GitHub Actions experience; uses Jenkins\"],\"explanation\":\"The candidate has React and TypeScript basics but most of the specific tooling has changed since their experience was formed. Redux, Webpack, Material-UI, and Enzyme are all older patterns that don't translate directly to the startup's modern stack. The core framework overlap is real but every supporting tool requires a significant shift.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pierre_infra\",\"seniority\":\"Senior\",\"roles\":[\"Infrastructure Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"Terraform\",\"Ansible\",\"Kubernetes\",\"Helm\",\"Docker\",\"Azure\",\"Prometheus\",\"Grafana\",\"Vault\"],\"architecture\":[\"Cloud-Native\",\"Multi-Tenant\"],\"ci_cd\":[\"Azure DevOps\",\"GitHub Actions\"],\"testing\":[\"Terratest\"]}\n\nJob Summary:\nEuropean fintech company with a large Azure-based infrastructure is hiring a senior infrastructure engineer. Terraform and Ansible required for IaC and configuration management. Kubernetes and Helm for workload orchestration. Azure is the cloud. Vault for secrets management. Prometheus and Grafana for observability.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform and Ansible satisfy IaC and configuration management\",\"Kubernetes and Helm cover workload orchestration\",\"Vault satisfies secrets management requirement\",\"Prometheus and Grafana match the observability stack\",\"Azure is listed as the cloud platform\"],\"gaps\":[\"No Azure-native managed service experience (AKS, Azure Monitor, Azure AD) beyond the general Azure label\",\"No Azure Bicep or ARM template experience for Azure-specific IaC\",\"Multi-Tenant architecture is listed but no Azure-specific multi-tenant design evidenced\"],\"explanation\":\"The candidate has strong cloud-agnostic infrastructure skills but the profile shows limited Azure-specific depth. For a large fintech Azure infrastructure, understanding Azure-managed services, native identity, and Azure-specific networking is important beyond Terraform and Kubernetes knowledge.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mia_fullstack_ph\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Express.js\",\"Prisma\",\"Docker\",\"Vercel\",\"Stripe\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nB2C SaaS startup with a subscription model is hiring a full stack engineer. React frontend with TypeScript. Node.js backend with Express. Prisma ORM with PostgreSQL. Stripe for billing and subscription management. Vercel deployment. Redis for caching. Must write backend integration tests.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React with TypeScript covers the frontend requirement\",\"Express.js satisfies the Node.js backend requirement\",\"Prisma with PostgreSQL is an exact ORM and database match\",\"Stripe is explicitly listed for billing\",\"Vercel satisfies deployment requirement\"],\"gaps\":[\"No webhook handling or idempotency pattern experience \\u2014 essential for reliable Stripe subscription management\",\"No background job processing for subscription lifecycle events (renewal, cancellation)\",\"No Stripe test mode or payment flow testing experience evidenced\"],\"explanation\":\"The candidate has a strong core stack match with Stripe listed explicitly, but subscription billing requires careful webhook handling and event-driven lifecycle management that is not evidenced. Webhook idempotency and background job processing for subscription events are real gaps for a production billing system.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yusuf_data_analyst\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Tableau\",\"Power BI\",\"Pandas\",\"Jupyter\"],\"databases\":[\"PostgreSQL\",\"MySQL\"]}\n\nJob Summary:\nRapid-growth fintech hiring a senior data engineer to build and own the streaming data pipeline on AWS. Must have Kafka and Apache Flink experience for real-time processing. Spark for batch. dbt for transformations and Snowflake as the warehouse. Python and Scala required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and SQL are present but not at the engineering depth required\"],\"gaps\":[\"Mid-level data analyst seniority does not meet senior data engineer requirement\",\"No Kafka or any streaming experience\",\"No Apache Flink or Spark experience\",\"No dbt experience\",\"No Snowflake experience\",\"No Scala knowledge\",\"No AWS data services experience\",\"BI tools (Tableau, Power BI) are not relevant to pipeline engineering\"],\"explanation\":\"The candidate is a business-facing data analyst, not a data engineer. The roles are fundamentally different \u2014 this candidate consumes data while the job requires building the pipelines that produce it. No streaming, Spark, dbt, or warehouse engineering experience is present, making this a role mismatch rather than a skill gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"chloe_sre_lon\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Prometheus\",\"Grafana\",\"Datadog\",\"AWS\",\"Docker\",\"Ansible\"],\"architecture\":[\"Microservices\",\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nMid-size SaaS company hiring a senior SRE to improve availability and incident response. AWS infrastructure. Kubernetes for container orchestration. Terraform for IaC. Observability with Prometheus and Grafana. Python or Go for automation. On-call experience and familiarity with incident management required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes and Terraform satisfy orchestration and IaC\",\"Prometheus and Grafana match the observability stack\",\"AWS is the target cloud\",\"Python and Go available for automation\",\"Datadog adds observability breadth\"],\"gaps\":[\"No PagerDuty or any incident management tooling despite on-call experience being a stated requirement\",\"No load testing tooling for availability work at a SaaS company\",\"No chaos engineering or game-day exercise experience evidenced\"],\"explanation\":\"The candidate covers the core infrastructure and observability requirements, but the absence of any incident management tooling is a direct gap for a stated requirement. An SRE role with on-call responsibilities requires explicit incident response and management tooling experience that is not evidenced.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tomas_fullstack_cz\",\"seniority\":\"Junior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Express.js\",\"Docker\",\"Prisma\"],\"databases\":[\"PostgreSQL\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nSeed-stage startup hiring a junior full stack engineer to help build an MVP. Stack is Next.js, TypeScript, and PostgreSQL with Prisma. Docker for dev environments. GitHub Actions for CI. Looking for someone who moves fast and can learn on the job.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Next.js and TypeScript match the core stack\",\"Prisma with PostgreSQL covers the data layer\",\"Docker and GitHub Actions cover dev and CI requirements\",\"Junior seniority aligns with the role\"],\"gaps\":[\"No testing framework visible \\u2014 even an MVP benefits from basic test coverage and the absence is a concern for code quality habits\",\"No state management or complex frontend data flow experience visible\",\"Express.js presence suggests possible confusion between Next.js API routes and separate server architectures\"],\"explanation\":\"The candidate has a good technology alignment for an MVP stack but the complete absence of testing experience is a meaningful gap, even for a fast-moving seed-stage startup. Code quality habits established early in a startup tend to persist, and the absence of any testing practice is a risk for a solo or small team.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leon_ml_de\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"Jupyter\",\"Matplotlib\",\"Tableau\"],\"databases\":[\"PostgreSQL\",\"MySQL\"]}\n\nJob Summary:\nRobotics company building an autonomous inspection system is hiring an ML engineer. PyTorch required for deep learning model development. CUDA for GPU acceleration. OpenCV for computer vision pipelines. ONNX for hardware deployment. Must have experience with real-world sensor data (LiDAR, cameras).",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and scikit-learn show general ML familiarity\"],\"gaps\":[\"No PyTorch experience \u2014 the required deep learning framework\",\"No CUDA experience for GPU acceleration\",\"No OpenCV or any computer vision experience\",\"No ONNX or edge/hardware deployment experience\",\"No sensor data (LiDAR, camera) processing experience\",\"R and visualization tools (Matplotlib, Tableau) suggest a statistical analysis rather than production ML engineering background\"],\"explanation\":\"The candidate has a statistical/analytical ML background that does not transfer to computer vision and robotics. The absence of PyTorch, CUDA, OpenCV, and ONNX represents every core technical requirement for this role. This is a fundamental domain mismatch between applied statistics and embedded computer vision engineering.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priscilla_sec\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\",\"AppSec Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Burp Suite\",\"OWASP ZAP\",\"Semgrep\",\"AWS\",\"Docker\",\"Kubernetes\",\"Vault\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nCloud-native startup hiring a senior application security engineer to embed in the engineering team. Must conduct security reviews of Go and Python codebases, integrate SAST tools (Semgrep preferred) into CI/CD, perform DAST with OWASP ZAP or Burp Suite, and manage secrets with Vault. AWS and Kubernetes security experience expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Semgrep satisfies SAST requirement with preferred tool match\",\"OWASP ZAP and Burp Suite together cover DAST requirement\",\"Vault satisfies secrets management\",\"Go and Python proficiency enables codebase security review\"],\"gaps\":[\"No threat modeling framework (STRIDE, PASTA) experience visible \\u2014 expected for an embedded AppSec engineer\",\"No compliance framework experience (SOC 2, ISO 27001, OWASP ASVS) for a startup approaching certification\",\"No dependency vulnerability management tooling (Dependabot, Snyk) explicitly evidenced\"],\"explanation\":\"The candidate has strong practical security tooling coverage but the profile lacks the security governance and compliance depth expected of a senior AppSec engineer embedded in an engineering team. Threat modeling and compliance framework knowledge are standard expectations not evidenced here.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dev_anon_sparse\",\"seniority\":\"Junior\",\"languages\":[\"Python\",\"JavaScript\"]}\n\nJob Summary:\nAdtech company building a real-time bidding system is hiring a senior backend engineer. Requires deep expertise in low-latency Go services, Redis for caching and pub/sub, Kafka for bid event streaming, and PostgreSQL. Must have experience with high-concurrency system design and Kubernetes deployment. Load testing with k6 or Locust expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Junior seniority is far below the senior requirement for high-stakes adtech systems\",\"No Go experience \u2014 the primary language for low-latency service development\",\"No Redis, Kafka, or any streaming infrastructure experience\",\"No Kubernetes or cloud deployment experience\",\"No high-concurrency or real-time system design experience\",\"No load testing experience\",\"Profile is sparse with only two general-purpose languages\"],\"explanation\":\"This sparse junior profile has no overlap with a senior low-latency systems engineering role. High-concurrency adtech bidding systems require deep distributed systems expertise that is entirely absent. This is both a seniority mismatch and a complete technical domain mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ibrahim_go\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Fiber\",\"Docker\",\"AWS\",\"Redis\",\"gRPC\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Go unit tests\",\"Supertest\"]}\n\nJob Summary:\nFinancial data API company hiring a mid-level backend engineer. Core stack is Go with Gin as the HTTP framework. gRPC for internal service communication. PostgreSQL as primary database. Redis for rate limiting. AWS deployment. Must have microservices experience.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go is the primary language \u2014 direct match\",\"gRPC experience satisfies internal service communication requirement\",\"PostgreSQL is listed as primary database\",\"Redis present for rate limiting use case\",\"AWS and microservices architecture both evidenced\"],\"gaps\":[\"Uses Fiber instead of Gin \u2014 different HTTP framework philosophy and API surface, some ramp-up required\",\"No Helm or Kubernetes experience for production Go service deployment\",\"No explicit financial data or API rate limiting design patterns visible\"],\"explanation\":\"The candidate has Go backend fundamentals and gRPC, which are core requirements, but the framework mismatch (Fiber vs. Gin) is a minor practical gap. The absence of Kubernetes experience for a financial API company deploying on AWS is a more meaningful concern for production readiness. Overall a viable candidate with some ramp-up needed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"emilia_lead_swe\",\"seniority\":\"Lead\",\"roles\":[\"Full Stack Engineer\",\"Software Architect\"],\"languages\":[\"TypeScript\",\"Python\",\"Go\"],\"tech\":[\"React\",\"Next.js\",\"FastAPI\",\"GraphQL\",\"Docker\",\"Kubernetes\",\"AWS\",\"Terraform\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Domain-Driven Design\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"Elasticsearch\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\",\"k6\"]}\n\nJob Summary:\nScaleup hiring a tech lead architect to own the technical roadmap across a full stack platform. Must be comfortable with React and a Python backend, GraphQL API design, Kubernetes infrastructure, and event-driven patterns. Domain-driven design experience valued. AWS required. Must define testing standards across the team.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Lead seniority and Software Architect role directly match ownership expectations\",\"React and Next.js cover the frontend requirement\",\"FastAPI satisfies the Python backend requirement\",\"GraphQL is explicitly listed for API design\",\"Kubernetes and AWS satisfy infrastructure requirements\",\"Event-Driven architecture and Domain-Driven Design are both listed satisfying stated and valued requirements\",\"Four testing frameworks (Jest, pytest, Playwright, k6) demonstrate the testing standards leadership the role requires\"],\"gaps\":[\"No explicit product or roadmap communication tooling visible beyond technical signals\"],\"explanation\":\"The candidate's profile satisfies every technical requirement at a Lead and Architect level. GraphQL, DDD, event-driven architecture, Kubernetes, and multi-layer testing all appear explicitly. The breadth of testing frameworks is a particularly strong signal for defining team-wide standards. An exceptional match for a technical leadership role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sunny_flutter\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"JavaScript\"],\"tech\":[\"Flutter\",\"Firebase\",\"Riverpod\",\"Dio\",\"Hive\"],\"databases\":[\"Firebase\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"Flutter test\",\"Integration tests\"]}\n\nJob Summary:\nConsumer marketplace app building a cross-platform shopping experience is hiring a mid-level Flutter developer. Dart required. Firebase for backend services. Riverpod for state management. Dio for HTTP networking. Must have integration test experience and Fastlane for release automation.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Flutter and Dart are the primary framework and language \\u2014 exact match\",\"Riverpod listed for state management \\u2014 a specific match\",\"Dio satisfies HTTP networking requirement\",\"Fastlane covers release automation\"],\"gaps\":[\"No crash reporting or analytics SDK experience for a consumer marketplace at scale\",\"No deep link or push notification implementation experience for a shopping app retention flow\",\"No payment integration experience for a marketplace with transactions\"],\"explanation\":\"The candidate's Flutter technical stack aligns precisely with stated requirements, but a consumer marketplace application has practical domain requirements around crash monitoring, push notifications, and payment processing that are absent. These are not stated requirements but represent real production readiness gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"victor_node\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Express.js\",\"Socket.io\",\"Redis\",\"Docker\",\"AWS\"],\"databases\":[\"MongoDB\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Mocha\",\"Chai\"]}\n\nJob Summary:\nCollaborative document editing startup seeking a backend engineer with NestJS experience and strong TypeScript skills. PostgreSQL as primary database. Redis for pub/sub and caching. GraphQL API. BullMQ for job queues. Must write Jest tests.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript is listed as a language covering the typing requirement\",\"Redis and PostgreSQL are both present\",\"AWS and Docker show deployment familiarity\",\"Socket.io experience is relevant background for a real-time collaboration product\"],\"gaps\":[\"No NestJS experience \u2014 the stated primary framework; Express knowledge only partially transfers\",\"No GraphQL experience \u2014 the API layer requirement is absent\",\"No BullMQ or explicit job queue library experience\",\"No Jest experience; Mocha and Chai are older testing patterns\",\"MongoDB as primary database suggests limited relational database depth\"],\"explanation\":\"The candidate has Node.js backend and real-time experience but the specific tooling required \u2014 NestJS, GraphQL, BullMQ, and Jest \u2014 are all absent. Socket.io experience is a genuine asset for a collaboration product, but the framework and API layer gaps require meaningful ramp-up time for a production NestJS GraphQL system.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"grace_platform\",\"seniority\":\"Staff\",\"roles\":[\"Platform Engineer\",\"Infrastructure Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Docker\",\"AWS\",\"Prometheus\",\"Grafana\",\"OpenTelemetry\",\"Argo CD\",\"Backstage\"],\"architecture\":[\"Cloud-Native\",\"Microservices\",\"Multi-Tenant\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\",\"Tekton\"],\"testing\":[\"Terratest\",\"k6\"]}\n\nJob Summary:\nLarge technology company building an internal developer platform is hiring a staff platform engineer. Kubernetes expertise and Terraform required. Backstage for developer portal. Observability with Prometheus, Grafana, and OpenTelemetry. GitOps via Argo CD. Multi-tenant cluster design. Go for internal tooling.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Backstage is explicitly listed \u2014 satisfying the developer portal requirement precisely\",\"Kubernetes, Terraform, and Helm form the infrastructure core \u2014 all present\",\"Prometheus, Grafana, and OpenTelemetry together satisfy the full observability requirement\",\"Argo CD satisfies the GitOps requirement\",\"Multi-Tenant architecture is listed for cluster design experience\",\"Go is available for internal tooling\",\"Staff seniority matches the level of platform ownership expected\"],\"gaps\":[\"No service mesh (Istio, Linkerd) experience visible for advanced cluster networking\"],\"explanation\":\"The candidate is an exceptional match. Every named requirement \u2014 Backstage, Kubernetes, Terraform, Prometheus, Grafana, OpenTelemetry, Argo CD, and multi-tenant design \u2014 is explicitly evidenced. Backstage is a particularly specific and uncommon match for a developer portal requirement. Staff seniority and Terratest discipline round out this profile as a strong hire.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"soren_data\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"dbt\",\"Airflow\",\"Docker\",\"AWS\",\"Pandas\",\"Dagster\"],\"databases\":[\"Snowflake\",\"PostgreSQL\",\"Redshift\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nSaaS analytics company hiring a mid-level data engineer. dbt and Airflow or Dagster for orchestration. Snowflake as the data warehouse. AWS infrastructure. Python and SQL required. Data quality tooling expected. Experience with both Redshift and Snowflake is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt and Airflow both present as core tools\",\"Dagster adds orchestration redundancy beyond stated requirements\",\"Snowflake is the primary warehouse\",\"Great Expectations covers data quality\",\"Python and SQL are primary languages\"],\"gaps\":[\"No streaming or real-time pipeline experience (Kafka, Flink, Kinesis) for a SaaS analytics company likely needing real-time dashboards\",\"No data modeling or dimensional design experience explicitly evidenced beyond dbt usage\",\"No cost optimization or warehouse performance tuning experience visible\"],\"explanation\":\"The candidate satisfies the batch data engineering requirements but a SaaS analytics company building dashboards for customers typically requires some streaming or near-real-time pipeline capability. The absence of any streaming tooling is a notable gap for the broader data platform responsibilities.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kenji_swe_jp\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Maven\",\"Docker\",\"AWS\",\"RabbitMQ\"],\"architecture\":[\"Monolith\",\"Layered Architecture\"],\"databases\":[\"MySQL\",\"Redis\"],\"ci_cd\":[\"Jenkins\"]}\n\nJob Summary:\nFast-growing startup migrating to a Kubernetes-based microservices platform built in Go. Seeking a mid-to-senior backend engineer comfortable with Go, gRPC, PostgreSQL, and Kafka. GitOps with Argo CD is standard. Microservices and event-driven architecture experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Strong backend engineering background and distributed systems concepts are broadly transferable\"],\"gaps\":[\"No Go experience \u2014 the job's primary language for all services\",\"No gRPC experience; uses RabbitMQ which is a different messaging paradigm\",\"No PostgreSQL experience; uses MySQL which differs in production patterns\",\"No Kubernetes or cloud-native orchestration experience\",\"No Argo CD or GitOps experience\",\"Monolith and Layered Architecture background is the opposite of the microservices migration target\",\"Jenkins CI/CD does not align with GitHub Actions or Argo CD expected tooling\"],\"explanation\":\"This candidate is a solid Java monolith engineer but lacks every technical requirement for a Go microservices migration role. The language, architecture paradigm, CI/CD tooling, and messaging stack all differ from what the job requires. The transition would require rebuilding foundational knowledge rather than extending existing skills.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leila_ml_ops\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"MLflow\",\"Weights & Biases\",\"Ray\",\"Kubernetes\",\"Docker\",\"FastAPI\",\"AWS\",\"Seldon Core\"],\"databases\":[\"PostgreSQL\",\"S3\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nAI infrastructure team at a large enterprise is hiring a senior ML engineer to own model deployment and serving infrastructure. Must have experience with model serving platforms (Seldon, BentoML, or Triton), Kubernetes for orchestration, Ray for distributed training, and MLflow or Weights and Biases for experiment tracking. AWS required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Seldon Core satisfies the model serving platform requirement precisely\",\"Kubernetes satisfies orchestration\",\"Ray satisfies distributed training\",\"MLflow and Weights and Biases exceed experiment tracking requirement\",\"AWS is listed\"],\"gaps\":[\"No feature store experience (Feast, Tecton, Hopsworks) \\u2014 standard at enterprise ML teams\",\"No model monitoring or drift detection tooling (Evidently, Arize) for post-deployment reliability\",\"No data versioning tooling (DVC, lakeFS) for reproducibility at enterprise scale\"],\"explanation\":\"The candidate has strong model deployment credentials but an enterprise ML team operates with feature stores, model monitoring, and data versioning as table stakes. The absence of all three represents meaningful gaps for a senior MLOps role expected to own the full ML lifecycle.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"erika_frontend_se\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Remix\",\"Tailwind CSS\",\"Vite\",\"Zustand\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nContent platform startup building a creator tools suite is hiring a frontend engineer. Stack is Remix with React and TypeScript. Tailwind for styling. Zustand for state management. Vite for build tooling. Must write E2E tests with Playwright.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Remix is the primary framework and is explicitly listed \u2014 a specific and uncommon match\",\"React and TypeScript are the underlying stack\",\"Tailwind CSS satisfies the styling requirement\",\"Zustand satisfies the state management requirement\",\"Vite satisfies the build tooling requirement\",\"Playwright satisfies the E2E testing requirement\"],\"gaps\":[],\"explanation\":\"The candidate matches every stated technology with precision: Remix, React, TypeScript, Tailwind, Zustand, Vite, and Playwright. The Remix match is particularly notable given its specificity. This is a textbook stack alignment with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nuno_backend_pt\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"JavaScript\",\"SQL\"],\"tech\":[\"Laravel\",\"Livewire\",\"Docker\",\"Nginx\",\"Redis\"],\"databases\":[\"MySQL\",\"PostgreSQL\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\",\"Pest\"]}\n\nJob Summary:\nEstablished SaaS company with a large Laravel codebase is hiring a mid-level backend PHP engineer. Laravel and MySQL are the core stack. Redis for caching. PHPUnit and Pest for testing. Livewire for reactive UI components. Nginx for serving. Must be comfortable with GitLab CI pipelines.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Laravel is the candidate's primary framework \u2014 exact match\",\"Livewire is explicitly present \u2014 a specific and direct match\",\"MySQL satisfies the primary database requirement\",\"Redis covers caching requirement\",\"PHPUnit and Pest both listed satisfying the dual testing requirement\",\"Nginx is listed for web serving\",\"GitLab CI matches the CI/CD platform\"],\"gaps\":[],\"explanation\":\"Every named technology in the job description appears in the candidate's profile. Laravel, Livewire, MySQL, Redis, PHPUnit, Pest, Nginx, and GitLab CI are all explicitly evidenced. The Livewire match is a particularly specific signal. This is a comprehensive and precise match for the described Laravel SaaS role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yara_mleng\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"FastAPI\",\"Docker\",\"MLflow\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nBiotech company building protein structure prediction models is hiring an ML engineer. Must have deep learning experience with PyTorch. Familiarity with bioinformatics libraries (BioPython, RDKit) or protein language models (ESM, AlphaFold) strongly preferred. Large-scale model training on GPUs. Python required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"PyTorch is the primary framework showing deep learning capability\",\"Python is the primary language\"],\"gaps\":[\"No bioinformatics library experience (BioPython, RDKit) \\u2014 strongly preferred and domain-critical\",\"No protein language model experience (ESM, AlphaFold) despite being the core research area\",\"No GPU cluster or distributed training experience for large-scale protein models\",\"No scientific computing or chemistry domain knowledge evidenced\",\"MLflow and FastAPI indicate software engineering maturity but not domain specialization\"],\"explanation\":\"The candidate has general ML engineering skills but lacks every domain-specific tool and knowledge area for biotech protein modeling. The gap between general deep learning engineering and computational biology is fundamental \\u2014 domain expertise in protein structures cannot be substituted by PyTorch proficiency alone.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lena_devops_ru\",\"seniority\":\"Junior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"GitHub Actions\",\"Terraform\",\"AWS\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nStartup looking for a junior DevOps engineer to manage CI/CD pipelines and AWS infrastructure. Docker and GitHub Actions required. Terraform for IaC. AWS is the cloud platform. Scripting in Bash or Python is expected. Kubernetes experience is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Docker, GitHub Actions, Terraform, and AWS all match stated requirements\",\"Bash and Python cover scripting requirements\",\"Junior seniority matches the role level\"],\"gaps\":[\"No Kubernetes experience despite it being a listed plus \\u2014 limits future scope\",\"No observability tooling (Prometheus, Grafana) for production infrastructure monitoring\",\"No security or secrets management experience for production environments\"],\"explanation\":\"The candidate covers every required technology but the profile is thin beyond the stated requirements. For a startup managing production AWS infrastructure, the absence of observability tooling and security practices represents practical gaps that will become relevant quickly. The role requires more than CI/CD pipeline management.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cole_android_ca\",\"seniority\":\"Senior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Hilt\",\"Retrofit\",\"Room\",\"WorkManager\",\"Coroutines\",\"Firebase\"],\"architecture\":[\"MVVM\",\"Clean Architecture\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Espresso\",\"Mockito\"]}\n\nJob Summary:\nStreaming app with millions of Android users hiring a senior Android engineer. Kotlin required. Jetpack Compose for UI. Clean Architecture and MVVM patterns required. Hilt for dependency injection. WorkManager for background sync. Must have Espresso UI testing experience. Firebase for push notifications.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kotlin is the primary language and Jetpack Compose is the primary UI framework\",\"Clean Architecture is explicitly listed \u2014 satisfying the architecture pattern requirement\",\"MVVM is listed alongside Clean Architecture\",\"Hilt satisfies dependency injection requirement\",\"WorkManager is explicitly present for background sync\",\"Espresso satisfies UI testing requirement\",\"Firebase covers push notifications requirement\"],\"gaps\":[\"No ExoPlayer or media streaming SDK experience despite streaming app context\"],\"explanation\":\"The candidate matches every stated requirement: Kotlin, Jetpack Compose, Clean Architecture, MVVM, Hilt, WorkManager, Espresso, and Firebase. WorkManager and Clean Architecture are specific and uncommon matches. The only domain-specific gap is media streaming SDK experience, which is not stated but practically relevant for a streaming application.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mario_fullstack_it\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Django\",\"HTMX\",\"Alpine.js\",\"Docker\",\"Tailwind CSS\",\"PostgreSQL\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Selenium\"]}\n\nJob Summary:\nBootstrapped SaaS company building internal business tools is hiring a full stack engineer. Backend is Django with Python. Frontend is HTMX and Alpine.js \u2014 no heavy JavaScript framework. Tailwind CSS for styling. PostgreSQL for data. Redis for caching. Must be comfortable shipping features end-to-end.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Django is the primary backend framework \\u2014 exact match\",\"HTMX and Alpine.js are both explicitly listed \\u2014 a rare and specific match\",\"Tailwind CSS satisfies styling requirement\",\"PostgreSQL and Redis are both listed\"],\"gaps\":[\"Selenium for E2E testing is outdated and brittle \\u2014 Playwright or Cypress expected for a modern SaaS product\",\"No REST API or authentication experience (DRF, JWT) for the SaaS API layer\",\"No multi-tenancy or subscription billing experience for a SaaS business context\"],\"explanation\":\"The candidate's HTMX and Django stack match is genuinely rare, but Selenium-based testing is a practical maintainability concern for a modern SaaS product. The absence of API design and SaaS-specific patterns (multi-tenancy, billing) also limits the candidate's full-stack SaaS capability.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alinta_backend_au\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"SQLAlchemy\",\"Docker\",\"AWS\",\"Celery\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nInsuretech startup building a policy management platform is hiring a mid-level backend engineer. Stack is FastAPI with Python and SQLAlchemy ORM. PostgreSQL database. Celery and Redis for async task processing. AWS deployment. Must write thorough pytest tests. REST API design experience needed.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"FastAPI is the primary framework \u2014 exact match\",\"SQLAlchemy satisfies the ORM requirement directly\",\"PostgreSQL is the primary database\",\"Celery and Redis together satisfy the async task processing requirement precisely\",\"AWS covers deployment requirement\",\"pytest is listed as the testing framework\",\"Python is the primary language\"],\"gaps\":[\"No OpenAPI documentation or Swagger experience explicitly evidenced for REST API design discipline\"],\"explanation\":\"The candidate maps to every stated requirement: FastAPI, SQLAlchemy, PostgreSQL, Celery, Redis, AWS, and pytest. The Celery plus Redis combination is a precise and specific match. This is a high-confidence technical match for the insuretech backend role with no meaningful gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ravi_principal\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\",\"Backend Engineer\"],\"languages\":[\"Go\",\"Java\",\"Python\",\"Rust\"],\"tech\":[\"Kubernetes\",\"Kafka\",\"Terraform\",\"Istio\",\"AWS\",\"GCP\",\"Docker\",\"Prometheus\",\"OpenTelemetry\",\"gRPC\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"CQRS\",\"Domain-Driven Design\",\"Distributed System\",\"Service Mesh\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"DynamoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\",\"Flux\"],\"testing\":[\"k6\",\"pytest\",\"Go unit tests\"]}\n\nJob Summary:\nHigh-growth company seeking a principal engineer to define distributed systems architecture across multiple product lines. Must have deep experience with Kafka, gRPC, and Kubernetes. Multi-cloud experience (AWS and GCP) preferred. Domain-driven design and CQRS knowledge required. Service mesh with Istio. Polyglot engineering background valued.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kafka and gRPC both present for event streaming and service communication\",\"Kubernetes with Istio satisfies the service mesh requirement precisely\",\"Both AWS and GCP listed satisfying the multi-cloud preference\",\"DDD and CQRS are both in the architecture profile\",\"Go, Java, Python, and Rust demonstrate the polyglot background explicitly valued\",\"Principal seniority matches the architectural leadership expectation\",\"OpenTelemetry and Prometheus demonstrate observability depth at scale\"],\"gaps\":[\"No formal RFC or ADR process signals for architectural decision governance at principal level\"],\"explanation\":\"This is a principal-level profile built for distributed systems architecture. Every requirement \u2014 Kafka, gRPC, Kubernetes, Istio, multi-cloud, DDD, CQRS, and polyglot experience \u2014 is explicitly evidenced. The multi-cloud and polyglot signals are strong differentiators. An exceptional match for a cross-cutting architecture leadership role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dani_vue_tr\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Vuex\",\"Bootstrap\",\"Webpack\",\"jQuery\"]}\n\nJob Summary:\nModern fintech startup hiring a mid-level frontend engineer. Stack is React 18 with TypeScript. Zustand for state management. Tailwind CSS for UI. Vite for build tooling. Must write tests with Vitest and React Testing Library. RESTful API integration experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript and JavaScript are present as languages\",\"Mid-level seniority matches the role level\"],\"gaps\":[\"No React experience \u2014 the job's primary frontend framework\",\"No Zustand or React-compatible state management experience\",\"No Tailwind CSS experience; uses Bootstrap\",\"No Vite experience; uses Webpack with Vue-specific configuration\",\"No Vitest or React Testing Library experience\",\"Vuex is Vue-specific and does not transfer to Zustand\",\"jQuery presence suggests older frontend patterns\"],\"explanation\":\"The candidate is a Vue.js developer with no React experience, and the job is entirely React-based. Framework knowledge does not transfer meaningfully between Vue and React. Beyond the core framework mismatch, every supporting tool \u2014 Zustand, Tailwind, Vite, and the testing stack \u2014 is also absent.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tom_analytics\",\"seniority\":\"Senior\",\"roles\":[\"Analytics Engineer\",\"Data Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Airflow\",\"Looker\",\"Snowflake\",\"Spark\",\"Docker\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"Redshift\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"dbt tests\",\"Great Expectations\"]}\n\nJob Summary:\nAdtech company building an audience segmentation platform is hiring a senior analytics engineer. dbt is the primary transformation tool. Snowflake and BigQuery are both used for different use cases. Looker for reporting. Airflow for orchestration. Must have SQL expertise and data quality tooling experience.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt is the primary transformation tool \\u2014 direct match\",\"Both Snowflake and BigQuery listed for dual warehouse requirement\",\"Looker satisfies reporting requirement\",\"Airflow covers orchestration\",\"dbt tests and Great Expectations show data quality depth\"],\"gaps\":[\"No real-time or streaming audience segmentation experience for an adtech company requiring low-latency audience activation\",\"No data activation or CDP integration experience relevant to adtech segmentation use cases\",\"No identity resolution or cookie-less targeting methodology experience\"],\"explanation\":\"The candidate has strong analytics engineering credentials for batch use cases but adtech audience segmentation often requires real-time pipeline capability for timely ad targeting. The absence of streaming experience and adtech-specific data activation patterns represents meaningful gaps for the specific domain.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"abby_ios_us\",\"seniority\":\"Junior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Firebase\",\"Xcode\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nConsumer social app hiring a junior iOS developer. Swift and SwiftUI required. Firebase for backend integration. XCTest for unit testing. UIKit for legacy view support. Must be comfortable submitting to the App Store.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Swift and SwiftUI are present matching core language and framework requirements\"],\"gaps\":[\"No Fastlane or App Store submission experience despite it being explicitly mentioned in the role\",\"No state management or complex data flow experience beyond basic SwiftUI\",\"No background processing, notifications, or networking library experience visible\",\"Profile is sparse and does not evidence production iOS engineering depth\"],\"explanation\":\"While the candidate has the core iOS stack, the profile is thin on production signals and explicitly lacks App Store submission experience, which the job mentions. A consumer social app needs engineers who can manage the release lifecycle end-to-end, which this profile does not demonstrate.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mads_backend_dk\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"Prisma\",\"Docker\",\"Redis\",\"GraphQL\",\"AWS\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nEdtech company building a learning platform is hiring a backend engineer with NestJS and GraphQL experience. TypeScript required. PostgreSQL via Prisma. Redis for session management. AWS deployment. Jest for testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS is the primary framework \u2014 exact match\",\"GraphQL is explicitly listed for the API layer\",\"TypeScript is the primary language\",\"Prisma with PostgreSQL satisfies the ORM and database requirements\",\"Redis covers session management requirement\",\"AWS satisfies deployment requirement\",\"Jest and Supertest demonstrate testing practice\"],\"gaps\":[\"No file upload or media storage experience (S3, CloudFront) relevant to an edtech platform with course content\"],\"explanation\":\"The candidate matches every stated requirement: NestJS, GraphQL, TypeScript, Prisma, PostgreSQL, Redis, AWS, and Jest. This is a precise technology match with high confidence across every dimension. A strong hire for the described edtech platform.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"farhan_devops\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Docker\",\"Terraform\",\"GCP\",\"Argo CD\",\"Prometheus\",\"Grafana\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"Terratest\"]}\n\nJob Summary:\nClimate tech startup hiring a mid-level DevOps engineer. GCP is the cloud platform. Kubernetes and Helm for orchestration. Terraform for infrastructure as code. Argo CD for GitOps. Prometheus and Grafana for observability. Python or Bash for automation scripts.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"GCP is the target cloud and is listed\",\"Kubernetes and Helm satisfy orchestration\",\"Terraform satisfies IaC\",\"Argo CD covers GitOps\",\"Prometheus and Grafana satisfy observability\"],\"gaps\":[\"No cost optimization or GCP billing management experience for a startup with budget constraints\",\"No multi-region deployment experience for production-grade GCP infrastructure\",\"No infrastructure security policy tooling (OPA, Checkov) despite Terratest presence\"],\"explanation\":\"The candidate satisfies the stated technical requirements well but the profile lacks depth in areas important for a production startup GCP environment: cost management, multi-region strategy, and security policy. These gaps matter as the startup scales beyond initial infrastructure.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ingrid_swe_se\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Scala\",\"Python\",\"SQL\"],\"tech\":[\"Akka\",\"Play Framework\",\"Kafka\",\"Docker\",\"AWS\",\"Spark\"],\"architecture\":[\"Event-Driven\",\"Microservices\",\"CQRS\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"MongoDB\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"],\"testing\":[\"ScalaTest\",\"Gatling\"]}\n\nJob Summary:\nGaming platform company building player event pipelines is hiring a senior backend engineer. Scala and Kafka required. Akka for actor-model concurrency. Cassandra for high-write event storage. AWS deployment. CQRS experience needed. Load testing experience valued.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Scala and Akka form the correct actor-model concurrency stack\",\"Kafka satisfies the event pipeline requirement\",\"Cassandra satisfies high-write storage requirement\",\"CQRS is in the architecture profile\",\"Gatling satisfies load testing valued requirement\"],\"gaps\":[\"No Kubernetes experience for containerized microservice orchestration at gaming platform scale\",\"No cloud platform (AWS or GCP) experience explicitly documented for gaming infrastructure\",\"Jenkins and GitHub Actions suggests mixed CI approaches that may need consolidation\"],\"explanation\":\"The candidate has a strong Scala-Akka-Kafka-Cassandra stack match, but the absence of Kubernetes and cloud platform experience represents a meaningful gap for a modern gaming platform that needs to scale player event pipelines across cloud infrastructure. The core compute stack is right but the deployment layer is missing.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"arjun_swe_in\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"Flask\",\"React\",\"Docker\",\"MySQL\"],\"databases\":[\"MySQL\",\"Redis\"]}\n\nJob Summary:\nB2B SaaS company building workflow automation tools is hiring a full stack engineer. FastAPI for the backend, React with TypeScript for the frontend. PostgreSQL as primary database. Celery and Redis for background job processing. Must write both frontend and backend tests. AWS deployment required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React is present matching the frontend framework\",\"Python background is transferable to FastAPI with significant ramp-up\"],\"gaps\":[\"No FastAPI experience; Flask has a different async model and patterns\",\"No TypeScript experience required for the React frontend\",\"No PostgreSQL experience; uses MySQL\",\"No Celery experience for background job processing\",\"No testing frameworks visible for frontend or backend\",\"No AWS experience\"],\"explanation\":\"The candidate has React and Python basics but lacks the specific tooling across every dimension: FastAPI, TypeScript, PostgreSQL, Celery, testing, and AWS. Flask experience provides a thin Python foundation, but the gaps are widespread and represent a near-complete stack mismatch for the described role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lily_principal_eng\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Go\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"NestJS\",\"GraphQL\",\"Kubernetes\",\"Terraform\",\"AWS\",\"Kafka\",\"Redis\",\"Docker\",\"OpenTelemetry\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Domain-Driven Design\",\"Hexagonal Architecture\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"DynamoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"Jest\",\"Vitest\",\"pytest\",\"Playwright\",\"k6\"]}\n\nJob Summary:\nTechscaleup seeking a principal engineer to set architecture standards and mentor senior engineers. Full stack TypeScript and Go knowledge required. GraphQL and Kafka for the API and event layers. Kubernetes infrastructure. Domain-driven design principles expected. Comprehensive testing culture is a priority.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"TypeScript and Go both listed as primary languages covering the dual language requirement\",\"GraphQL is present for the API layer\",\"Kafka satisfies the event layer requirement\",\"Kubernetes satisfies infrastructure requirement\",\"Domain-Driven Design and Hexagonal Architecture demonstrate architectural depth beyond stated requirements\",\"Five testing frameworks demonstrate and can set a comprehensive testing culture\",\"Principal seniority matches the architectural standards and mentorship expectation\"],\"gaps\":[\"No formal engineering mentorship or RFC process signals beyond technical capabilities\"],\"explanation\":\"This is a comprehensive principal-level profile covering every stated requirement and more. TypeScript, Go, GraphQL, Kafka, Kubernetes, and DDD are all present. The diversity of testing frameworks is a strong differentiator for a role prioritizing testing culture. Hexagonal Architecture adds architectural sophistication beyond what is required.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"olga_dataeng_pl\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Airflow\",\"dbt\",\"Docker\",\"GCP\",\"Polars\",\"Pandas\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"dbt tests\"]}\n\nJob Summary:\nSaaScompany hiring a mid-level data engineer. Stack is dbt and Airflow for transformations and orchestration. BigQuery as data warehouse. GCP cloud platform. Python and SQL required. Data quality via dbt tests. Familiarity with Polars or pandas for data processing is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt satisfies the primary transformation tool requirement\",\"Airflow satisfies orchestration requirement\",\"BigQuery is the data warehouse and is listed\",\"GCP is the cloud platform and is listed\",\"dbt tests satisfy the data quality requirement\",\"Both Polars and Pandas are listed satisfying the processing plus requirement with redundancy\",\"Python and SQL are primary languages\"],\"gaps\":[\"No streaming pipeline experience visible\"],\"explanation\":\"The candidate matches every stated and bonus requirement: dbt, Airflow, BigQuery, GCP, dbt tests, Polars, and Pandas. Having both Polars and Pandas exceeds the plus requirement. Python and SQL are both primary languages. A precise and confident match for this data engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ben_swiftui\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"CoreData\",\"Combine\",\"StoreKit\",\"Firebase\",\"Fastlane\"],\"ci_cd\":[\"Bitrise\"],\"testing\":[\"XCTest\",\"XCUITest\"]}\n\nJob Summary:\nIndependent game studio building a mobile strategy game is hiring a mid-level iOS engineer. Swift and SpriteKit or SceneKit for game rendering required. Must have Game Center integration experience. StoreKit for in-app purchases. Performance profiling with Instruments required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Swift is the primary language\",\"StoreKit is listed for in-app purchases \\u2014 a specific partial match\"],\"gaps\":[\"No SpriteKit or SceneKit experience \\u2014 the primary rendering frameworks for mobile game development\",\"No Game Center integration experience despite it being a stated requirement\",\"No Instruments or game performance profiling experience\",\"SwiftUI-based iOS development experience does not transfer to game engine programming patterns\",\"Bitrise CI is the only game-adjacent signal but is not a game development skill\"],\"explanation\":\"The candidate is a general iOS developer with no game development framework experience. SpriteKit and Game Center are both absent and are central requirements. StoreKit is a partial match for in-app purchases but is insufficient to qualify a non-game developer for a mobile game engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"zara_sec_eng\",\"seniority\":\"Mid\",\"roles\":[\"Security Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Semgrep\",\"Burp Suite\",\"Trivy\",\"Docker\",\"GitHub Actions\",\"AWS\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nCloud-first startup hiring a mid-level security engineer. Must integrate SAST into CI pipelines using Semgrep. Container security scanning with Trivy or Snyk. AWS security configuration and IAM hardening. Burp Suite for application security testing. Python for automation.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Semgrep satisfies the SAST CI integration requirement directly\",\"Trivy satisfies the container security scanning requirement\",\"Burp Suite satisfies the application security testing requirement\",\"AWS is listed for cloud security and IAM configuration\",\"GitHub Actions enables CI pipeline security integration\",\"Python is listed for security automation\"],\"gaps\":[\"No explicit IAM policy analysis or AWS Security Hub experience documented\",\"No secrets detection tooling (truffleHog, detect-secrets) visible\"],\"explanation\":\"The candidate matches every named requirement: Semgrep, Trivy, Burp Suite, AWS, and Python automation. All three security tooling requirements are directly evidenced. This is a precise match for an embedded security engineering role at a cloud-first startup.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"marco_java_ro\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Hibernate\",\"Docker\",\"AWS\",\"Maven\"],\"databases\":[\"MySQL\",\"PostgreSQL\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nEnterprise healthcare company maintaining a Java Spring Boot platform is hiring a mid-level backend engineer. Spring Boot and Hibernate for the application layer. PostgreSQL as primary database. AWS deployment. JUnit and Mockito for testing. Jenkins CI. Maven for builds.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Spring Boot is the primary framework \u2014 exact match\",\"Hibernate satisfies the ORM requirement directly\",\"PostgreSQL is the primary database\",\"AWS covers deployment requirement\",\"JUnit and Mockito satisfy testing requirements explicitly\",\"Jenkins is the CI platform \u2014 exact match\",\"Maven satisfies the build tool requirement\"],\"gaps\":[\"No FHIR or healthcare interoperability standards experience despite healthcare domain\"],\"explanation\":\"The candidate matches every stated technology: Spring Boot, Hibernate, PostgreSQL, AWS, JUnit, Mockito, Jenkins, and Maven. This is a comprehensive technology alignment with no tooling gaps relative to stated requirements. The only domain-specific consideration is healthcare interoperability standards knowledge, which is not stated but contextually relevant.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"felix_de_web\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Next.js\",\"Tailwind CSS\",\"shadcn/ui\",\"Framer Motion\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\"]}\n\nJob Summary:\nSeries B product company hiring a mid-level frontend engineer. Must have React and TypeScript experience. Next.js required. Tailwind CSS and shadcn/ui for the design system. Animations with Framer Motion. Write unit tests with Vitest. Team is moving fast and needs someone who can work independently.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React, TypeScript, and Next.js match the core frontend stack\",\"Tailwind CSS and shadcn/ui satisfy the design system requirement\",\"Framer Motion is an uncommon specific match\"],\"gaps\":[\"Junior seniority does not meet mid-level requirement for independent work at a Series B company\",\"No state management library experience for complex application state at scale\",\"No E2E testing experience (Playwright, Cypress) \\u2014 only unit tests visible\",\"No API integration patterns or backend communication experience beyond basic Axios usage\"],\"explanation\":\"Despite a strong technology alignment on paper, junior seniority is a disqualifying constraint for a mid-level role at a fast-moving Series B. The company explicitly needs someone who can work independently, and the sparse profile with no state management or E2E testing experience further confirms this candidate is not production-ready for the described scope.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nadia_data_sci\",\"seniority\":\"Senior\",\"roles\":[\"Data Scientist\",\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"R\",\"SQL\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"XGBoost\",\"Pandas\",\"MLflow\",\"Weights & Biases\",\"Plotly\",\"dbt\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nE-commerce company building a product recommendation engine is hiring a senior data scientist. Must have tabular ML experience with XGBoost or LightGBM. Python required. MLflow or W&B for experiment tracking. SQL and data warehouse experience (Snowflake or BigQuery). A/B testing methodology experience is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"XGBoost satisfies tabular ML requirement\",\"MLflow and Weights and Biases exceed experiment tracking requirement\",\"Both Snowflake and BigQuery listed for dual warehouse coverage\",\"Python and SQL primary\",\"dbt adds feature engineering depth\"],\"gaps\":[\"No explicit A/B testing or statistical experimentation framework visible despite recommendation engine context where experimentation is critical\",\"No recommendation-specific modeling experience (collaborative filtering, two-tower models, matrix factorization) evidenced\",\"No model serving or online inference experience for real-time product recommendations\"],\"explanation\":\"The candidate has strong ML fundamentals and data tooling but the profile lacks recommendation-system-specific modeling experience and A/B testing methodology that drives recommendation engine iteration. Online inference capability for real-time recommendations is also absent.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pat_generalist\",\"seniority\":\"Mid\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"FastAPI\",\"Docker\",\"AWS\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"]}\n\nJob Summary:\nBlockchain company building a DeFi protocol is hiring a smart contract developer. Must have Solidity experience and deep understanding of EVM. Hardhat or Foundry for testing and deployment. OpenZeppelin for contract standards. TypeScript for integration scripts. Experience with Layer 2 networks (Optimism, Arbitrum) preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript is present for integration scripting\"],\"gaps\":[\"No Solidity experience \u2014 the primary language for all smart contract work\",\"No EVM knowledge or blockchain development background\",\"No Hardhat or Foundry experience\",\"No OpenZeppelin or contract standards knowledge\",\"No Layer 2 or DeFi protocol experience\",\"Web development stack (React, FastAPI, Docker) is not transferable to smart contract engineering\"],\"explanation\":\"The candidate is a general web developer with no blockchain or smart contract engineering background. Solidity, EVM, Hardhat, and OpenZeppelin are all absent. TypeScript is the only present skill with any relevance, and it covers only the peripheral integration scripting work. This is a fundamental domain mismatch.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wren_backend\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Echo\",\"Docker\",\"Kubernetes\",\"AWS\",\"Redis\",\"gRPC\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"Go unit tests\",\"k6\"]}\n\nJob Summary:\nSaaS infrastructure company hiring a senior backend engineer for their Go-based microservices platform. Echo is the HTTP framework in use. gRPC for internal communication. PostgreSQL as the primary database. Redis for distributed caching. AWS and Kubernetes for deployment. Must have load testing experience.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go is the primary language and Echo is the HTTP framework \u2014 exact match\",\"gRPC satisfies internal service communication requirement\",\"PostgreSQL is listed as the primary database\",\"Redis covers distributed caching requirement\",\"Kubernetes and AWS satisfy deployment requirements\",\"k6 demonstrates load testing experience\"],\"gaps\":[\"No Kafka or message queue experience for event-driven async patterns\"],\"explanation\":\"The candidate matches every stated requirement with precision: Go, Echo, gRPC, PostgreSQL, Redis, Kubernetes, and AWS. The k6 load testing experience directly satisfies the stated expectation. Echo is an uncommon framework match that signals genuine Go web development depth.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dev_junior_sparse\",\"seniority\":\"Junior\",\"languages\":[\"Python\",\"JavaScript\"]}\n\nJob Summary:\nEnterprise bank seeking a staff-level solutions architect to lead multi-cloud strategy across AWS and GCP. Candidates must have deep Kubernetes expertise, Terraform and Pulumi for infrastructure as code, service mesh experience with Istio, and a track record of designing distributed systems at scale. Domain-driven design required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Junior seniority is far below staff-level architect requirement\",\"No cloud platform experience of any kind\",\"No Kubernetes, Terraform, or Pulumi experience\",\"No service mesh or Istio knowledge\",\"No distributed systems or domain-driven design background\",\"Profile is sparse with only two general-purpose languages\"],\"explanation\":\"This candidate has no meaningful overlap with the role. Staff-level architecture work requires years of distributed systems experience, cloud infrastructure depth, and technical leadership \u2014 none of which are present in this profile. The seniority mismatch alone is disqualifying.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"noah_react\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Jotai\",\"Tailwind CSS\",\"Framer Motion\",\"Storybook\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nCreative agency building interactive marketing experiences is hiring a mid-level frontend engineer. React and Next.js required with TypeScript. Framer Motion for animations. Tailwind CSS for styling. Storybook for component documentation. Must write E2E tests with Playwright.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Next.js match the primary framework requirements\",\"Framer Motion is explicitly listed for animations\",\"Tailwind CSS satisfies the styling requirement\",\"Playwright satisfies E2E testing requirement\"],\"gaps\":[\"Storybook is present but no design token or theming system experience for a creative agency requiring brand consistency\",\"No WebGL or Three.js experience for high-fidelity interactive marketing experiences\",\"Jotai state management suggests complex app state that may be over-engineered for agency marketing sites\"],\"explanation\":\"The candidate has solid technology alignment across React, Next.js, Framer Motion, and Tailwind, but creative agency interactive marketing work often requires more advanced visual programming (WebGL, canvas) and brand system tooling than is evidenced. The match is good for standard agency work but uncertain for high-end interactive campaigns.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"claire_dataeng\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Prefect\",\"dbt\",\"Docker\",\"AWS\",\"Pandas\",\"Polars\"],\"databases\":[\"Snowflake\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"dbt tests\"]}\n\nJob Summary:\nRetail analytics company hiring a mid-level data engineer. dbt for transformations. Prefect for pipeline orchestration. Snowflake as the data warehouse. AWS for cloud infrastructure. Python and SQL required. Data quality via dbt tests.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt is the primary transformation tool \\u2014 direct match\",\"Prefect is explicitly listed for orchestration \\u2014 an uncommon and specific match\",\"Snowflake is the data warehouse and is listed\",\"AWS covers the cloud infrastructure requirement\",\"dbt tests satisfy the data quality requirement\",\"Python and SQL are both primary languages\"],\"gaps\":[\"No streaming pipeline experience visible\"],\"explanation\":\"The candidate matches every stated requirement: dbt, Prefect, Snowflake, AWS, dbt tests, Python, and SQL. The Prefect match is particularly specific as it is a less common orchestration tool. A precise and high-confidence fit for this retail analytics data engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mateo_devops_co\",\"seniority\":\"Junior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"Terraform\",\"AWS\",\"Ansible\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nSeries C startup seeking a senior DevOps engineer to architect and own the Kubernetes infrastructure on AWS. Must design multi-tenant cluster topologies, implement GitOps with Argo CD or Flux, configure Istio service mesh, and build observability with Prometheus and Grafana. Go scripting experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Terraform and AWS are present and relevant\",\"Bash and Python show scripting capability\"],\"gaps\":[\"Junior seniority is far below senior requirement for infrastructure architecture ownership\",\"No Kubernetes experience despite it being the core platform\",\"No Argo CD or Flux GitOps experience\",\"No Istio or service mesh experience\",\"No Prometheus or Grafana observability experience\",\"No Go experience for scripting requirement\"],\"explanation\":\"The candidate is an early-career DevOps engineer with basic tooling knowledge but no Kubernetes, GitOps, or observability experience. The seniority gap is compounded by the absence of every core technical requirement for architecting a multi-tenant Kubernetes platform.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sasha_ml\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"XGBoost\",\"LightGBM\",\"CatBoost\",\"MLflow\",\"Weights & Biases\",\"FastAPI\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"BigQuery\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nInsurance company building actuarial risk models is hiring a senior ML engineer. Must have deep tabular ML experience with gradient boosting frameworks. Python required. MLflow or Weights and Biases for experiment tracking. FastAPI for model serving. SQL and data warehouse experience preferred.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"XGBoost, LightGBM, and CatBoost together demonstrate deep gradient boosting expertise across all major frameworks\",\"MLflow and Weights and Biases both present \u2014 exceeds experiment tracking requirement\",\"FastAPI satisfies model serving requirement\",\"Python is the primary language\",\"BigQuery satisfies the data warehouse preference\",\"Docker demonstrates production deployment discipline\"],\"gaps\":[\"No actuarial or insurance domain-specific feature engineering experience explicitly evidenced\"],\"explanation\":\"The candidate's tabular ML depth is exceptional \u2014 having all three major gradient boosting frameworks (XGBoost, LightGBM, CatBoost) is a direct and rare match for actuarial risk modeling. Dual experiment tracking tools and FastAPI serving complete the production ML picture. A compelling hire with deep direct stack alignment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hana_fullstack\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\"],\"tech\":[\"React\",\"Remix\",\"NestJS\",\"Prisma\",\"Docker\",\"Vercel\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nStartup building a content management platform is hiring a full stack engineer. Backend is NestJS with TypeScript. Frontend uses Remix with React. Prisma ORM with PostgreSQL. Redis for caching. Vercel for deployment. Must write integration and E2E tests.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"NestJS is the primary backend framework \\u2014 exact match\",\"Remix frontend match is specific and uncommon\",\"Prisma with PostgreSQL satisfies ORM and database\",\"Redis covers caching\",\"Vercel satisfies deployment requirement\"],\"gaps\":[\"No CMS-specific integration experience (headless CMS APIs, media uploads, content versioning) for a content management platform\",\"TypeScript-only background means no polyglot experience if the platform integrates with other language services\",\"No search or full-text indexing experience (Elasticsearch, Typesense) which content platforms typically require\"],\"explanation\":\"The candidate has precise framework alignment but a content management platform has domain-specific requirements around rich media handling, content versioning, and search that are not evidenced. The technology stack is a strong match, but the product domain depth is uncertain.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elan_ios\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"CoreData\",\"Firebase\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nStreaming media company hiring a mid-level iOS engineer. Swift and SwiftUI required. AVFoundation for media playback integration. Must have offline playback support via CoreData or local storage. Firebase for analytics and crash reporting. Must write XCTest unit tests.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Swift and SwiftUI match the core language and framework requirements\",\"CoreData is listed for offline storage\",\"Firebase covers analytics and crash reporting\"],\"gaps\":[\"No AVFoundation experience \\u2014 the central technical requirement for a streaming media application\",\"No DRM or content protection experience for licensed streaming content\",\"No adaptive bitrate or network-aware playback experience (HLS, DASH) for media streaming\",\"No background audio or picture-in-picture implementation experience\"],\"explanation\":\"The candidate has iOS fundamentals but the complete absence of AVFoundation is disqualifying for a streaming media company. Media playback, DRM, and adaptive streaming are the core engineering challenges of a streaming app, and none of these are evidenced. This is a fundamental domain skill gap for this specific product type.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"obi_backend_ng\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"Celery\",\"Redis\",\"Docker\",\"AWS\",\"Stripe\"],\"architecture\":[\"Monolith\",\"Modular Architecture\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nPayment-focused SaaS company hiring a mid-level backend engineer. Django with Python for the backend. Celery and Redis for asynchronous payment event processing. Stripe integration required. PostgreSQL for data. AWS deployment. Load testing experience valued.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Django is the primary framework \\u2014 exact match\",\"Celery and Redis satisfy async payment event processing\",\"Stripe is explicitly listed for payment integration\",\"PostgreSQL is listed\",\"AWS covers deployment\"],\"gaps\":[\"No webhook signature verification or idempotency key pattern experience for reliable Stripe event processing\",\"Locust for load testing is present but no latency-specific payment SLA testing experience evidenced\",\"No PCI DSS compliance or payment security awareness signals for a payment-focused product\"],\"explanation\":\"The candidate matches the core technical stack but payment-focused SaaS requires payment security practices (PCI DSS, webhook idempotency) that are not evidenced. The Stripe presence is a strong signal, but production payment system engineering requires more than framework familiarity with the SDK.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"iris_android\",\"seniority\":\"Senior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Hilt\",\"Retrofit\",\"Room\",\"WorkManager\",\"Coroutines\"],\"architecture\":[\"Clean Architecture\",\"MVVM\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Espresso\",\"Mockito\"]}\n\nJob Summary:\nEnterprise B2B Android app hiring a senior Android engineer. Kotlin required. Jetpack Compose for modern UI. Clean Architecture with MVVM. WorkManager for scheduled background sync. Hilt for dependency injection. Must have Espresso UI testing experience.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin and Jetpack Compose are the primary stack \\u2014 direct match\",\"Clean Architecture and MVVM both listed\",\"WorkManager is explicitly present for background sync\",\"Hilt satisfies dependency injection requirement\",\"Espresso satisfies UI testing requirement\"],\"gaps\":[\"No enterprise Android management experience (Android for Work, MDM APIs) for a B2B enterprise context\",\"No data encryption or secure storage experience for sensitive enterprise data on device\",\"No ProGuard or R8 obfuscation experience for enterprise app hardening\"],\"explanation\":\"The candidate covers the technical Android requirements precisely but an enterprise B2B Android app typically requires device management APIs, secure data storage, and app hardening that are not evidenced in the profile. These enterprise-specific requirements go beyond the stated job description but represent practical delivery gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"raj_fe_in\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"React\",\"Bootstrap\",\"jQuery\"]}\n\nJob Summary:\nFAANG-adjacent company building a large-scale design system is hiring a senior frontend engineer. Must have deep TypeScript expertise, Angular or React proficiency, and experience building and maintaining component libraries with Storybook. NgRx or Redux for state management. Playwright for E2E testing. Accessibility (WCAG) compliance experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React is present as a framework\"],\"gaps\":[\"Junior seniority is far below senior requirement for a design system role\",\"No TypeScript experience \u2014 required for all production code\",\"No state management library (NgRx, Redux) experience\",\"No Storybook experience for component library documentation\",\"No Playwright or E2E testing experience\",\"No accessibility or WCAG knowledge\",\"jQuery presence suggests older frontend development patterns\"],\"explanation\":\"The candidate is a junior JavaScript developer with no TypeScript, state management, component library tooling, or accessibility experience. Every specific technical requirement for a senior design system engineer is absent. This is both a seniority mismatch and a comprehensive skills gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lars_sre_no\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Prometheus\",\"Grafana\",\"PagerDuty\",\"AWS\",\"Datadog\",\"OpenTelemetry\",\"Docker\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"k6\",\"Locust\"]}\n\nJob Summary:\nGrowth-stage fintech hiring a senior SRE to own reliability for a microservices platform. Must define SLOs, build observability with Prometheus, Grafana, and OpenTelemetry, manage incidents with PagerDuty, conduct load testing, and deploy infrastructure via Terraform on AWS. Kubernetes expertise required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Prometheus, Grafana, and OpenTelemetry together satisfy the full observability requirement\",\"PagerDuty is explicitly listed for incident management\",\"Terraform satisfies IaC requirement on AWS\",\"Kubernetes is the core platform and is clearly present\",\"k6 and Locust together demonstrate comprehensive load testing capability\",\"Datadog adds observability depth beyond requirements\",\"Go and Python for SRE tooling scripting\"],\"gaps\":[\"No explicit SLO tooling (Sloth, OpenSLO) for formalizing error budgets\"],\"explanation\":\"The candidate matches every stated requirement: Prometheus, Grafana, OpenTelemetry, PagerDuty, Terraform, AWS, Kubernetes, and load testing. Dual load testing tools (k6 and Locust) and dual observability stacks (Prometheus/Grafana plus Datadog) demonstrate exceptional depth. A compelling SRE hire for a fintech reliability role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"yuki_data\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"Kafka\",\"Airflow\",\"Docker\",\"GCP\",\"Pandas\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nMedia company building a batch and streaming data platform on GCP is hiring a mid-level data engineer. Apache Spark for batch processing. Kafka for streaming ingestion. Airflow for orchestration. BigQuery as the data warehouse. Python and Scala required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Apache Spark and Kafka are both present\",\"Airflow covers orchestration\",\"BigQuery is the data warehouse\",\"GCP is the cloud platform\",\"Python and Scala are both primary languages\"],\"gaps\":[\"No dbt or SQL transformation layer experience for structured warehouse modeling on BigQuery\",\"No data quality tooling (Great Expectations) visible for production pipeline reliability\",\"No GCP-native streaming service experience (Dataflow, Pub/Sub) alongside Kafka\"],\"explanation\":\"The candidate has the batch and streaming infrastructure fundamentals but lacks the transformation layer (dbt) and data quality tooling expected at a mature media company data platform. The absence of GCP-native streaming alternatives is also a notable gap for a GCP-centric organization.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"diana_php\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"SQL\"],\"tech\":[\"Symfony\",\"Doctrine\",\"Docker\",\"Nginx\",\"Redis\"],\"databases\":[\"MySQL\",\"PostgreSQL\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"PHPUnit\"]}\n\nJob Summary:\nE-commerce platform hiring a mid-level PHP developer. Laravel is the primary framework. MySQL for data. Redis for caching. Nginx for serving. PHPUnit for testing. Docker for containerization. GitLab CI for pipelines.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PHP is the primary language\",\"MySQL and Redis are both listed covering database and caching requirements\",\"Nginx is present for web serving\",\"PHPUnit satisfies testing requirement\",\"Docker and GitLab CI match the containerization and CI requirements\"],\"gaps\":[\"Uses Symfony rather than Laravel \u2014 different framework philosophy, routing, and ORM patterns require adjustment\",\"Doctrine ORM is Symfony-specific and does not transfer directly to Laravel's Eloquent\",\"No Composer or Laravel ecosystem tooling experience explicitly evidenced\"],\"explanation\":\"The candidate is a PHP developer with infrastructure tool overlap (MySQL, Redis, Nginx, Docker, GitLab CI, PHPUnit) but comes from a Symfony background rather than Laravel. The framework difference is meaningful \u2014 Eloquent vs. Doctrine and Laravel's conventions differ significantly enough to require a ramp-up period for a production codebase.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tom_k8s_pl\",\"seniority\":\"Senior\",\"roles\":[\"Platform Engineer\"],\"languages\":[\"Go\",\"Bash\",\"Python\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"Docker\",\"AWS\",\"Prometheus\",\"Grafana\",\"Argo CD\",\"Vault\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"Terratest\",\"k6\"]}\n\nJob Summary:\nScale-up company building an internal developer platform on AWS is hiring a senior platform engineer. Kubernetes and Helm for workload management. Terraform for infrastructure as code. Argo CD for GitOps. Vault for secrets management. Prometheus and Grafana for observability. Go for internal tooling.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kubernetes and Helm satisfy workload management requirements\",\"Terraform satisfies IaC\",\"Argo CD covers GitOps requirement\",\"Vault satisfies secrets management\",\"Prometheus and Grafana match observability requirements\",\"Terratest demonstrates IaC testing discipline\"],\"gaps\":[\"No Backstage or developer portal tooling for a company explicitly building an internal developer platform\",\"No golden path template or scaffolding experience for internal platform self-service\",\"No multi-tenancy or namespace isolation design experience for shared Kubernetes clusters\"],\"explanation\":\"The candidate has strong platform engineering fundamentals but the specific purpose \\u2014 building an internal developer platform \\u2014 requires Backstage or equivalent portal tooling that is absent. Developer portal design is the differentiating skill for an IDP and its absence is a meaningful practical gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"luca_vue\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Vuex\",\"Tailwind CSS\",\"Vite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Cypress\"]}\n\nJob Summary:\nFintech startup hiring a mid-level frontend engineer. React with TypeScript is the core stack. Zustand for state management. TanStack Query for data fetching. Tailwind CSS for styling. Vite for build tooling. Must test with Vitest and Playwright.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript is present as the primary language\",\"Tailwind CSS and Vite are matching skills\",\"Vitest experience is present and transferable\"],\"gaps\":[\"No React experience \u2014 the primary framework for this role\",\"No Zustand experience; Vuex is Vue-specific and does not transfer\",\"No TanStack Query experience for data fetching\",\"No Playwright experience; uses Cypress instead\",\"Vue.js ecosystem knowledge does not transfer directly to React patterns\"],\"explanation\":\"The candidate is a Vue.js developer and the job is React-based. Vue and React require fundamentally different mental models for component composition and state management. While Tailwind, Vite, and TypeScript overlap, the core framework mismatch makes this a poor fit without a significant retraining investment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ada_cloud\",\"seniority\":\"Senior\",\"roles\":[\"Cloud Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"AWS\",\"Terraform\",\"Docker\",\"Kubernetes\",\"Ansible\",\"Pulumi\",\"Vault\",\"Consul\"],\"architecture\":[\"Cloud-Native\",\"Serverless\"],\"databases\":[\"PostgreSQL\",\"DynamoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"Terratest\"]}\n\nJob Summary:\nEnterprise SaaS company migrating workloads from on-premises to AWS is hiring a senior cloud engineer. Must have deep AWS experience (EC2, S3, EKS, Lambda), Terraform for IaC, Ansible for configuration management, and Docker and Kubernetes for containerization. Python or Bash scripting required. GitOps a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform satisfies IaC requirement\",\"Kubernetes and Docker satisfy containerization\",\"Ansible satisfies configuration management\",\"Python and Bash cover scripting\",\"Argo CD satisfies GitOps plus requirement\",\"AWS is the target cloud\"],\"gaps\":[\"No AWS migration-specific tooling (AWS Application Migration Service, DMS, Snow Family) for an on-premises migration project\",\"No hybrid networking experience (Direct Connect, VPN, on-prem AD integration) for an enterprise migration context\",\"Pulumi alongside Terraform may indicate preference for a tool the team does not use\"],\"explanation\":\"The candidate has strong cloud infrastructure skills, but a large-scale on-premises to AWS migration requires migration-specific tooling and hybrid connectivity experience that are not evidenced. Enterprise migrations involve network bridging, identity federation, and data transfer tooling beyond Terraform and Kubernetes.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"priya_nest\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"TypeORM\",\"Docker\",\"AWS\",\"Redis\",\"Swagger\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nHealthtech platform hiring a mid-level backend engineer. Stack is NestJS with TypeScript. TypeORM for database access. PostgreSQL as primary database. Redis for caching. AWS deployment. Must document APIs with Swagger. Write tests with Jest.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"NestJS and TypeORM are present satisfying framework and ORM requirements\",\"TypeScript is the primary language\",\"PostgreSQL and Redis are listed\"],\"gaps\":[\"No HIPAA, HITRUST, or healthcare compliance signals \\u2014 a critical regulatory requirement for any healthtech platform handling patient data\",\"No encryption at rest or in transit configuration experience for Protected Health Information (PHI)\",\"No audit logging or access control design for healthcare data governance\",\"No HL7, FHIR, or EHR integration experience relevant to healthtech platform interoperability\"],\"explanation\":\"While the technical stack matches precisely, a healthtech platform operates under strict regulatory requirements (HIPAA) that are entirely absent from this profile. Healthcare compliance is not optional and requires specific engineering practices for PHI handling, audit trails, and access control that are not evidenced. This is a domain compliance mismatch that outweighs the technology alignment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"zev_ml_il\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"FastAPI\",\"Docker\",\"AWS\",\"MLflow\"],\"databases\":[\"PostgreSQL\",\"S3\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nCybersecurity company hiring a mid-level ML engineer to build anomaly detection models for network traffic. Must have PyTorch or TensorFlow experience. scikit-learn for classical models. Python required. FastAPI for model serving. AWS for deployment. Experience with time-series data modeling is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"PyTorch satisfies the deep learning framework requirement\",\"FastAPI satisfies the model serving requirement\",\"AWS covers deployment\",\"MLflow shows experiment tracking maturity\",\"Python is the primary language\"],\"gaps\":[\"No scikit-learn experience \u2014 required for classical anomaly detection models\",\"No time-series modeling experience despite it being a plus for network traffic analysis\",\"No cybersecurity domain knowledge or network data experience evidenced\",\"Hugging Face Transformers suggests NLP background rather than tabular or time-series ML\"],\"explanation\":\"The candidate has strong deep learning fundamentals but lacks scikit-learn, which is explicitly required for classical anomaly detection models. The NLP-heavy profile (Hugging Face Transformers) suggests a different ML specialization than the network traffic anomaly detection this role requires. Ramp-up time is needed for both the models and the domain.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"evan_rails\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Ruby\",\"SQL\"],\"tech\":[\"Ruby on Rails\",\"Sidekiq\",\"Redis\",\"Docker\",\"AWS\",\"Nginx\"],\"architecture\":[\"Monolith\",\"Modular Architecture\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"CircleCI\"],\"testing\":[\"RSpec\",\"Capybara\"]}\n\nJob Summary:\nSaaS company with a mature Rails monolith is hiring a senior backend engineer to help decouple and modularize the codebase. Strong Ruby on Rails required. PostgreSQL. Sidekiq for background jobs. Must write thorough tests with RSpec. Redis for caching. Docker for local development.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Ruby on Rails is the primary framework \u2014 exact match\",\"Sidekiq satisfies the background job requirement directly\",\"PostgreSQL is the primary database\",\"RSpec satisfies the testing requirement\",\"Redis covers caching requirement\",\"Docker satisfies local development requirement\",\"Modular Architecture in the profile aligns with the codebase decoupling goal\"],\"gaps\":[\"Capybara is present for integration testing but may be brittle for a large modularization effort\"],\"explanation\":\"The candidate matches every stated requirement: Rails, Sidekiq, PostgreSQL, RSpec, Redis, and Docker. The Modular Architecture experience is a meaningful signal for the codebase decoupling goal. Senior seniority and a comprehensive Rails testing stack make this a strong hire for monolith modernization work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mei_fullstack\",\"seniority\":\"Junior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Node.js\",\"Express.js\",\"Docker\"],\"databases\":[\"MongoDB\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nSeed-stage consumer app startup seeking a junior full stack engineer. React frontend with TypeScript. Node.js backend with Express. PostgreSQL as the primary database. Docker for local development. GitHub Actions for CI. Looking for fast learners comfortable in a scrappy environment.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and TypeScript cover the frontend requirement\",\"Node.js and Express.js satisfy the backend requirement\",\"PostgreSQL is listed\",\"Docker and GitHub Actions match dev and CI requirements\",\"Junior seniority aligns with the role\"],\"gaps\":[\"No testing framework visible \\u2014 seed-stage startups that skip testing from day one face compounding technical debt\",\"MongoDB as primary database experience may conflict with PostgreSQL-first data modeling expectations\",\"No API design or REST documentation experience visible for a junior engineer shipping features independently\"],\"explanation\":\"The candidate covers most stated technologies but the complete absence of testing experience is a practical concern even for a scrappy seed-stage product. The MongoDB background alongside PostgreSQL suggests mixed data modeling instincts that require alignment on a relational-first team.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"amal_de_eng\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Dagster\",\"dbt\",\"Docker\",\"AWS\",\"Pandas\",\"Spark\"],\"databases\":[\"Snowflake\",\"Redshift\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nHealthcare data company hiring a senior data engineer. Dagster for pipeline orchestration. dbt for transformations. Snowflake as the data warehouse. AWS infrastructure. Python required. Great Expectations for data quality. Must be comfortable with HIPAA-compliant data handling.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Dagster satisfies the orchestration requirement directly \u2014 an uncommon specific match\",\"dbt satisfies transformation requirement\",\"Snowflake is the primary warehouse\",\"Great Expectations satisfies the data quality requirement\",\"AWS covers infrastructure\",\"Python is the primary language\"],\"gaps\":[\"No HIPAA compliance or healthcare data governance signals \u2014 a stated requirement for sensitive health data handling\",\"No data encryption or access control patterns evidenced for PHI data\",\"Redshift experience is present but the company uses Snowflake, and the prior Redshift focus suggests possible workflow adjustment\"],\"explanation\":\"The candidate matches the core tooling requirements precisely but the absence of any HIPAA compliance experience is a meaningful gap for a healthcare data company where regulatory compliance is a stated requirement. The technical stack is a strong match, but the compliance dimension is unaddressed.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sam_swift\",\"seniority\":\"Junior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"Firebase\",\"Xcode\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nConsumer fitness app hiring a junior iOS developer. Swift and SwiftUI required. Firebase for backend integration and analytics. XCTest for unit tests. Must be comfortable shipping to the App Store with Fastlane or Xcode Cloud.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Swift and SwiftUI are present matching core requirements\",\"Firebase covers backend integration and analytics\"],\"gaps\":[\"No Fastlane or Xcode Cloud experience \\u2014 explicitly required for App Store release automation\",\"No HealthKit or fitness platform APIs for a fitness-focused app\",\"No analytics event tracking or A/B testing experience for a consumer fitness product\",\"Profile is sparse with only three tools and no testing or CI/CD experience\",\"No background task or local notification experience for fitness reminders and workout tracking\"],\"explanation\":\"The candidate matches the basic iOS stack but lacks the App Store release automation that is explicitly required. For a consumer fitness app, the absence of HealthKit, notification handling, background task management, and analytics tracking represents practical engineering gaps that go beyond the stated requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"felix_principal\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\",\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\",\"Go\",\"Python\"],\"tech\":[\"Spring Boot\",\"Kafka\",\"Kubernetes\",\"Terraform\",\"AWS\",\"Docker\",\"Istio\",\"gRPC\",\"Prometheus\",\"OpenTelemetry\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Domain-Driven Design\",\"CQRS\",\"Service Mesh\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\",\"DynamoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"JUnit\",\"Mockito\",\"k6\"]}\n\nJob Summary:\nLarge financial services firm seeking a principal engineer to define architecture across Java-based microservices. Must have Spring Boot expertise, Kafka for event streaming, CQRS and DDD knowledge, service mesh experience with Istio, and Kubernetes on AWS. gRPC for service communication. Observability required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Spring Boot is the primary framework \u2014 exact match\",\"Kafka satisfies event streaming requirement\",\"CQRS and Domain-Driven Design both listed \u2014 precise architecture match\",\"Istio satisfies service mesh requirement\",\"Kubernetes and AWS cover orchestration and cloud\",\"gRPC is listed for service communication\",\"Prometheus and OpenTelemetry satisfy observability requirement\",\"Principal seniority matches architectural leadership expectation\"],\"gaps\":[\"No explicit API gateway design or rate-limiting experience at enterprise scale\"],\"explanation\":\"The candidate is an exceptional match for every requirement: Spring Boot, Kafka, CQRS, DDD, Istio, Kubernetes, AWS, gRPC, and observability. The combination of principal seniority and comprehensive distributed systems architecture (DDD, CQRS, Service Mesh) directly addresses the stated leadership and design expectations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cleo_analytics\",\"seniority\":\"Mid\",\"roles\":[\"Analytics Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Looker\",\"Airflow\",\"Snowflake\",\"Tableau\"],\"databases\":[\"Snowflake\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"dbt tests\"]}\n\nJob Summary:\nConsumer tech company hiring a mid-level analytics engineer. dbt for transformations. Snowflake as the data warehouse. Looker for business intelligence. Airflow for orchestration. SQL and Python required. dbt tests for data quality.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"dbt is the primary analytics tool \\u2014 direct match\",\"Snowflake is the data warehouse\",\"Looker satisfies BI requirement\",\"Airflow covers orchestration\",\"dbt tests satisfy data quality requirement\",\"SQL and Python are both primary languages\"],\"gaps\":[\"No streaming or event-based analytics experience for a consumer tech company with high-frequency user events\",\"No experimentation or A/B testing framework experience relevant to consumer product analytics\",\"Tableau listed alongside Looker suggests a generalist BI background rather than deep Looker specialization\"],\"explanation\":\"The candidate matches the stated requirements well but a consumer tech analytics team typically requires A/B testing methodology and near-real-time user event processing that are not evidenced. The Tableau presence alongside Looker suggests cross-tool familiarity without deep Looker LookML expertise.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"otto_java\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Maven\",\"Docker\",\"AWS\",\"Hibernate\"],\"architecture\":[\"Monolith\",\"Layered Architecture\"],\"databases\":[\"MySQL\"],\"ci_cd\":[\"Jenkins\"]}\n\nJob Summary:\nFast-growing e-commerce company rewriting their backend from PHP to Kotlin microservices. Seeking a mid-level engineer comfortable with Kotlin and Spring Boot. Kafka for event streaming. PostgreSQL as the database. Kubernetes for deployment. GitHub Actions for CI. Must have microservices experience.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Spring Boot experience is transferable across Java and Kotlin\"],\"gaps\":[\"No Kotlin experience despite it being the primary language for the rewrite\",\"No Kafka or event streaming experience\",\"No PostgreSQL experience; uses MySQL only\",\"No Kubernetes experience for microservices deployment\",\"No GitHub Actions experience; uses Jenkins\",\"Monolith and Layered Architecture background is the opposite of the microservices target\"],\"explanation\":\"The candidate has Java Spring Boot experience that is partially transferable, but lacks Kotlin, Kafka, PostgreSQL, Kubernetes, and microservices architecture experience \u2014 the core requirements for a Kotlin microservices rewrite. The architectural background (monolith + layered) is the inverse of what the role requires.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nour_llm\",\"seniority\":\"Senior\",\"roles\":[\"AI Engineer\",\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"LangChain\",\"LangGraph\",\"OpenAI API\",\"Ollama\",\"FastAPI\",\"Docker\",\"ChromaDB\",\"Weaviate\",\"MLflow\"],\"architecture\":[\"RAG\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Weaviate\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nLegal tech startup building an AI document review system is hiring a senior AI engineer. Must have LangChain and RAG pipeline experience. Vector database required (Weaviate or Pinecone). FastAPI for service endpoints. OpenAI API integration. Python required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"LangChain and RAG architecture are both explicitly present\",\"Weaviate satisfies the vector database requirement\",\"OpenAI API satisfies integration requirement\",\"FastAPI covers the service endpoint requirement\",\"LangGraph adds agentic workflow capability\"],\"gaps\":[\"No legal domain experience or contract parsing knowledge for a legal tech document review context\",\"No document ingestion pipeline experience (PDF parsing, OCR, chunking strategies) for legal document processing\",\"No evaluation framework for RAG quality (RAGAS, LangSmith) to maintain retrieval accuracy on legal documents\"],\"explanation\":\"The candidate has strong LLM application engineering skills but legal document review requires domain-specific RAG tuning, document preprocessing, and quality evaluation practices that are not evidenced. The technical stack is aligned but the legal AI application depth is uncertain for a production legal tech product.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kai_flutter_de\",\"seniority\":\"Mid\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"Dart\",\"TypeScript\"],\"tech\":[\"Flutter\",\"Expo\",\"React Native\",\"Firebase\",\"Fastlane\"],\"databases\":[\"Firebase\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"Flutter test\"]}\n\nJob Summary:\nTravel app startup hiring a mid-level mobile engineer for their React Native platform. TypeScript required. Expo for the build system. Firebase for authentication and notifications. Must have integration testing experience. Cross-platform (iOS and Android) experience needed.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Expo is present satisfying the build system requirement\",\"Firebase covers authentication and notifications\",\"Fastlane is listed for release automation\"],\"gaps\":[\"Flutter is the primary framework, not React Native \\u2014 the candidate's React Native experience is secondary and depth is uncertain\",\"No Jest or React Testing Library for the integration testing requirement\",\"No TypeScript-specific React Native patterns or navigation library (React Navigation) experience\",\"No performance optimization experience for React Native (Hermes engine, bridgeless mode)\"],\"explanation\":\"The candidate is primarily a Flutter developer and the role requires React Native proficiency. Expo and Firebase are strong matches, but the core framework mismatch represents a fundamental risk for a React Native-first team. The integration testing gap further compounds the uncertainty about React Native production depth.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pita_backend_nz\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\",\"SQL\"],\"tech\":[\"FastAPI\",\"Gin\",\"Docker\",\"Kubernetes\",\"AWS\",\"Kafka\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"DynamoDB\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"],\"testing\":[\"pytest\",\"Go unit tests\",\"k6\"]}\n\nJob Summary:\nAPI gateway company building a multi-cloud developer platform is hiring a senior backend engineer. Python with FastAPI or Go with Gin required. PostgreSQL. Kafka for event-driven architecture. Kubernetes and AWS. API Gateway pattern experience. Must have load testing experience.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"FastAPI (Python) and Gin (Go) are both listed covering either language path\",\"Kafka satisfies event-driven architecture requirement\",\"PostgreSQL is listed\",\"k6 satisfies load testing requirement\"],\"gaps\":[\"No multi-cloud experience (GCP, Azure) despite an explicitly multi-cloud developer platform context \\u2014 AWS-only background is insufficient\",\"No API gateway design patterns (rate limiting, authentication middleware, circuit breaking) for a gateway company\",\"No observability for distributed API traffic (distributed tracing, latency histograms) visible\",\"API Gateway architecture is listed but no production gateway implementation experience evidenced\"],\"explanation\":\"Despite language and infrastructure coverage, a multi-cloud API gateway company requires deep multi-cloud networking expertise and API gateway design patterns that are not evidenced. The AWS-only cloud background and the listing of API Gateway as an architecture pattern rather than hands-on implementation experience are significant gaps for a company building a gateway product.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"min_fe_kr\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Redux\",\"Tailwind CSS\",\"Webpack\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"React Testing Library\"]}\n\nJob Summary:\nLarge enterprise software company hiring a mid-level frontend engineer. React with TypeScript. Redux for state management. Tailwind CSS for styling. Jest and React Testing Library for testing. Webpack for build tooling. Azure DevOps for CI/CD.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and TypeScript match the core framework and language requirements\",\"Redux satisfies state management requirement exactly\",\"Tailwind CSS matches the styling requirement\",\"Jest and React Testing Library satisfy the testing requirements\",\"Webpack satisfies the build tooling requirement\"],\"gaps\":[\"No Azure DevOps experience \u2014 uses GitHub Actions instead, requiring CI/CD pipeline migration knowledge\",\"No enterprise-specific patterns (accessibility, i18n, WCAG compliance) visible for a large enterprise software context\"],\"explanation\":\"The candidate matches every technical requirement except the CI/CD platform \u2014 GitHub Actions vs. Azure DevOps is a workflow difference requiring adjustment but is not a fundamental skill gap. Redux, Tailwind, Jest, and Webpack are all precise matches. The CI/CD gap and absence of enterprise accessibility practices are modest concerns.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ada_infra_pl\",\"seniority\":\"Mid\",\"roles\":[\"Infrastructure Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Terraform\",\"Docker\",\"AWS\",\"Ansible\",\"GitHub Actions\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nMid-size company hiring a mid-level infrastructure engineer to maintain AWS infrastructure with Terraform, manage configuration with Ansible, and run Docker-based workloads. Python or Bash for automation. GitHub Actions for CI/CD pipelines.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Terraform satisfies IaC requirement\",\"AWS is the target cloud and is listed\",\"Ansible satisfies configuration management requirement\",\"Docker covers container workload requirement\",\"Python and Bash satisfy automation scripting requirements\",\"GitHub Actions matches the CI/CD platform exactly\"],\"gaps\":[\"No Kubernetes or container orchestration beyond Docker alone\",\"No observability tooling (Prometheus, Grafana) visible\"],\"explanation\":\"The candidate satisfies every stated requirement: Terraform, AWS, Ansible, Docker, Python, Bash, and GitHub Actions. Mid-level seniority matches the role. The gaps in Kubernetes and observability are not stated requirements and are minor concerns given the described scope.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"eli_rust_de\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"Go\",\"C++\"],\"tech\":[\"Actix\",\"Tokio\",\"Docker\",\"Kubernetes\",\"AWS\"],\"architecture\":[\"Microservices\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Rust unit tests\",\"k6\"]}\n\nJob Summary:\nSystems startup building a high-performance message broker is hiring a senior Rust engineer. Actix or Axum for the server layer. Async Rust with Tokio required. PostgreSQL for metadata storage. Redis for pub/sub. Kubernetes for deployment. Must have distributed systems architecture experience.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Rust is the primary language \u2014 exact match\",\"Actix satisfies the server layer requirement directly\",\"Tokio confirms async Rust runtime proficiency\",\"PostgreSQL satisfies metadata storage requirement\",\"Redis is listed for pub/sub\",\"Kubernetes covers deployment\",\"Distributed System architecture confirms relevant design experience\"],\"gaps\":[\"No explicit message broker internals experience (protocol design, persistence guarantees)\"],\"explanation\":\"The candidate is a strong match: Rust, Actix, Tokio, PostgreSQL, Redis, Kubernetes, and distributed systems architecture are all explicitly evidenced. The Actix match is precise and uncommon. The only gap is the absence of message broker-specific design experience, which is a domain nuance rather than a technical skills gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tara_csharp\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"C#\",\"SQL\"],\"tech\":[\"ASP.NET\",\"Entity Framework\",\"Docker\",\"Azure\"],\"architecture\":[\"Microservices\"],\"databases\":[\"MS SQL Server\",\"PostgreSQL\"],\"ci_cd\":[\"Azure DevOps\"],\"testing\":[\"xUnit\",\"Mocha\"]}\n\nJob Summary:\nEnterprise logistics company hiring a mid-level .NET backend engineer. ASP.NET Core and Entity Framework required. Azure for cloud deployment. Azure DevOps for CI/CD. SQL Server as primary database. xUnit for testing. Must have microservices experience.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"ASP.NET and Entity Framework are the exact stack required\",\"C# is the primary language\",\"Azure covers the cloud deployment requirement\",\"Azure DevOps matches the CI/CD platform exactly\",\"MS SQL Server satisfies the primary database requirement\",\"xUnit satisfies the testing requirement\",\"Microservices architecture confirms the design pattern experience\"],\"gaps\":[\"Mocha in the testing profile is a JavaScript testing tool which is inconsistent with a .NET codebase \u2014 suggests mixed background\"],\"explanation\":\"Every stated requirement is met: ASP.NET, Entity Framework, C#, Azure, Azure DevOps, SQL Server, xUnit, and microservices. The Mocha presence is an anomaly in an otherwise pure .NET profile but does not undermine the core match. A strong hire for this enterprise .NET logistics role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ananya_backend_in\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Flask\",\"Docker\",\"PostgreSQL\"],\"databases\":[\"PostgreSQL\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nFinancial data startup hiring a mid-level backend engineer. FastAPI with Python for all services. PostgreSQL as the database. Redis for caching and pub/sub. Kafka for event streaming. Kubernetes for deployment. Must write pytest tests and have microservices experience.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and SQL are present and match the language requirements\",\"PostgreSQL is listed\"],\"gaps\":[\"Junior seniority does not meet mid-level requirement\",\"No FastAPI experience; uses Flask which has a different async model\",\"No Redis experience\",\"No Kafka or event streaming experience\",\"No Kubernetes experience\",\"No pytest testing experience visible\",\"No microservices architecture experience\"],\"explanation\":\"The candidate is an early-career Python web developer with a Flask background and no exposure to the async, streaming, and orchestration infrastructure this role requires. The seniority gap compounds the technical gaps across Redis, Kafka, Kubernetes, and FastAPI, making this a poor fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"bjorn_data\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\",\"Analytics Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"dbt\",\"Airflow\",\"Kafka\",\"Docker\",\"AWS\"],\"databases\":[\"Redshift\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Great Expectations\",\"dbt tests\"]}\n\nJob Summary:\nStreaming music company building a near-real-time recommendation data platform on AWS is hiring a senior data engineer. Must have Apache Spark and Kafka experience for streaming pipelines. dbt for transformations. Redshift as the data warehouse. Airflow for orchestration. Python and Scala required. Data quality tooling expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Apache Spark and Kafka are both present for streaming pipeline requirements\",\"dbt satisfies the transformation requirement\",\"Redshift is listed as the primary warehouse \u2014 exact match\",\"Airflow satisfies orchestration requirement\",\"Python and Scala are both primary languages\",\"Great Expectations and dbt tests together demonstrate data quality depth\",\"AWS covers the cloud infrastructure requirement\"],\"gaps\":[\"No real-time feature serving experience for recommendation system online inference\"],\"explanation\":\"The candidate maps to every stated requirement: Spark, Kafka, dbt, Redshift, Airflow, Python, Scala, and data quality tooling. Redshift as the warehouse and the dual data quality tooling are specific and strong matches. A compelling hire for a streaming music recommendation data platform.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pooja_swe\",\"seniority\":\"Mid\",\"roles\":[\"Software Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Gatsby\",\"React\",\"GraphQL\",\"Tailwind CSS\",\"Netlify\"],\"databases\":[\"Contentful\",\"Sanity\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nDigital agency building static marketing sites and content-driven web properties is hiring a mid-level frontend engineer. Must have experience with React-based static site generators (Gatsby or Next.js). GraphQL for CMS data fetching. Headless CMS experience (Contentful or Sanity). Tailwind CSS. Netlify or Vercel for deployment.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Gatsby satisfies the React-based static site generator requirement\",\"GraphQL is listed for CMS data fetching\",\"Contentful and Sanity both present \\u2014 exceeds headless CMS requirement\",\"Tailwind CSS satisfies styling\",\"Netlify satisfies deployment requirement\"],\"gaps\":[\"No Next.js experience \\u2014 the increasingly dominant alternative to Gatsby in agency work with more flexibility\",\"No Cloudflare or CDN optimization experience for performance-critical marketing sites\",\"No accessibility or WCAG compliance experience for enterprise client work\"],\"explanation\":\"The candidate matches the stated requirements with Gatsby, but Gatsby is increasingly less common in modern agency work compared to Next.js, and the profile lacks evidence of the performance optimization and accessibility practices that enterprise client agencies require. The CMS and GraphQL matches are strong, but the broader agency engineering depth is limited.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"remy_infra_fr\",\"seniority\":\"Senior\",\"roles\":[\"Infrastructure Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\",\"Go\"],\"tech\":[\"Terraform\",\"Pulumi\",\"Kubernetes\",\"Docker\",\"GCP\",\"Helm\",\"Argo CD\",\"Prometheus\",\"Grafana\"],\"ci_cd\":[\"GitLab CI\",\"Argo CD\"],\"testing\":[\"Terratest\"]}\n\nJob Summary:\nEuropean fintech hiring a senior infrastructure engineer. GCP as the cloud platform. Terraform for infrastructure as code. Kubernetes and Helm for orchestration. Argo CD for GitOps. Prometheus and Grafana for observability. Python or Go for automation.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"GCP is the target cloud and is listed\",\"Terraform satisfies IaC requirement\",\"Kubernetes and Helm satisfy orchestration\",\"Argo CD covers GitOps\",\"Prometheus and Grafana satisfy observability\",\"Pulumi adds IaC redundancy\",\"Terratest shows infrastructure testing discipline\"],\"gaps\":[\"No GCP-native managed service experience (Cloud SQL, Cloud Armor, Cloud CDN) beyond the general GCP label\",\"No multi-region or global load balancing experience for a fintech company requiring high availability\",\"GitLab CI as CI/CD alongside Argo CD suggests tooling fragmentation that may need consolidation\"],\"explanation\":\"The candidate matches the stated infrastructure requirements but the profile lacks GCP-specific managed service depth expected for a fintech company where cloud-native services (Cloud SQL, IAM, VPC) differ meaningfully from generic Kubernetes skills. The tooling profile is strong but the GCP specialization is uncertain.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mira_frontend_hr\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Vite\",\"Axios\"]}\n\nJob Summary:\nGrowth-stage B2B SaaS startup seeking a mid-level frontend engineer. React with TypeScript. SWR for data fetching. Zustand for state management. Tailwind CSS. Must write tests with Vitest and React Testing Library. Familiar with Storybook for component documentation.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and TypeScript are present\",\"Tailwind CSS matches the styling requirement\"],\"gaps\":[\"Junior seniority does not meet mid-level requirement\",\"No SWR experience for data fetching\",\"No Zustand or any state management library experience\",\"No Vitest or React Testing Library experience \u2014 no testing visible at all\",\"No Storybook experience for component documentation\",\"Profile is sparse and lacks depth for a mid-level role\"],\"explanation\":\"The candidate has React and Tailwind basics but lacks every specialized tool required: SWR, Zustand, Vitest, Testing Library, and Storybook. The seniority gap compounds the tooling gaps, making this candidate a poor fit for a mid-level role at a growth-stage SaaS company expecting independent contributions.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"alex_ml_fr\",\"seniority\":\"Mid\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"PyTorch\",\"scikit-learn\",\"Pandas\",\"NumPy\",\"spaCy\",\"NLTK\",\"FastAPI\",\"Docker\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nRegtech company building a contract analysis NLP system is hiring a mid-level ML engineer. Python required. spaCy for named entity recognition and text processing pipelines. PyTorch for custom model training. FastAPI for model serving endpoints. PostgreSQL for data storage.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"spaCy is the primary NLP library satisfying NER requirement\",\"PyTorch satisfies custom model training requirement\",\"FastAPI satisfies model serving requirement\",\"PostgreSQL covers data storage\",\"NLTK adds additional NLP depth\"],\"gaps\":[\"No Hugging Face Transformers experience for modern transformer-based NER models that outperform classical spaCy pipelines\",\"No legal contract preprocessing experience (clause extraction, sentence boundary detection in legal text)\",\"No model fine-tuning experience on domain-specific legal corpora\"],\"explanation\":\"The candidate has solid NLP engineering fundamentals with spaCy and PyTorch, but modern legal AI systems increasingly rely on Transformer-based models fine-tuned on legal corpora, which are not evidenced. The spaCy match is strong for classical NLP pipelines but may not cover the model performance requirements of a production contract analysis system.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cole_intern\",\"seniority\":\"Intern\",\"languages\":[\"Python\",\"JavaScript\"],\"tech\":[\"React\",\"Flask\"]}\n\nJob Summary:\nEarly-stage AI startup seeking a junior full stack engineer comfortable with React, a Python backend, and PostgreSQL. Must be able to integrate with OpenAI API and build lightweight internal tooling. Docker for local development. GitHub Actions for CI.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and Python basics partially align with the role\"],\"gaps\":[\"Intern seniority is below the junior requirement for independent feature development\",\"No PostgreSQL experience despite it being the primary database\",\"No OpenAI API integration experience\",\"No Docker experience for local development\",\"No GitHub Actions for CI pipelines\",\"No testing framework visible\",\"Flask experience does not cover the FastAPI or Node.js patterns the role may evolve toward\"],\"explanation\":\"The intern profile has only the most basic alignment with this role. Every specific technical requirement \\u2014 PostgreSQL, OpenAI API, Docker, and GitHub Actions \\u2014 is absent. Intern-level experience without any explicit tooling beyond React and Flask requires too much investment for a startup that needs an independent junior contributor.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fiona_staff\",\"seniority\":\"Staff\",\"roles\":[\"Backend Engineer\",\"Software Architect\"],\"languages\":[\"Go\",\"Python\",\"Rust\"],\"tech\":[\"Kubernetes\",\"Kafka\",\"Terraform\",\"AWS\",\"Docker\",\"gRPC\",\"Istio\",\"Vault\",\"Prometheus\",\"OpenTelemetry\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Service Mesh\",\"CQRS\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"CockroachDB\",\"Redis\",\"Cassandra\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\",\"Flux\"],\"testing\":[\"Go unit tests\",\"k6\",\"pytest\"]}\n\nJob Summary:\nHigh-scale infrastructure company hiring a staff engineer to lead platform evolution. Must have deep Go and distributed systems expertise, Kafka for event streaming, gRPC for service communication, and Kubernetes with service mesh (Istio). Terraform on AWS. OpenTelemetry for observability. CQRS pattern knowledge required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go is the primary language and the role's core language requirement\",\"Kafka satisfies the event streaming requirement\",\"gRPC satisfies service communication requirement\",\"Kubernetes and Istio together satisfy the service mesh requirement\",\"Terraform and AWS satisfy infrastructure requirements\",\"OpenTelemetry satisfies the observability requirement\",\"CQRS is listed in the architecture profile\",\"Staff seniority matches the platform leadership expectation\"],\"gaps\":[\"No formal RFC or architectural decision record (ADR) process signals for staff-level governance\"],\"explanation\":\"This candidate satisfies every requirement precisely: Go, Kafka, gRPC, Kubernetes, Istio, Terraform, AWS, OpenTelemetry, and CQRS. The staff seniority and distributed systems architecture depth (CQRS, Service Mesh, Event-Driven, Distributed System) directly align with the platform leadership scope. An exceptional fit.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nat_py_be\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"FastAPI\",\"SQLAlchemy\",\"Alembic\",\"Docker\",\"AWS\",\"Redis\",\"Celery\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nLogistics SaaS company hiring a mid-level Python backend engineer. FastAPI for all services. SQLAlchemy with Alembic for database schema management. PostgreSQL as primary database. Celery and Redis for task queues. AWS for deployment. Must have load testing experience.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"FastAPI is the primary framework \\u2014 exact match\",\"SQLAlchemy and Alembic satisfy ORM and schema migration requirements\",\"PostgreSQL is the primary database\",\"Celery and Redis satisfy task queue requirements\",\"Locust covers load testing requirement\"],\"gaps\":[\"No OpenAPI or Swagger documentation experience for a logistics SaaS API that external clients likely integrate with\",\"No multi-tenancy or tenant isolation patterns visible for a SaaS product serving multiple logistics clients\",\"AWS is listed but no specific AWS services (SQS, SNS, ECS) experience relevant to logistics workloads\"],\"explanation\":\"The candidate has a strong FastAPI and SQLAlchemy alignment with precise Alembic and Celery matches, but a logistics SaaS product serving external clients requires API documentation, multi-tenancy design, and AWS service depth that are not evidenced. The core stack alignment is strong but the SaaS product engineering breadth is limited.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hugo_ts\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Express.js\",\"Mongoose\",\"Docker\",\"AWS\"],\"databases\":[\"MongoDB\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nB2B SaaS company building an analytics dashboard is hiring a full stack engineer. Backend is NestJS with TypeScript. Frontend is React with TypeScript. PostgreSQL via Prisma ORM. Tanstack Query for data fetching. Must write Jest tests. AWS deployment.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"TypeScript is present as a language\",\"PostgreSQL and Redis are listed\"],\"gaps\":[\"No NestJS experience \\u2014 the specific backend framework required\",\"No Prisma or any TypeScript ORM experience; uses Mongoose (MongoDB-specific)\",\"No TanStack Query experience for frontend data fetching\\\", \\\"MongoDB-first background creates a schema mismatch for a PostgreSQL-first analytics dashboard\",\"No API documentation (OpenAPI, Swagger) experience for a B2B SaaS product with external integrations\"],\"explanation\":\"The candidate is a MongoDB and Express.js developer with no NestJS, Prisma, or TanStack Query experience. For a B2B analytics dashboard, the database mismatch (MongoDB document model vs. PostgreSQL relational) and the absence of the backend framework are fundamental technical gaps that require a significant stack transition.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sam_kotlin_fi\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Kotlin\",\"Java\",\"SQL\"],\"tech\":[\"Spring Boot\",\"Kafka\",\"Docker\",\"Kubernetes\",\"AWS\",\"Gradle\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\",\"TestContainers\"]}\n\nJob Summary:\nCloud communications platform hiring a mid-level backend engineer for Kotlin microservices. Spring Boot with Kotlin. Kafka for message queuing. PostgreSQL and Redis. Kubernetes on AWS. Gradle for builds. Must write integration tests, ideally with TestContainers.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kotlin is the primary language satisfying the preference\",\"Spring Boot is the primary framework\",\"Kafka satisfies message queuing requirement\",\"PostgreSQL and Redis are both listed\",\"Kubernetes and AWS satisfy deployment\",\"TestContainers satisfies the integration testing requirement\"],\"gaps\":[\"No gRPC or service-to-service communication protocol experience for a cloud communications platform requiring reliable inter-service calls\",\"No API versioning or backward compatibility patterns for a communications platform with external clients\",\"Gradle build tool experience is present but no multi-module project structure experience for a large microservices platform\"],\"explanation\":\"The candidate is technically aligned across most requirements, but a cloud communications platform serving external clients requires gRPC or equivalent inter-service communication patterns and API versioning discipline that are not evidenced. TestContainers is a strong specific match, but the service communication gap is meaningful for a communications-specific platform.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ruby_devops\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"Jenkins\",\"Ansible\",\"AWS\",\"Terraform\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nData platform company seeking a senior DevOps engineer to own Kubernetes infrastructure on GCP. Must have strong Kubernetes and Helm experience, Terraform for IaC, GitOps with Flux or Argo CD, Prometheus and Grafana for observability, and Go for internal tooling development.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Terraform and AWS experience provides transferable IaC knowledge\",\"Ansible and Docker show configuration and containerization fundamentals\"],\"gaps\":[\"Mid-level seniority does not meet senior requirement for owning Kubernetes infrastructure\",\"No Kubernetes or Helm experience \u2014 the core platform requirement\",\"No GCP experience \u2014 the target cloud platform\",\"No GitOps experience (Flux or Argo CD)\",\"No Prometheus or Grafana observability experience\",\"No Go experience for internal tooling development\",\"Uses Jenkins for CI rather than GitOps-based approaches\"],\"explanation\":\"The candidate has general DevOps fundamentals but lacks Kubernetes, GCP, GitOps, observability tooling, and Go \u2014 every specific technical requirement for this senior role. The cloud platform mismatch (AWS vs. GCP) and the absence of Kubernetes experience are particularly disqualifying for a role centered on owning GCP Kubernetes infrastructure.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ana_be_br\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"DRF\",\"Celery\",\"Redis\",\"Docker\",\"AWS\",\"Elasticsearch\"],\"architecture\":[\"Monolith\",\"Modular Architecture\"],\"databases\":[\"PostgreSQL\",\"Elasticsearch\"],\"ci_cd\":[\"GitHub Actions\",\"CircleCI\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nMarketplace company hiring a senior Django engineer to build search and recommendation features. Django REST Framework required. Elasticsearch for search indexing. Celery and Redis for async processing. PostgreSQL for primary data. AWS. Must write pytest tests.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Django and Django REST Framework are the primary stack \u2014 exact match including DRF specifically\",\"Elasticsearch is explicitly listed for search indexing \u2014 a specific and direct match\",\"Celery and Redis together satisfy async processing requirement\",\"PostgreSQL is the primary database\",\"AWS covers cloud deployment\",\"pytest satisfies testing requirement\"],\"gaps\":[\"No recommendation system or ML-based personalization experience beyond search\"],\"explanation\":\"The candidate matches every stated requirement: Django, DRF, Elasticsearch, Celery, Redis, PostgreSQL, AWS, and pytest. The Elasticsearch and DRF matches are particularly specific. A precise and high-confidence match for a Django search engineering role at a marketplace company.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"drew_ts_fe\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React\",\"Next.js\",\"Zustand\",\"SWR\",\"Tailwind CSS\",\"shadcn/ui\",\"Storybook\",\"Vite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"React Testing Library\",\"Playwright\"]}\n\nJob Summary:\nProduct company building a developer tools SaaS is hiring a senior frontend engineer. React and Next.js with TypeScript. Zustand for state management. SWR for data fetching. Tailwind CSS with shadcn/ui component library. Must maintain a Storybook component library. Comprehensive testing with Vitest, Testing Library, and Playwright.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React and Next.js match the frontend framework exactly\",\"Zustand satisfies the state management requirement\",\"SWR satisfies the data fetching requirement directly\",\"Tailwind CSS and shadcn/ui together satisfy the component library requirements\",\"Storybook is listed for component library maintenance\",\"Vitest, React Testing Library, and Playwright together satisfy all testing requirements precisely\",\"TypeScript is the primary language\"],\"gaps\":[],\"explanation\":\"The candidate is a textbook match for every stated requirement: React, Next.js, Zustand, SWR, Tailwind, shadcn/ui, Storybook, Vitest, Testing Library, and Playwright. All three testing frameworks are present. This is an exceptional technology alignment with no meaningful gaps for a senior frontend role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"petra_devex\",\"seniority\":\"Lead\",\"roles\":[\"Backend Engineer\",\"Platform Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Terraform\",\"Helm\",\"Argo CD\",\"Prometheus\",\"Grafana\",\"AWS\",\"Docker\",\"Vault\",\"Consul\"],\"architecture\":[\"Cloud-Native\",\"Microservices\",\"Service Mesh\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\",\"Tekton\"],\"testing\":[\"Terratest\",\"k6\"]}\n\nJob Summary:\nTech company building an internal developer platform is hiring a lead platform engineer. Kubernetes with Helm on AWS. Terraform for IaC. Argo CD for GitOps. Vault for secrets management. Consul for service discovery. Prometheus and Grafana for observability. Go for tooling. Lead-level seniority required.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubernetes, Helm, and AWS satisfy the orchestration and cloud requirements\",\"Terraform satisfies IaC requirement\",\"Argo CD is the GitOps tool and CI/CD platform \u2014 exact match\",\"Vault satisfies secrets management requirement\",\"Consul is explicitly listed for service discovery \u2014 an uncommon specific match\",\"Prometheus and Grafana satisfy observability requirements\",\"Go is listed for tooling\",\"Lead seniority matches the stated level\"],\"gaps\":[\"No Backstage or developer portal tooling for an internal developer platform context\"],\"explanation\":\"The candidate is an exceptional match. Every stated requirement \u2014 Kubernetes, Helm, AWS, Terraform, Argo CD, Vault, Consul, Prometheus, Grafana, Go, and lead seniority \u2014 is explicitly present. The Consul match is particularly specific and uncommon. A compelling hire for a lead platform engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mila_qa\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Express.js\",\"Docker\",\"AWS\",\"Redis\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Mocha\",\"Supertest\",\"Playwright\"]}\n\nJob Summary:\nAPI-first startup hiring a mid-level backend engineer for their Hapi.js-based REST API platform. TypeScript required. PostgreSQL via Knex.js query builder. Redis for caching. Must write thorough Jest tests and use Swagger for API documentation. AWS deployment.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"TypeScript is present as a primary language\",\"PostgreSQL and Redis are both listed\",\"Jest satisfies the testing requirement\",\"AWS covers deployment\",\"Supertest and Playwright demonstrate testing breadth\"],\"gaps\":[\"No Hapi.js experience \u2014 the specific backend framework; uses Express.js instead\",\"No Knex.js experience for the query builder requirement\",\"No Swagger or OpenAPI documentation experience\",\"MongoDB experience alongside PostgreSQL suggests mixed data model background rather than relational-first focus\"],\"explanation\":\"The candidate has Node.js backend experience and most infrastructure requirements, but the specific framework (Hapi.js vs Express.js) and query builder (Knex.js) are absent. Swagger documentation is also missing. For an API-first startup where the HTTP framework is a core engineering decision, the Hapi.js gap requires a focused transition period.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"leo_scala_se\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Scala\",\"Java\",\"SQL\"],\"tech\":[\"Play Framework\",\"Akka\",\"Docker\",\"AWS\",\"Kafka\"],\"architecture\":[\"Event-Driven\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ScalaTest\",\"Gatling\"]}\n\nJob Summary:\nAdtech company building a real-time bidding engine is hiring a senior backend engineer. Scala required. Akka for actor-model concurrency. Kafka for bid event streaming. Cassandra for high-write bid storage. Must have load testing experience. AWS deployment.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Scala and Akka form the actor-model concurrency stack \\u2014 direct match\",\"Kafka satisfies event streaming for bid events\",\"Cassandra satisfies high-write bid storage requirement\",\"Gatling satisfies load testing requirement\",\"AWS covers deployment\"],\"gaps\":[\"No OpenRTB or real-time bidding protocol experience for adtech domain work\",\"No sub-millisecond latency tuning experience for bid response time requirements (<100ms typical)\",\"No JVM performance tuning (GC, heap, thread management) experience for a latency-critical Scala application\"],\"explanation\":\"The candidate has the correct Scala-Akka-Cassandra stack for high-throughput event processing, but a real-time bidding engine has extreme latency requirements that demand JVM performance tuning and adtech domain knowledge neither of which are evidenced. The technical stack matches but the production performance engineering depth for sub-millisecond bid responses is uncertain.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nadia_ops\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Docker\",\"Terraform\",\"AWS\",\"Datadog\",\"GitHub Actions\"],\"architecture\":[\"Cloud-Native\"],\"ci_cd\":[\"GitHub Actions\",\"CircleCI\"]}\n\nJob Summary:\nTelecommunications company seeking a senior DevOps engineer to manage on-premise Linux infrastructure, configure Puppet for configuration management, and maintain Jenkins CI/CD pipelines. Must have network configuration experience (BGP, VLANs). Python scripting required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python scripting satisfies the scripting requirement\",\"General DevOps experience is broadly relevant\"],\"gaps\":[\"Mid-level seniority does not meet senior requirement\",\"No Puppet experience \u2014 the required configuration management tool\",\"No Jenkins experience \u2014 the required CI/CD platform\",\"No on-premise or bare-metal Linux infrastructure experience\",\"No network configuration experience (BGP, VLANs) \u2014 a core stated requirement\",\"Cloud-native and Kubernetes background is opposite to the on-premise focus of this role\"],\"explanation\":\"The candidate is a cloud-native DevOps engineer and this role requires on-premise Linux infrastructure expertise with Puppet, Jenkins, and networking skills. The technical domain mismatch is fundamental \u2014 cloud orchestration experience does not transfer to bare-metal infrastructure management and network configuration.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kat_mlops\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"MLflow\",\"Weights & Biases\",\"Ray\",\"Docker\",\"Kubernetes\",\"FastAPI\",\"AWS\"],\"architecture\":[\"Microservices\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\",\"Argo CD\"]}\n\nJob Summary:\nE-commerce company building a dynamic pricing ML system is hiring a senior ML engineer. Must have PyTorch for modeling, Ray for distributed training, MLflow for experiment tracking, FastAPI for model serving, Kubernetes for deployment. AWS required. Python.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PyTorch satisfies the modeling framework requirement\",\"Ray satisfies the distributed training requirement\",\"MLflow satisfies the experiment tracking requirement\",\"FastAPI satisfies the model serving requirement\",\"Kubernetes covers deployment\",\"AWS is the target cloud\",\"Weights and Biases adds experiment tracking depth beyond requirements\"],\"gaps\":[\"No pricing optimization or operations research background visible for dynamic pricing domain\"],\"explanation\":\"The candidate matches every stated requirement: PyTorch, Ray, MLflow, FastAPI, Kubernetes, and AWS. Weights and Biases alongside MLflow demonstrates tracking maturity beyond requirements. The only gap is dynamic pricing domain expertise, which is contextual rather than a technical skills gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"james_ts_lead\",\"seniority\":\"Lead\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\"],\"tech\":[\"React\",\"Next.js\",\"NestJS\",\"Docker\",\"AWS\",\"Kafka\",\"Redis\",\"GraphQL\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nFast-growing proptech company hiring a lead full stack engineer. React and Next.js on the frontend. NestJS on the backend with TypeScript. GraphQL API layer. PostgreSQL as the database. Kafka for event-driven property data streams. Redis for caching. AWS. Lead-level seniority.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React and Next.js match the frontend requirement\",\"NestJS is the backend framework \u2014 exact match\",\"GraphQL is listed for the API layer\",\"PostgreSQL is the primary database\",\"Kafka satisfies the event-driven property data stream requirement\",\"Redis covers caching\",\"AWS covers cloud deployment\",\"Lead seniority matches the stated level\"],\"gaps\":[\"No real estate or property domain-specific data modeling experience visible\"],\"explanation\":\"The candidate maps to every stated technology: React, Next.js, NestJS, GraphQL, PostgreSQL, Kafka, Redis, and AWS. Lead seniority matches the expectation. The full-stack depth combined with event-driven architecture experience makes this a high-confidence hire for a proptech lead engineering role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"gwen_analytics\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\",\"Analytics Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Looker\",\"Power BI\",\"dbt\",\"Airflow\",\"Pandas\"],\"databases\":[\"BigQuery\",\"Redshift\",\"PostgreSQL\"]}\n\nJob Summary:\nMarket research firm seeking a senior data engineer to build and maintain streaming pipelines with Kafka and Apache Flink. Must have PySpark for batch, Scala or Python, Snowflake as the data warehouse, and AWS infrastructure. Databricks experience is a plus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"SQL and Python are present\",\"dbt experience provides some data engineering foundation\"],\"gaps\":[\"Mid-level analyst seniority does not meet senior data engineer requirement\",\"No Kafka or Flink experience for streaming pipelines\",\"No PySpark or Spark experience for batch processing\",\"No Snowflake experience \u2014 the required data warehouse\",\"No AWS experience\",\"No Databricks experience despite it being a plus\",\"BI tool focus (Looker, Power BI) confirms an analytics rather than engineering background\"],\"explanation\":\"The candidate is a business-facing analytics engineer and not a pipeline engineer. Kafka, Flink, PySpark, and Snowflake are all absent \u2014 these form the core of the role. The seniority and domain mismatch between analytics engineering and streaming data pipeline engineering is fundamental.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rkowalski_dev\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\"],\"tech\":[\"FastAPI\",\"Django\",\"Docker\",\"Kubernetes\",\"AWS\"],\"architecture\":[\"Microservices\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"pytest\",\"Locust\"]}\n\nJob Summary:\nWe are a fintech startup building high-throughput payment processing services. We need a senior backend engineer comfortable with Python or Go microservices deployed on Kubernetes. The ideal candidate has experience with event-driven architecture, PostgreSQL, Redis caching, and automated testing. You will own service reliability and contribute to infrastructure decisions using AWS and GitOps workflows.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Senior-level Python and Go align directly with the required stack\",\"Kubernetes and ArgoCD demonstrate GitOps proficiency the role demands\",\"Event-Driven and Microservices architecture experience matches the payment service design\",\"PostgreSQL and Redis usage covers both persistence and caching needs\",\"pytest and Locust show both unit and load testing capability\"],\"gaps\":[\"No explicit fintech or payments domain experience visible\"],\"explanation\":\"This candidate's technical profile is an exceptionally close match across language, infrastructure, and architecture requirements. The combination of ArgoCD, Kubernetes, and AWS shows production-grade cloud-native maturity. The only minor gap is the absence of explicit payments domain context, which is a soft concern given the strong engineering signals.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tran_minh_fullstack\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"Node.js\",\"Tailwind CSS\",\"Prisma\",\"Vercel\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nEarly-stage B2B SaaS startup looking for a full stack engineer to own the entire product surface. We build with Next.js and React on the frontend, Node.js on the backend, and deploy via Vercel. You should be comfortable with TypeScript, Tailwind, and a relational database. We value engineers who can ship fast and write tests for critical paths.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js, React, and Tailwind CSS are exact matches for the frontend stack\",\"Prisma with PostgreSQL and Supabase covers the relational database requirement\",\"Vercel deployment experience aligns with the team's delivery pipeline\",\"Playwright and Jest demonstrate testing discipline across E2E and unit layers\",\"TypeScript proficiency across the full stack matches the role's expectations\"],\"gaps\":[\"Mid-level seniority may require closer mentorship in a startup with no senior support\"],\"explanation\":\"The candidate's stack is essentially a direct mirror of the job requirements with no significant technology gaps. Vercel, Next.js, Supabase, and TypeScript together are strong signals of familiarity with the modern SaaS toolchain. The only mild concern is seniority given the expectation to own the full product surface independently.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"data_eng_priya\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Spark\",\"Apache Airflow\",\"dbt\",\"Pandas\",\"Docker\"],\"architecture\":[\"Event-Driven\",\"Distributed System\"],\"databases\":[\"Snowflake\",\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"pytest\",\"Great Expectations\"]}\n\nJob Summary:\nEnterprise analytics company hiring a senior data engineer to build and maintain scalable ELT pipelines. The stack is Snowflake, dbt, and Airflow. Experience with Spark for large-scale batch processing is a plus. We write Python, validate data quality with automated tooling, and deploy on GCP. Candidates should be comfortable with SQL and cloud data warehouse design.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Snowflake, dbt, and Airflow are all present and listed prominently\",\"Great Expectations signals mature data quality practices aligned with the role\",\"Spark experience satisfies the stated bonus requirement\",\"BigQuery and GCP-adjacent experience supports the cloud data warehouse context\",\"Senior seniority with distributed system architecture understanding fits the scale expectations\"],\"gaps\":[\"No explicit GCP infrastructure experience beyond BigQuery usage\"],\"explanation\":\"The candidate matches every core requirement of the role and also satisfies the Spark bonus criterion. Great Expectations for data validation and dbt for transformations together indicate production pipeline maturity. The only minor gap is limited explicit GCP infrastructure knowledge, though BigQuery familiarity is a reasonable proxy.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"jl_frontend\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"Firebase\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nGrowth-stage startup building a developer tools product. Looking for a mid-to-senior frontend engineer with deep React and TypeScript expertise. The candidate should have experience with state management libraries like Redux or Zustand, performance optimization, design system contributions, and writing comprehensive component tests. We move fast and expect autonomy.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React and TypeScript are present and relevant\"],\"gaps\":[\"Junior seniority does not meet the mid-to-senior requirement\",\"No state management library experience (Redux, Zustand, or equivalent)\",\"No design system or component library contributions visible\",\"Testing coverage appears minimal with only Jest and no component-level testing library\",\"No evidence of performance optimization work\"],\"explanation\":\"While the candidate has the foundational frontend skills, they fall short on seniority and the specialized React ecosystem depth this role requires. The absence of state management, design system work, and Testing Library signals an early-career profile that would struggle with the autonomy expectations. This role needs someone with significantly more production React experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devops_ali99\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"Kubernetes\",\"Terraform\",\"AWS\",\"Helm\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"ci_cd\":[\"GitHub Actions\",\"Jenkins\"],\"testing\":[\"k6\"]}\n\nJob Summary:\nScale-up company seeking a mid-level DevOps engineer to manage infrastructure as code on AWS, maintain CI/CD pipelines, and support Kubernetes cluster operations. Familiarity with Terraform, Helm, and GitHub Actions is expected. Experience with observability tooling such as Prometheus or Grafana is highly valued.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Terraform, Helm, and Kubernetes directly match the stated infrastructure expectations\",\"AWS and Docker demonstrate cloud-native infrastructure maturity\",\"GitHub Actions and Jenkins cover the CI/CD pipeline requirement\",\"Mid-level seniority is an exact match for the role level\"],\"gaps\":[\"No observability tooling visible — Prometheus, Grafana, or equivalent are absent\",\"No logging stack experience (ELK, Loki, etc.) evident\"],\"explanation\":\"The candidate covers the core infrastructure and CI/CD requirements confidently, and seniority is well-aligned. However, the absence of any observability tooling is a meaningful gap given it is explicitly called out as highly valued. The role could work but the candidate would need to ramp on monitoring and alerting practices quickly.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mobdev_sara\",\"seniority\":\"Senior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Kotlin\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Expo\",\"React Native\"],\"databases\":[\"Firebase\",\"SQLite\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"Detox\",\"XCTest\"]}\n\nJob Summary:\nConsumer app company building a cross-platform mobile product for iOS and Android. We use React Native with Expo for the shared codebase and need an engineer who can also drop into native Swift or Kotlin when needed. CI/CD is managed through Fastlane. We need someone senior enough to own the mobile release process end to end.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"React Native and Expo are direct matches for the cross-platform stack\",\"Native Swift and Kotlin capability satisfies the requirement for native drop-in work\",\"Fastlane experience aligns with the stated CI/CD toolchain\",\"Detox shows cross-platform E2E testing maturity\",\"Senior seniority supports the expectation to own the release process autonomously\"],\"gaps\":[\"No explicit App Store or Play Store release management mentioned beyond Fastlane\"],\"explanation\":\"This candidate is well-suited across every dimension the role specifies, from cross-platform React Native to native fallback capability and release automation. The Fastlane and Detox combination demonstrates production mobile delivery experience. The only gap is a minor one around explicit release management documentation, which is a soft signal rather than a technical deficiency.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_intern_alex\",\"seniority\":\"Intern\",\"languages\":[\"Python\"],\"tech\":[\"TensorFlow\",\"NumPy\",\"Pandas\"],\"testing\":[\"unittest\"]}\n\nJob Summary:\nFAANG-adjacent AI lab seeking a machine learning engineer with at least three years of experience. The candidate must have hands-on experience with PyTorch, distributed training with Ray or similar, model serving infrastructure, and MLflow or Weights and Biases for experiment tracking. Publications or significant open source contributions in ML are strongly preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Intern seniority is far below the three-year minimum requirement\",\"Uses TensorFlow, not PyTorch which is required\",\"No distributed training experience (Ray or equivalent)\",\"No model serving or MLOps tooling visible\",\"No MLflow or Weights and Biases for experiment tracking\",\"No research publications or notable open source contributions apparent\"],\"explanation\":\"This candidate is at the very beginning of their ML career and does not meet any of the experience thresholds the role requires. The technology mismatch between TensorFlow and the required PyTorch stack compounds the seniority gap. There is no evidence of the MLOps, distributed training, or research depth this lab-level role demands.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"backend_franz\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Docker\",\"Kubernetes\",\"AWS\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"CQRS\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"Redis\"],\"ci_cd\":[\"Jenkins\",\"GitLab CI\"],\"testing\":[\"JUnit\",\"Mockito\"]}\n\nJob Summary:\nEnterprise software company modernizing a legacy Java monolith into microservices. We use Spring Boot, Kubernetes, and PostgreSQL. Architects comfortable with CQRS and event-driven patterns are highly valued. The team is JVM-focused and the candidate should be comfortable owning services from design to deployment on AWS.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Java and Kotlin with Spring Boot directly match the JVM-focused team requirement\",\"Microservices, CQRS, and Event-Driven architecture are all explicitly present\",\"Cassandra alongside PostgreSQL shows experience with high-availability data storage patterns\",\"Kubernetes and AWS support end-to-end ownership of services in production\",\"JUnit and Mockito demonstrate mature Java testing practices\"],\"gaps\":[\"No Kafka or messaging broker experience visible for event-driven integration\"],\"explanation\":\"This candidate is exceptionally well-matched to the modernization initiative, bringing both the JVM expertise and the architectural patterns the team is building toward. The CQRS and event-driven experience in particular addresses the most specialized requirements. The only minor gap is the absence of an explicit messaging broker like Kafka, which is common in event-driven microservice systems.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sre_nguyen\",\"seniority\":\"Senior\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Prometheus\",\"Grafana\",\"Terraform\",\"Docker\",\"Istio\"],\"architecture\":[\"Service Mesh\",\"Cloud-Native\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"]}\n\nJob Summary:\nHigh-scale platform team at a Series C company looking for a senior SRE to own reliability of a Kubernetes-based service mesh. You will manage Prometheus and Grafana dashboards, run incident response, and improve infrastructure as code with Terraform. Experience with Istio or Linkerd is a strong plus. We write automation in Go or Python.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Prometheus and Grafana are direct matches for the observability requirements\",\"Istio experience satisfies the stated strong-plus bonus requirement\",\"Terraform covers the infrastructure as code expectation\",\"Go and Python for automation align with the team's scripting preferences\",\"ArgoCD and Kubernetes together demonstrate GitOps-based cluster management maturity\"],\"gaps\":[\"No explicit incident response tooling (PagerDuty, etc.) visible\"],\"explanation\":\"The candidate's profile reads like a tailored match for this role, covering observability, service mesh, IaC, and automation languages simultaneously. The Istio experience in particular addresses the most differentiated requirement. The only minor absence is explicit incident response tooling, which is a process-level gap rather than a technical deficiency.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"php_legacy_dev\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"Laravel\",\"Nginx\",\"Bootstrap\"],\"databases\":[\"MySQL\"],\"ci_cd\":[\"GitLab CI\"]}\n\nJob Summary:\nModern fintech startup hiring a backend engineer to build REST APIs and event-driven services in Python or Go. The team uses FastAPI, PostgreSQL, Kafka, and deploys via Kubernetes on GCP. We value clean architecture, automated testing, and engineers comfortable with container-native workflows.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Backend engineering background and REST API experience are transferable\"],\"gaps\":[\"No Python or Go experience — the role requires one of these languages\",\"FastAPI and Kafka are both absent from the profile\",\"No Kubernetes or container-native deployment experience\",\"MySQL experience does not transfer to the PostgreSQL-centric stack without demonstrated migration\",\"No automated testing visible\",\"No GCP or cloud-native infrastructure experience\"],\"explanation\":\"The candidate's skill set is centered on a PHP/Laravel/MySQL stack that has minimal overlap with this startup's modern Python or Go microservices environment. The gaps span language, framework, infrastructure, and testing — making this a significant mismatch rather than a ramp-up challenge. A substantial retraining period would be required before meaningful contribution.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cloudarch_mei\",\"seniority\":\"Principal\",\"roles\":[\"Solutions Architect\",\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\",\"TypeScript\"],\"tech\":[\"AWS\",\"Terraform\",\"Pulumi\",\"Kubernetes\",\"Docker\",\"Kafka\"],\"architecture\":[\"Cloud-Native\",\"Distributed System\",\"Event-Driven\",\"Microservices\",\"API Gateway\"],\"databases\":[\"DynamoDB\",\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"]}\n\nJob Summary:\nHigh-growth enterprise SaaS company looking for a principal engineer to lead distributed systems design and cloud architecture decisions across multiple product teams. Candidates should have deep AWS expertise, experience with event-driven and microservices patterns at scale, and the ability to define infrastructure standards using IaC. Kafka experience is highly valued.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Principal seniority directly matches the leadership scope of the role\",\"AWS with Terraform and Pulumi demonstrates IaC depth across multiple paradigms\",\"Kafka, Event-Driven, and Distributed System together satisfy the most critical architecture requirements\",\"API Gateway and Microservices experience supports the multi-team platform design context\",\"ArgoCD and Kubernetes indicate hands-on production delivery alongside architecture work\"],\"gaps\":[\"No explicit multi-team technical leadership or cross-functional architecture governance signals\"],\"explanation\":\"This is a high-confidence match across every technical dimension of the role. The candidate's breadth — spanning IaC tools, messaging, cloud-native architecture, and multiple languages — is exactly what a principal engineer guiding multiple product teams requires. The only gap is a soft one around documented cross-team leadership, which may exist but is not visible from the profile.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"react_dev_omar\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Redux\",\"Webpack\",\"SCSS\"],\"databases\":[\"Firebase\"],\"testing\":[\"Jest\",\"React Testing Library\"]}\n\nJob Summary:\nEnterprise software company migrating a large Angular codebase to React. The candidate should have strong React and TypeScript skills, familiarity with Redux for state management, and experience writing unit and integration tests. Bonus if the candidate has worked on large-scale frontend migrations or contributed to a design system.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React, Redux, and TypeScript are all present and directly applicable\",\"Jest and React Testing Library cover the unit and integration testing requirement\",\"Mid-level seniority is appropriate for this type of migration work\"],\"gaps\":[\"No Angular experience, which may limit ability to read and reason about the legacy codebase during migration\",\"No design system contribution experience visible\",\"No large-scale codebase migration experience documented\"],\"explanation\":\"The candidate has the React ecosystem skills needed for the target state of this migration but lacks familiarity with the Angular source they would be migrating from. This is a moderate fit because the React and testing fundamentals are solid, but the lack of Angular context could slow ramp-up significantly. No design system experience is also a mild gap given the enterprise scale of the work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_ops_lena\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"MLflow\",\"Weights & Biases\",\"Docker\",\"Kubernetes\",\"Ray\",\"ONNX\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAI product company looking for a senior ML engineer to own the model training and deployment lifecycle. The stack is PyTorch, Ray for distributed training, and MLflow for experiment tracking. We containerize everything with Docker and deploy models to Kubernetes. Experience with model optimization formats like ONNX is a bonus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PyTorch is the primary framework and is explicitly present\",\"Ray for distributed training directly matches the training infrastructure requirement\",\"MLflow and Weights and Biases together demonstrate strong experiment tracking maturity\",\"Docker and Kubernetes satisfy the containerized model deployment requirement\",\"ONNX satisfies the bonus optimization criterion\"],\"gaps\":[\"No model serving framework visible (Triton, TorchServe, BentoML, etc.)\"],\"explanation\":\"This candidate's profile covers every stated requirement and the bonus criterion for the role. The combination of Ray, MLflow, and ONNX alongside PyTorch is highly specific and signals production ML engineering experience rather than research-only exposure. The only gap is the absence of an explicit model serving framework, which is worth probing in an interview.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"junior_node\",\"seniority\":\"Junior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Express.js\",\"Docker\"],\"databases\":[\"MongoDB\",\"Redis\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nMid-stage startup building internal tooling for operations teams. Looking for a mid-level backend engineer comfortable with Node.js, REST API design, and basic DevOps. PostgreSQL experience required. Familiarity with message queues (RabbitMQ or similar) and CI/CD pipelines would be a strong advantage.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Express.js and TypeScript cover the Node.js and REST API foundation\",\"Docker shows basic containerization familiarity\",\"MongoDB and Redis indicate multi-database exposure\"],\"gaps\":[\"Junior seniority is one level below the mid-level requirement\",\"No PostgreSQL experience — the role states this as required\",\"No message queue experience (RabbitMQ or equivalent)\",\"No CI/CD pipeline configuration visible\"],\"explanation\":\"The candidate has the right technology direction but falls short on seniority and two of the stated requirements: PostgreSQL and message queue experience. The Express.js and Docker foundation is a positive starting point, but the gaps in database type and async messaging mean there would be meaningful ramp-up needed. A junior engineer without these specifics is a moderate risk for a role expecting mid-level autonomy.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"k8s_platform_eng\",\"seniority\":\"Staff\",\"roles\":[\"Platform Engineer\",\"DevOps Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"Docker\",\"Istio\",\"Vault\",\"Consul\"],\"architecture\":[\"Service Mesh\",\"Cloud-Native\",\"Multi-Tenant\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\",\"Tekton\"]}\n\nJob Summary:\nLarge-scale platform team at an enterprise company looking for a staff platform engineer to own the internal developer platform. The candidate should have deep Kubernetes expertise, Helm chart authoring experience, Terraform for multi-cloud IaC, and experience with secrets management. GitOps with ArgoCD is the deployment model. Multi-tenant architecture experience is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Staff seniority matches the ownership scope expected of this role\",\"Kubernetes and Helm cover the core platform infrastructure requirements\",\"Vault for secrets management directly addresses that stated requirement\",\"ArgoCD and Tekton demonstrate deep GitOps pipeline experience\",\"Multi-Tenant architecture experience satisfies the strong-plus bonus criterion\",\"Consul and Istio add service mesh and networking depth beyond baseline requirements\"],\"gaps\":[\"No explicit multi-cloud experience — Terraform is present but cloud providers are unspecified\"],\"explanation\":\"This candidate is a compelling match for the staff platform role, with depth across every requirement and several bonus criteria. The Vault, Consul, and Istio combination signals genuine enterprise-grade platform engineering experience. The only ambiguity is around multi-cloud IaC scope, which is a minor point given the Terraform proficiency.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"data_sci_rookie\",\"seniority\":\"Junior\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nEnterprise analytics firm seeking a senior data scientist with five or more years of experience. The candidate must have PyTorch or TensorFlow experience for deep learning, MLflow for experiment tracking, and strong SQL skills for data extraction. Experience with Spark for large-scale data processing and cloud platforms (AWS or GCP) is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and scikit-learn show foundational ML capability\"],\"gaps\":[\"Junior seniority is far below the five-year senior requirement\",\"No deep learning framework (PyTorch or TensorFlow) present\",\"No MLflow or experiment tracking tooling visible\",\"No Apache Spark or large-scale data processing experience\",\"No cloud platform experience (AWS or GCP)\",\"R is present but the role is SQL and Python focused\"],\"explanation\":\"This candidate is early in their data science career and lacks the depth, tooling, and scale experience the role demands. The absence of deep learning frameworks, MLflow, Spark, and cloud platforms are all critical gaps relative to the stated requirements. Scikit-learn and Pandas alone are insufficient for a senior role requiring production ML infrastructure expertise.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rustlang_sys\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Rust\",\"C\",\"Go\"],\"tech\":[\"Actix\",\"Axum\",\"Docker\",\"Kubernetes\"],\"architecture\":[\"Microservices\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Cargo\"]}\n\nJob Summary:\nInfrastructure startup building a high-performance networking layer in Rust. We need a senior engineer comfortable with async Rust, Actix or Axum for service building, and low-level systems programming in C. Experience with distributed systems and containerized deployment on Kubernetes is a strong advantage.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Rust is the primary language and both Actix and Axum are present\",\"C language experience supports the low-level systems programming requirement\",\"Distributed System and Microservices architecture experience aligns with the networking layer context\",\"Kubernetes and Docker cover the containerized deployment advantage criterion\",\"Go as a third systems language adds further depth to the low-level engineering profile\"],\"gaps\":[\"No explicit async Rust or tokio runtime experience documented separately from Actix and Axum\"],\"explanation\":\"This is an excellent match for a highly specialized role. The candidate brings both Rust web frameworks (Actix and Axum) and native C experience, which directly addresses the dual requirement. The distributed systems background further supports the networking layer infrastructure context. The only minor ambiguity is whether the async Rust depth goes beyond framework usage into lower-level runtime work.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"android_dev_kwame\",\"seniority\":\"Mid\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Firebase\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Espresso\"]}\n\nJob Summary:\nConsumer fintech app company looking for an Android engineer with Jetpack Compose experience and solid Kotlin skills. The candidate should understand MVVM architecture, be comfortable with Firebase for real-time features, and have experience automating builds with Fastlane. We use GitHub Actions for CI and expect tests to cover critical payment flows.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Jetpack Compose and Kotlin are direct matches for the stated stack preferences\",\"Firebase covers the real-time feature requirement\",\"Fastlane and GitHub Actions together satisfy the build automation and CI expectations\",\"JUnit and Espresso show testing maturity relevant to the payment flow testing requirement\",\"Mid-level seniority is appropriate given the role's scope\"],\"gaps\":[\"No explicit MVVM or other Android architecture pattern documented\"],\"explanation\":\"The candidate maps closely to the role requirements across framework, tooling, and testing. The Jetpack Compose plus Firebase combination with Fastlane automation is a strong signal of modern Android engineering practice. The only gap is the absence of an explicit MVVM architecture reference, which is worth confirming in an interview given the payment flow sensitivity.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wordpress_blogger\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"PHP\",\"JavaScript\"],\"tech\":[\"WordPress\",\"Bootstrap\",\"jQuery\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nModern product startup hiring a full stack engineer to build a React and TypeScript frontend backed by a FastAPI Python service. The team uses PostgreSQL, deploys on AWS with Docker and Kubernetes, and ships features continuously using GitHub Actions. We need engineers who can work across the full stack in a cloud-native, containerized environment.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Full stack background is nominally relevant\"],\"gaps\":[\"No React or TypeScript experience — the core frontend requirement\",\"No Python or FastAPI experience for the backend\",\"No Docker, Kubernetes, or cloud-native infrastructure experience\",\"PostgreSQL is absent — only MySQL is present\",\"No CI/CD pipeline experience visible\",\"WordPress and jQuery are not transferable to the modern product stack described\"],\"explanation\":\"This candidate's profile is built around a traditional PHP/WordPress/MySQL stack that has almost no overlap with the role's React, FastAPI, PostgreSQL, and Kubernetes requirements. The technology gaps span every layer of the stated stack. A significant career transition and retraining period would be necessary before the candidate could contribute meaningfully to this team.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"llm_builder\",\"seniority\":\"Senior\",\"roles\":[\"AI Engineer\",\"Backend Engineer\"],\"languages\":[\"Python\",\"TypeScript\"],\"tech\":[\"LangChain\",\"LangGraph\",\"OpenAI API\",\"FastAPI\",\"Docker\",\"ChromaDB\",\"Pinecone\"],\"architecture\":[\"RAG\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"ChromaDB\",\"Pinecone\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAI startup building autonomous agent workflows for enterprise customers. We need a senior AI engineer with deep LLM orchestration experience using LangChain or LangGraph. The candidate should be proficient in RAG pipeline design, vector database integration, and building production APIs in Python. Experience with OpenAI or similar model providers is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LangChain and LangGraph both present, directly satisfying the LLM orchestration requirement\",\"RAG architecture and dual vector database experience (ChromaDB and Pinecone) demonstrate pipeline design depth\",\"OpenAI API proficiency meets the model provider expectation explicitly\",\"FastAPI supports the production Python API requirement\",\"Senior seniority is appropriate for the autonomous agent complexity described\"],\"gaps\":[\"No explicit evaluation or observability tooling for LLM outputs visible\"],\"explanation\":\"This candidate is purpose-built for this AI engineering role, with the exact LangChain/LangGraph, RAG, and vector database combination the job specifies. The dual vector database experience (ChromaDB and Pinecone) signals genuine production RAG pipeline work rather than toy examples. The only gap worth probing is LLM output evaluation and monitoring tooling, which is increasingly important in enterprise contexts.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"scala_data_eng\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Scala\",\"Python\",\"SQL\"],\"tech\":[\"Apache Spark\",\"Apache Kafka\",\"Apache Airflow\",\"Docker\"],\"databases\":[\"Cassandra\",\"PostgreSQL\",\"Redshift\"],\"ci_cd\":[\"GitLab CI\"]}\n\nJob Summary:\nFinancial data platform company looking for a senior data engineer to build real-time streaming pipelines. The ideal candidate has strong Kafka experience, is comfortable with Scala or Python for Spark workloads, and has worked with columnar data warehouses like Redshift or Snowflake. Familiarity with dbt for transformation logic is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Kafka and Spark together directly match the streaming pipeline core requirement\",\"Scala is a strong bonus for Spark-native development\",\"Redshift satisfies the columnar data warehouse requirement\",\"Senior seniority fits the ownership expectations\"],\"gaps\":[\"No dbt experience visible — listed as a plus but absent\",\"No Snowflake experience — only Redshift of the named warehouses is present\",\"Airflow for batch orchestration may not cover real-time streaming orchestration patterns\"],\"explanation\":\"The candidate has strong streaming fundamentals with Kafka and Spark in Scala, which are the most critical requirements. However, the absence of dbt and limited cloud warehouse exposure (only Redshift, no Snowflake) creates some gaps relative to the full role description. This is a solid candidate for the streaming work but may need ramp-up on the transformation and warehouse tooling side.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ios_swift_dev\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Expo\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"Fastlane\"],\"testing\":[\"XCTest\"]}\n\nJob Summary:\nHealthcare app company building a native iOS application for patient monitoring. The candidate should have solid SwiftUI and UIKit experience, familiarity with HealthKit or CoreData for local data persistence, and a track record of shipping apps through the App Store review process. Security and privacy-aware development practices are important.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SwiftUI and UIKit are both present and relevant to native iOS development\",\"XCTest demonstrates iOS-native testing familiarity\",\"Fastlane indicates App Store deployment experience\"],\"gaps\":[\"No HealthKit or CoreData experience visible — both relevant for patient data persistence\",\"SQLite and Firebase are present but not the local-native persistence stack expected in healthcare\",\"No explicit security or privacy-aware development signals\",\"No healthcare domain or HIPAA-related experience mentioned\"],\"explanation\":\"The candidate has a reasonable iOS foundation with SwiftUI, UIKit, and Fastlane but lacks the specific frameworks and domain knowledge this healthcare app requires. HealthKit and CoreData are meaningful absences for a patient monitoring use case. The lack of visible security or privacy practices is a concern in a regulated healthcare context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dbt_analytics\",\"seniority\":\"Mid\",\"roles\":[\"Analytics Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Metabase\",\"Looker\",\"Airflow\"],\"databases\":[\"BigQuery\",\"Snowflake\",\"PostgreSQL\"]}\n\nJob Summary:\nE-commerce company building a self-serve analytics platform. Hiring an analytics engineer to own dbt models, maintain BigQuery pipelines, and support data consumers via Looker. The candidate should be comfortable with SQL at scale, understand dimensional modeling, and have experience working closely with business stakeholders on metric definitions.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt is the primary transformation tool and is explicitly listed\",\"BigQuery is the data warehouse and is present in the candidate profile\",\"Looker covers the BI layer requirement directly\",\"Snowflake and PostgreSQL add additional warehouse breadth\",\"Airflow shows pipeline orchestration familiarity relevant to maintaining data workflows\"],\"gaps\":[\"No explicit dimensional modeling or data modeling methodology documented\"],\"explanation\":\"This candidate's profile aligns closely with the analytics engineering role, covering dbt, BigQuery, and Looker as a complete stack. The Airflow and Metabase experience adds adjacent value for pipeline management and democratized reporting. The only gap worth probing is whether the candidate has deliberate experience with dimensional modeling practices rather than ad hoc SQL transformations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"go_backend_intern\",\"seniority\":\"Intern\",\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Gin\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nSeries A startup looking for a junior to mid backend engineer with Go experience. The candidate should be comfortable building REST APIs with Gin or Echo, understand basic PostgreSQL schema design, and be able to work in a Dockerized local environment. CI/CD experience and testing habits are a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go is the primary language and Gin satisfies the framework requirement\",\"PostgreSQL presence aligns with the database expectation\",\"Docker shows containerization familiarity for local development workflows\"],\"gaps\":[\"Intern seniority is below the junior-to-mid target range\",\"No CI/CD experience visible — listed as a plus but absent\",\"No testing framework or habits documented\",\"No Echo experience, though Gin is an acceptable alternative\"],\"explanation\":\"The candidate has the right foundational Go stack for this role but is at intern level where junior-to-mid is the target. The core API and database signals are good, but the absence of testing practices and CI/CD familiarity means there would be meaningful mentorship and onboarding investment required. A strong intern with Go experience could grow into this role but is not there yet.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vue_nuxt_front\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Nuxt.js\",\"Pinia\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"Firebase\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nEuropean SaaS startup looking for a frontend engineer experienced with Vue 3 and Nuxt. The candidate should be comfortable with Pinia for state management, Tailwind for styling, and have end-to-end testing habits. TypeScript is used throughout. We value engineers who can own features from design handoff to production.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Vue.js and Nuxt.js directly match the stated framework requirement\",\"Pinia is the exact state management library specified\",\"Tailwind CSS covers the styling requirement\",\"Playwright satisfies the end-to-end testing expectation\",\"TypeScript proficiency aligns with the team's language standard\",\"Vitest adds unit testing depth alongside E2E coverage\"],\"gaps\":[\"No component library or design system experience mentioned\"],\"explanation\":\"This candidate is a near-perfect technical match for the role, with every named technology in the job description represented in the profile. The Pinia and Playwright combination in particular demonstrates modern Vue 3 ecosystem maturity. The only minor gap is the absence of any design system or component library experience, which could matter given the design handoff expectation.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devops_no_k8s\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Jenkins\",\"Ansible\",\"Docker\",\"AWS\"],\"databases\":[\"MySQL\"],\"ci_cd\":[\"Jenkins\"]}\n\nJob Summary:\nCloud-native platform team at a scale-up hiring a mid-level DevOps engineer. The candidate must have strong Kubernetes cluster management experience, Helm chart authoring, and Terraform for IaC. We are fully on AWS. GitOps via ArgoCD is our deployment model. Experience with service mesh tools like Istio is a plus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"AWS and Docker provide a baseline cloud and containerization foundation\",\"Mid-level seniority matches the role level\"],\"gaps\":[\"No Kubernetes experience — the most critical requirement\",\"No Helm chart experience\",\"No Terraform or IaC tooling visible — Ansible is present but not equivalent\",\"No ArgoCD or GitOps experience\",\"No Istio or service mesh tooling\",\"Jenkins-based CI does not cover the GitOps deployment model expected\"],\"explanation\":\"The candidate's DevOps background is built around traditional tooling (Jenkins, Ansible) and lacks the Kubernetes-native skills this cloud-native platform team requires. Every core requirement of the role — Kubernetes, Helm, Terraform, and ArgoCD — is absent from the profile. The Docker and AWS foundation is too basic to bridge these gaps in the near term.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nestjs_backend\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"Express.js\",\"Docker\",\"AWS\",\"Redis\"],\"architecture\":[\"Microservices\",\"REST\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nB2B SaaS company building a multi-tenant API platform in Node.js. We use NestJS as our primary backend framework and deploy to AWS with Docker. PostgreSQL is the primary database. The candidate should be experienced with REST API design, familiar with Redis for caching, and write tests with Jest. Multi-tenant architecture exposure is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS is the primary framework and is listed prominently\",\"PostgreSQL and Redis together cover both persistence and caching requirements\",\"Jest and Supertest satisfy the testing expectations\",\"Microservices experience is a relevant architecture signal for the API platform context\",\"GitHub Actions and Docker support the AWS deployment workflow\"],\"gaps\":[\"No explicit multi-tenant architecture experience documented\"],\"explanation\":\"This candidate is an excellent match for the role with NestJS, PostgreSQL, Redis, and Jest all present and primary. The Supertest inclusion alongside Jest signals API-level integration testing maturity which is directly relevant for a platform product. The only gap is the absence of documented multi-tenant architecture experience, which is the stated strong-plus criterion.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"data_analyst_basic\",\"seniority\":\"Junior\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Tableau\",\"Pandas\",\"NumPy\"]}\n\nJob Summary:\nAnalytics team at a Series B startup looking for a mid-level data analyst. The candidate should have strong SQL skills, experience with Tableau or Power BI for dashboarding, and comfort working with large datasets. Familiarity with dbt or any transformation tool is a plus. We work in Snowflake and expect stakeholder-facing communication skills.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SQL and Tableau directly satisfy the core analytics and dashboarding requirements\",\"Pandas and Python provide data manipulation capabilities alongside SQL\"],\"gaps\":[\"Junior seniority is below the mid-level requirement\",\"No Snowflake experience — the team's primary data warehouse\",\"No dbt or transformation tooling experience\",\"No Power BI as an alternative BI tool\"],\"explanation\":\"The candidate has the right foundational tools (SQL and Tableau) but is a level below the desired seniority and lacks familiarity with the team's warehouse (Snowflake). The absence of dbt or any transformation tooling also limits fit for a team expecting analysts to work closer to the data platform. This could be a near-miss if the startup is open to hiring slightly below level with a growth trajectory.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elixir_distributed\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Elixir\",\"Erlang\",\"Python\"],\"tech\":[\"Docker\",\"Kubernetes\",\"AWS\",\"RabbitMQ\"],\"architecture\":[\"Distributed System\",\"Event-Driven\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"Cassandra\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nReal-time communications platform looking for a senior backend engineer with distributed systems expertise. Elixir or Erlang experience is strongly preferred given our BEAM-based infrastructure. The candidate should understand message passing patterns, have worked with RabbitMQ or Kafka, and be comfortable with fault-tolerant system design in Kubernetes.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Elixir and Erlang are both present, directly addressing the BEAM-based infrastructure preference\",\"RabbitMQ satisfies the message broker requirement\",\"Distributed System and Event-Driven architecture experience is core to the role's focus\",\"Kubernetes and AWS support the production fault-tolerant deployment context\",\"Cassandra alongside PostgreSQL shows experience with high-availability data patterns\"],\"gaps\":[\"No Kafka experience — only RabbitMQ is present of the two named brokers\"],\"explanation\":\"This candidate is a rare and strong match for a role that specifically seeks BEAM ecosystem experience. The Elixir and Erlang combination with RabbitMQ and distributed system architecture gives high confidence in fit. Kafka is absent but RabbitMQ satisfies the message broker requirement adequately and the missing tool is learnable given the candidate's existing messaging background.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"fullstack_sparse\",\"seniority\":\"Junior\",\"languages\":[\"JavaScript\"],\"tech\":[\"React\",\"Node.js\"]}\n\nJob Summary:\nEarly-stage startup looking for a junior full stack engineer comfortable with React and Node.js. No prior professional experience required but the candidate should show initiative with side projects. Bonus if they have worked with any SQL database or understand basic REST API design. We value curiosity and growth mindset over credentials.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Node.js directly match the stated core stack\",\"Junior seniority aligns with the role level explicitly\",\"JavaScript across both frontend and backend is appropriate for a full stack role\"],\"gaps\":[\"No SQL database experience visible — listed as a bonus\",\"No REST API design or backend framework experience beyond raw Node.js\",\"Very sparse profile with no testing, CI/CD, or tooling signals\"],\"explanation\":\"The candidate's profile is thin but aligned in direction. React and Node.js are the right technologies and the seniority match is good for a startup open to junior engineers. The sparseness of the profile makes it difficult to assess initiative or side project depth, which the role explicitly values. The lack of any database or REST API experience is a mild gap that the startup seems open to given their explicit flexibility.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"embedded_fw_eng\",\"seniority\":\"Senior\",\"roles\":[\"Embedded Engineer\",\"Firmware Engineer\"],\"languages\":[\"C\",\"C++\",\"Rust\"],\"tech\":[\"CMake\",\"Docker\",\"CUDA\"],\"architecture\":[\"Distributed System\"],\"ci_cd\":[\"GitHub Actions\",\"Jenkins\"]}\n\nJob Summary:\nRobotics company hiring a senior embedded software engineer to write firmware for custom hardware platforms. The candidate should be proficient in C and C++ for low-level hardware control, familiar with real-time operating systems, and comfortable with CMake-based build systems. Experience with Rust for systems programming is a nice-to-have.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"C and C++ proficiency satisfies the core firmware language requirements\",\"Rust is present, satisfying the nice-to-have criterion\",\"CMake is the build system of choice and is explicitly listed\",\"Senior seniority matches the role level\"],\"gaps\":[\"No RTOS (FreeRTOS, Zephyr, or equivalent) experience visible\",\"No hardware-specific debugging or toolchain experience documented\",\"No signal processing or sensor integration experience apparent\"],\"explanation\":\"The candidate has the right language foundation and build system experience for embedded work but lacks evidence of RTOS experience, which is typically central to firmware development for robotics hardware. CMake, C, and C++ are positive signals, but the absence of real-time operating system familiarity is a meaningful gap that would require ramp-up in a hardware-critical context.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rails_saas\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"Ruby\",\"JavaScript\"],\"tech\":[\"Ruby on Rails\",\"React\",\"Sidekiq\",\"Redis\",\"Docker\"],\"architecture\":[\"Monolith\",\"REST\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"CircleCI\"],\"testing\":[\"RSpec\",\"Capybara\"]}\n\nJob Summary:\nEstablished B2B SaaS company looking for a senior Rails engineer to maintain and extend a large Rails monolith. The candidate should be comfortable with background job processing using Sidekiq, PostgreSQL at scale, and feature delivery in a React-based frontend. We use CircleCI for CI and RSpec for testing. Experience with multi-tenant SaaS patterns is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Ruby on Rails is the primary framework and is the core of this role\",\"Sidekiq and Redis together directly satisfy the background job processing requirement\",\"PostgreSQL is the database of choice and is present\",\"CircleCI and RSpec are exact matches for the stated CI and testing tools\",\"React experience covers the frontend delivery expectation\",\"Monolith architecture experience is directly relevant given the existing codebase context\"],\"gaps\":[\"No multi-tenant SaaS architecture experience documented explicitly\"],\"explanation\":\"This candidate is a highly precise match for a Rails monolith role, with every named tool (Sidekiq, RSpec, CircleCI, PostgreSQL, React) present in the profile. The Monolith architecture experience is particularly relevant given the team's existing codebase. The only gap is the absence of explicit multi-tenant SaaS patterns, which is listed as a plus rather than a requirement.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"security_eng_chen\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\",\"Backend Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Docker\",\"Kubernetes\",\"AWS\",\"Vault\"],\"architecture\":[\"Zero Trust\",\"Cloud-Native\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nCloud security company looking for a senior application security engineer. The candidate should have experience with secrets management (Vault or equivalent), container security in Kubernetes environments, and security automation in Python or Go. Familiarity with SAST/DAST tooling and secure SDLC practices is expected. AWS cloud security knowledge is important.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Vault for secrets management directly satisfies a key stated requirement\",\"Kubernetes and Docker provide container security context\",\"Python and Go cover the security automation language requirements\",\"AWS cloud security knowledge aligns with the stated importance\",\"Senior seniority matches the ownership scope\"],\"gaps\":[\"No explicit SAST or DAST tooling experience visible\",\"No secure SDLC or threat modeling documentation\"],\"explanation\":\"The candidate has strong infrastructure security fundamentals with Vault, Kubernetes, and AWS alongside the right automation languages. These are the highest-signal requirements in the job description. The gaps around SAST/DAST and secure SDLC practices are meaningful given they are explicitly expected, but the infrastructure security depth likely compensates in a senior role where these tools are learnable.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"blockchain_sol\",\"seniority\":\"Mid\",\"roles\":[\"Blockchain Engineer\",\"Smart Contract Developer\"],\"languages\":[\"Solidity\",\"TypeScript\",\"Python\"],\"tech\":[\"Hardhat\",\"ethers.js\",\"IPFS\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"]}\n\nJob Summary:\nWeb3 startup building a decentralized finance protocol. Looking for a smart contract developer with Solidity experience, familiarity with Hardhat for testing and deployment, and understanding of DeFi primitives like AMMs or lending protocols. TypeScript for frontend integration scripts is expected. Auditing experience or formal verification is a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Solidity is the core smart contract language and is present\",\"Hardhat satisfies the testing and deployment tooling requirement\",\"TypeScript is available for frontend integration work\",\"IPFS shows decentralized storage familiarity relevant to Web3 context\"],\"gaps\":[\"No explicit DeFi protocol or AMM experience documented\",\"No formal verification or audit experience visible\",\"ethers.js is present but no Web3.js or Viem as alternatives\",\"Mid-level seniority may be light for a protocol-level ownership role\"],\"explanation\":\"The candidate has the right base Solidity and Hardhat toolkit for Web3 development but lacks evidence of DeFi-specific protocol experience, which is central to this role. The auditing and formal verification gap is notable given it is a strong-plus criterion. The candidate could contribute to smart contract development but may not be ready for protocol-level ownership without more domain-specific experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"csharp_dotnet_dev\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Software Engineer\"],\"languages\":[\"C#\",\"SQL\"],\"tech\":[\"ASP.NET\",\".NET Core\",\"Docker\",\"Azure\"],\"architecture\":[\"Microservices\",\"CQRS\",\"Event-Driven\"],\"databases\":[\"MS SQL Server\",\"Redis\",\"PostgreSQL\"],\"ci_cd\":[\"Azure DevOps\",\"GitHub Actions\"],\"testing\":[\"xUnit\",\"NUnit\"]}\n\nJob Summary:\nEnterprise financial services company building internal API services on the Microsoft stack. We need a senior backend engineer with C# and ASP.NET Core experience, comfortable with Azure for deployment, and familiar with CQRS and event-driven architecture patterns. SQL Server is our primary database. We use Azure DevOps for CI/CD and xUnit for testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"C# and ASP.NET Core are the primary stack and both are present\",\"Azure for deployment is explicitly listed and matches the cloud requirement\",\"CQRS and Event-Driven architecture are directly called out and present\",\"MS SQL Server satisfies the primary database requirement\",\"Azure DevOps and xUnit are exact matches for the stated CI and testing tools\"],\"gaps\":[\"No explicit Entity Framework or ORM experience documented\"],\"explanation\":\"This candidate is a precise fit for a Microsoft-stack enterprise backend role. Every tool and pattern named in the job description appears in the profile. The CQRS and event-driven architecture experience in particular addresses the most specialized requirements. The only minor gap is the absence of an explicit ORM reference, which is a common assumption for .NET development.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"svelte_indie\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"SvelteKit\",\"Svelte\",\"Tailwind CSS\",\"Vite\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nSolo-founder startup looking for a generalist frontend or full stack engineer to help build a SaaS product. The stack is SvelteKit with Tailwind and Supabase as the backend. We need someone who can move fast across the full stack, write clean TypeScript, and handle both UI and database concerns. Testing is encouraged but not mandatory.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"SvelteKit and Svelte are the exact frontend stack specified\",\"Supabase is the backend-as-a-service the startup uses\",\"Tailwind CSS matches the styling approach\",\"TypeScript is present and fluent\",\"Vitest and Playwright show proactive testing habits that exceed the stated expectations\"],\"gaps\":[\"No authentication or user management experience explicitly visible\"],\"explanation\":\"This candidate is an ideal match for the startup's specific and somewhat niche SvelteKit and Supabase stack. Every core technology is present and primary in the profile. The proactive testing with Vitest and Playwright actually exceeds the role's stated expectations. The only minor gap is the absence of explicit auth or user management experience, which is relevant for a SaaS product.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"java_monolith\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\"],\"tech\":[\"Spring\",\"Hibernate\",\"Maven\",\"Apache Tomcat\"],\"architecture\":[\"Monolith\",\"Layered Architecture\"],\"databases\":[\"Oracle\",\"MySQL\"],\"ci_cd\":[\"Jenkins\"]}\n\nJob Summary:\nScale-up startup rebuilding their architecture from a Kotlin microservices perspective. Looking for a backend engineer comfortable with Kotlin and Spring Boot, Kubernetes for orchestration, and PostgreSQL. The team values clean architecture and domain-driven design. Experience with event-driven patterns and Kafka is highly valued.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Java Spring experience is adjacent to the Kotlin Spring Boot requirement\"],\"gaps\":[\"No Kotlin experience — the primary language for the new architecture\",\"No Kubernetes or container-native experience\",\"No PostgreSQL — uses Oracle and MySQL\",\"No clean architecture or DDD experience\",\"No Kafka or event-driven architecture patterns\",\"Monolith and layered architecture experience is the opposite of the microservices direction\"],\"explanation\":\"This candidate's background is built around traditional Java monolith patterns that are the antithesis of what this team is building. The shift to Kotlin, Kubernetes, DDD, and Kafka represents a fundamental stack and philosophy change that the candidate shows no evidence of having made. Java Spring is a loose adjacency to Spring Boot but does not bridge the broader architectural and tooling gaps.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"python_generalist\",\"seniority\":\"Mid\",\"roles\":[\"Software Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Flask\",\"Celery\",\"Docker\",\"AWS\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nGrowth-stage startup hiring a mid-level backend engineer to build internal automation tooling. The stack is FastAPI with PostgreSQL and Redis for caching. We use Celery for async task processing and deploy on AWS via Docker. The candidate should write tests with pytest and be comfortable owning small services end to end.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python is the primary language and is present\",\"Celery and Redis cover the async task processing requirement\",\"PostgreSQL, Docker, and AWS satisfy deployment and database expectations\",\"pytest aligns with the testing requirement\",\"Mid-level seniority is an exact match\"],\"gaps\":[\"Uses Flask rather than FastAPI — relevant difference given FastAPI's async-first design\",\"No explicit FastAPI experience\"],\"explanation\":\"The candidate is well-aligned on most technical dimensions but uses Flask where the team uses FastAPI. While both are Python web frameworks, FastAPI's async model and type system are meaningfully different from Flask's synchronous defaults. The rest of the stack (Celery, PostgreSQL, Redis, pytest) is a solid match. Ramp-up on FastAPI would be relatively quick but is still a gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"lead_eng_aditi\",\"seniority\":\"Lead\",\"roles\":[\"Lead Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"Python\",\"Go\"],\"tech\":[\"Next.js\",\"FastAPI\",\"Docker\",\"Kubernetes\",\"AWS\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"DynamoDB\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"Jest\",\"pytest\",\"Playwright\"]}\n\nJob Summary:\nSeries B startup looking for a tech lead to own architecture decisions and guide a team of five engineers. The candidate should be comfortable across frontend and backend, have experience with event-driven microservices, and be able to drive technical roadmaps. AWS, Kubernetes, and Kafka exposure is expected. Strong testing practices are a must.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Lead seniority matches the tech lead ownership and team guidance expectations\",\"Full stack capability across TypeScript and Python covers both frontend and backend needs\",\"Kafka, Event-Driven, and Microservices together satisfy the architecture requirements\",\"ArgoCD and Kubernetes signal production-grade infrastructure experience\",\"Jest, pytest, and Playwright demonstrate comprehensive testing discipline across layers\"],\"gaps\":[\"No explicit engineering management or mentorship signals beyond seniority level\"],\"explanation\":\"This candidate is a compelling match for a tech lead role, bringing both the technical depth and the seniority level to own architecture and guide a team. The combination of full stack TypeScript and Python capability with Kafka and event-driven architecture is precisely what the role requires. The only gap worth exploring is how the candidate has demonstrated mentorship and technical leadership in practice.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"csv_uploader_dev\",\"seniority\":\"Junior\",\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Pandas\",\"NumPy\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nCloud startup seeking a mid-to-senior platform engineer with infrastructure as code expertise. The candidate must have experience with Terraform, Kubernetes cluster management, and CI/CD pipeline design using GitHub Actions or equivalent. Go or Python for automation scripting is expected. AWS or GCP cloud experience is required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is present and applicable to automation scripting\"],\"gaps\":[\"Junior seniority is far below the mid-to-senior requirement\",\"No Terraform or infrastructure as code experience\",\"No Kubernetes experience\",\"No CI/CD pipeline design experience\",\"No cloud platform experience (AWS or GCP)\",\"Profile is data-focused (Pandas, NumPy, MySQL) with no DevOps or platform engineering signals\"],\"explanation\":\"This candidate's profile is oriented toward data analysis and scripting, which has almost no overlap with the platform engineering requirements of this role. The technology gaps span infrastructure as code, container orchestration, CI/CD, and cloud platforms. Seniority is also a significant mismatch. This candidate would need a full career pivot to be competitive for this role.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"remix_builder\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\",\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Remix\",\"React\",\"Tailwind CSS\",\"Prisma\",\"shadcn/ui\"],\"databases\":[\"PostgreSQL\",\"SQLite\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nIndependent software product company hiring a full stack engineer for a Remix and React application. The candidate should be comfortable with TypeScript across the stack, Tailwind for styling, Prisma for database access, and PostgreSQL. Component testing and end-to-end test coverage are important. We prefer engineers who ship polished, accessible UIs.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Remix is the primary framework and is listed first in the tech stack\",\"Prisma and PostgreSQL cover the data access and database requirements precisely\",\"Tailwind CSS satisfies the styling requirement\",\"Vitest and Playwright provide component-level and E2E testing coverage\",\"TypeScript across the full stack aligns with the stated expectation\"],\"gaps\":[\"No explicit accessibility (a11y) tooling or documentation visible\"],\"explanation\":\"The candidate's profile is an excellent match for this Remix-based full stack role, with every named technology present and prominent. The Prisma and PostgreSQL combination alongside Tailwind is particularly strong signal. The only gap is the absence of explicit accessibility tooling or practice documentation, which matters given the role's emphasis on polished, accessible UIs.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"haskell_functional\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Haskell\",\"Scala\",\"Python\"],\"tech\":[\"Docker\",\"AWS\"],\"architecture\":[\"Functional\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nFintech startup building risk modeling systems in Python. The team uses FastAPI, pandas, NumPy, and deploys statistical models as REST APIs on AWS. PostgreSQL is the primary database. Strong Python skills and statistical computing experience are essential. Experience with ML libraries like scikit-learn is a bonus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"AWS deployment experience and PostgreSQL are directly relevant\",\"Distributed system architecture understanding transfers to the production API context\",\"Strong functional programming background may support statistical and numerical computing patterns\"],\"gaps\":[\"Haskell and Scala are not the team's language — Python is required and is secondary in this profile\",\"No FastAPI, pandas, or NumPy experience visible\",\"No scikit-learn or any ML tooling present\",\"Functional programming focus may not align with the team's applied data science orientation\"],\"explanation\":\"The candidate has adjacent strengths in functional programming and distributed systems but the core language mismatch (Haskell and Scala vs Python) is a meaningful hurdle for a role that requires fluent Python for statistical computing. AWS and PostgreSQL are transferable, but the absence of the data science toolchain (pandas, NumPy, scikit-learn) is a significant gap for a risk modeling system.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"gcp_data_platform\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\",\"Analytics Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Apache Beam\",\"dbt\",\"Apache Airflow\",\"Docker\",\"Google Cloud\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"BigQuery\",\"PostgreSQL\",\"Firestore\"],\"ci_cd\":[\"GitHub Actions\",\"GitLab CI\"]}\n\nJob Summary:\nMedia analytics company running entirely on GCP. Hiring a senior data engineer to build and maintain BigQuery pipelines, author dbt models, and orchestrate workflows with Airflow. Apache Beam experience is a strong bonus. The candidate should be comfortable with Python, SQL at scale, and understand event-driven data pipeline design.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"GCP and BigQuery are the primary cloud and warehouse and both are present\",\"dbt and Airflow directly match the transformation and orchestration requirements\",\"Apache Beam satisfies the stated strong-bonus requirement\",\"Event-Driven architecture experience is relevant to the pipeline design context\",\"Senior seniority is appropriate for ownership of production data infrastructure\"],\"gaps\":[\"No Dataflow or Pub/Sub experience visible beyond Apache Beam and Airflow\"],\"explanation\":\"This candidate is an outstanding match for the GCP-native data engineering role, covering BigQuery, dbt, Airflow, and Apache Beam — including the bonus criterion. The combination of distributed system and event-driven architecture experience adds depth to the pipeline design expectation. The only gap is the absence of Pub/Sub or Dataflow specifically within the GCP streaming ecosystem, which is a minor point given the Beam experience.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"design_to_code\",\"seniority\":\"Junior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Framer Motion\",\"Tailwind CSS\",\"Next.js\"],\"databases\":[\"Firebase\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nProduct design tools company looking for a mid-level frontend engineer with strong React and animation experience. Framer Motion or GSAP knowledge is expected. The candidate should be comfortable with TypeScript, Next.js for SSR, and have contributed to a component library or design system. We care deeply about UI quality and micro-interactions.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and Next.js are direct matches for the stated framework requirements\",\"Framer Motion explicitly satisfies the animation library expectation\",\"TypeScript and Tailwind CSS align with the team's frontend standards\"],\"gaps\":[\"Junior seniority is below the mid-level requirement\",\"No design system or component library contribution visible\",\"No accessibility or UI quality tooling documented\",\"Testing coverage is minimal for a role that emphasizes UI quality\"],\"explanation\":\"The candidate has the right frontend stack and notably includes Framer Motion, which directly addresses the animation requirement. However, junior seniority and the absence of design system contributions are meaningful gaps for a role that expects mid-level autonomy in a design-quality-focused company. Strong junior candidate who may be close to the right level but not quite there yet.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"backend_go_grpc\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"gRPC\",\"Kafka\",\"Docker\",\"Kubernetes\",\"AWS\"],\"architecture\":[\"Microservices\",\"Distributed System\",\"Event-Driven\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"Cassandra\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Go test\",\"k6\"]}\n\nJob Summary:\nHigh-performance infrastructure company building internal gRPC-based microservices in Go. We need a senior engineer with production Go experience, gRPC API design skills, and familiarity with Kafka for async messaging. Kubernetes is our deployment platform. We care about performance and run load tests regularly.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go is the primary language and is listed first\",\"gRPC is present and matches the API design requirement directly\",\"Kafka satisfies the async messaging requirement\",\"Kubernetes is the deployment platform and is present\",\"k6 demonstrates load testing capability aligned with the team's performance focus\"],\"gaps\":[\"No Protocol Buffers experience documented separately from gRPC\"],\"explanation\":\"This candidate is a precise match for a high-performance Go gRPC microservices role. The combination of Go, gRPC, Kafka, and Kubernetes covers every stated requirement, and k6 for load testing directly addresses the team's performance culture. The only minor gap is the absence of explicit Protocol Buffers experience, which is typically implied by gRPC but worth confirming.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"react_native_noob\",\"seniority\":\"Junior\",\"roles\":[\"Mobile Engineer\"],\"languages\":[\"JavaScript\"],\"tech\":[\"React Native\",\"Expo\"],\"databases\":[\"Firebase\"]}\n\nJob Summary:\nConsumer social app company looking for a mid-level React Native engineer. The candidate should have TypeScript experience in React Native, familiarity with state management (Redux or Zustand), experience with native module bridging, and a track record of shipping to both iOS and Android app stores. Performance optimization experience is valued.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"React Native and Expo are present and relevant\"],\"gaps\":[\"Junior seniority is below the mid-level requirement\",\"No TypeScript experience — the role requires TypeScript in React Native\",\"No state management library experience (Redux or Zustand)\",\"No native module bridging experience\",\"No App Store or Play Store shipping experience documented\",\"No performance optimization signals\"],\"explanation\":\"The candidate has the foundational React Native exposure but lacks the TypeScript, state management, native bridging, and app store shipping experience that the role expects at a mid-level. The absence of TypeScript is particularly notable since it is explicitly required. This is an early-career mobile developer who would need significant mentorship and growth before meeting the role's expectations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"aiops_platform\",\"seniority\":\"Senior\",\"roles\":[\"DevOps Engineer\",\"Platform Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Prometheus\",\"Grafana\",\"Datadog\",\"Kubernetes\",\"Terraform\",\"AWS\",\"Docker\"],\"architecture\":[\"Cloud-Native\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nAI infrastructure team at a FAANG-adjacent company looking for a senior platform engineer with deep observability expertise. The candidate should have production experience with Prometheus, Grafana, and ideally a commercial APM tool like Datadog or New Relic. Kubernetes cluster management and Terraform IaC experience required. We use GitOps extensively.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Prometheus and Grafana are both present, directly satisfying the observability requirement\",\"Datadog is listed, satisfying the commercial APM bonus criterion\",\"Kubernetes and Terraform cover the cluster management and IaC requirements\",\"ArgoCD demonstrates GitOps experience explicitly called out as extensive in the role\",\"AWS and senior seniority support FAANG-adjacent infrastructure scale expectations\"],\"gaps\":[\"No distributed tracing experience (Jaeger, Zipkin, or OpenTelemetry) visible\"],\"explanation\":\"This candidate's observability and infrastructure profile is an excellent match for the role. Prometheus, Grafana, and Datadog together address both the open-source and commercial APM requirements. The ArgoCD experience directly satisfies the extensive GitOps expectation. The only gap is the absence of distributed tracing tooling, which is increasingly common in FAANG-scale observability stacks.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cms_headless_dev\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\",\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"Contentful\",\"Sanity\",\"GraphQL\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Playwright\"]}\n\nJob Summary:\nDigital agency building content-driven websites for enterprise clients. We use Next.js with a headless CMS (Contentful or Sanity) and GraphQL for the content API layer. The candidate should be comfortable with TypeScript, familiar with Jamstack patterns, and have experience integrating CMS platforms into modern frontend applications. Testing and CI/CD hygiene matter.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js is the primary framework and is present\",\"Contentful and Sanity both appear, covering both named CMS platforms\",\"GraphQL satisfies the content API layer requirement\",\"Jest and Playwright demonstrate testing practices that the role values\",\"GitHub Actions covers the CI/CD hygiene expectation\"],\"gaps\":[\"No explicit Jamstack deployment platform experience (Vercel or Netlify)\"],\"explanation\":\"The candidate's profile is a near-exact match for a headless CMS and Next.js digital agency role. The presence of both Contentful and Sanity is particularly strong, as both named CMS platforms are covered. GraphQL for the API layer and GitHub Actions for CI/CD round out the requirements. The only gap is the absence of an explicit Jamstack deployment platform like Vercel, though Next.js experience implies familiarity.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"backend_sparse_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"Docker\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nHealthtech startup building a patient data API using FastAPI and PostgreSQL. The candidate should be comfortable with Python, understand REST API design, have basic Docker knowledge, and be familiar with JWT-based authentication. The ability to write tests with pytest is expected. Experience with HIPAA compliance or healthcare data is a bonus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python and PostgreSQL are present and relevant\",\"Docker satisfies the containerization requirement\",\"Django experience provides REST API design background transferable to FastAPI\"],\"gaps\":[\"Uses Django rather than FastAPI — meaningful difference in async and type system design\",\"No JWT or authentication implementation experience documented\",\"No pytest testing experience visible\",\"No healthcare or HIPAA compliance experience\"],\"explanation\":\"The candidate has a solid Python backend foundation but the Django-to-FastAPI difference is worth noting given the role's specific framework preference. The absence of pytest and JWT experience are also gaps relative to stated expectations. Django skills would transfer in terms of REST patterns, but the candidate would need ramp-up on FastAPI's async model and authentication patterns. Healthcare experience gap is a soft concern for a HIPAA-adjacent product.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"infra_terraform_lead\",\"seniority\":\"Lead\",\"roles\":[\"Infrastructure Engineer\",\"DevOps Engineer\"],\"languages\":[\"Python\",\"Go\",\"Bash\"],\"tech\":[\"Terraform\",\"Pulumi\",\"Kubernetes\",\"Docker\",\"AWS\",\"Vault\",\"Consul\"],\"architecture\":[\"Cloud-Native\",\"Multi-Tenant\",\"Distributed System\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\",\"Tekton\"],\"testing\":[\"pytest\",\"k6\"]}\n\nJob Summary:\nEnterprise SaaS company looking for a lead infrastructure engineer to own the IaC strategy and Kubernetes fleet across multiple AWS accounts. The candidate should have experience with Terraform or Pulumi, Vault for secrets management, multi-tenant infrastructure design, and GitOps workflows. Python or Go for automation is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Lead seniority matches the IaC strategy ownership expected of this role\",\"Both Terraform and Pulumi are present, exceeding the stated IaC requirement\",\"Vault for secrets management directly addresses that requirement\",\"Multi-Tenant architecture experience satisfies the multi-account design context\",\"ArgoCD and Tekton demonstrate deep GitOps pipeline expertise\",\"Go and Python cover the automation scripting expectations\"],\"gaps\":[\"No explicit multi-account AWS Organizations or landing zone experience documented\"],\"explanation\":\"This candidate is a compelling match for the lead infrastructure role, with depth across IaC (both Terraform and Pulumi), secrets management, multi-tenancy, and GitOps. The Consul and Vault pairing alongside Kubernetes suggests genuine production HashiCorp stack experience at scale. The only gap worth probing is multi-account AWS Organizations strategy, which is central to enterprise fleet management.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"astro_ssr_dev\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Astro\",\"React\",\"Tailwind CSS\",\"Vite\",\"shadcn/ui\"],\"databases\":[\"Supabase\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nContent-first startup building a public documentation and blog platform. We use Astro for static and server-rendered pages, React for interactive islands, and Tailwind for styling. The candidate should be comfortable with TypeScript, have experience integrating headless CMS or database backends, and write both unit and end-to-end tests. Mid-level seniority expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Astro is the primary framework and is listed first in the stack\",\"React for interactive islands directly matches the stated rendering pattern\",\"Tailwind CSS satisfies the styling requirement\",\"Supabase and PostgreSQL demonstrate backend integration capability\",\"Vitest and Playwright cover unit and end-to-end testing expectations\",\"Mid-level seniority is an exact match\"],\"gaps\":[\"No headless CMS integration experience (Contentful, Sanity, etc.) explicitly visible\"],\"explanation\":\"This candidate maps precisely to the role's Astro-centric stack with React islands, Tailwind, and database-backed content delivery. The testing profile with Vitest and Playwright is exactly what the role asks for. The only minor gap is the absence of explicit headless CMS experience, though Supabase as a backend data source is a reasonable substitute signal.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"k8s_newbie_ops\",\"seniority\":\"Junior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Docker\",\"AWS\",\"GitHub Actions\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nMid-size SaaS company hiring a senior DevOps engineer to own Kubernetes cluster operations across three AWS regions. The candidate must have deep Helm and Terraform experience, familiarity with service mesh tools like Istio, and a track record of running GitOps workflows with ArgoCD. Prometheus and Grafana for observability are required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Docker and AWS provide a basic cloud containerization foundation\"],\"gaps\":[\"Junior seniority is far below the senior requirement\",\"No Kubernetes experience — the central technology of this role\",\"No Helm or Terraform visible\",\"No Istio or service mesh tooling\",\"No ArgoCD or GitOps experience\",\"No observability tooling (Prometheus or Grafana)\"],\"explanation\":\"This candidate is at the very beginning of their DevOps career and lacks every specialized skill the role requires. Docker and AWS are entry-level signals that do not bridge the Kubernetes, Helm, Terraform, Istio, and ArgoCD gaps. The seniority mismatch alone would disqualify this profile, compounded by the depth of missing technical skills.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"pyspark_pipeline\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\",\"Scala\"],\"tech\":[\"Apache Spark\",\"PySpark\",\"Apache Kafka\",\"dbt\",\"Apache Airflow\",\"Docker\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"Redshift\",\"PostgreSQL\",\"Cassandra\"],\"ci_cd\":[\"GitLab CI\"]}\n\nJob Summary:\nStreaming data platform at a logistics company. We need a senior data engineer with strong PySpark and Kafka experience to build real-time ingestion pipelines. Our warehouse is Redshift and we orchestrate with Airflow. dbt is used for transformation modeling. Comfort with distributed system design and SQL at scale is essential.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PySpark and Kafka directly satisfy the real-time ingestion pipeline requirements\",\"Redshift is the team's warehouse and is present prominently\",\"Airflow covers the orchestration requirement\",\"dbt satisfies the transformation modeling expectation\",\"Distributed System and Event-Driven architecture experience supports the pipeline design context\",\"Senior seniority matches the ownership expectations\"],\"gaps\":[\"No data quality tooling (Great Expectations or equivalent) documented\"],\"explanation\":\"The candidate's stack is a near-exact match for every named technology in the job description, covering Kafka, PySpark, Redshift, Airflow, and dbt together. The distributed system and event-driven architecture experience provides the design depth needed for a real-time logistics platform. The only gap worth noting is the absence of explicit data quality or validation tooling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"spring_cloud_dev\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Spring Boot\",\"Spring\",\"Docker\",\"Kubernetes\",\"AWS\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"API Gateway\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MongoDB\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"],\"testing\":[\"JUnit\",\"Mockito\",\"Testcontainers\"]}\n\nJob Summary:\nCloud-native fintech building a payments microservices platform on the JVM. Looking for a senior backend engineer with Spring Boot and Kafka expertise who is comfortable designing API gateway patterns and deploying on Kubernetes. PostgreSQL and Redis are the primary data stores. Strong test coverage with JUnit and integration tests is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Spring Boot and Kafka are both listed prominently and satisfy the core requirements\",\"API Gateway architecture experience directly addresses the stated design pattern\",\"PostgreSQL and Redis are both present as primary data stores\",\"JUnit and Mockito cover the unit testing expectation, with Testcontainers adding integration test depth\",\"Kubernetes deployment experience supports the cloud-native fintech context\",\"Senior seniority aligns with platform ownership expectations\"],\"gaps\":[\"No explicit circuit breaker or resilience pattern tooling (Resilience4j, etc.) visible\"],\"explanation\":\"This candidate's profile is a high-confidence match across every named technology in the role. The addition of Testcontainers beyond basic JUnit signals mature integration testing practices that are particularly valuable in a payments context. The only gap worth probing is resilience pattern tooling, which is common in payments microservices but not explicitly stated in the job description.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"wasm_rust_front\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\",\"Backend Engineer\"],\"languages\":[\"Rust\",\"TypeScript\",\"JavaScript\"],\"tech\":[\"Axum\",\"React\",\"Vite\",\"Docker\",\"Cloudflare\"],\"architecture\":[\"Microservices\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"]}\n\nJob Summary:\nDeveloper tools company building a browser-based IDE using WebAssembly and React. We compile Rust to WASM for performance-critical components and use TypeScript for the UI layer. Cloudflare Workers for edge deployment. Looking for an engineer comfortable with both Rust and modern frontend tooling. Experience with Vite or bundler configuration is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Rust is the primary systems language and is listed first, enabling WASM compilation work\",\"React and TypeScript together satisfy the UI layer requirement\",\"Cloudflare experience aligns with the edge deployment model\",\"Vite satisfies the bundler configuration bonus criterion\",\"The combination of Rust systems depth and modern frontend capability is rare and directly relevant\"],\"gaps\":[\"No explicit WebAssembly or wasm-bindgen experience documented separately from Rust\"],\"explanation\":\"This candidate is uniquely positioned for a role requiring both Rust and frontend expertise, which is a rare combination. The Cloudflare and Vite experience further align with the edge deployment and bundler expectations. The only gap is the absence of explicit WebAssembly toolchain experience, though Rust proficiency is the primary prerequisite and the rest follows.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"tableau_analyst\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"Tableau\",\"Power BI\",\"Pandas\"]}\n\nJob Summary:\nE-commerce company seeking a senior analytics engineer to own dbt model development, BigQuery pipeline maintenance, and Looker dashboard delivery. The candidate must be comfortable with dimensional modeling, understand Airflow for orchestration, and have strong stakeholder communication skills demonstrated through data tooling. Experience with data quality frameworks is a bonus.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"SQL proficiency is foundational and transferable\",\"Python and Pandas provide data manipulation capability\"],\"gaps\":[\"Mid-level seniority is below the senior analytics engineer requirement\",\"No dbt experience — the primary transformation tool for this role\",\"No BigQuery experience — the team's data warehouse\",\"No Looker experience — the required BI delivery tool\",\"No Airflow or orchestration experience\",\"No dimensional modeling or data quality framework experience documented\"],\"explanation\":\"While the candidate has core SQL and BI reporting skills, they use Tableau and Power BI where the role requires Looker, and lack the dbt, BigQuery, and Airflow toolchain entirely. This is an analyst profile rather than an analytics engineering profile, and the gap between these roles is substantial in terms of both tooling and technical depth.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ts_monorepo_lead\",\"seniority\":\"Lead\",\"roles\":[\"Full Stack Engineer\",\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"tRPC\",\"Turborepo\",\"Tailwind CSS\",\"Prisma\"],\"architecture\":[\"Monorepo\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\",\"Jest\"]}\n\nJob Summary:\nProduct startup building a multi-product TypeScript monorepo. We use Next.js, tRPC, and Prisma across shared packages, deploy on Vercel, and manage the repo with Turborepo. Looking for a lead engineer who can set architecture standards, own the monorepo toolchain, and mentor junior engineers. Tailwind and PostgreSQL are in the stack.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Turborepo is the monorepo toolchain and is explicitly present\",\"tRPC satisfies the type-safe API layer requirement\",\"Next.js and Prisma are both present as core stack tools\",\"Tailwind CSS and PostgreSQL cover the styling and database expectations\",\"Lead seniority is appropriate for setting architecture standards and mentorship\",\"Comprehensive testing with Vitest, Playwright, and Jest demonstrates mature testing discipline\"],\"gaps\":[\"No explicit Vercel deployment experience documented\"],\"explanation\":\"This candidate is a precision match for a TypeScript monorepo lead role, with Turborepo, tRPC, Next.js, and Prisma all present and prominent. The lead seniority and breadth of testing tooling signal the technical leadership and quality standards the role requires. The only gap is the absence of explicit Vercel deployment experience, which is minor given the Next.js familiarity.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"django_rest_mid\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Django\",\"Celery\",\"Redis\",\"Docker\",\"Nginx\"],\"architecture\":[\"REST\",\"Monolith\"],\"databases\":[\"PostgreSQL\",\"MySQL\"],\"ci_cd\":[\"GitLab CI\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nHealthtech startup building a patient management REST API in FastAPI. We need a mid-level Python engineer who is comfortable with async Python, PostgreSQL, Celery for background tasks, and Docker-based local development. pytest is our testing standard. Experience with Redis caching is a plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Python with Celery and Redis covers the background task and caching requirements\",\"PostgreSQL is the primary database and is present\",\"pytest aligns with the testing standard\",\"Docker supports the local development workflow expectation\",\"Mid-level seniority is an exact match\"],\"gaps\":[\"Uses Django rather than FastAPI — the async Python expectation is not met by Django's synchronous default architecture\",\"No async Python or ASGI framework experience documented\",\"No FastAPI experience explicitly\"],\"explanation\":\"The candidate has a solid Python backend foundation with Celery, Redis, PostgreSQL, and pytest that maps well to most of the role's requirements. However, the Django-to-FastAPI shift is meaningful because the role explicitly values async Python, which is a core design principle of FastAPI and not native to Django. The ramp-up on async patterns and FastAPI idioms would be required.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_research_eng\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\",\"Data Scientist\"],\"languages\":[\"Python\"],\"tech\":[\"PyTorch\",\"Hugging Face Transformers\",\"Weights & Biases\",\"CUDA\",\"Docker\",\"Ray\"],\"architecture\":[\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"]}\n\nJob Summary:\nAI research lab at a large tech company hiring a senior ML engineer to train and fine-tune large language models. PyTorch is the training framework. Experience with Hugging Face Transformers and distributed training at scale using Ray or similar is required. CUDA optimization knowledge is highly valued. Experiment tracking with Weights and Biases is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"PyTorch is the training framework and is listed first\",\"Hugging Face Transformers directly addresses the LLM fine-tuning requirement\",\"Ray satisfies the distributed training at scale requirement\",\"CUDA optimization knowledge meets the highly valued criterion\",\"Weights and Biases covers the experiment tracking expectation\"],\"gaps\":[\"No model serving or inference optimization experience visible (vLLM, TGI, Triton)\"],\"explanation\":\"This candidate's profile is a direct match for an LLM training and fine-tuning research role, covering every named tool and framework. The CUDA experience is particularly valuable given it is specifically called out as highly valued. The only gap is the absence of inference serving infrastructure, which is more relevant to productionization than to the research lab context described.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"vue_midlevel\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"Vue.js\",\"Vuex\",\"Axios\",\"Bootstrap\"],\"databases\":[\"Firebase\"],\"testing\":[\"Jest\"]}\n\nJob Summary:\nModern SaaS startup looking for a frontend engineer experienced with Vue 3 and Pinia. The candidate should be comfortable with TypeScript, Tailwind CSS, and Vite for the build toolchain. End-to-end testing with Playwright is expected. We are migrating from Vue 2 and need someone who understands the Composition API and modern Vue patterns.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Vue.js experience is directly relevant as the role's framework\",\"TypeScript and Jest provide a foundational development and testing baseline\",\"Mid-level seniority aligns with the role level\"],\"gaps\":[\"Uses Vuex (Vue 2 state management) rather than Pinia, the required Vue 3 solution\",\"No Tailwind CSS experience — Bootstrap is used instead\",\"No Vite experience — build toolchain is not addressed\",\"No Playwright experience — Jest alone does not cover the E2E testing expectation\",\"No Composition API or Vue 3 migration experience documented\"],\"explanation\":\"The candidate has Vue experience but appears to be working in Vue 2 patterns, which is the opposite of what this migration-focused role requires. The Vuex-to-Pinia, Bootstrap-to-Tailwind, and Jest-to-Playwright gaps together represent a meaningful tooling shift. The candidate could be a fit with ramp-up investment, but brings Vue 2 rather than Vue 3 expertise.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"golang_microsvcs\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\"],\"tech\":[\"Fiber\",\"Docker\",\"Kubernetes\",\"AWS\",\"RabbitMQ\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"REST\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Go test\",\"Testify\"]}\n\nJob Summary:\nLogistics startup building internal microservices in Go. The candidate should be comfortable with REST API development in Go, async messaging patterns with RabbitMQ or Kafka, and Kubernetes for deployment. PostgreSQL is the primary database. We value clean service boundaries and test coverage with the standard Go testing tools.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Go is the primary language and Fiber satisfies the REST API framework expectation\",\"RabbitMQ directly addresses the async messaging requirement\",\"Kubernetes and AWS support the deployment context\",\"PostgreSQL is the primary database and is present\",\"Go test and Testify align with the standard Go testing tools expectation\",\"Microservices and Event-Driven architecture experience demonstrates service boundary design maturity\"],\"gaps\":[\"No Kafka experience — only RabbitMQ of the two named messaging systems is present\"],\"explanation\":\"This candidate is a strong match for a Go microservices role, covering the language, framework, messaging, database, and testing requirements with precision. The Testify library alongside standard Go testing signals a mature test suite approach. Kafka is absent but RabbitMQ is an accepted alternative that the role also names, making this a minor and acceptable gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"intern_web_basics\",\"seniority\":\"Intern\",\"languages\":[\"JavaScript\",\"HTML\",\"CSS\"],\"tech\":[\"React\"]}\n\nJob Summary:\nEnterprise software company seeking a senior frontend architect to lead the design system, establish component standards, and mentor a team of eight frontend engineers. The candidate must have deep React and TypeScript experience, have shipped a design system at scale, and understand accessibility standards. Performance profiling and bundle optimization experience is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"Intern seniority is far below the senior architect requirement\",\"No TypeScript experience\",\"No design system experience\",\"No component standards or team mentorship signals\",\"No accessibility knowledge documented\",\"No performance profiling or bundle optimization experience\",\"No testing, CI/CD, or production-grade tooling visible\"],\"explanation\":\"This candidate is at the earliest stage of a frontend career with a profile that covers only the most basic web development fundamentals. The role requires a senior architect with specific design system leadership, TypeScript depth, accessibility expertise, and team mentorship experience — none of which are present. There is no meaningful overlap between this profile and the role's requirements.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"rag_llm_ops\",\"seniority\":\"Senior\",\"roles\":[\"AI Engineer\",\"Backend Engineer\"],\"languages\":[\"Python\",\"TypeScript\"],\"tech\":[\"LangChain\",\"OpenAI API\",\"Pinecone\",\"Weaviate\",\"FastAPI\",\"Docker\",\"AWS\"],\"architecture\":[\"RAG\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Pinecone\",\"Weaviate\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nEnterprise AI company building a knowledge retrieval product for large document collections. We need a senior AI engineer with deep RAG pipeline experience, vector database expertise (Pinecone or Weaviate), and LangChain for orchestration. FastAPI for the backend API layer. Python and TypeScript across the stack. AWS for deployment.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LangChain satisfies the orchestration requirement\",\"Both Pinecone and Weaviate are present, exceeding the stated vector database requirement\",\"RAG architecture is the primary pattern and is listed first\",\"FastAPI covers the backend API layer expectation\",\"Python and TypeScript across the stack aligns with the stated languages\",\"AWS satisfies the deployment environment expectation\"],\"gaps\":[\"No explicit document parsing or chunking pipeline tooling (LlamaParse, Unstructured, etc.) visible\"],\"explanation\":\"This candidate is purpose-built for a RAG-focused enterprise knowledge retrieval role, with LangChain, dual vector database experience, FastAPI, and AWS all present. The presence of both Pinecone and Weaviate is a particularly strong signal of genuine production RAG work across different vector store backends. The only gap is the absence of explicit document parsing tooling, which is a component-level detail rather than a strategic gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"sre_oncall\",\"seniority\":\"Mid\",\"roles\":[\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Bash\"],\"tech\":[\"Prometheus\",\"Grafana\",\"Kubernetes\",\"Docker\",\"PagerDuty\",\"AWS\"],\"ci_cd\":[\"GitHub Actions\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nConsumer tech company looking for a mid-level SRE to manage on-call rotations, build Prometheus alerting rules, and maintain Grafana dashboards for a Kubernetes-hosted platform. PagerDuty for incident management. Go for automation scripting. AWS is the cloud. Experience with distributed tracing is a plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Prometheus and Grafana directly match the alerting and dashboard requirements\",\"Kubernetes is the hosting platform and is present\",\"PagerDuty satisfies the incident management tool expectation\",\"Go satisfies the automation scripting language requirement\",\"AWS aligns with the cloud environment\",\"Mid-level seniority is an exact match\"],\"gaps\":[\"No distributed tracing experience (Jaeger, Zipkin, OpenTelemetry) — listed as a plus but absent\"],\"explanation\":\"This candidate hits every primary requirement for the role with precision, covering Prometheus, Grafana, Kubernetes, PagerDuty, and Go in a mid-level SRE profile. The only gap is the distributed tracing bonus criterion, which is a growth area rather than a disqualifier. This is a high-confidence match for the stated scope.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"react_redux_mid\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"TypeScript\"],\"tech\":[\"React\",\"Redux\",\"Webpack\",\"SCSS\",\"Axios\"],\"testing\":[\"Jest\",\"React Testing Library\"]}\n\nJob Summary:\nLegacy enterprise application company modernizing their frontend stack to React and TypeScript. They are adopting Vite as the build tool, TanStack Query for server state, and Tailwind for styling. The candidate should have strong React fundamentals, TypeScript fluency, and experience writing tests. Experience with the older Webpack-based toolchain is a plus during the transition period.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"React and TypeScript are strong foundational matches\",\"Jest and React Testing Library satisfy the testing requirement\",\"Webpack experience satisfies the stated transition-period bonus criterion\",\"Redux background provides state management experience transferable to TanStack Query patterns\"],\"gaps\":[\"No Vite experience — the new build tool being adopted\",\"No TanStack Query experience — the replacement for Redux server state\",\"No Tailwind CSS — SCSS is used instead\",\"No familiarity with modern React patterns beyond Redux\"],\"explanation\":\"The candidate has solid React fundamentals and the Webpack experience is genuinely valued during the transition. However, the three new tools being adopted (Vite, TanStack Query, Tailwind) are all absent from the profile. This is a moderate fit who can contribute from day one on React fundamentals while ramping up on the new toolchain in parallel.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"cloudnative_arch\",\"seniority\":\"Principal\",\"roles\":[\"Software Architect\",\"Backend Engineer\"],\"languages\":[\"Go\",\"Python\",\"TypeScript\"],\"tech\":[\"Kubernetes\",\"Istio\",\"Terraform\",\"Pulumi\",\"AWS\",\"Google Cloud\",\"Kafka\",\"Docker\"],\"architecture\":[\"Cloud-Native\",\"Microservices\",\"Service Mesh\",\"Event-Driven\",\"Multi-Tenant\"],\"databases\":[\"PostgreSQL\",\"Cassandra\",\"DynamoDB\",\"Redis\"],\"ci_cd\":[\"ArgoCD\",\"GitHub Actions\",\"Tekton\"]}\n\nJob Summary:\nFAANG-scale platform company looking for a principal architect to define the multi-cloud infrastructure strategy, own service mesh standards, and drive event-driven architecture adoption across twenty-plus product teams. Go and Python are the scripting standards. The candidate must have multi-tenant design experience and deep Kubernetes expertise.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Principal seniority is appropriate for the cross-team architecture ownership scope\",\"Both AWS and Google Cloud present, directly satisfying the multi-cloud strategy requirement\",\"Istio and Service Mesh architecture address the stated service mesh standards responsibility\",\"Kafka and Event-Driven architecture support the event-driven adoption mandate\",\"Multi-Tenant architecture experience directly meets the stated design requirement\",\"Terraform, Pulumi, ArgoCD, and Tekton together demonstrate platform engineering maturity at scale\"],\"gaps\":[\"No explicit API gateway or developer portal experience for enabling twenty-plus teams\"],\"explanation\":\"This candidate's profile reads as a deliberate match for a FAANG-scale principal architecture role, covering multi-cloud, service mesh, event-driven, and multi-tenant design simultaneously. The breadth of IaC tooling (both Terraform and Pulumi) and GitOps tools (ArgoCD and Tekton) signals hands-on platform engineering experience rather than theoretical architecture work. The only gap is around developer experience tooling for enabling large engineering organizations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ruby_fullstack\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"Ruby\",\"JavaScript\"],\"tech\":[\"Ruby on Rails\",\"React\",\"Sidekiq\",\"Docker\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"CircleCI\"],\"testing\":[\"RSpec\",\"Cypress\"]}\n\nJob Summary:\nB2C marketplace startup hiring a mid-level full stack engineer to build new features across a Rails backend and React frontend. PostgreSQL is the database. Sidekiq for background processing. We use CircleCI for CI and value both API and end-to-end testing. Redis for caching and queuing. Comfort with Docker for local dev is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Ruby on Rails directly matches the backend requirement\",\"React satisfies the frontend expectation\",\"Sidekiq and Redis together cover the background processing and caching requirements\",\"PostgreSQL is the primary database and is present\",\"CircleCI satisfies the CI tool requirement exactly\",\"RSpec and Cypress cover both API and end-to-end testing expectations\",\"Mid-level seniority is a direct match\"],\"gaps\":[\"No explicit experience with marketplace-specific patterns (payments, listings, search)\"],\"explanation\":\"This candidate's profile is an exact match for the stated full stack Rails and React role, with every named technology present and correctly placed. The RSpec and Cypress combination covers both the API and E2E testing expectations the role specifies. The only minor gap is the absence of marketplace domain patterns, which is a soft signal rather than a technical disqualifier.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_notebook_only\",\"seniority\":\"Junior\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"R\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"Jupyter\"]}\n\nJob Summary:\nML platform team at a fintech company looking for a senior ML engineer to build production model serving infrastructure. The candidate must have PyTorch or TensorFlow experience, familiarity with model serving frameworks (TorchServe, Triton, or BentoML), Kubernetes for deployment, and MLflow for experiment tracking. Python is the primary language. Three or more years of production ML experience required.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python and scikit-learn provide a foundational ML baseline\"],\"gaps\":[\"Junior seniority is far below the three-year senior requirement\",\"No PyTorch or TensorFlow experience\",\"No model serving framework experience (TorchServe, Triton, BentoML)\",\"No Kubernetes or production deployment experience\",\"No MLflow or experiment tracking tooling\",\"Profile is notebook-centric with no production engineering signals\"],\"explanation\":\"This candidate's profile is entirely research and exploration focused — Jupyter, scikit-learn, and Pandas without any production tooling. The role requires production ML infrastructure engineering, which demands a fundamentally different skill set. Every critical requirement, from deep learning frameworks to model serving and Kubernetes deployment, is absent.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nextjs_saas\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"React\",\"Prisma\",\"Tailwind CSS\",\"Stripe\",\"Vercel\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nBootstrapped SaaS product company hiring a senior full stack engineer to help build and grow a subscription-based product. Next.js and React on the frontend, Prisma with PostgreSQL on the backend. Stripe for payments integration. Deployed on Vercel. Strong TypeScript fundamentals required. Automated testing with Vitest and Playwright valued.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and React satisfy the frontend framework requirements directly\",\"Prisma and PostgreSQL match the backend data access stack\",\"Stripe integration experience directly addresses the payments requirement\",\"Vercel deployment aligns with the hosting environment\",\"Vitest and Playwright satisfy both unit and end-to-end testing expectations\",\"Tailwind CSS and Supabase add relevant stack depth\"],\"gaps\":[\"No explicit subscription billing or SaaS metering pattern experience documented beyond Stripe presence\"],\"explanation\":\"This candidate is an exceptionally precise match for a bootstrapped SaaS full stack role, with every named technology — Next.js, Prisma, Stripe, Vercel, Vitest, and Playwright — present in the profile. The Stripe experience in particular is a high-value signal for a subscription business. The only gap is the absence of explicit subscription lifecycle or metering pattern experience beyond Stripe usage.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ios_obj_c_dev\",\"seniority\":\"Senior\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Objective-C\",\"Swift\"],\"tech\":[\"UIKit\",\"CoreData\",\"Xcode\"],\"databases\":[\"SQLite\",\"CoreData\"],\"ci_cd\":[\"Jenkins\"]}\n\nJob Summary:\nModern fintech app company looking for an iOS engineer to build new features in SwiftUI. The candidate should be comfortable with Combine or async/await for concurrency, have experience integrating financial APIs, and understand iOS security best practices. Fastlane for CI/CD. We expect test coverage using XCTest.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Senior Swift experience provides a strong native iOS foundation\",\"CoreData experience demonstrates persistent local storage capability relevant to financial data\",\"UIKit background provides UI development depth transferable to SwiftUI\"],\"gaps\":[\"Primary experience is Objective-C and UIKit, not SwiftUI which is the stated development framework\",\"No Combine or async/await concurrency experience documented\",\"No Fastlane experience — Jenkins is the CI tool, not Fastlane\",\"No XCTest visible in the profile\",\"No financial API integration or iOS security experience documented\"],\"explanation\":\"The candidate has deep native iOS experience but is anchored in Objective-C and UIKit patterns rather than the SwiftUI and modern Swift concurrency patterns this role requires. The CI/CD toolchain mismatch (Jenkins vs Fastlane) and absence of XCTest are additional gaps. This is an experienced iOS engineer who would need meaningful ramp-up on the modern Swift and SwiftUI ecosystem.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ops_ansible_cfg\",\"seniority\":\"Mid\",\"roles\":[\"DevOps Engineer\",\"Infrastructure Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Ansible\",\"Terraform\",\"Docker\",\"AWS\",\"Prometheus\",\"Grafana\"],\"ci_cd\":[\"Jenkins\",\"GitHub Actions\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nMid-market company looking for a mid-level infrastructure engineer to manage AWS resources with Terraform, automate configuration with Ansible, and maintain monitoring with Prometheus and Grafana. CI/CD via GitHub Actions. No Kubernetes experience required — VMs and ECS are the deployment model. Python scripting for automation is expected.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Terraform and Ansible directly match the IaC and configuration automation requirements\",\"Prometheus and Grafana satisfy the monitoring and observability expectations\",\"GitHub Actions covers the CI/CD requirement\",\"AWS provides the cloud environment alignment\",\"Python scripting is present for automation\",\"Mid-level seniority is an exact match\",\"VM-based deployment model aligns with the role's explicitly non-Kubernetes infrastructure\"],\"gaps\":[\"No ECS-specific experience documented alongside Docker\"],\"explanation\":\"This candidate is a strong fit for a traditional AWS infrastructure role that explicitly does not require Kubernetes. The Terraform, Ansible, Prometheus, and Grafana combination covers every stated requirement. ECS-specific experience is a minor gap, but Docker familiarity and AWS experience together are sufficient context for an ECS ramp-up.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kotlin_android_sr\",\"seniority\":\"Senior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Kotlin\",\"Java\"],\"tech\":[\"Jetpack Compose\",\"Android SDK\",\"Kotlin Multiplatform\",\"Coroutines\",\"Hilt\"],\"databases\":[\"SQLite\",\"Room\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Fastlane\"],\"testing\":[\"JUnit\",\"Espresso\",\"Mockito\"]}\n\nJob Summary:\nConsumer app company investing in Kotlin Multiplatform to share business logic across Android and iOS. Looking for a senior Android engineer with deep Kotlin expertise, Jetpack Compose experience, and willingness to lead KMP module development. Coroutines for async patterns, Hilt for dependency injection. Firebase for backend. Testing with JUnit and Espresso.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kotlin Multiplatform is present and directly matches the KMP module development expectation\",\"Jetpack Compose satisfies the UI framework requirement\",\"Coroutines and Hilt both present for async and dependency injection patterns\",\"Firebase aligns with the backend integration requirement\",\"JUnit and Espresso cover the stated testing tools\",\"Senior seniority supports leading KMP module development\"],\"gaps\":[\"No Swift or iOS baseline knowledge visible for cross-platform KMP integration work\"],\"explanation\":\"This candidate is an excellent match for an Android-first KMP role, covering every named technology with Kotlin Multiplatform as the differentiating skill. The combination of Coroutines, Hilt, Jetpack Compose, and KMP signals a genuinely modern Android engineering profile. The only gap worth noting is the absence of any Swift or iOS exposure, which can matter when KMP modules need to be integrated on the iOS side.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"frontend_jquery\",\"seniority\":\"Mid\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"JavaScript\",\"PHP\"],\"tech\":[\"jQuery\",\"Bootstrap\",\"WordPress\"],\"databases\":[\"MySQL\"]}\n\nJob Summary:\nModern product company rebuilding their frontend in React and TypeScript. Looking for a mid-level engineer with strong React component architecture skills, familiarity with state management (Zustand or Jotai), end-to-end testing using Playwright, and Vite for the build toolchain. We ship features continuously with GitHub Actions.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"JavaScript experience is foundational and partially transferable\"],\"gaps\":[\"No React or TypeScript experience\",\"No modern state management library experience (Zustand or Jotai)\",\"No Playwright or modern testing experience\",\"No Vite or modern build toolchain experience\",\"No GitHub Actions or CI/CD pipeline experience\",\"jQuery and Bootstrap-based profile is incompatible with the modern React ecosystem\"],\"explanation\":\"This candidate's profile is built around legacy web technologies that have no meaningful overlap with the React, TypeScript, and modern frontend toolchain this role requires. JavaScript is the only shared element, and at the framework and tooling level there is a complete mismatch. A significant retraining investment would be required before this candidate could contribute to the team.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"clojure_backend\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Clojure\",\"Java\",\"Python\"],\"tech\":[\"Ring\",\"Docker\",\"AWS\",\"Kafka\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Datomic\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nFinancial data company looking for a senior backend engineer to build event-driven microservices in Clojure. Kafka for messaging. PostgreSQL for persistence. Familiarity with functional programming and immutable data patterns is essential. AWS deployment. Experience with CQRS or event sourcing is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Clojure is the primary language and is listed first — rare and direct match\",\"Kafka satisfies the messaging requirement\",\"Event-Driven and Microservices architecture aligns with the service design expectations\",\"Datomic demonstrates functional database and immutable data pattern familiarity\",\"PostgreSQL covers the persistence requirement\",\"Distributed System experience supports the financial data platform context\"],\"gaps\":[\"No explicit CQRS or event sourcing pattern documented\"],\"explanation\":\"This candidate is a rare and compelling match for a Clojure-based event-driven backend role. The combination of Clojure, Kafka, Datomic, and functional architecture demonstrates authentic immutable data and event-driven design experience. The Datomic database choice in particular signals deep functional programming philosophy alignment. The only gap is the absence of explicit CQRS or event sourcing documentation, which is the stated strong-plus criterion.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"platform_staff_eng\",\"seniority\":\"Staff\",\"roles\":[\"Platform Engineer\",\"Site Reliability Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Helm\",\"Terraform\",\"Istio\",\"Prometheus\",\"Grafana\",\"OpenTelemetry\",\"AWS\"],\"architecture\":[\"Service Mesh\",\"Cloud-Native\",\"Multi-Tenant\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"ArgoCD\",\"GitHub Actions\"]}\n\nJob Summary:\nLarge-scale cloud company looking for a staff platform engineer to define observability standards, own the service mesh strategy, and lead Kubernetes fleet operations for fifty-plus engineering teams. OpenTelemetry adoption is a current initiative. Terraform and Helm are the IaC standards. Go or Python for automation.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Staff seniority is appropriate for defining standards and leading fifty-plus team platform work\",\"OpenTelemetry directly satisfies the current initiative requirement\",\"Istio and Service Mesh architecture address the service mesh strategy ownership\",\"Prometheus and Grafana support the observability standards definition\",\"Terraform and Helm are both present as required IaC tools\",\"Go and Python cover the automation scripting expectations\"],\"gaps\":[\"No developer experience or internal tooling for large-team enablement documented\"],\"explanation\":\"This candidate's profile is a high-confidence match for a staff-level platform engineering role at scale. OpenTelemetry being listed alongside Prometheus and Grafana is a particularly strong signal given the stated adoption initiative. The combination of Istio, Helm, Terraform, and ArgoCD demonstrates full-lifecycle platform ownership capability. The only gap is the absence of internal developer platform or tooling experience, which matters when enabling large engineering organizations.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"python_scripts_only\",\"seniority\":\"Junior\",\"languages\":[\"Python\"],\"tech\":[\"Pandas\",\"NumPy\"]}\n\nJob Summary:\nStartup building a customer-facing API platform. Hiring a mid-level backend engineer with experience in Node.js, REST API design, PostgreSQL schema design, and Docker containerization. TypeScript is required. CI/CD via GitHub Actions. Testing with Jest and Supertest. Redis for caching.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[],\"gaps\":[\"No Node.js or TypeScript experience\",\"No REST API design or web framework experience\",\"No PostgreSQL or relational schema design experience\",\"No Docker or containerization experience\",\"No GitHub Actions or CI/CD experience\",\"Junior seniority is below the mid-level requirement\",\"Profile is data-focused with no web backend signals\"],\"explanation\":\"This candidate's profile consists entirely of data science tooling (Pandas, NumPy) and has no overlap with the Node.js, TypeScript, PostgreSQL, and Docker requirements of this API platform role. The technology gap spans every layer of the stack. Junior seniority further compounds the mismatch. There is no reasonable path to contribution without a complete stack change.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ts_backend_node\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Express.js\",\"Prisma\",\"Docker\",\"AWS\",\"BullMQ\"],\"architecture\":[\"REST\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nE-commerce platform hiring a mid-level backend engineer for a Node.js and TypeScript API. PostgreSQL is the database and Prisma is the ORM. BullMQ for job queuing with Redis. Docker for local and production containers. Testing with Jest and Supertest. AWS for deployment. We ship REST APIs and expect clean API design.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"TypeScript and Express.js satisfy the Node.js backend API requirement\",\"Prisma is the ORM and is explicitly listed\",\"BullMQ and Redis together cover the job queuing requirement directly\",\"PostgreSQL is the primary database and is present\",\"Jest and Supertest match the stated testing tools exactly\",\"Mid-level seniority is a direct match\"],\"gaps\":[\"No explicit REST API versioning or contract testing experience documented\"],\"explanation\":\"This candidate's profile maps precisely to every named technology in the job description. The BullMQ plus Redis combination is a specific and strong signal of familiarity with the team's exact queuing setup. Jest and Supertest together satisfy both unit and API integration testing expectations. The only gap is a documentation-level one around REST API design patterns and versioning practices.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"senior_android_java\",\"seniority\":\"Senior\",\"roles\":[\"Android Engineer\"],\"languages\":[\"Java\",\"Kotlin\"],\"tech\":[\"Android SDK\",\"Firebase\",\"Retrofit\",\"SQLite\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"Jenkins\"],\"testing\":[\"JUnit\",\"Espresso\"]}\n\nJob Summary:\nFintech mobile company modernizing their Android app to Jetpack Compose and Kotlin-first development. They need a senior Android engineer who can lead the migration from View-based UI to Compose, adopt Hilt for dependency injection, and implement Kotlin Flow for reactive state. Fastlane for build automation. Testing with JUnit and Espresso.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Senior Kotlin and Java experience provides a strong Android foundation for the migration\",\"JUnit and Espresso satisfy the testing requirements exactly\",\"Firebase and Retrofit experience shows API integration and backend connectivity maturity\"],\"gaps\":[\"No Jetpack Compose experience — the primary migration target\",\"No Hilt dependency injection experience\",\"No Kotlin Flow or reactive state management experience\",\"No Fastlane experience — Jenkins is the CI tool, not Fastlane\"],\"explanation\":\"The candidate has a solid traditional Android foundation and the testing skills are a direct match. However, the three core modern Kotlin patterns the migration requires — Jetpack Compose, Hilt, and Kotlin Flow — are all absent from the profile. This is an experienced Android developer who would need meaningful ramp-up on the modern Android stack before leading the migration effectively.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dagster_data_ops\",\"seniority\":\"Mid\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"Dagster\",\"dbt\",\"Docker\",\"Google Cloud\"],\"databases\":[\"BigQuery\",\"PostgreSQL\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nGrowth analytics company on GCP looking for a mid-level data engineer to build and maintain transformation pipelines. dbt is the transformation layer, Dagster is the orchestration tool, and BigQuery is the warehouse. Python for scripting. We value tested, version-controlled pipelines deployed via GitHub Actions.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Dagster is the orchestration tool and is listed first — a precise and uncommon match\",\"dbt directly satisfies the transformation layer requirement\",\"BigQuery is the warehouse and is present\",\"GCP experience aligns with the cloud environment\",\"pytest and GitHub Actions demonstrate tested and version-controlled pipeline practices\",\"Mid-level seniority is an exact match\"],\"gaps\":[\"No explicit data quality tooling (Great Expectations or equivalent) documented\"],\"explanation\":\"This candidate's profile is an exact match for every named tool in the role description, including the less common Dagster orchestration platform. The dbt, BigQuery, and GCP combination covers the full transformation and warehouse stack. The only gap is the absence of data quality validation tooling, which is a common complement to dbt pipelines but not explicitly stated as required.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"devrel_backend\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Software Engineer\"],\"languages\":[\"Python\",\"JavaScript\",\"TypeScript\"],\"tech\":[\"FastAPI\",\"Express.js\",\"Docker\",\"AWS\",\"Postman\",\"OpenAPI\"],\"architecture\":[\"REST\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"MongoDB\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\",\"Jest\"]}\n\nJob Summary:\nDeveloper platform company building public APIs for third-party integrations. Hiring a senior backend engineer with strong REST and OpenAPI design experience. Python with FastAPI is the primary stack. PostgreSQL and Redis are used. We value excellent API documentation via OpenAPI or Swagger, and GitHub Actions for CI. Postman for API testing and collection management.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"FastAPI is the primary stack and is listed prominently\",\"OpenAPI and Postman directly address the API documentation and testing requirements\",\"PostgreSQL and Redis are both present as expected data stores\",\"REST architecture and Microservices experience aligns with the public API platform context\",\"pytest covers the Python testing expectation\",\"Senior seniority supports the API design ownership the role requires\"],\"gaps\":[\"No explicit developer portal or SDK generation experience documented\"],\"explanation\":\"This candidate is a strong match for a developer platform API role, with FastAPI, OpenAPI, and Postman all present as a cohesive API development and documentation toolchain. The combination of REST API design experience and OpenAPI documentation familiarity is precisely what a public-facing API company needs. The only gap is the absence of developer portal or SDK tooling experience, which is relevant for third-party integration platforms.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"junior_ds_py\",\"seniority\":\"Junior\",\"roles\":[\"Data Scientist\"],\"languages\":[\"Python\",\"SQL\"],\"tech\":[\"scikit-learn\",\"Pandas\",\"NumPy\",\"Matplotlib\"]}\n\nJob Summary:\nAnalytics team at a Series A startup looking for a junior data analyst to write SQL queries, build Tableau dashboards, and clean datasets for business reporting. Python is a plus. No ML or advanced statistics required. We use Snowflake as the data warehouse. Comfort with Excel for ad hoc analysis is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Junior seniority is an exact match for the role level\",\"Python and SQL provide the analytical baseline the role requires\",\"Pandas and NumPy support dataset cleaning and transformation tasks\"],\"gaps\":[\"No Tableau experience — the primary dashboarding tool\",\"No Snowflake experience — the team's data warehouse\",\"No Excel experience visible\",\"Matplotlib is present for visualization but is not a substitute for Tableau in a business reporting context\"],\"explanation\":\"The candidate has the right foundational analytical skills and seniority level, and SQL combined with Python and Pandas is a solid starting point. However, the absence of Tableau and Snowflake — both explicitly required — means there would be meaningful tooling ramp-up needed. Excel is also not documented, which is a practical gap for a data analyst role. The Python skills would transfer well once the BI and warehouse tools are learned.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"kube_security_eng\",\"seniority\":\"Senior\",\"roles\":[\"Security Engineer\",\"DevOps Engineer\"],\"languages\":[\"Go\",\"Python\",\"Bash\"],\"tech\":[\"Kubernetes\",\"Vault\",\"Terraform\",\"AWS\",\"Falco\",\"OPA\"],\"architecture\":[\"Cloud-Native\",\"Zero Trust\"],\"ci_cd\":[\"GitHub Actions\"],\"databases\":[\"PostgreSQL\"]}\n\nJob Summary:\nCloud security company hiring a senior security engineer to harden Kubernetes environments, implement policy-as-code with OPA, manage secrets with Vault, and build Zero Trust network controls on AWS. Go or Python for security automation tooling. Familiarity with runtime threat detection (Falco or equivalent) is a strong plus.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"OPA directly satisfies the policy-as-code requirement\",\"Vault covers the secrets management expectation\",\"Falco satisfies the runtime threat detection strong-plus criterion\",\"Zero Trust architecture is explicitly present and listed\",\"Kubernetes hardening experience aligns with the core security focus\",\"Go and Python cover the security automation tooling languages\"],\"gaps\":[\"No SAST, DAST, or supply chain security tooling documented\"],\"explanation\":\"This candidate covers every stated requirement and the Falco strong-plus criterion in a single profile, which is a rare alignment for a specialized Kubernetes security role. OPA, Vault, Falco, and Zero Trust together form a cohesive cloud security posture that matches the role's scope precisely. The only gap is the absence of supply chain or SAST/DAST tooling, which is a complementary security discipline.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"graphql_api_dev\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\",\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"Apollo GraphQL\",\"Prisma\",\"Docker\",\"AWS\"],\"architecture\":[\"GraphQL\",\"Microservices\",\"REST\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nProduct company building a GraphQL API platform for mobile and web clients. NestJS is the backend framework. Apollo Server for GraphQL. Prisma with PostgreSQL for data access. Redis for caching. TypeScript throughout. We expect tests with Jest and integration coverage with Supertest. Mid-level seniority preferred.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS is the backend framework and is explicitly present\",\"Apollo GraphQL satisfies the GraphQL server requirement\",\"Prisma and PostgreSQL match the data access stack\",\"Redis is listed for caching\",\"Jest and Supertest cover the unit and integration testing expectations\",\"Mid-level seniority is a direct match\"],\"gaps\":[\"No explicit DataLoader or N+1 query optimization experience documented for GraphQL\"],\"explanation\":\"This candidate's profile is an exact mirror of the role's technology requirements, with NestJS, Apollo GraphQL, Prisma, PostgreSQL, Redis, Jest, and Supertest all present. The full-stack breadth with both GraphQL and REST experience adds contextual flexibility. The only gap worth probing is GraphQL-specific performance patterns like DataLoader, which matters at scale.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"senior_dbt_snowflake\",\"seniority\":\"Senior\",\"roles\":[\"Analytics Engineer\",\"Data Engineer\"],\"languages\":[\"SQL\",\"Python\"],\"tech\":[\"dbt\",\"Snowflake\",\"Airflow\",\"Looker\",\"Great Expectations\"],\"databases\":[\"Snowflake\",\"PostgreSQL\",\"BigQuery\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nRetail analytics company hiring a senior analytics engineer to own dbt model development, Snowflake warehouse management, and Looker dashboard delivery. Airflow for pipeline orchestration. Data quality validation is important and tooling like Great Expectations is valued. SQL is the primary language.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"dbt is the transformation tool and is listed first\",\"Snowflake is the warehouse and is present prominently\",\"Looker satisfies the BI delivery requirement\",\"Airflow covers the orchestration expectation\",\"Great Expectations directly satisfies the valued data quality tooling criterion\",\"Senior seniority aligns with ownership expectations\"],\"gaps\":[\"No explicit dimensional modeling methodology or documentation visible\"],\"explanation\":\"This candidate is a high-confidence match for the analytics engineering role, with every named tool covered including the valued Great Expectations for data quality. The combination of dbt, Snowflake, Looker, and Airflow represents the complete modern analytics stack this company uses. The only gap is the absence of explicit dimensional modeling documentation, which is a methodology concern rather than a tooling gap.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"scala_spark_eng\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Scala\",\"Java\"],\"tech\":[\"Apache Spark\",\"Apache Kafka\",\"Hadoop\",\"Docker\"],\"architecture\":[\"Distributed System\",\"Event-Driven\"],\"databases\":[\"Cassandra\",\"MySQL\",\"HDFS\"]}\n\nJob Summary:\nModern cloud data platform company looking for a senior data engineer to build streaming and batch pipelines using PySpark and Kafka on GCP. dbt for SQL transformations. BigQuery as the target warehouse. The team writes Python and SQL, not Scala. Experience with Airflow or Dagster for orchestration is expected.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Spark and Kafka experience is directly relevant to the streaming pipeline work\",\"Distributed System and Event-Driven architecture aligns with the platform design context\",\"Senior seniority matches the role level\"],\"gaps\":[\"Uses Scala rather than Python — the team's language for PySpark is Python\",\"No GCP or BigQuery experience — cloud-native warehouse is a gap\",\"No dbt experience for SQL transformations\",\"No Airflow or Dagster orchestration experience\",\"Hadoop and HDFS experience is legacy and not applicable to the GCP-native stack\"],\"explanation\":\"The candidate has genuine Spark and Kafka depth but is anchored in an older Scala/Hadoop/Cassandra stack that diverges significantly from this team's Python, GCP, dbt, and BigQuery environment. The language shift from Scala to Python for Spark is achievable, but the cloud warehouse and orchestration gaps represent a broader reorientation. This is a strong data engineer who would need meaningful ramp-up on the modern cloud-native toolchain.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"mobile_rn_lead\",\"seniority\":\"Lead\",\"roles\":[\"Mobile Engineer\",\"React Native Developer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"React Native\",\"Expo\",\"Redux\",\"React Query\",\"Fastlane\",\"Detox\"],\"databases\":[\"SQLite\",\"Firebase\"],\"ci_cd\":[\"GitHub Actions\",\"Bitbucket Pipelines\"]}\n\nJob Summary:\nDigital health company building a React Native app for iOS and Android. Looking for a lead mobile engineer to own the technical roadmap, manage a team of three engineers, and drive architecture decisions. TypeScript required. State management with Redux or similar. E2E testing with Detox. Fastlane for build automation.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Lead seniority is appropriate for owning the roadmap and managing a team of three\",\"React Native and Expo cover the cross-platform framework requirements\",\"Redux satisfies the state management requirement\",\"Detox directly addresses the E2E testing expectation\",\"Fastlane covers build automation\",\"TypeScript is present throughout the profile\"],\"gaps\":[\"No explicit healthcare or HIPAA-aware development experience documented\"],\"explanation\":\"This candidate is a comprehensive match for the lead React Native role, covering every named technology and the seniority level required to own the technical roadmap and manage engineers. The Detox and Fastlane combination demonstrates production mobile delivery maturity. The only gap is the absence of healthcare domain or compliance experience, which is a soft concern for a digital health product.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ml_infra_ops\",\"seniority\":\"Senior\",\"roles\":[\"Machine Learning Engineer\"],\"languages\":[\"Python\",\"Go\"],\"tech\":[\"PyTorch\",\"MLflow\",\"Kubeflow\",\"Kubernetes\",\"Docker\",\"AWS\",\"ONNX\"],\"architecture\":[\"Distributed System\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nAI infrastructure team at a scale-up building the ML platform for ten data science teams. We need a senior ML engineer comfortable with Kubeflow for orchestration, MLflow for tracking, and model export via ONNX. Kubernetes for workload scheduling. Python and Go for tooling. AWS is the cloud environment.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Kubeflow directly satisfies the orchestration requirement and is relatively uncommon\",\"MLflow covers the experiment tracking expectation\",\"ONNX satisfies the model export requirement\",\"Kubernetes and AWS support the workload scheduling and cloud environment\",\"Python and Go are both present for tooling\",\"Senior seniority aligns with the platform team scope\"],\"gaps\":[\"No model serving framework experience (Seldon, BentoML, Triton) documented for production inference\"],\"explanation\":\"This candidate is a precise match for an ML platform engineering role, with Kubeflow, MLflow, and ONNX covering every named tool. Kubeflow in particular is a specialized platform tool that signals genuine ML infrastructure experience rather than data science tooling. The only gap is the absence of inference serving infrastructure, which is relevant for a team supporting ten data science teams.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"dotnet_mvc_senior\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\",\"Software Engineer\"],\"languages\":[\"C#\",\"SQL\",\"JavaScript\"],\"tech\":[\"ASP.NET\",\".NET Core\",\"Entity Framework\",\"Azure\",\"Docker\"],\"architecture\":[\"Monolith\",\"REST\",\"Layered Architecture\"],\"databases\":[\"MS SQL Server\",\"Redis\"],\"ci_cd\":[\"Azure DevOps\"],\"testing\":[\"xUnit\",\"NUnit\"]}\n\nJob Summary:\nHealthcare company migrating from a .NET Framework monolith to cloud-native microservices on Azure. Looking for a senior backend engineer with C# and .NET Core, familiar with Azure Service Bus for event-driven messaging, and comfortable with CQRS and clean architecture patterns. Docker and Kubernetes for deployment. Azure DevOps for CI/CD.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"C# and .NET Core are the primary language and framework and are present\",\"Azure and Azure DevOps satisfy the cloud and CI/CD environment expectations\",\"Entity Framework and xUnit demonstrate mature .NET development practices\",\"Docker experience supports the containerization direction\"],\"gaps\":[\"No Azure Service Bus or event-driven messaging experience\",\"No Kubernetes experience — listed as a deployment requirement\",\"No CQRS or clean architecture patterns documented\",\"Monolith and Layered Architecture background is the opposite of the microservices target\",\"No microservices design experience visible\"],\"explanation\":\"The candidate has the right .NET and Azure foundation but their experience is rooted in monolithic layered architecture, which is the starting point the company is migrating away from. The absence of Azure Service Bus, Kubernetes, and CQRS means the three most specialized requirements for the migration work are all gaps. This is a strong .NET developer who would need deliberate upskilling in modern distributed patterns.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"senior_node_api\",\"seniority\":\"Senior\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"NestJS\",\"Kafka\",\"Docker\",\"Kubernetes\",\"AWS\",\"Redis\"],\"architecture\":[\"Microservices\",\"Event-Driven\",\"REST\"],\"databases\":[\"PostgreSQL\",\"MongoDB\",\"DynamoDB\"],\"ci_cd\":[\"GitHub Actions\",\"ArgoCD\"],\"testing\":[\"Jest\",\"Supertest\"]}\n\nJob Summary:\nE-commerce platform at Series C hiring a senior backend engineer for a high-scale Node.js microservices stack. TypeScript throughout. NestJS as the framework. Kafka for asynchronous order event processing. PostgreSQL for transactional data. Kubernetes and AWS for deployment. Jest and Supertest for testing standards.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"NestJS is the framework and is listed first\",\"Kafka directly addresses the async order event processing requirement\",\"PostgreSQL covers the transactional data store expectation\",\"Kubernetes and AWS satisfy the deployment environment requirements\",\"Jest and Supertest are exact matches for the testing standards\",\"Event-Driven and Microservices architecture experience supports the high-scale platform context\"],\"gaps\":[\"No explicit rate limiting, API throttling, or backpressure handling experience documented for high-scale scenarios\"],\"explanation\":\"This candidate is a high-confidence match for a senior NestJS microservices role at scale, covering every named technology with precision. The Kafka and Event-Driven architecture combination is particularly strong for order processing workflows. ArgoCD alongside Kubernetes signals GitOps deployment maturity beyond the baseline Docker/Kubernetes requirement. The only gap is undocumented high-scale reliability patterns, which is worth exploring in an interview.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"power_bi_analyst\",\"seniority\":\"Mid\",\"roles\":[\"Data Analyst\"],\"languages\":[\"SQL\",\"DAX\"],\"tech\":[\"Power BI\",\"Excel\",\"Power Query\"]}\n\nJob Summary:\nGlobal retail company hiring a senior data engineer to build ETL pipelines in Python, manage Snowflake warehouse operations, and orchestrate workflows with Apache Airflow. dbt for data modeling. Strong Python and SQL required. Familiarity with cloud platforms (AWS or Azure) and containerization with Docker is expected.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"SQL expertise is foundational and partially transferable\"],\"gaps\":[\"Mid-level seniority is below the senior data engineer requirement\",\"No Python experience — required for ETL pipeline development\",\"No Snowflake experience — the team's warehouse\",\"No Airflow or pipeline orchestration experience\",\"No dbt experience\",\"No Docker or containerization experience\",\"No cloud platform (AWS or Azure) experience\",\"Profile is BI reporting focused, not data engineering focused\"],\"explanation\":\"This candidate is a business intelligence analyst, not a data engineer. The toolset (Power BI, DAX, Excel) is oriented toward reporting consumption rather than pipeline construction and warehouse management. The role requires a fundamentally different skill set including Python, Snowflake, Airflow, and Docker, none of which are present. This is a mismatch of role type rather than just tooling.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"swift_ios_mid\",\"seniority\":\"Mid\",\"roles\":[\"iOS Engineer\"],\"languages\":[\"Swift\",\"Objective-C\"],\"tech\":[\"SwiftUI\",\"UIKit\",\"Combine\",\"CoreData\"],\"databases\":[\"CoreData\",\"SQLite\"],\"ci_cd\":[\"Fastlane\",\"GitHub Actions\"],\"testing\":[\"XCTest\",\"XCUITest\"]}\n\nJob Summary:\nMedia streaming company hiring a mid-level iOS engineer to build and maintain features in SwiftUI using Combine for reactive state. The candidate should be comfortable with CoreData for local persistence, UIKit for legacy views, and Fastlane for CI/CD automation. XCTest and XCUITest for testing. Experience with video playback APIs (AVFoundation) is a strong plus.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"SwiftUI and Combine directly match the stated reactive development pattern\",\"CoreData and UIKit satisfy the persistence and legacy view requirements\",\"Fastlane and GitHub Actions cover the CI/CD automation expectation\",\"XCTest and XCUITest are exact matches for the testing tools\",\"Mid-level seniority is a direct match\"],\"gaps\":[\"No AVFoundation or video playback API experience — the strong-plus criterion for a media streaming context\",\"No network streaming or HLS experience documented\"],\"explanation\":\"The candidate matches every explicit technical requirement in the job description across SwiftUI, Combine, CoreData, Fastlane, and testing tools. The only notable gap is AVFoundation experience, which is listed as a strong plus and is particularly meaningful given this is a media streaming product. The candidate would be productive from day one on feature work but would need to ramp up on video playback specifics.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"infra_as_code_junior\",\"seniority\":\"Junior\",\"roles\":[\"DevOps Engineer\"],\"languages\":[\"Bash\",\"Python\"],\"tech\":[\"Terraform\",\"Docker\",\"AWS\",\"GitHub Actions\"],\"ci_cd\":[\"GitHub Actions\"]}\n\nJob Summary:\nStartup looking for a junior DevOps engineer to assist with Terraform-based IaC, manage Docker environments, and help maintain GitHub Actions pipelines. AWS is the cloud. No Kubernetes required. Python or Bash for scripting. Mentorship provided. Strong learning mindset valued over deep experience.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Terraform directly satisfies the IaC requirement\",\"Docker covers the container environment management expectation\",\"GitHub Actions satisfies the CI/CD pipeline requirement\",\"AWS aligns with the cloud environment\",\"Bash and Python provide scripting capability as stated\",\"Junior seniority is an exact match for a role that explicitly provides mentorship\"],\"gaps\":[\"No observability or monitoring tooling experience documented\"],\"explanation\":\"This candidate's profile is a direct match for a junior DevOps role that explicitly prioritizes learning over experience depth. Every named technology — Terraform, Docker, GitHub Actions, and AWS — is present, and the seniority is exactly right for a mentored onboarding context. The only gap is the absence of monitoring or observability tooling, which is a reasonable area to grow into with mentorship.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"elixir_phoenix_dev\",\"seniority\":\"Mid\",\"roles\":[\"Backend Engineer\"],\"languages\":[\"Elixir\",\"JavaScript\"],\"tech\":[\"Phoenix\",\"LiveView\",\"Docker\",\"PostgreSQL\"],\"databases\":[\"PostgreSQL\",\"Redis\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"ExUnit\"]}\n\nJob Summary:\nReal-time collaboration tool startup building with Elixir and Phoenix LiveView. Looking for a mid-level backend engineer comfortable with Elixir, Phoenix channels for WebSocket communication, and PostgreSQL. LiveView for interactive UI. Docker for containerization. ExUnit for testing. Redis for pub/sub.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Elixir and Phoenix are the primary stack and both are listed\",\"LiveView directly satisfies the interactive UI requirement\",\"PostgreSQL and Redis cover persistence and pub/sub expectations\",\"ExUnit satisfies the testing requirement\",\"Docker supports the containerization context\",\"Mid-level seniority aligns with the role level\"],\"gaps\":[\"No explicit Phoenix Channels or WebSocket experience documented separately from LiveView\"],\"explanation\":\"This candidate is a strong and rare match for an Elixir/Phoenix LiveView role, which requires a niche and specific stack. The combination of LiveView, PostgreSQL, Redis, and ExUnit covers every stated requirement. The only minor ambiguity is whether Phoenix Channels for WebSocket communication is part of the candidate's experience alongside LiveView, which is worth confirming in an interview.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"hadoop_legacy_de\",\"seniority\":\"Senior\",\"roles\":[\"Data Engineer\"],\"languages\":[\"Java\",\"Python\",\"SQL\"],\"tech\":[\"Hadoop\",\"Hive\",\"Apache Spark\",\"Sqoop\",\"Docker\"],\"architecture\":[\"Distributed System\"],\"databases\":[\"HDFS\",\"MySQL\",\"Cassandra\"]}\n\nJob Summary:\nCloud-first data platform startup building real-time analytics pipelines on AWS. We use Kafka, AWS Glue, and Athena. dbt for transformations, Airflow for orchestration, and Redshift as the warehouse. Python and SQL are the primary languages. We are not using any Hadoop or on-premise infrastructure.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Spark and distributed system experience provides general big data engineering background\",\"Python and SQL are transferable to the new stack\"],\"gaps\":[\"No Kafka experience for real-time ingestion\",\"No AWS Glue or Athena experience\",\"No dbt experience for transformations\",\"No Airflow experience for orchestration\",\"No Redshift experience — only HDFS and on-premise warehouses\",\"Stack is entirely Hadoop-era on-premise tooling, which the role explicitly excludes\"],\"explanation\":\"The candidate has legitimate large-scale data engineering experience, but the entire technology foundation is anchored in an on-premise Hadoop ecosystem that the startup has explicitly moved away from. While Python and SQL are transferable, every specific tool in the job description — Kafka, Glue, Athena, dbt, Airflow, and Redshift — is absent from the profile. A significant cloud migration and tooling transition would be required.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"nextauth_saas_dev\",\"seniority\":\"Mid\",\"roles\":[\"Full Stack Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Next.js\",\"NextAuth.js\",\"Prisma\",\"Tailwind CSS\",\"Stripe\"],\"databases\":[\"PostgreSQL\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"Vitest\",\"Playwright\"]}\n\nJob Summary:\nBootstrapped SaaS company building a multi-tenant subscription product. We use Next.js with NextAuth for authentication, Prisma with PostgreSQL, Tailwind for UI, and Stripe for billing. Mid-level engineer expected to own end-to-end features. Vitest for unit tests and Playwright for E2E. GitHub Actions for CI.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js is the framework and is listed first\",\"NextAuth.js directly satisfies the authentication requirement\",\"Prisma and PostgreSQL cover the data access stack\",\"Stripe addresses the billing integration expectation\",\"Tailwind CSS satisfies the UI styling requirement\",\"Vitest and Playwright are exact matches for the testing tools\"],\"gaps\":[\"No explicit multi-tenant architecture patterns documented\"],\"explanation\":\"This candidate's profile is a precise match for every named technology in the job description. The NextAuth.js inclusion in particular is a strong differentiating signal given its role as the authentication layer. The combination of Stripe and multi-tenant context further reinforces SaaS product experience. The only gap is the absence of explicit multi-tenant architecture documentation, which is worth exploring given the product's design.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"backend_sparse_go\",\"seniority\":\"Junior\",\"languages\":[\"Go\"],\"tech\":[\"Docker\"]}\n\nJob Summary:\nInfrastructure tooling startup looking for a junior backend engineer who knows Go and is eager to learn. The team builds internal CLIs and APIs. Familiarity with Docker for local dev is expected. REST API basics in Go are a plus. We provide mentorship and have a strong learning culture. Kubernetes and cloud experience not required.",
    "output": "{\"verdict\":\"Moderate\",\"strengths\":[\"Go is the primary language and is present\",\"Docker satisfies the local dev containerization expectation\",\"Junior seniority aligns with the role level and mentorship model\"],\"gaps\":[\"No REST API or HTTP framework experience in Go documented (Gin, Echo, or net/http)\",\"No testing habits or framework visible\",\"Very sparse profile makes it difficult to assess initiative or project depth\",\"No CLI tooling experience documented\"],\"explanation\":\"The candidate has the right foundational Go and Docker signals for a junior role that values learning over experience. However, the extremely sparse profile makes it hard to evaluate initiative, project depth, or REST API basics — all of which the role asks about. This is a plausible match given the startup's stated mentorship culture, but the profile provides insufficient signal for confident assessment.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"angular_enterprise\",\"seniority\":\"Senior\",\"roles\":[\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\"],\"tech\":[\"Angular\",\"NgRx\",\"RxJS\",\"Webpack\",\"Karma\"],\"architecture\":[\"Microservices\",\"Modular Architecture\"],\"databases\":[\"PostgreSQL\"],\"ci_cd\":[\"Azure DevOps\"],\"testing\":[\"Jasmine\",\"Protractor\"]}\n\nJob Summary:\nLarge enterprise software company maintaining and extending a long-running Angular application. The candidate should be experienced with Angular and NgRx for state management, RxJS for reactive patterns, and have worked on modular Angular architecture at scale. Azure DevOps for CI/CD. TypeScript throughout. Jasmine and Karma for unit testing.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Angular is the primary framework and is listed first\",\"NgRx directly satisfies the state management requirement\",\"RxJS covers the reactive patterns expectation\",\"Modular Architecture experience aligns with the large-scale Angular design context\",\"Azure DevOps satisfies the CI/CD requirement\",\"Jasmine and Karma are the exact testing tools named in the role\"],\"gaps\":[\"Webpack and Karma are legacy tooling — the team may be moving toward Angular CLI defaults or esbuild-based builds\"],\"explanation\":\"This candidate is an exact match for a long-running enterprise Angular application, with NgRx, RxJS, Jasmine, Karma, and Azure DevOps all present. The Modular Architecture experience is particularly relevant for large-scale Angular codebase maintenance. The Webpack and Protractor signals suggest a slightly older Angular profile, but Jasmine and Karma alignment means the testing layer is current.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"ai_chatbot_builder\",\"seniority\":\"Mid\",\"roles\":[\"AI Engineer\",\"Backend Engineer\"],\"languages\":[\"Python\",\"TypeScript\"],\"tech\":[\"LangChain\",\"OpenAI API\",\"FastAPI\",\"Docker\",\"Pinecone\"],\"architecture\":[\"RAG\",\"REST\"],\"databases\":[\"PostgreSQL\",\"Pinecone\"],\"ci_cd\":[\"GitHub Actions\"],\"testing\":[\"pytest\"]}\n\nJob Summary:\nCustomer support AI startup building a chatbot platform backed by a RAG pipeline. We use LangChain, OpenAI API, and Pinecone for vector search. FastAPI for the backend API layer. Python is primary. We expect engineers to write pytest-covered code and deploy on Docker. Mid-level seniority preferred.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"LangChain and OpenAI API are the orchestration and model provider tools and both are present\",\"Pinecone satisfies the vector search requirement\",\"RAG architecture is the primary pattern and is listed first\",\"FastAPI covers the backend API expectation\",\"pytest and Docker align with the testing and deployment standards\",\"Mid-level seniority is an exact match\"],\"gaps\":[\"No streaming response or chat memory management experience explicitly documented\"],\"explanation\":\"This candidate is a direct match for the RAG-based chatbot platform role, with LangChain, OpenAI API, Pinecone, and FastAPI all present as a cohesive LLM application stack. The pytest coverage and Docker deployment alignment shows production readiness. The only gap worth probing is experience with streaming LLM responses and conversational memory, which are common requirements in customer support chatbot products.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"net_devops_intern\",\"seniority\":\"Intern\",\"languages\":[\"Python\",\"Bash\"],\"tech\":[\"Docker\",\"Linux\"]}\n\nJob Summary:\nCybersecurity firm seeking a senior security engineer with deep penetration testing experience, familiarity with SIEM platforms (Splunk or equivalent), and ability to write custom exploit tooling in Python or Go. Kubernetes hardening and cloud security posture management on AWS are required. OSCP or equivalent certification preferred.",
    "output": "{\"verdict\":\"Weak\",\"strengths\":[\"Python is transferable to security scripting in the future\"],\"gaps\":[\"Intern seniority is far below the senior security engineer requirement\",\"No penetration testing or offensive security experience\",\"No SIEM platform experience (Splunk or equivalent)\",\"No Kubernetes hardening experience\",\"No AWS cloud security experience\",\"No exploit development or security research tooling documented\",\"Linux knowledge is a baseline and insufficient on its own\"],\"explanation\":\"This candidate is at the very beginning of a technology career and has no demonstrated security domain experience. The role requires senior-level penetration testing expertise, SIEM operations, Kubernetes hardening, and cloud security management — none of which appear in the profile. There is no meaningful overlap between an intern's foundational Docker and Python skills and the advanced security engineering requirements of this position.\"}"
  },
  {
    "instruction": "Evaluate the candidate's fit for the job and respond with a JSON object containing verdict, strengths, gaps, and explanation.",
    "input": "Candidate Profile:\n{\"username\":\"react_ssr_fullstack\",\"seniority\":\"Senior\",\"roles\":[\"Full Stack Engineer\",\"Frontend Engineer\"],\"languages\":[\"TypeScript\",\"JavaScript\",\"Python\"],\"tech\":[\"Next.js\",\"React\",\"FastAPI\",\"Docker\",\"AWS\",\"Tailwind CSS\",\"TanStack Query\"],\"architecture\":[\"REST\",\"Microservices\"],\"databases\":[\"PostgreSQL\",\"Redis\",\"Supabase\"],\"ci_cd\":[\"GitHub Actions\",\"Vercel\"],\"testing\":[\"Vitest\",\"Playwright\",\"pytest\"]}\n\nJob Summary:\nProduct startup building a B2B SaaS tool with a Next.js frontend and FastAPI backend. Looking for a senior full stack engineer comfortable owning features across both layers. TypeScript and Python required. Tailwind for styling, TanStack Query for server state, PostgreSQL as the database. Automated testing expected. AWS and Vercel for deployment.",
    "output": "{\"verdict\":\"Strong\",\"strengths\":[\"Next.js and FastAPI cover both the frontend and backend framework requirements\",\"TypeScript and Python satisfy the dual language requirement\",\"Tailwind CSS and TanStack Query are both explicitly present\",\"PostgreSQL satisfies the database requirement\",\"Vitest, Playwright, and pytest provide comprehensive testing coverage across frontend and backend\",\"Vercel and AWS satisfy the deployment environment expectations\"],\"gaps\":[\"No explicit authentication or multi-tenancy implementation experience documented for a B2B context\"],\"explanation\":\"This candidate is a comprehensive match for a full stack role requiring both Next.js and FastAPI, with TypeScript and Python breadth across the stack. The TanStack Query and Tailwind specifics are precise alignments, and the three-testing-tool profile signals mature quality practices. The only gap is the absence of B2B-specific patterns like authentication, SSO, or multi-tenancy, which are common requirements in B2B SaaS products.\"}"
  }
]